{
  ".": {
    "bundles": {
      "/lib/loader.js": {
        "modules": {
          "/lib/loader.js": {
            "requireId": "/lib/loader",
            "memoizeId": "/lib/loader.js",
            "descriptor": {
              "filename": "loader.js",
              "filepath": "lib/loader.js",
              "mtime": 1379828059,
              "code": "\nconst ASSERT = require(\"assert\");\nconst PATH = require(\"path\");\nconst FS = require(\"fs-extra\");\nconst HTTP = require(\"http\");\nconst HTTPS = require(\"https\");\nconst VM = require(\"vm\");\nconst REQUEST = require(\"request\");\nconst LOADER = require(\"pinf-loader-js/loader\");\n\n\nexports.sandbox = function(sandboxIdentifier, sandboxOptions, loadedCallback, errorCallback) {\n\n\tif (!sandboxIdentifier) {\n\t\tif (errorCallback) return errorCallback(new Error(\"'sandboxIdentifier' not specified\"));\n\t\tthrow new Error(\"'sandboxIdentifier' not specified\");\n\t}\n\n\tif (typeof sandboxOptions === \"function\" && typeof loadedCallback === \"function\" && typeof errorCallback === \"undefined\") {\n\t\terrorCallback = loadedCallback;\n\t\tloadedCallback = sandboxOptions;\n\t\tsandboxOptions = {};\n\t} else\n\tif (typeof sandboxOptions === \"function\" && typeof loadedCallback === \"undefined\") {\n\t\tloadedCallback = sandboxOptions;\n\t\tsandboxOptions = {};\n\t} else {\n\t\tsandboxOptions = sandboxOptions || {};\n\t}\n\n\tvar options = {};\n\n\tfor (var key in sandboxOptions) {\n\t\toptions[key] = sandboxOptions[key];\n\t}\n\n\tdelete options.globals;\n\n\tsandboxOptions._realpath = function(path) {\n\t\tif (!sandboxOptions.rootPath) return path;\n\t\tif (/^\\/|:\\/\\//.test(path)) return path;\n\t\treturn PATH.join(sandboxOptions.rootPath, path);\n\t}\n\n\t// Set our own loader for the sandbox.\n\toptions.load = function(uri, loadedCallback) {\t\t\n\t\tfunction loadCode(uri, callback) {\n            if (/:\\/\\//.test(uri)) {\n                return REQUEST(uri, function(err, result) {\n                \tif (err) return callback(err);\n                \treturn callback(null, result.body);\n                });\n            } else {\n                return FS.readFile(sandboxOptions._realpath(uri), \"utf8\", callback);\n            }\n        }\n        return loadCode(uri, function(err, code) {\n\t\t\tif (err) {\n\t\t\t\tconsole.error(\"Error reading file: \" + sandboxOptions._realpath(uri));\n\t\t\t\treturn loadedCallback(err);\n\t\t\t}\n\t\t\ttry {\n\t\t    \tevalBundle(sandboxOptions._realpath(uri), code);\n\t\t        return loadedCallback(null);\n\t\t    } catch(err) {\n\t\t        return loadedCallback(err);\n\t\t    }\n        });\n\t}\n\n\tfunction evalBundle(uri, code) {\n    \t// NOTE: If there are sytnax errors in code this will print\n    \t//\t\t error to stdout (if fourth argument set to `true`).\n    \t//\t\t There is no way to capture errors from here.\n    \t// @see https://github.com/joyent/node/issues/1307#issuecomment-1551157\n    \t// TODO: Find a better solution to handle errors here.\n    \t// TODO: Capture errors by watching this processe's stdout file log from\n    \t//\t\t another process.\n    \tvar globals = {\n\t\t    // TODO: Inject and fix environment based on options.\n        \tPINF: LOADER,\n        \t// TODO: Wrap to `console` object provided by `sandboxOptions` and inject module info.\n        \tconsole: console,\n        \t// NodeJS globals.\n        \t// @see http://nodejs.org/docs/latest/api/globals.html\n        \tglobal: global,\n        \tprocess: process,\n        \tBuffer: Buffer,\n        \tsetTimeout: setTimeout,\n        \tclearTimeout: clearTimeout,\n        \tsetInterval: setInterval,\n        \tclearInterval: clearInterval,\n        \tsetImmediate: setImmediate,\n        \t// Browser\n        \tnavigator: {}\n    \t};\n    \tif (sandboxOptions.globals) {\n    \t\tfor (var name in sandboxOptions.globals) {\n    \t\t\tglobals[name] = sandboxOptions.globals[name];\n    \t\t}\n    \t}\n        VM.runInNewContext(code, globals, uri, true);\n\t}\n\n\tfunction loadResolvedDynamicSync(uri, bundleIdentifier, options) {\n\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs] loadResolveDynamicSync\", \"uri\", uri, \"bundleIdentifier\", bundleIdentifier);\n\n\t\t// Load the bundle SYNCHRONOUSLY as new modules must be available before we return.\n\t\tvar code = null;\n\t\ttry {\n\t\t\tcode = FS.readFileSync(sandboxOptions._realpath(uri), \"utf8\");\n\t\t} catch(err) {\n\t\t\tconsole.error(\"Error reading file: \" + sandboxOptions._realpath(uri));\n\t\t\tthrow err;\n\t\t}\n\t\tevalBundle(uri, code);\n\n\t\t// Activate the new modules from the bundle.\n\t\treturn options.finalizeLoad(bundleIdentifier);\n\t}\n\n\tfunction getBundleBasePath(moduleObj) {\n\n\t\tASSERT.equal(typeof moduleObj.bundle, \"string\");\n\n\t\treturn moduleObj.bundle.replace(/\\.js$/, \"\");\n\t}\n\n\tvar lastModuleRequireContext = null;\n\n\toptions.onInitModule = function(moduleInterface, moduleObj, pkg, sandbox, options) {\n\t\tif (typeof sandboxOptions.onInitModule === \"function\") {\n\t\t\tsandboxOptions.onInitModule(moduleInterface, moduleObj);\n\t\t}\n\n\t\tmoduleInterface.filename = sandboxOptions._realpath(moduleInterface.filename);\n\n\t\tvar origRequire = moduleObj.require;\n\n\t\tmoduleObj.require = function(identifier) {\n\n\t\t\tlastModuleRequireContext = {\n\t\t\t\tmoduleObj: moduleObj\n\t\t\t};\n\n\t\t\tif (/^\\./.test(identifier)) {\n\n\t\t\t\tvar moduleIdentifier = PATH.normalize(options.resolveIdentifier(identifier)[1]).replace(/^[\\/\\.]$/, \"\");\n\n\t            if (moduleIdentifier) {\n\t            \tif (!/^\\//.test(moduleIdentifier)) {\n\t\t                moduleIdentifier = \"/\" + options.libPath + moduleIdentifier;\n\t\t            }\n\t\t\t\t\tvar canonicalId = pkg.id + moduleIdentifier;\n\t            } else {\n\t            \tmoduleIdentifier = pkg.main;\n\t\t\t\t\tvar canonicalId = moduleIdentifier;\n\t            }\n\n\t\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t}\n\n\t\t\t\tif (options.initializedModules[canonicalId.replace(/\\.js$/, \"/index.js\")] || options.moduleInitializers[canonicalId.replace(/\\.js$/, \"/index.js\")]) {\n\t\t\t\t\treturn origRequire(identifier + \"/index\");\n\t\t\t\t}\n\n\t\t\t\t// We encountered a dynamic sync require.\n\n\t\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][moduleObj.require] relative\", \"identifier\", identifier, \"pkg.id\", pkg.id, \"moduleIdentifier\", moduleIdentifier, \"canonicalId\", canonicalId);\n\n\t\t\t\tvar bundleBasePath = getBundleBasePath(moduleObj);\n\n\t\t\t\tvar uri = null;\n\n\t\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t\t// We have a runtime bundler.\n\t\t\t\t\turi = sandboxOptions.resolveDynamicSync(moduleObj, pkg, sandbox, canonicalId, options);\n\t\t\t\t} else {\n//\t\t\t\t\turi = PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\").replace(/\\//g, \"+\"));\n\t\t\t\t\turi = PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\"));\n\t\t\t\t}\n\n//\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\").replace(/\\//g, \"+\")), options);\n\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\")), options);\n\n\t\t\t\t// Now let the loader continue.\n\t\t\t\treturn origRequire(identifier);\n\n\t\t\t} else {\n\n\t\t\t\tvar splitIdentifier = identifier.split(\"/\");\n\n\t\t\t\tif (typeof pkg.mappings[splitIdentifier[0]] !== \"undefined\") return origRequire(identifier);\n\n\t\t\t\ttry {\n\t\t\t\t\tvar canonicalId = options.resolveIdentifier(identifier)[1];\n\n\t\t\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t\t}\n\t\t\t\t} catch(err) {\n\t\t\t\t\t// We get here when running `pinf-it-bundler` tests.\n\t\t\t\t}\n\n\t\t\t\t// Check if we are delaing with a native nodejs module.\n\t\t\t\t// TODO: Use a better flag than '__' to indicate that module should be loaded here! Use proper versioned uri.\n\t\t\t\tif (splitIdentifier[0] === \"__SYSTEM__\") {\n\t\t\t\t\treturn require(splitIdentifier.slice(1).join(\"/\"));\n\t\t\t\t}\n\t\t\t\t// HACK: We catch any module IDs that were not re-written in the hope that we catch any system modules.\n\t\t\t\t// This happens when wrapping r.js for example which tests for nodejs and requires system modules.\n\t\t\t\t// These system module requires should be rewritten by now.\n\t\t\t\t// TODO: Set in config file how to resolve these system modules.\n\t\t\t\ttry {\n\t\t\t\t\tif (require.resolve(identifier) === identifier) {\n\t\t\t\t\t\treturn require(identifier);\n\t\t\t\t\t}\n\t\t\t\t} catch(err) {}\t\t\n\n\t\t\t\t// We encountered a dynamic sync require.\n\n\t\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][moduleObj.require] absolute\", \"identifier\", identifier, \"pkg.id\", pkg.id);\n\n\t\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t\t// We have a runtime bundler.\n\n\t\t\t\t\tvar uri = sandboxOptions.resolveDynamicSync(moduleObj, pkg, sandbox, identifier, options);\n\n\t\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(moduleObj.bundle.replace(/\\.js$/, \"\"), identifier), options);\n\n\t\t\t\t\t// Now let the loader continue.\n\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// HACK: We catch any module IDs that were not re-written in the hope that we catch any system modules.\n\t\t\t// TODO: Set in config file how to resolve these system modules.\n\t\t\ttry {\n\t\t\t\tif (require.resolve(identifier) === identifier) {\n\t\t\t\t\treturn require(identifier);\n\t\t\t\t}\n\t\t\t} catch(err) {}\n\n\t\t\tthrow new Error(\"Could not find module '\" + identifier + \"'\");\n\n/*\n\t\t\t// We assume we have a 'dynamic sync require' (`require(<id>)`) vs a 'static sync require' (`require(\"<id>\")`) as module\n\t\t\t// should already be in bundle in the latter case. If we do have a 'static sync require'\n\t\t\t// and module is not in bundle, the bundler should use `async require` (`require.async(<id>, callback)`).\n\t\t\tthrow new Error(\"Could not resolve dynamic sync require for '\" + identifier + \"'\");\n*/\n\t\t}\n\n\t\tfor (var property in origRequire) {\n\t\t\tmoduleObj.require[property] = origRequire[property];\n\t\t}\n\n\t\t// @see http://nodejs.org/docs/latest/api/globals.html\n\t\tmoduleObj.require.resolve = function() {\n\t\t\treturn origRequire.id.apply(null, arguments);\n\t\t}\n\n\t\tmoduleObj.require.async = function(id, successCallback, errorCallback) {\n\t\t\tif (sandboxOptions.ensureAsync) {\n\t\t\t\treturn sandboxOptions.ensureAsync(moduleObj, pkg, sandbox, id, options, function(err) {\n\t\t\t\t\tif (err) return errorCallback(err);\n\t\t\t\t\treturn origRequire.async(id, successCallback, errorCallback);\n\t\t\t\t});\n\t\t\t}\n\t\t\treturn origRequire.async(id, successCallback, errorCallback);\n\t\t}\n\t};\n\n\toptions.onInitPackage = function(pkg, sandbox, options) {\n\t\tvar origRequire = pkg.require;\n\t\t\n\t\tpkg.require = function(moduleIdentifier) {\n\t\t\tvar origModuleIdentifier = PATH.normalize(moduleIdentifier).replace(/^\\.$/, \"\").replace(/^\\/$/, \"\");\n\t\t\tvar canonicalId = null;\n\t\t\tif (origModuleIdentifier) {\n\t\t\t\tmoduleIdentifier = origModuleIdentifier;\n            \tif (!/^\\//.test(moduleIdentifier)) {\n\t                moduleIdentifier = \"/\" + ((moduleIdentifier.substring(0, pkg.libPath.length)===pkg.libPath)?\"\":pkg.libPath) + moduleIdentifier;\n\t            }\n\t\t\t\tcanonicalId = pkg.id + moduleIdentifier;\n\t\t\t} else\n\t\t\tif (pkg.descriptor && pkg.descriptor.main) {\n\t\t\t\tcanonicalId = moduleIdentifier = pkg.descriptor.main;\n\t\t\t} else {\n\t\t\t\tmoduleIdentifier = \"\";\n\t\t\t\tcanonicalId = pkg.id;\n\t\t\t}\n\n\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\treturn origRequire(origModuleIdentifier);\n\t\t\t}\n\n\t\t\t// If `canonicalId` is just an alias we assume that the main module is memoized\n\t\t\t// if the package descriptor for the alias is memoized.\n\n\t\t\tif (!/\\//.test(canonicalId)) {\n\t\t\t\tif (options.initializedModules[canonicalId + \"/package.json\"] || options.moduleInitializers[canonicalId + \"/package.json\"]) {\n\t\t\t\t\treturn origRequire(origModuleIdentifier);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// We encountered a dynamic sync require.\n\n\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][pkg.require]\", \"moduleIdentifier\", moduleIdentifier, \"pkg.id\", pkg.id, \"canonicalId\", canonicalId);\n\n\t\t\tvar bundleBasePath = getBundleBasePath(lastModuleRequireContext.moduleObj);\n\n\t\t\tvar uri = null;\n\n\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t// We have a runtime bundler.\n\n\t\t\t\tvar opts = {};\n\t\t\t\tfor (var name in options) {\n\t\t\t\t\topts[name] = options[name];\n\t\t\t\t}\n\t\t\t\topts.lastModuleRequireContext = lastModuleRequireContext;\n\n\t\t\t\turi = sandboxOptions.resolveDynamicSync(null, pkg, sandbox, canonicalId, opts);\n\t\t\t} else {\n\n\t\t\t\t// We assume that `canonicalId` is a package ID (not an alias) as the package mapping should\n\t\t\t\t// already be loaded if requiring a dependency by alias using pure bundles (without runtime bundler).\n\n\t\t\t\tvar canonicalIdParts = canonicalId.split(\"/\");\n\t\t\t\tvar packageId = canonicalIdParts.shift();\n\t\t\t\tvar moduleId = canonicalIdParts.join(\"/\");\n//\t\t\t\turi = PATH.join(bundleBasePath, options.normalizeIdentifier((packageId + ((moduleId) ? \"/\" + moduleId : \"\")).replace(/\\//g, \"+\")));\n\t\t\t\turi = PATH.join(bundleBasePath, options.normalizeIdentifier(packageId + ((moduleId) ? \"/\" + moduleId : \"\")));\n\t\t\t}\n\n//\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/\\//g, \"+\")), options);\n\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId), options);\n\n\t\t\t// Now let the loader continue.\n\t\t\treturn origRequire(origModuleIdentifier);\n/*\n\t\t\t// We assume we have a 'dynamic sync require' (`require(<id>)`) vs a 'static sync require' (`require(\"<id>\")`) as module\n\t\t\t// should already be in bundle in the latter case. If we do have a 'static sync require'\n\t\t\t// and module is not in bundle, the bundler should use `async require` (`require.async(<id>, callback)`).\n\t\t\tthrow new Error(\"Could not resolve dynamic sync require for '\" + origModuleIdentifier + \"'\");\n*/\n\t\t};\n\n\t\tfor (var property in origRequire) {\n\t\t\tpkg.require[property] = origRequire[property];\n\t\t}\n\t}\n\n\treturn LOADER.sandbox(sandboxIdentifier, options, loadedCallback, errorCallback);\n}\n\nexports.getReport = LOADER.getReport;\n\nexports.reset = LOADER.reset;\n",
              "globals": {
                "ASSERT": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "PATH": {
                  "type": "assign"
                },
                "FS": {
                  "type": "assign"
                },
                "HTTP": {
                  "type": "assign"
                },
                "HTTPS": {
                  "type": "assign"
                },
                "VM": {
                  "type": "assign"
                },
                "REQUEST": {
                  "type": "assign"
                },
                "LOADER": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  },
                  "fs-extra": {
                    "where": "inline"
                  },
                  "http": {
                    "where": "inline"
                  },
                  "https": {
                    "where": "inline"
                  },
                  "vm": {
                    "where": "inline"
                  },
                  "request": {
                    "where": "inline"
                  },
                  "pinf-loader-js/loader": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'lib';",
              "code": "function(require, exports, module) {var __dirname = 'lib';\n\nconst ASSERT = require(\"__SYSTEM__/assert\");\nconst PATH = require(\"__SYSTEM__/path\");\nconst FS = require(\"fs-extra\");\nconst HTTP = require(\"__SYSTEM__/http\");\nconst HTTPS = require(\"__SYSTEM__/https\");\nconst VM = require(\"__SYSTEM__/vm\");\nconst REQUEST = require(\"request\");\nconst LOADER = require(\"pinf-loader-js/loader\");\n\n\nexports.sandbox = function(sandboxIdentifier, sandboxOptions, loadedCallback, errorCallback) {\n\n\tif (!sandboxIdentifier) {\n\t\tif (errorCallback) return errorCallback(new Error(\"'sandboxIdentifier' not specified\"));\n\t\tthrow new Error(\"'sandboxIdentifier' not specified\");\n\t}\n\n\tif (typeof sandboxOptions === \"function\" && typeof loadedCallback === \"function\" && typeof errorCallback === \"undefined\") {\n\t\terrorCallback = loadedCallback;\n\t\tloadedCallback = sandboxOptions;\n\t\tsandboxOptions = {};\n\t} else\n\tif (typeof sandboxOptions === \"function\" && typeof loadedCallback === \"undefined\") {\n\t\tloadedCallback = sandboxOptions;\n\t\tsandboxOptions = {};\n\t} else {\n\t\tsandboxOptions = sandboxOptions || {};\n\t}\n\n\tvar options = {};\n\n\tfor (var key in sandboxOptions) {\n\t\toptions[key] = sandboxOptions[key];\n\t}\n\n\tdelete options.globals;\n\n\tsandboxOptions._realpath = function(path) {\n\t\tif (!sandboxOptions.rootPath) return path;\n\t\tif (/^\\/|:\\/\\//.test(path)) return path;\n\t\treturn PATH.join(sandboxOptions.rootPath, path);\n\t}\n\n\t// Set our own loader for the sandbox.\n\toptions.load = function(uri, loadedCallback) {\t\t\n\t\tfunction loadCode(uri, callback) {\n            if (/:\\/\\//.test(uri)) {\n                return REQUEST(uri, function(err, result) {\n                \tif (err) return callback(err);\n                \treturn callback(null, result.body);\n                });\n            } else {\n                return FS.readFile(sandboxOptions._realpath(uri), \"utf8\", callback);\n            }\n        }\n        return loadCode(uri, function(err, code) {\n\t\t\tif (err) {\n\t\t\t\tconsole.error(\"Error reading file: \" + sandboxOptions._realpath(uri));\n\t\t\t\treturn loadedCallback(err);\n\t\t\t}\n\t\t\ttry {\n\t\t    \tevalBundle(sandboxOptions._realpath(uri), code);\n\t\t        return loadedCallback(null);\n\t\t    } catch(err) {\n\t\t        return loadedCallback(err);\n\t\t    }\n        });\n\t}\n\n\tfunction evalBundle(uri, code) {\n    \t// NOTE: If there are sytnax errors in code this will print\n    \t//\t\t error to stdout (if fourth argument set to `true`).\n    \t//\t\t There is no way to capture errors from here.\n    \t// @see https://github.com/joyent/node/issues/1307#issuecomment-1551157\n    \t// TODO: Find a better solution to handle errors here.\n    \t// TODO: Capture errors by watching this processe's stdout file log from\n    \t//\t\t another process.\n    \tvar globals = {\n\t\t    // TODO: Inject and fix environment based on options.\n        \tPINF: LOADER,\n        \t// TODO: Wrap to `console` object provided by `sandboxOptions` and inject module info.\n        \tconsole: console,\n        \t// NodeJS globals.\n        \t// @see http://nodejs.org/docs/latest/api/globals.html\n        \tglobal: global,\n        \tprocess: process,\n        \tBuffer: Buffer,\n        \tsetTimeout: setTimeout,\n        \tclearTimeout: clearTimeout,\n        \tsetInterval: setInterval,\n        \tclearInterval: clearInterval,\n        \tsetImmediate: setImmediate,\n        \t// Browser\n        \tnavigator: {}\n    \t};\n    \tif (sandboxOptions.globals) {\n    \t\tfor (var name in sandboxOptions.globals) {\n    \t\t\tglobals[name] = sandboxOptions.globals[name];\n    \t\t}\n    \t}\n        VM.runInNewContext(code, globals, uri, true);\n\t}\n\n\tfunction loadResolvedDynamicSync(uri, bundleIdentifier, options) {\n\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs] loadResolveDynamicSync\", \"uri\", uri, \"bundleIdentifier\", bundleIdentifier);\n\n\t\t// Load the bundle SYNCHRONOUSLY as new modules must be available before we return.\n\t\tvar code = null;\n\t\ttry {\n\t\t\tcode = FS.readFileSync(sandboxOptions._realpath(uri), \"utf8\");\n\t\t} catch(err) {\n\t\t\tconsole.error(\"Error reading file: \" + sandboxOptions._realpath(uri));\n\t\t\tthrow err;\n\t\t}\n\t\tevalBundle(uri, code);\n\n\t\t// Activate the new modules from the bundle.\n\t\treturn options.finalizeLoad(bundleIdentifier);\n\t}\n\n\tfunction getBundleBasePath(moduleObj) {\n\n\t\tASSERT.equal(typeof moduleObj.bundle, \"string\");\n\n\t\treturn moduleObj.bundle.replace(/\\.js$/, \"\");\n\t}\n\n\tvar lastModuleRequireContext = null;\n\n\toptions.onInitModule = function(moduleInterface, moduleObj, pkg, sandbox, options) {\n\t\tif (typeof sandboxOptions.onInitModule === \"function\") {\n\t\t\tsandboxOptions.onInitModule(moduleInterface, moduleObj);\n\t\t}\n\n\t\tmoduleInterface.filename = sandboxOptions._realpath(moduleInterface.filename);\n\n\t\tvar origRequire = moduleObj.require;\n\n\t\tmoduleObj.require = function(identifier) {\n\n\t\t\tlastModuleRequireContext = {\n\t\t\t\tmoduleObj: moduleObj\n\t\t\t};\n\n\t\t\tif (/^\\./.test(identifier)) {\n\n\t\t\t\tvar moduleIdentifier = PATH.normalize(options.resolveIdentifier(identifier)[1]).replace(/^[\\/\\.]$/, \"\");\n\n\t            if (moduleIdentifier) {\n\t            \tif (!/^\\//.test(moduleIdentifier)) {\n\t\t                moduleIdentifier = \"/\" + options.libPath + moduleIdentifier;\n\t\t            }\n\t\t\t\t\tvar canonicalId = pkg.id + moduleIdentifier;\n\t            } else {\n\t            \tmoduleIdentifier = pkg.main;\n\t\t\t\t\tvar canonicalId = moduleIdentifier;\n\t            }\n\n\t\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t}\n\n\t\t\t\tif (options.initializedModules[canonicalId.replace(/\\.js$/, \"/index.js\")] || options.moduleInitializers[canonicalId.replace(/\\.js$/, \"/index.js\")]) {\n\t\t\t\t\treturn origRequire(identifier + \"/index\");\n\t\t\t\t}\n\n\t\t\t\t// We encountered a dynamic sync require.\n\n\t\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][moduleObj.require] relative\", \"identifier\", identifier, \"pkg.id\", pkg.id, \"moduleIdentifier\", moduleIdentifier, \"canonicalId\", canonicalId);\n\n\t\t\t\tvar bundleBasePath = getBundleBasePath(moduleObj);\n\n\t\t\t\tvar uri = null;\n\n\t\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t\t// We have a runtime bundler.\n\t\t\t\t\turi = sandboxOptions.resolveDynamicSync(moduleObj, pkg, sandbox, canonicalId, options);\n\t\t\t\t} else {\n//\t\t\t\t\turi = PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\").replace(/\\//g, \"+\"));\n\t\t\t\t\turi = PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\"));\n\t\t\t\t}\n\n//\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\").replace(/\\//g, \"+\")), options);\n\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/^\\//, \"\")), options);\n\n\t\t\t\t// Now let the loader continue.\n\t\t\t\treturn origRequire(identifier);\n\n\t\t\t} else {\n\n\t\t\t\tvar splitIdentifier = identifier.split(\"/\");\n\n\t\t\t\tif (typeof pkg.mappings[splitIdentifier[0]] !== \"undefined\") return origRequire(identifier);\n\n\t\t\t\ttry {\n\t\t\t\t\tvar canonicalId = options.resolveIdentifier(identifier)[1];\n\n\t\t\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t\t}\n\t\t\t\t} catch(err) {\n\t\t\t\t\t// We get here when running `pinf-it-bundler` tests.\n\t\t\t\t}\n\n\t\t\t\t// Check if we are delaing with a native nodejs module.\n\t\t\t\t// TODO: Use a better flag than '__' to indicate that module should be loaded here! Use proper versioned uri.\n\t\t\t\tif (splitIdentifier[0] === \"__SYSTEM__\") {\n\t\t\t\t\treturn require(splitIdentifier.slice(1).join(\"/\"));\n\t\t\t\t}\n\t\t\t\t// HACK: We catch any module IDs that were not re-written in the hope that we catch any system modules.\n\t\t\t\t// This happens when wrapping r.js for example which tests for nodejs and requires system modules.\n\t\t\t\t// These system module requires should be rewritten by now.\n\t\t\t\t// TODO: Set in config file how to resolve these system modules.\n\t\t\t\ttry {\n\t\t\t\t\tif (require.resolve(identifier) === identifier) {\n\t\t\t\t\t\treturn require(identifier);\n\t\t\t\t\t}\n\t\t\t\t} catch(err) {}\t\t\n\n\t\t\t\t// We encountered a dynamic sync require.\n\n\t\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][moduleObj.require] absolute\", \"identifier\", identifier, \"pkg.id\", pkg.id);\n\n\t\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t\t// We have a runtime bundler.\n\n\t\t\t\t\tvar uri = sandboxOptions.resolveDynamicSync(moduleObj, pkg, sandbox, identifier, options);\n\n\t\t\t\t\tloadResolvedDynamicSync(uri, PATH.join(moduleObj.bundle.replace(/\\.js$/, \"\"), identifier), options);\n\n\t\t\t\t\t// Now let the loader continue.\n\t\t\t\t\treturn origRequire(identifier);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// HACK: We catch any module IDs that were not re-written in the hope that we catch any system modules.\n\t\t\t// TODO: Set in config file how to resolve these system modules.\n\t\t\ttry {\n\t\t\t\tif (require.resolve(identifier) === identifier) {\n\t\t\t\t\treturn require(identifier);\n\t\t\t\t}\n\t\t\t} catch(err) {}\n\n\t\t\tthrow new Error(\"Could not find module '\" + identifier + \"'\");\n\n/*\n\t\t\t// We assume we have a 'dynamic sync require' (`require(<id>)`) vs a 'static sync require' (`require(\"<id>\")`) as module\n\t\t\t// should already be in bundle in the latter case. If we do have a 'static sync require'\n\t\t\t// and module is not in bundle, the bundler should use `async require` (`require.async(<id>, callback)`).\n\t\t\tthrow new Error(\"Could not resolve dynamic sync require for '\" + identifier + \"'\");\n*/\n\t\t}\n\n\t\tfor (var property in origRequire) {\n\t\t\tmoduleObj.require[property] = origRequire[property];\n\t\t}\n\n\t\t// @see http://nodejs.org/docs/latest/api/globals.html\n\t\tmoduleObj.require.resolve = function() {\n\t\t\treturn origRequire.id.apply(null, arguments);\n\t\t}\n\n\t\tmoduleObj.require.async = function(id, successCallback, errorCallback) {\n\t\t\tif (sandboxOptions.ensureAsync) {\n\t\t\t\treturn sandboxOptions.ensureAsync(moduleObj, pkg, sandbox, id, options, function(err) {\n\t\t\t\t\tif (err) return errorCallback(err);\n\t\t\t\t\treturn origRequire.async(id, successCallback, errorCallback);\n\t\t\t\t});\n\t\t\t}\n\t\t\treturn origRequire.async(id, successCallback, errorCallback);\n\t\t}\n\t};\n\n\toptions.onInitPackage = function(pkg, sandbox, options) {\n\t\tvar origRequire = pkg.require;\n\t\t\n\t\tpkg.require = function(moduleIdentifier) {\n\t\t\tvar origModuleIdentifier = PATH.normalize(moduleIdentifier).replace(/^\\.$/, \"\").replace(/^\\/$/, \"\");\n\t\t\tvar canonicalId = null;\n\t\t\tif (origModuleIdentifier) {\n\t\t\t\tmoduleIdentifier = origModuleIdentifier;\n            \tif (!/^\\//.test(moduleIdentifier)) {\n\t                moduleIdentifier = \"/\" + ((moduleIdentifier.substring(0, pkg.libPath.length)===pkg.libPath)?\"\":pkg.libPath) + moduleIdentifier;\n\t            }\n\t\t\t\tcanonicalId = pkg.id + moduleIdentifier;\n\t\t\t} else\n\t\t\tif (pkg.descriptor && pkg.descriptor.main) {\n\t\t\t\tcanonicalId = moduleIdentifier = pkg.descriptor.main;\n\t\t\t} else {\n\t\t\t\tmoduleIdentifier = \"\";\n\t\t\t\tcanonicalId = pkg.id;\n\t\t\t}\n\n\t\t\tif (options.initializedModules[canonicalId] || options.moduleInitializers[canonicalId]) {\n\t\t\t\treturn origRequire(origModuleIdentifier);\n\t\t\t}\n\n\t\t\t// If `canonicalId` is just an alias we assume that the main module is memoized\n\t\t\t// if the package descriptor for the alias is memoized.\n\n\t\t\tif (!/\\//.test(canonicalId)) {\n\t\t\t\tif (options.initializedModules[canonicalId + \"/package.json\"] || options.moduleInitializers[canonicalId + \"/package.json\"]) {\n\t\t\t\t\treturn origRequire(origModuleIdentifier);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// We encountered a dynamic sync require.\n\n\t\t\tif (sandboxOptions.debug) console.log(\"[loader-for-nodejs][pkg.require]\", \"moduleIdentifier\", moduleIdentifier, \"pkg.id\", pkg.id, \"canonicalId\", canonicalId);\n\n\t\t\tvar bundleBasePath = getBundleBasePath(lastModuleRequireContext.moduleObj);\n\n\t\t\tvar uri = null;\n\n\t\t\tif (typeof sandboxOptions.resolveDynamicSync === \"function\") {\n\t\t\t\t// We have a runtime bundler.\n\n\t\t\t\tvar opts = {};\n\t\t\t\tfor (var name in options) {\n\t\t\t\t\topts[name] = options[name];\n\t\t\t\t}\n\t\t\t\topts.lastModuleRequireContext = lastModuleRequireContext;\n\n\t\t\t\turi = sandboxOptions.resolveDynamicSync(null, pkg, sandbox, canonicalId, opts);\n\t\t\t} else {\n\n\t\t\t\t// We assume that `canonicalId` is a package ID (not an alias) as the package mapping should\n\t\t\t\t// already be loaded if requiring a dependency by alias using pure bundles (without runtime bundler).\n\n\t\t\t\tvar canonicalIdParts = canonicalId.split(\"/\");\n\t\t\t\tvar packageId = canonicalIdParts.shift();\n\t\t\t\tvar moduleId = canonicalIdParts.join(\"/\");\n//\t\t\t\turi = PATH.join(bundleBasePath, options.normalizeIdentifier((packageId + ((moduleId) ? \"/\" + moduleId : \"\")).replace(/\\//g, \"+\")));\n\t\t\t\turi = PATH.join(bundleBasePath, options.normalizeIdentifier(packageId + ((moduleId) ? \"/\" + moduleId : \"\")));\n\t\t\t}\n\n//\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId.replace(/\\//g, \"+\")), options);\n\t\t\tloadResolvedDynamicSync(uri, PATH.join(bundleBasePath, canonicalId), options);\n\n\t\t\t// Now let the loader continue.\n\t\t\treturn origRequire(origModuleIdentifier);\n/*\n\t\t\t// We assume we have a 'dynamic sync require' (`require(<id>)`) vs a 'static sync require' (`require(\"<id>\")`) as module\n\t\t\t// should already be in bundle in the latter case. If we do have a 'static sync require'\n\t\t\t// and module is not in bundle, the bundler should use `async require` (`require.async(<id>, callback)`).\n\t\t\tthrow new Error(\"Could not resolve dynamic sync require for '\" + origModuleIdentifier + \"'\");\n*/\n\t\t};\n\n\t\tfor (var property in origRequire) {\n\t\t\tpkg.require[property] = origRequire[property];\n\t\t}\n\t}\n\n\treturn LOADER.sandbox(sandboxIdentifier, options, loadedCallback, errorCallback);\n}\n\nexports.getReport = LOADER.getReport;\n\nexports.reset = LOADER.reset;\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                },
                "fs-extra": {
                  "where": "inline"
                },
                "http": {
                  "where": "inline"
                },
                "https": {
                  "where": "inline"
                },
                "vm": {
                  "where": "inline"
                },
                "request": {
                  "where": "inline"
                },
                "pinf-loader-js/loader": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/index.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/index.js",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/fs-extra/lib/index.js",
              "mtime": 1368547337,
              "code": "\"use strict\"\n\nvar fs = null\n  , path = require('path')\n  , jsonFile = require('jsonfile')\n  , json = require('./json')\n  , fse = {};\n\ntry {\n  // optional dependency\n  fs = require(\"graceful-fs\")\n} catch (er) {\n  fs = require(\"fs\")\n}\n\nObject.keys(fs).forEach(function(key) {\n  var func = fs[key];\n  if (typeof func == 'function')\n    fse[key] = func;\n});\n\nfs = fse;\n\n// copy\n\nfs.copy = require('./copy').copy;\n\n// remove\n\nvar remove = require('./remove');\nfs.remove = remove.remove;\nfs.removeSync = remove.removeSync;\nfs['delete'] = fs.remove\nfs.deleteSync = fs.removeSync\n\n// mkdir\n\nvar mkdir = require('./mkdir')\nfs.mkdirs = mkdir.mkdirs\nfs.mkdirsSync = mkdir.mkdirsSync\nfs.mkdirp = mkdir.mkdirs\nfs.mkdirpSync = mkdir.mkdirsSync\n\n// create\n\nvar create = require('./create')\nfs.createFile = create.createFile;\nfs.createFileSync = create.createFileSync;\n\n//deprecated\nfs.touch = function touch() {\n  console.log('fs.touch() is deprecated. Please use fs.createFile().')\n  fs.createFile.apply(null, arguments)\n}\n\nfs.touchSync = function touchSync() {\n  console.log('fs.touchSync() is deprecated. Please use fs.createFileSync().')\n  fs.createFileSync.apply(null, arguments)\n}\n\n// output\n\nvar output = require('./output');\nfs.outputFile = output.outputFile;\nfs.outputFileSync = output.outputFileSync;\n\n// read\n\n/*fs.readTextFile = function(file, callback) {\n  return fs.readFile(file, 'utf8', callback)\n}\n\nfs.readTextFileSync = function(file, callback) {\n  return fs.readFileSync(file, 'utf8')\n}*/\n\n// json files\n\nfs.readJsonFile = jsonFile.readFile;\nfs.readJSONFile = jsonFile.readFile;\nfs.readJsonFileSync = jsonFile.readFileSync;\nfs.readJSONFileSync = jsonFile.readFileSync;\n\nfs.readJson = jsonFile.readFile;\nfs.readJSON = jsonFile.readFile;\nfs.readJsonSync = jsonFile.readFileSync;\nfs.readJSONSync = jsonFile.readFileSync;\n\nfs.outputJsonSync = json.outputJsonSync;\nfs.outputJSONSync = json.outputJsonSync;\nfs.outputJson = json.outputJson;\nfs.outputJSON = json.outputJson;\n\nfs.writeJsonFile = jsonFile.writeFile;\nfs.writeJSONFile = jsonFile.writeFile;\nfs.writeJsonFileSync = jsonFile.writeFileSync;\nfs.writeJSONFileSync = jsonFile.writeFileSync;\n\nfs.writeJson = jsonFile.writeFile;\nfs.writeJSON = jsonFile.writeFile;\nfs.writeJsonSync = jsonFile.writeFileSync;\nfs.writeJSONSync = jsonFile.writeFileSync;\n\n\nmodule.exports = fs\n\njsonFile.spaces = 2; //set to 2\nmodule.exports.jsonfile = jsonFile; //so users of fs-extra can modify jsonFile.spaces;\n\n",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "path": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "jsonFile": {
                  "type": "assign"
                },
                "json": {
                  "type": "assign"
                },
                "fse": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "remove": {
                  "type": "assign"
                },
                "mkdir": {
                  "type": "assign"
                },
                "create": {
                  "type": "assign"
                },
                "console": {
                  "type": "reference"
                },
                "output": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "path": {
                    "where": "inline"
                  },
                  "jsonfile": {
                    "where": "inline"
                  },
                  "./json": {
                    "where": "inline"
                  },
                  "graceful-fs": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  },
                  "./copy": {
                    "where": "inline"
                  },
                  "./remove": {
                    "where": "inline"
                  },
                  "./mkdir": {
                    "where": "inline"
                  },
                  "./create": {
                    "where": "inline"
                  },
                  "./output": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar fs = null\n  , path = require('__SYSTEM__/path')\n  , jsonFile = require('jsonfile')\n  , json = require('./json')\n  , fse = {};\n\ntry {\n  // optional dependency\n  fs = require(\"graceful-fs\")\n} catch (er) {\n  fs = require(\"__SYSTEM__/fs\")\n}\n\nObject.keys(fs).forEach(function(key) {\n  var func = fs[key];\n  if (typeof func == 'function')\n    fse[key] = func;\n});\n\nfs = fse;\n\n// copy\n\nfs.copy = require('./copy').copy;\n\n// remove\n\nvar remove = require('./remove');\nfs.remove = remove.remove;\nfs.removeSync = remove.removeSync;\nfs['delete'] = fs.remove\nfs.deleteSync = fs.removeSync\n\n// mkdir\n\nvar mkdir = require('./mkdir')\nfs.mkdirs = mkdir.mkdirs\nfs.mkdirsSync = mkdir.mkdirsSync\nfs.mkdirp = mkdir.mkdirs\nfs.mkdirpSync = mkdir.mkdirsSync\n\n// create\n\nvar create = require('./create')\nfs.createFile = create.createFile;\nfs.createFileSync = create.createFileSync;\n\n//deprecated\nfs.touch = function touch() {\n  console.log('fs.touch() is deprecated. Please use fs.createFile().')\n  fs.createFile.apply(null, arguments)\n}\n\nfs.touchSync = function touchSync() {\n  console.log('fs.touchSync() is deprecated. Please use fs.createFileSync().')\n  fs.createFileSync.apply(null, arguments)\n}\n\n// output\n\nvar output = require('./output');\nfs.outputFile = output.outputFile;\nfs.outputFileSync = output.outputFileSync;\n\n// read\n\n/*fs.readTextFile = function(file, callback) {\n  return fs.readFile(file, 'utf8', callback)\n}\n\nfs.readTextFileSync = function(file, callback) {\n  return fs.readFileSync(file, 'utf8')\n}*/\n\n// json files\n\nfs.readJsonFile = jsonFile.readFile;\nfs.readJSONFile = jsonFile.readFile;\nfs.readJsonFileSync = jsonFile.readFileSync;\nfs.readJSONFileSync = jsonFile.readFileSync;\n\nfs.readJson = jsonFile.readFile;\nfs.readJSON = jsonFile.readFile;\nfs.readJsonSync = jsonFile.readFileSync;\nfs.readJSONSync = jsonFile.readFileSync;\n\nfs.outputJsonSync = json.outputJsonSync;\nfs.outputJSONSync = json.outputJsonSync;\nfs.outputJson = json.outputJson;\nfs.outputJSON = json.outputJson;\n\nfs.writeJsonFile = jsonFile.writeFile;\nfs.writeJSONFile = jsonFile.writeFile;\nfs.writeJsonFileSync = jsonFile.writeFileSync;\nfs.writeJSONFileSync = jsonFile.writeFileSync;\n\nfs.writeJson = jsonFile.writeFile;\nfs.writeJSON = jsonFile.writeFile;\nfs.writeJsonSync = jsonFile.writeFileSync;\nfs.writeJSONSync = jsonFile.writeFileSync;\n\n\nmodule.exports = fs\n\njsonFile.spaces = 2; //set to 2\nmodule.exports.jsonfile = jsonFile; //so users of fs-extra can modify jsonFile.spaces;\n\n\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    jsonFile: (typeof jsonFile !== \"undefined\") ? jsonFile : null,\n    json: (typeof json !== \"undefined\") ? json : null,\n    fse: (typeof fse !== \"undefined\") ? fse : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    remove: (typeof remove !== \"undefined\") ? remove : null,\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    create: (typeof create !== \"undefined\") ? create : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    output: (typeof output !== \"undefined\") ? output : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    jsonFile: (typeof jsonFile !== \"undefined\") ? jsonFile : null,\n    json: (typeof json !== \"undefined\") ? json : null,\n    fse: (typeof fse !== \"undefined\") ? fse : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    remove: (typeof remove !== \"undefined\") ? remove : null,\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    create: (typeof create !== \"undefined\") ? create : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    output: (typeof output !== \"undefined\") ? output : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "path": {
                  "where": "inline"
                },
                "jsonfile": {
                  "where": "inline"
                },
                "./json": {
                  "where": "inline"
                },
                "graceful-fs": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                },
                "./copy": {
                  "where": "inline"
                },
                "./remove": {
                  "where": "inline"
                },
                "./mkdir": {
                  "where": "inline"
                },
                "./create": {
                  "where": "inline"
                },
                "./output": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/lib/jsonfile.js": {
            "requireId": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/lib/jsonfile.js",
            "memoizeId": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/lib/jsonfile.js",
            "descriptor": {
              "filename": "jsonfile.js",
              "filepath": "node_modules/fs-extra/node_modules/jsonfile/lib/jsonfile.js",
              "mtime": 1372433517,
              "code": "var fs = require('fs');\n\nvar me = module.exports;\n\nme.spaces = 2;\n\nme.readFile = function(file, callback) {\n  fs.readFile(file, 'utf8', function(err, data) {\n    if (err) return callback(err, null);\n        \n    try {\n      var obj = JSON.parse(data);\n      callback(null, obj);\n    } catch (err2) {\n      callback(err2, null);\n    }      \n  })\n}\n\nme.readFileSync = function(file) {\n  return JSON.parse(fs.readFileSync(file, 'utf8'));\n}\n\nme.writeFile = function(file, obj, callback) {\n  var str = '';\n  try {\n    str = JSON.stringify(obj, null, module.exports.spaces);\n  } catch (err) {\n    callback(err, null);\n  }\n  fs.writeFile(file, str, callback);\n}\n\nme.writeFileSync = function(file, obj) {\n  var str = JSON.stringify(obj, null, module.exports.spaces);\n  return fs.writeFileSync(file, str); //not sure if fs.writeFileSync returns anything, but just in case\n}",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "me": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "JSON": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/jsonfile/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/jsonfile/lib';\nvar fs = require('__SYSTEM__/fs');\n\nvar me = module.exports;\n\nme.spaces = 2;\n\nme.readFile = function(file, callback) {\n  fs.readFile(file, 'utf8', function(err, data) {\n    if (err) return callback(err, null);\n        \n    try {\n      var obj = JSON.parse(data);\n      callback(null, obj);\n    } catch (err2) {\n      callback(err2, null);\n    }      \n  })\n}\n\nme.readFileSync = function(file) {\n  return JSON.parse(fs.readFileSync(file, 'utf8'));\n}\n\nme.writeFile = function(file, obj, callback) {\n  var str = '';\n  try {\n    str = JSON.stringify(obj, null, module.exports.spaces);\n  } catch (err) {\n    callback(err, null);\n  }\n  fs.writeFile(file, str, callback);\n}\n\nme.writeFileSync = function(file, obj) {\n  var str = JSON.stringify(obj, null, module.exports.spaces);\n  return fs.writeFileSync(file, str); //not sure if fs.writeFileSync returns anything, but just in case\n}\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    me: (typeof me !== \"undefined\") ? me : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    me: (typeof me !== \"undefined\") ? me : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/json.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/json",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/json.js",
            "descriptor": {
              "filename": "json.js",
              "filepath": "node_modules/fs-extra/lib/json.js",
              "mtime": 1368547291,
              "code": "\"use strict\"\n\nvar jsonFile = require('jsonfile')\n  , fs = require('fs')\n  , mkdir = require('./mkdir')\n  , path = require('path')\n\nvar me = module.exports\n\nme.outputJsonSync = function(file, data) {\n  var dir = path.dirname(file)\n\n  if (!fs.existsSync(dir))\n    mkdir.mkdirsSync(dir)\n\n  jsonFile.writeFileSync(file, data)\n}\n\nme.outputJson = function(file, data, callback) {\n  var dir = path.dirname(file)\n\n  fs.exists(dir, function(itDoes) {\n    if (itDoes) return jsonFile.writeFile(file, data, callback)\n\n    mkdir.mkdirs(dir, function(err) {\n      if (err) return callback(err)\n      jsonFile.writeFile(file, data, callback)\n    })\n  })\n}",
              "globals": {
                "jsonFile": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "fs": {
                  "type": "assign"
                },
                "mkdir": {
                  "type": "assign"
                },
                "path": {
                  "type": "assign"
                },
                "me": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "jsonfile": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  },
                  "./mkdir": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar jsonFile = require('jsonfile')\n  , fs = require('__SYSTEM__/fs')\n  , mkdir = require('./mkdir')\n  , path = require('__SYSTEM__/path')\n\nvar me = module.exports\n\nme.outputJsonSync = function(file, data) {\n  var dir = path.dirname(file)\n\n  if (!fs.existsSync(dir))\n    mkdir.mkdirsSync(dir)\n\n  jsonFile.writeFileSync(file, data)\n}\n\nme.outputJson = function(file, data, callback) {\n  var dir = path.dirname(file)\n\n  fs.exists(dir, function(itDoes) {\n    if (itDoes) return jsonFile.writeFile(file, data, callback)\n\n    mkdir.mkdirs(dir, function(err) {\n      if (err) return callback(err)\n      jsonFile.writeFile(file, data, callback)\n    })\n  })\n}\nreturn {\n    jsonFile: (typeof jsonFile !== \"undefined\") ? jsonFile : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    me: (typeof me !== \"undefined\") ? me : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    jsonFile: (typeof jsonFile !== \"undefined\") ? jsonFile : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    me: (typeof me !== \"undefined\") ? me : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "jsonfile": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                },
                "./mkdir": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/mkdir.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/mkdir",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/mkdir.js",
            "descriptor": {
              "filename": "mkdir.js",
              "filepath": "node_modules/fs-extra/lib/mkdir.js",
              "mtime": 1368545736,
              "code": "\"use strict\"\n\nvar mkdirp = require('mkdirp');\n\nmodule.exports.mkdirs = mkdirp;\nmodule.exports.mkdirsSync = mkdirp.sync;\n\n\n",
              "globals": {
                "mkdirp": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "mkdirp": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar mkdirp = require('mkdirp');\n\nmodule.exports.mkdirs = mkdirp;\nmodule.exports.mkdirsSync = mkdirp.sync;\n\n\n\nreturn {\n    mkdirp: (typeof mkdirp !== \"undefined\") ? mkdirp : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    mkdirp: (typeof mkdirp !== \"undefined\") ? mkdirp : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "mkdirp": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/index.js": {
            "requireId": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/index.js",
            "memoizeId": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/fs-extra/node_modules/mkdirp/index.js",
              "mtime": 1345465530,
              "code": "var path = require('path');\nvar fs = require('fs');\n\nmodule.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;\n\nfunction mkdirP (p, mode, f, made) {\n    if (typeof mode === 'function' || mode === undefined) {\n        f = mode;\n        mode = 0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    var cb = f || function () {};\n    if (typeof mode === 'string') mode = parseInt(mode, 8);\n    p = path.resolve(p);\n\n    fs.mkdir(p, mode, function (er) {\n        if (!er) {\n            made = made || p;\n            return cb(null, made);\n        }\n        switch (er.code) {\n            case 'ENOENT':\n                mkdirP(path.dirname(p), mode, function (er, made) {\n                    if (er) cb(er, made);\n                    else mkdirP(p, mode, cb, made);\n                });\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                fs.stat(p, function (er2, stat) {\n                    // if the stat fails, then that's super weird.\n                    // let the original error be the failure reason.\n                    if (er2 || !stat.isDirectory()) cb(er, made)\n                    else cb(null, made);\n                });\n                break;\n        }\n    });\n}\n\nmkdirP.sync = function sync (p, mode, made) {\n    if (mode === undefined) {\n        mode = 0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    if (typeof mode === 'string') mode = parseInt(mode, 8);\n    p = path.resolve(p);\n\n    try {\n        fs.mkdirSync(p, mode);\n        made = made || p;\n    }\n    catch (err0) {\n        switch (err0.code) {\n            case 'ENOENT' :\n                made = sync(path.dirname(p), mode, made);\n                sync(p, mode, made);\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                var stat;\n                try {\n                    stat = fs.statSync(p);\n                }\n                catch (err1) {\n                    throw err0;\n                }\n                if (!stat.isDirectory()) throw err0;\n                break;\n        }\n    }\n\n    return made;\n};\n",
              "globals": {
                "path": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "fs": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "mkdirP": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "parseInt": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "path": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/mkdirp';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/mkdirp';\nvar path = require('__SYSTEM__/path');\nvar fs = require('__SYSTEM__/fs');\n\nmodule.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;\n\nfunction mkdirP (p, mode, f, made) {\n    if (typeof mode === 'function' || mode === undefined) {\n        f = mode;\n        mode = 0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    var cb = f || function () {};\n    if (typeof mode === 'string') mode = parseInt(mode, 8);\n    p = path.resolve(p);\n\n    fs.mkdir(p, mode, function (er) {\n        if (!er) {\n            made = made || p;\n            return cb(null, made);\n        }\n        switch (er.code) {\n            case 'ENOENT':\n                mkdirP(path.dirname(p), mode, function (er, made) {\n                    if (er) cb(er, made);\n                    else mkdirP(p, mode, cb, made);\n                });\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                fs.stat(p, function (er2, stat) {\n                    // if the stat fails, then that's super weird.\n                    // let the original error be the failure reason.\n                    if (er2 || !stat.isDirectory()) cb(er, made)\n                    else cb(null, made);\n                });\n                break;\n        }\n    });\n}\n\nmkdirP.sync = function sync (p, mode, made) {\n    if (mode === undefined) {\n        mode = 0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    if (typeof mode === 'string') mode = parseInt(mode, 8);\n    p = path.resolve(p);\n\n    try {\n        fs.mkdirSync(p, mode);\n        made = made || p;\n    }\n    catch (err0) {\n        switch (err0.code) {\n            case 'ENOENT' :\n                made = sync(path.dirname(p), mode, made);\n                sync(p, mode, made);\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                var stat;\n                try {\n                    stat = fs.statSync(p);\n                }\n                catch (err1) {\n                    throw err0;\n                }\n                if (!stat.isDirectory()) throw err0;\n                break;\n        }\n    }\n\n    return made;\n};\n\nreturn {\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    mkdirP: (typeof mkdirP !== \"undefined\") ? mkdirP : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null\n};\n}",
              "bottom": "return {\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    mkdirP: (typeof mkdirP !== \"undefined\") ? mkdirP : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "path": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/copy.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/copy",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/copy.js",
            "descriptor": {
              "filename": "copy.js",
              "filepath": "node_modules/fs-extra/lib/copy.js",
              "mtime": 1368545713,
              "code": "\"use strict\"\n\nvar fs = require('fs')\n  , ncp = require('ncp').ncp;\n\nvar BUF_LENGTH = 64 * 1024;\nvar _buff = new Buffer(BUF_LENGTH);\n\nvar copyFileSync = function(srcFile, destFile) {\n  var bytesRead, fdr, fdw, pos;\n  fdr = fs.openSync(srcFile, 'r');\n  fdw = fs.openSync(destFile, 'w');\n  bytesRead = 1;\n  pos = 0;\n  while (bytesRead > 0) {\n    bytesRead = fs.readSync(fdr, _buff, 0, BUF_LENGTH, pos);\n    fs.writeSync(fdw, _buff, 0, bytesRead);\n    pos += bytesRead;\n  }\n  fs.closeSync(fdr);\n  return fs.closeSync(fdw);\n};\n\nvar copyFile = function(srcFile, destFile, cb) {\n  var fdr, fdw;\n  fdr = fs.createReadStream(srcFile);\n  fdw = fs.createWriteStream(destFile);\n  fdr.on('end', function() {\n    return cb(null);\n  });\n  return fdr.pipe(fdw);\n};\n\nfunction copy(source, dest, callback) {\n    if (callback)\n      ncp(source, dest, callback);\n    else \n      ncp(source, dest, function(){});\n};\n\n\nmodule.exports.copyFileSync = copyFileSync;\nmodule.exports.copyFile = copyFile;\nmodule.exports.copy = copy;",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "ncp": {
                  "type": "assign"
                },
                "BUF_LENGTH": {
                  "type": "assign"
                },
                "_buff": {
                  "type": "assign"
                },
                "copyFileSync": {
                  "type": "assign"
                },
                "copyFile": {
                  "type": "assign"
                },
                "copy": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "ncp": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar fs = require('__SYSTEM__/fs')\n  , ncp = require('ncp').ncp;\n\nvar BUF_LENGTH = 64 * 1024;\nvar _buff = new Buffer(BUF_LENGTH);\n\nvar copyFileSync = function(srcFile, destFile) {\n  var bytesRead, fdr, fdw, pos;\n  fdr = fs.openSync(srcFile, 'r');\n  fdw = fs.openSync(destFile, 'w');\n  bytesRead = 1;\n  pos = 0;\n  while (bytesRead > 0) {\n    bytesRead = fs.readSync(fdr, _buff, 0, BUF_LENGTH, pos);\n    fs.writeSync(fdw, _buff, 0, bytesRead);\n    pos += bytesRead;\n  }\n  fs.closeSync(fdr);\n  return fs.closeSync(fdw);\n};\n\nvar copyFile = function(srcFile, destFile, cb) {\n  var fdr, fdw;\n  fdr = fs.createReadStream(srcFile);\n  fdw = fs.createWriteStream(destFile);\n  fdr.on('end', function() {\n    return cb(null);\n  });\n  return fdr.pipe(fdw);\n};\n\nfunction copy(source, dest, callback) {\n    if (callback)\n      ncp(source, dest, callback);\n    else \n      ncp(source, dest, function(){});\n};\n\n\nmodule.exports.copyFileSync = copyFileSync;\nmodule.exports.copyFile = copyFile;\nmodule.exports.copy = copy;\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ncp: (typeof ncp !== \"undefined\") ? ncp : null,\n    BUF_LENGTH: (typeof BUF_LENGTH !== \"undefined\") ? BUF_LENGTH : null,\n    _buff: (typeof _buff !== \"undefined\") ? _buff : null,\n    copyFileSync: (typeof copyFileSync !== \"undefined\") ? copyFileSync : null,\n    copyFile: (typeof copyFile !== \"undefined\") ? copyFile : null,\n    copy: (typeof copy !== \"undefined\") ? copy : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ncp: (typeof ncp !== \"undefined\") ? ncp : null,\n    BUF_LENGTH: (typeof BUF_LENGTH !== \"undefined\") ? BUF_LENGTH : null,\n    _buff: (typeof _buff !== \"undefined\") ? _buff : null,\n    copyFileSync: (typeof copyFileSync !== \"undefined\") ? copyFileSync : null,\n    copyFile: (typeof copyFile !== \"undefined\") ? copyFile : null,\n    copy: (typeof copy !== \"undefined\") ? copy : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "ncp": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/lib/ncp.js": {
            "requireId": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/lib/ncp.js",
            "memoizeId": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/lib/ncp.js",
            "descriptor": {
              "filename": "ncp.js",
              "filepath": "node_modules/fs-extra/node_modules/ncp/lib/ncp.js",
              "mtime": 1363107721,
              "code": "var fs = require('fs'),\n    path = require('path');\n\nmodule.exports = ncp\nncp.ncp = ncp\n\nfunction ncp (source, dest, options, callback) {\n  if (!callback) {\n    callback = options;\n    options = {};\n  }\n\n  var basePath = process.cwd(),\n      currentPath = path.resolve(basePath, source),\n      targetPath = path.resolve(basePath, dest),\n      filter = options.filter,\n      transform = options.transform,\n      clobber = options.clobber !== false,\n      errs = null,\n      started = 0,\n      finished = 0,\n      running = 0,\n      limit = options.limit || ncp.limit || 16;\n\n  limit = (limit < 1) ? 1 : (limit > 512) ? 512 : limit;\n\n  startCopy(currentPath);\n  \n  function startCopy(source) {\n    started++;\n    if (filter) {\n      if (filter instanceof RegExp) {\n        if (!filter.test(source)) {\n          return cb(true);\n        }\n      }\n      else if (typeof filter === 'function') {\n        if (!filter(source)) {\n          return cb(true);\n        }\n      }\n    }\n    return getStats(source);\n  }\n\n  function defer(fn) {\n    if (typeof(setImmediate) === 'function')\n      return setImmediate(fn);\n    return process.nextTick(fn);\n  }\n\n  function getStats(source) {\n    if (running >= limit) {\n      return defer(function () {\n        getStats(source);\n      });\n    }\n    running++;\n    fs.lstat(source, function (err, stats) {\n      var item = {};\n      if (err) {\n        return onError(err);\n      }\n\n      // We need to get the mode from the stats object and preserve it.\n      item.name = source;\n      item.mode = stats.mode;\n\n      if (stats.isDirectory()) {\n        return onDir(item);\n      }\n      else if (stats.isFile()) {\n        return onFile(item);\n      }\n      else if (stats.isSymbolicLink()) {\n        // Symlinks don't really need to know about the mode.\n        return onLink(source);\n      }\n    });\n  }\n\n  function onFile(file) {\n    var target = file.name.replace(currentPath, targetPath);\n    isWritable(target, function (writable) {\n      if (writable) {\n        return copyFile(file, target);\n      }\n      if(clobber)\n        rmFile(target, function () {\n          copyFile(file, target);\n        });\n    });\n  }\n\n  function copyFile(file, target) {\n    var readStream = fs.createReadStream(file.name),\n        writeStream = fs.createWriteStream(target, { mode: file.mode });\n    if(transform) {\n      transform(readStream, writeStream,file);\n    } else {\n      readStream.pipe(writeStream);\n    }\n    readStream.once('end', cb);\n  }\n\n  function rmFile(file, done) {\n    fs.unlink(file, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      return done();\n    });\n  }\n\n  function onDir(dir) {\n    var target = dir.name.replace(currentPath, targetPath);\n    isWritable(target, function (writable) {\n      if (writable) {\n        return mkDir(dir, target);\n      }\n      copyDir(dir.name);\n    });\n  }\n\n  function mkDir(dir, target) {\n    fs.mkdir(target, dir.mode, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      copyDir(dir.name);\n    });\n  }\n\n  function copyDir(dir) {\n    fs.readdir(dir, function (err, items) {\n      if (err) {\n        return onError(err);\n      }\n      items.forEach(function (item) {\n        startCopy(dir + '/' + item);\n      });\n      return cb();\n    });\n  }\n\n  function onLink(link) {\n    var target = link.replace(currentPath, targetPath);\n    fs.readlink(link, function (err, resolvedPath) {\n      if (err) {\n        return onError(err);\n      }\n      checkLink(resolvedPath, target);\n    });\n  }\n\n  function checkLink(resolvedPath, target) {\n    isWritable(target, function (writable) {\n      if (writable) {\n        return makeLink(resolvedPath, target);\n      }\n      fs.readlink(target, function (err, targetDest) {\n        if (err) {\n          return onError(err);\n        }\n        if (targetDest === resolvedPath) {\n          return cb();\n        }\n        return rmFile(target, function () {\n          makeLink(resolvedPath, target);\n        });\n      });\n    });\n  }\n\n  function makeLink(linkPath, target) {\n    fs.symlink(linkPath, target, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      return cb();\n    });\n  }\n\n  function isWritable(path, done) {\n    fs.lstat(path, function (err, stats) {\n      if (err) {\n        if (err.code === 'ENOENT') return done(true);\n        return done(false);\n      }\n      return done(false);\n    });\n  }\n\n  function onError(err) {\n    if (options.stopOnError) {\n      return callback(err);\n    }\n    else if (!errs && options.errs) {\n      errs = fs.createWriteStream(options.errs);\n    }\n    else if (!errs) {\n      errs = [];\n    }\n    if (typeof errs.write === 'undefined') {\n        errs.push(err);\n    }\n    else { \n        errs.write(err.stack + '\\n\\n');\n    }\n    return cb();\n  }\n\n  function cb(skipped) {\n    if (!skipped) running--;\n    finished++;\n    if ((started === finished) && (running === 0)) {\n      return errs ? callback(errs) : callback(null);\n    }\n  }\n};\n\n\n",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "path": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "ncp": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "setImmediate": {
                  "type": "typeof"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/ncp/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/ncp/lib';\nvar fs = require('__SYSTEM__/fs'),\n    path = require('__SYSTEM__/path');\n\nmodule.exports = ncp\nncp.ncp = ncp\n\nfunction ncp (source, dest, options, callback) {\n  if (!callback) {\n    callback = options;\n    options = {};\n  }\n\n  var basePath = process.cwd(),\n      currentPath = path.resolve(basePath, source),\n      targetPath = path.resolve(basePath, dest),\n      filter = options.filter,\n      transform = options.transform,\n      clobber = options.clobber !== false,\n      errs = null,\n      started = 0,\n      finished = 0,\n      running = 0,\n      limit = options.limit || ncp.limit || 16;\n\n  limit = (limit < 1) ? 1 : (limit > 512) ? 512 : limit;\n\n  startCopy(currentPath);\n  \n  function startCopy(source) {\n    started++;\n    if (filter) {\n      if (filter instanceof RegExp) {\n        if (!filter.test(source)) {\n          return cb(true);\n        }\n      }\n      else if (typeof filter === 'function') {\n        if (!filter(source)) {\n          return cb(true);\n        }\n      }\n    }\n    return getStats(source);\n  }\n\n  function defer(fn) {\n    if (typeof(setImmediate) === 'function')\n      return setImmediate(fn);\n    return process.nextTick(fn);\n  }\n\n  function getStats(source) {\n    if (running >= limit) {\n      return defer(function () {\n        getStats(source);\n      });\n    }\n    running++;\n    fs.lstat(source, function (err, stats) {\n      var item = {};\n      if (err) {\n        return onError(err);\n      }\n\n      // We need to get the mode from the stats object and preserve it.\n      item.name = source;\n      item.mode = stats.mode;\n\n      if (stats.isDirectory()) {\n        return onDir(item);\n      }\n      else if (stats.isFile()) {\n        return onFile(item);\n      }\n      else if (stats.isSymbolicLink()) {\n        // Symlinks don't really need to know about the mode.\n        return onLink(source);\n      }\n    });\n  }\n\n  function onFile(file) {\n    var target = file.name.replace(currentPath, targetPath);\n    isWritable(target, function (writable) {\n      if (writable) {\n        return copyFile(file, target);\n      }\n      if(clobber)\n        rmFile(target, function () {\n          copyFile(file, target);\n        });\n    });\n  }\n\n  function copyFile(file, target) {\n    var readStream = fs.createReadStream(file.name),\n        writeStream = fs.createWriteStream(target, { mode: file.mode });\n    if(transform) {\n      transform(readStream, writeStream,file);\n    } else {\n      readStream.pipe(writeStream);\n    }\n    readStream.once('end', cb);\n  }\n\n  function rmFile(file, done) {\n    fs.unlink(file, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      return done();\n    });\n  }\n\n  function onDir(dir) {\n    var target = dir.name.replace(currentPath, targetPath);\n    isWritable(target, function (writable) {\n      if (writable) {\n        return mkDir(dir, target);\n      }\n      copyDir(dir.name);\n    });\n  }\n\n  function mkDir(dir, target) {\n    fs.mkdir(target, dir.mode, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      copyDir(dir.name);\n    });\n  }\n\n  function copyDir(dir) {\n    fs.readdir(dir, function (err, items) {\n      if (err) {\n        return onError(err);\n      }\n      items.forEach(function (item) {\n        startCopy(dir + '/' + item);\n      });\n      return cb();\n    });\n  }\n\n  function onLink(link) {\n    var target = link.replace(currentPath, targetPath);\n    fs.readlink(link, function (err, resolvedPath) {\n      if (err) {\n        return onError(err);\n      }\n      checkLink(resolvedPath, target);\n    });\n  }\n\n  function checkLink(resolvedPath, target) {\n    isWritable(target, function (writable) {\n      if (writable) {\n        return makeLink(resolvedPath, target);\n      }\n      fs.readlink(target, function (err, targetDest) {\n        if (err) {\n          return onError(err);\n        }\n        if (targetDest === resolvedPath) {\n          return cb();\n        }\n        return rmFile(target, function () {\n          makeLink(resolvedPath, target);\n        });\n      });\n    });\n  }\n\n  function makeLink(linkPath, target) {\n    fs.symlink(linkPath, target, function (err) {\n      if (err) {\n        return onError(err);\n      }\n      return cb();\n    });\n  }\n\n  function isWritable(path, done) {\n    fs.lstat(path, function (err, stats) {\n      if (err) {\n        if (err.code === 'ENOENT') return done(true);\n        return done(false);\n      }\n      return done(false);\n    });\n  }\n\n  function onError(err) {\n    if (options.stopOnError) {\n      return callback(err);\n    }\n    else if (!errs && options.errs) {\n      errs = fs.createWriteStream(options.errs);\n    }\n    else if (!errs) {\n      errs = [];\n    }\n    if (typeof errs.write === 'undefined') {\n        errs.push(err);\n    }\n    else { \n        errs.write(err.stack + '\\n\\n');\n    }\n    return cb();\n  }\n\n  function cb(skipped) {\n    if (!skipped) running--;\n    finished++;\n    if ((started === finished) && (running === 0)) {\n      return errs ? callback(errs) : callback(null);\n    }\n  }\n};\n\n\n\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    ncp: (typeof ncp !== \"undefined\") ? ncp : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    setImmediate: (typeof setImmediate !== \"undefined\") ? setImmediate : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    ncp: (typeof ncp !== \"undefined\") ? ncp : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    setImmediate: (typeof setImmediate !== \"undefined\") ? setImmediate : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/remove.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/remove",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/remove.js",
            "descriptor": {
              "filename": "remove.js",
              "filepath": "node_modules/fs-extra/lib/remove.js",
              "mtime": 1368545758,
              "code": "\"use strict\"\n\nvar rimraf = require('rimraf')\n  , fs = require('fs');\n\nfunction rmrfSync(dir) {\n    return rimraf.sync(dir);\n}\n\nfunction rmrf(dir, cb) {\n    if (cb != null) {\n        return rimraf(dir, cb);\n    } else {\n        return rimraf(dir, (function() {}));\n    }\n}\n\nmodule.exports.remove = rmrf;\nmodule.exports.removeSync = rmrfSync;\n",
              "globals": {
                "rimraf": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "fs": {
                  "type": "assign"
                },
                "rmrfSync": {
                  "type": "assign"
                },
                "rmrf": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "rimraf": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar rimraf = require('rimraf')\n  , fs = require('__SYSTEM__/fs');\n\nfunction rmrfSync(dir) {\n    return rimraf.sync(dir);\n}\n\nfunction rmrf(dir, cb) {\n    if (cb != null) {\n        return rimraf(dir, cb);\n    } else {\n        return rimraf(dir, (function() {}));\n    }\n}\n\nmodule.exports.remove = rmrf;\nmodule.exports.removeSync = rmrfSync;\n\nreturn {\n    rimraf: (typeof rimraf !== \"undefined\") ? rimraf : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    rmrfSync: (typeof rmrfSync !== \"undefined\") ? rmrfSync : null,\n    rmrf: (typeof rmrf !== \"undefined\") ? rmrf : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    rimraf: (typeof rimraf !== \"undefined\") ? rimraf : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    rmrfSync: (typeof rmrfSync !== \"undefined\") ? rmrfSync : null,\n    rmrf: (typeof rmrf !== \"undefined\") ? rmrf : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "rimraf": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/rimraf.js": {
            "requireId": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/rimraf.js",
            "memoizeId": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/rimraf.js",
            "descriptor": {
              "filename": "rimraf.js",
              "filepath": "node_modules/fs-extra/node_modules/rimraf/rimraf.js",
              "mtime": 1373827261,
              "code": "module.exports = rimraf\nrimraf.sync = rimrafSync\n\nvar path = require(\"path\")\n  , fs\n\ntry {\n  // optional dependency\n  fs = require(\"graceful-fs\")\n} catch (er) {\n  fs = require(\"fs\")\n}\n\n// for EMFILE handling\nvar timeout = 0\nexports.EMFILE_MAX = 1000\nexports.BUSYTRIES_MAX = 3\n\nvar isWindows = (process.platform === \"win32\")\n\nfunction rimraf (p, cb) {\n  if (!cb) throw new Error(\"No callback passed to rimraf()\")\n\n  var busyTries = 0\n  rimraf_(p, function CB (er) {\n    if (er) {\n      if (er.code === \"EBUSY\" && busyTries < exports.BUSYTRIES_MAX) {\n        busyTries ++\n        var time = busyTries * 100\n        // try again, with the same exact callback as this one.\n        return setTimeout(function () {\n          rimraf_(p, CB)\n        }, time)\n      }\n\n      // this one won't happen if graceful-fs is used.\n      if (er.code === \"EMFILE\" && timeout < exports.EMFILE_MAX) {\n        return setTimeout(function () {\n          rimraf_(p, CB)\n        }, timeout ++)\n      }\n\n      // already gone\n      if (er.code === \"ENOENT\") er = null\n    }\n\n    timeout = 0\n    cb(er)\n  })\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, cb) {\n  fs.unlink(p, function (er) {\n    if (er) {\n      if (er.code === \"ENOENT\")\n        return cb()\n      if (er.code === \"EPERM\")\n        return (isWindows) ? fixWinEPERM(p, er, cb) : rmdir(p, er, cb)\n      if (er.code === \"EISDIR\")\n        return rmdir(p, er, cb)\n    }\n    return cb(er)\n  })\n}\n\nfunction fixWinEPERM (p, er, cb) {\n  fs.chmod(p, 666, function (er2) {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      fs.stat(p, function(er3, stats) {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, er, cb)\n        else\n          fs.unlink(p, cb)\n      })\n  })\n}\n\nfunction fixWinEPERMSync (p, er, cb) {\n  try {\n    fs.chmodSync(p, 666)\n  } catch (er2) {\n    if (er2.code !== \"ENOENT\")\n      throw er\n  }\n\n  try {\n    var stats = fs.statSync(p)\n  } catch (er3) {\n    if (er3 !== \"ENOENT\")\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, er)\n  else\n    fs.unlinkSync(p)\n}\n\nfunction rmdir (p, originalEr, cb) {\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  fs.rmdir(p, function (er) {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\"))\n      rmkids(p, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nfunction rmkids(p, cb) {\n  fs.readdir(p, function (er, files) {\n    if (er)\n      return cb(er)\n    var n = files.length\n    if (n === 0)\n      return fs.rmdir(p, cb)\n    var errState\n    files.forEach(function (f) {\n      rimraf(path.join(p, f), function (er) {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          fs.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p) {\n  try {\n    fs.unlinkSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"EPERM\")\n      return isWindows ? fixWinEPERMSync(p, er) : rmdirSync(p, er)\n    if (er.code !== \"EISDIR\")\n      throw er\n    rmdirSync(p, er)\n  }\n}\n\nfunction rmdirSync (p, originalEr) {\n  try {\n    fs.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\")\n      rmkidsSync(p)\n  }\n}\n\nfunction rmkidsSync (p) {\n  fs.readdirSync(p).forEach(function (f) {\n    rimrafSync(path.join(p, f))\n  })\n  fs.rmdirSync(p)\n}\n",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "rimraf": {
                  "type": "reference"
                },
                "path": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "fs": {
                  "type": "assign"
                },
                "timeout": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "isWindows": {
                  "type": "assign"
                },
                "process": {
                  "type": "reference"
                },
                "rimraf_": {
                  "type": "call"
                },
                "setTimeout": {
                  "type": "call"
                },
                "fixWinEPERM": {
                  "type": "call"
                },
                "rmdir": {
                  "type": "call"
                },
                "fixWinEPERMSync": {
                  "type": "assign"
                },
                "rmdirSync": {
                  "type": "call"
                },
                "rmkids": {
                  "type": "call"
                },
                "rimrafSync": {
                  "type": "assign"
                },
                "rmkidsSync": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "path": {
                    "where": "inline"
                  },
                  "graceful-fs": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf';\nmodule.exports = rimraf\nrimraf.sync = rimrafSync\n\nvar path = require(\"__SYSTEM__/path\")\n  , fs\n\ntry {\n  // optional dependency\n  fs = require(\"graceful-fs\")\n} catch (er) {\n  fs = require(\"__SYSTEM__/fs\")\n}\n\n// for EMFILE handling\nvar timeout = 0\nexports.EMFILE_MAX = 1000\nexports.BUSYTRIES_MAX = 3\n\nvar isWindows = (process.platform === \"win32\")\n\nfunction rimraf (p, cb) {\n  if (!cb) throw new Error(\"No callback passed to rimraf()\")\n\n  var busyTries = 0\n  rimraf_(p, function CB (er) {\n    if (er) {\n      if (er.code === \"EBUSY\" && busyTries < exports.BUSYTRIES_MAX) {\n        busyTries ++\n        var time = busyTries * 100\n        // try again, with the same exact callback as this one.\n        return setTimeout(function () {\n          rimraf_(p, CB)\n        }, time)\n      }\n\n      // this one won't happen if graceful-fs is used.\n      if (er.code === \"EMFILE\" && timeout < exports.EMFILE_MAX) {\n        return setTimeout(function () {\n          rimraf_(p, CB)\n        }, timeout ++)\n      }\n\n      // already gone\n      if (er.code === \"ENOENT\") er = null\n    }\n\n    timeout = 0\n    cb(er)\n  })\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nfunction rimraf_ (p, cb) {\n  fs.unlink(p, function (er) {\n    if (er) {\n      if (er.code === \"ENOENT\")\n        return cb()\n      if (er.code === \"EPERM\")\n        return (isWindows) ? fixWinEPERM(p, er, cb) : rmdir(p, er, cb)\n      if (er.code === \"EISDIR\")\n        return rmdir(p, er, cb)\n    }\n    return cb(er)\n  })\n}\n\nfunction fixWinEPERM (p, er, cb) {\n  fs.chmod(p, 666, function (er2) {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      fs.stat(p, function(er3, stats) {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, er, cb)\n        else\n          fs.unlink(p, cb)\n      })\n  })\n}\n\nfunction fixWinEPERMSync (p, er, cb) {\n  try {\n    fs.chmodSync(p, 666)\n  } catch (er2) {\n    if (er2.code !== \"ENOENT\")\n      throw er\n  }\n\n  try {\n    var stats = fs.statSync(p)\n  } catch (er3) {\n    if (er3 !== \"ENOENT\")\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, er)\n  else\n    fs.unlinkSync(p)\n}\n\nfunction rmdir (p, originalEr, cb) {\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  fs.rmdir(p, function (er) {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\"))\n      rmkids(p, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nfunction rmkids(p, cb) {\n  fs.readdir(p, function (er, files) {\n    if (er)\n      return cb(er)\n    var n = files.length\n    if (n === 0)\n      return fs.rmdir(p, cb)\n    var errState\n    files.forEach(function (f) {\n      rimraf(path.join(p, f), function (er) {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          fs.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nfunction rimrafSync (p) {\n  try {\n    fs.unlinkSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"EPERM\")\n      return isWindows ? fixWinEPERMSync(p, er) : rmdirSync(p, er)\n    if (er.code !== \"EISDIR\")\n      throw er\n    rmdirSync(p, er)\n  }\n}\n\nfunction rmdirSync (p, originalEr) {\n  try {\n    fs.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\")\n      rmkidsSync(p)\n  }\n}\n\nfunction rmkidsSync (p) {\n  fs.readdirSync(p).forEach(function (f) {\n    rimrafSync(path.join(p, f))\n  })\n  fs.rmdirSync(p)\n}\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "path": {
                  "where": "inline"
                },
                "graceful-fs": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/graceful-fs.js": {
            "requireId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/graceful-fs.js",
            "memoizeId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/graceful-fs.js",
            "descriptor": {
              "filename": "graceful-fs.js",
              "filepath": "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs/graceful-fs.js",
              "mtime": 1373526487,
              "code": "// Monkey-patching the fs module.\n// It's ugly, but there is simply no other way to do this.\nvar fs = module.exports = require('fs')\n\nvar assert = require('assert')\n\n// fix up some busted stuff, mostly on windows and old nodes\nrequire('./polyfills.js')\n\n// The EMFILE enqueuing stuff\n\nvar util = require('util')\n\nfunction noop () {}\n\nvar debug = noop\nvar util = require('util')\nif (util.debuglog)\n  debug = util.debuglog('gfs')\nelse if (/\\bgfs\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS: ' + m.split(/\\n/).join('\\nGFS: ')\n    console.error(m)\n  }\n\nif (/\\bgfs\\b/i.test(process.env.NODE_DEBUG || '')) {\n  process.on('exit', function() {\n    debug('fds', fds)\n    debug(queue)\n    assert.equal(queue.length, 0)\n  })\n}\n\n\nvar originalOpen = fs.open\nfs.open = open\n\nfunction open(path, flags, mode, cb) {\n  if (typeof mode === \"function\") cb = mode, mode = null\n  if (typeof cb !== \"function\") cb = noop\n  new OpenReq(path, flags, mode, cb)\n}\n\nfunction OpenReq(path, flags, mode, cb) {\n  this.path = path\n  this.flags = flags\n  this.mode = mode\n  this.cb = cb\n  Req.call(this)\n}\n\nutil.inherits(OpenReq, Req)\n\nOpenReq.prototype.process = function() {\n  originalOpen.call(fs, this.path, this.flags, this.mode, this.done)\n}\n\nvar fds = {}\nOpenReq.prototype.done = function(er, fd) {\n  debug('open done', er, fd)\n  if (fd)\n    fds['fd' + fd] = this.path\n  Req.prototype.done.call(this, er, fd)\n}\n\n\nvar originalReaddir = fs.readdir\nfs.readdir = readdir\n\nfunction readdir(path, cb) {\n  if (typeof cb !== \"function\") cb = noop\n  new ReaddirReq(path, cb)\n}\n\nfunction ReaddirReq(path, cb) {\n  this.path = path\n  this.cb = cb\n  Req.call(this)\n}\n\nutil.inherits(ReaddirReq, Req)\n\nReaddirReq.prototype.process = function() {\n  originalReaddir.call(fs, this.path, this.done)\n}\n\nReaddirReq.prototype.done = function(er, files) {\n  Req.prototype.done.call(this, er, files)\n  onclose()\n}\n\n\nvar originalClose = fs.close\nfs.close = close\n\nfunction close (fd, cb) {\n  debug('close', fd)\n  if (typeof cb !== \"function\") cb = noop\n  delete fds['fd' + fd]\n  originalClose.call(fs, fd, function(er) {\n    onclose()\n    cb(er)\n  })\n}\n\n\nvar originalCloseSync = fs.closeSync\nfs.closeSync = closeSync\n\nfunction closeSync (fd) {\n  try {\n    return originalCloseSync(fd)\n  } finally {\n    onclose()\n  }\n}\n\n\n// Req class\nfunction Req () {\n  // start processing\n  this.done = this.done.bind(this)\n  this.failures = 0\n  this.process()\n}\n\nReq.prototype.done = function (er, result) {\n  // if an error, and the code is EMFILE, then get in the queue\n  if (er && er.code === \"EMFILE\") {\n    this.failures ++\n    enqueue(this)\n  } else {\n    var cb = this.cb\n    cb(er, result)\n  }\n}\n\nvar queue = []\n\nfunction enqueue(req) {\n  queue.push(req)\n  debug('enqueue %d %s', queue.length, req.constructor.name, req)\n}\n\nfunction onclose() {\n  var req = queue.shift()\n  if (req) {\n    debug('process', req.constructor.name, req)\n    req.process()\n  }\n}\n",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                },
                "assert": {
                  "type": "assign"
                },
                "util": {
                  "type": "assign"
                },
                "noop": {
                  "type": "assign"
                },
                "debug": {
                  "type": "assign"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "fds": {
                  "type": "reference"
                },
                "queue": {
                  "type": "reference"
                },
                "originalOpen": {
                  "type": "assign"
                },
                "open": {
                  "type": "assign"
                },
                "OpenReq": {
                  "type": "assign"
                },
                "Req": {
                  "type": "reference"
                },
                "originalReaddir": {
                  "type": "assign"
                },
                "readdir": {
                  "type": "assign"
                },
                "ReaddirReq": {
                  "type": "assign"
                },
                "onclose": {
                  "type": "call"
                },
                "originalClose": {
                  "type": "assign"
                },
                "close": {
                  "type": "assign"
                },
                "originalCloseSync": {
                  "type": "assign"
                },
                "closeSync": {
                  "type": "assign"
                },
                "enqueue": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "assert": {
                    "where": "inline"
                  },
                  "./polyfills.js": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs';\n// Monkey-patching the fs module.\n// It's ugly, but there is simply no other way to do this.\nvar fs = module.exports = require('__SYSTEM__/fs')\n\nvar assert = require('__SYSTEM__/assert')\n\n// fix up some busted stuff, mostly on windows and old nodes\nrequire('./polyfills.js')\n\n// The EMFILE enqueuing stuff\n\nvar util = require('__SYSTEM__/util')\n\nfunction noop () {}\n\nvar debug = noop\nvar util = require('__SYSTEM__/util')\nif (util.debuglog)\n  debug = util.debuglog('gfs')\nelse if (/\\bgfs\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS: ' + m.split(/\\n/).join('\\nGFS: ')\n    console.error(m)\n  }\n\nif (/\\bgfs\\b/i.test(process.env.NODE_DEBUG || '')) {\n  process.on('exit', function() {\n    debug('fds', fds)\n    debug(queue)\n    assert.equal(queue.length, 0)\n  })\n}\n\n\nvar originalOpen = fs.open\nfs.open = open\n\nfunction open(path, flags, mode, cb) {\n  if (typeof mode === \"function\") cb = mode, mode = null\n  if (typeof cb !== \"function\") cb = noop\n  new OpenReq(path, flags, mode, cb)\n}\n\nfunction OpenReq(path, flags, mode, cb) {\n  this.path = path\n  this.flags = flags\n  this.mode = mode\n  this.cb = cb\n  Req.call(this)\n}\n\nutil.inherits(OpenReq, Req)\n\nOpenReq.prototype.process = function() {\n  originalOpen.call(fs, this.path, this.flags, this.mode, this.done)\n}\n\nvar fds = {}\nOpenReq.prototype.done = function(er, fd) {\n  debug('open done', er, fd)\n  if (fd)\n    fds['fd' + fd] = this.path\n  Req.prototype.done.call(this, er, fd)\n}\n\n\nvar originalReaddir = fs.readdir\nfs.readdir = readdir\n\nfunction readdir(path, cb) {\n  if (typeof cb !== \"function\") cb = noop\n  new ReaddirReq(path, cb)\n}\n\nfunction ReaddirReq(path, cb) {\n  this.path = path\n  this.cb = cb\n  Req.call(this)\n}\n\nutil.inherits(ReaddirReq, Req)\n\nReaddirReq.prototype.process = function() {\n  originalReaddir.call(fs, this.path, this.done)\n}\n\nReaddirReq.prototype.done = function(er, files) {\n  Req.prototype.done.call(this, er, files)\n  onclose()\n}\n\n\nvar originalClose = fs.close\nfs.close = close\n\nfunction close (fd, cb) {\n  debug('close', fd)\n  if (typeof cb !== \"function\") cb = noop\n  delete fds['fd' + fd]\n  originalClose.call(fs, fd, function(er) {\n    onclose()\n    cb(er)\n  })\n}\n\n\nvar originalCloseSync = fs.closeSync\nfs.closeSync = closeSync\n\nfunction closeSync (fd) {\n  try {\n    return originalCloseSync(fd)\n  } finally {\n    onclose()\n  }\n}\n\n\n// Req class\nfunction Req () {\n  // start processing\n  this.done = this.done.bind(this)\n  this.failures = 0\n  this.process()\n}\n\nReq.prototype.done = function (er, result) {\n  // if an error, and the code is EMFILE, then get in the queue\n  if (er && er.code === \"EMFILE\") {\n    this.failures ++\n    enqueue(this)\n  } else {\n    var cb = this.cb\n    cb(er, result)\n  }\n}\n\nvar queue = []\n\nfunction enqueue(req) {\n  queue.push(req)\n  debug('enqueue %d %s', queue.length, req.constructor.name, req)\n}\n\nfunction onclose() {\n  var req = queue.shift()\n  if (req) {\n    debug('process', req.constructor.name, req)\n    req.process()\n  }\n}\n\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    noop: (typeof noop !== \"undefined\") ? noop : null,\n    debug: (typeof debug !== \"undefined\") ? debug : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    fds: (typeof fds !== \"undefined\") ? fds : null,\n    queue: (typeof queue !== \"undefined\") ? queue : null,\n    originalOpen: (typeof originalOpen !== \"undefined\") ? originalOpen : null,\n    open: (typeof open !== \"undefined\") ? open : null,\n    OpenReq: (typeof OpenReq !== \"undefined\") ? OpenReq : null,\n    Req: (typeof Req !== \"undefined\") ? Req : null,\n    originalReaddir: (typeof originalReaddir !== \"undefined\") ? originalReaddir : null,\n    readdir: (typeof readdir !== \"undefined\") ? readdir : null,\n    ReaddirReq: (typeof ReaddirReq !== \"undefined\") ? ReaddirReq : null,\n    onclose: (typeof onclose !== \"undefined\") ? onclose : null,\n    originalClose: (typeof originalClose !== \"undefined\") ? originalClose : null,\n    close: (typeof close !== \"undefined\") ? close : null,\n    originalCloseSync: (typeof originalCloseSync !== \"undefined\") ? originalCloseSync : null,\n    closeSync: (typeof closeSync !== \"undefined\") ? closeSync : null,\n    enqueue: (typeof enqueue !== \"undefined\") ? enqueue : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    noop: (typeof noop !== \"undefined\") ? noop : null,\n    debug: (typeof debug !== \"undefined\") ? debug : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    fds: (typeof fds !== \"undefined\") ? fds : null,\n    queue: (typeof queue !== \"undefined\") ? queue : null,\n    originalOpen: (typeof originalOpen !== \"undefined\") ? originalOpen : null,\n    open: (typeof open !== \"undefined\") ? open : null,\n    OpenReq: (typeof OpenReq !== \"undefined\") ? OpenReq : null,\n    Req: (typeof Req !== \"undefined\") ? Req : null,\n    originalReaddir: (typeof originalReaddir !== \"undefined\") ? originalReaddir : null,\n    readdir: (typeof readdir !== \"undefined\") ? readdir : null,\n    ReaddirReq: (typeof ReaddirReq !== \"undefined\") ? ReaddirReq : null,\n    onclose: (typeof onclose !== \"undefined\") ? onclose : null,\n    originalClose: (typeof originalClose !== \"undefined\") ? originalClose : null,\n    close: (typeof close !== \"undefined\") ? close : null,\n    originalCloseSync: (typeof originalCloseSync !== \"undefined\") ? originalCloseSync : null,\n    closeSync: (typeof closeSync !== \"undefined\") ? closeSync : null,\n    enqueue: (typeof enqueue !== \"undefined\") ? enqueue : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "assert": {
                  "where": "inline"
                },
                "./polyfills.js": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/polyfills.js": {
            "requireId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/polyfills.js",
            "memoizeId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/polyfills.js",
            "descriptor": {
              "filename": "polyfills.js",
              "filepath": "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs/polyfills.js",
              "mtime": 1373526487,
              "code": "var fs = require('fs')\nvar constants = require('constants')\n\nvar origCwd = process.cwd\nvar cwd = null\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\nvar chdir = process.chdir\nprocess.chdir = function(d) {\n  cwd = null\n  chdir.call(process, d)\n}\n\n// (re-)implement some things that are known busted or missing.\n\n// lchmod, broken prior to 0.6.2\n// back-port the fix here.\nif (constants.hasOwnProperty('O_SYMLINK') &&\n    process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n  fs.lchmod = function (path, mode, callback) {\n    callback = callback || noop\n    fs.open( path\n           , constants.O_WRONLY | constants.O_SYMLINK\n           , mode\n           , function (err, fd) {\n      if (err) {\n        callback(err)\n        return\n      }\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      fs.fchmod(fd, mode, function (err) {\n        fs.close(fd, function(err2) {\n          callback(err || err2)\n        })\n      })\n    })\n  }\n\n  fs.lchmodSync = function (path, mode) {\n    var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n    // prefer to return the chmod error, if one occurs,\n    // but still try to close, and report closing errors if they occur.\n    var err, err2\n    try {\n      var ret = fs.fchmodSync(fd, mode)\n    } catch (er) {\n      err = er\n    }\n    try {\n      fs.closeSync(fd)\n    } catch (er) {\n      err2 = er\n    }\n    if (err || err2) throw (err || err2)\n    return ret\n  }\n}\n\n\n// lutimes implementation, or no-op\nif (!fs.lutimes) {\n  if (constants.hasOwnProperty(\"O_SYMLINK\")) {\n    fs.lutimes = function (path, at, mt, cb) {\n      fs.open(path, constants.O_SYMLINK, function (er, fd) {\n        cb = cb || noop\n        if (er) return cb(er)\n        fs.futimes(fd, at, mt, function (er) {\n          fs.close(fd, function (er2) {\n            return cb(er || er2)\n          })\n        })\n      })\n    }\n\n    fs.lutimesSync = function (path, at, mt) {\n      var fd = fs.openSync(path, constants.O_SYMLINK)\n        , err\n        , err2\n        , ret\n\n      try {\n        var ret = fs.futimesSync(fd, at, mt)\n      } catch (er) {\n        err = er\n      }\n      try {\n        fs.closeSync(fd)\n      } catch (er) {\n        err2 = er\n      }\n      if (err || err2) throw (err || err2)\n      return ret\n    }\n\n  } else if (fs.utimensat && constants.hasOwnProperty(\"AT_SYMLINK_NOFOLLOW\")) {\n    // maybe utimensat will be bound soonish?\n    fs.lutimes = function (path, at, mt, cb) {\n      fs.utimensat(path, at, mt, constants.AT_SYMLINK_NOFOLLOW, cb)\n    }\n\n    fs.lutimesSync = function (path, at, mt) {\n      return fs.utimensatSync(path, at, mt, constants.AT_SYMLINK_NOFOLLOW)\n    }\n\n  } else {\n    fs.lutimes = function (_a, _b, _c, cb) { process.nextTick(cb) }\n    fs.lutimesSync = function () {}\n  }\n}\n\n\n// https://github.com/isaacs/node-graceful-fs/issues/4\n// Chown should not fail on einval or eperm if non-root.\n\nfs.chown = chownFix(fs.chown)\nfs.fchown = chownFix(fs.fchown)\nfs.lchown = chownFix(fs.lchown)\n\nfs.chownSync = chownFixSync(fs.chownSync)\nfs.fchownSync = chownFixSync(fs.fchownSync)\nfs.lchownSync = chownFixSync(fs.lchownSync)\n\nfunction chownFix (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid, cb) {\n    return orig.call(fs, target, uid, gid, function (er, res) {\n      if (chownErOk(er)) er = null\n      cb(er, res)\n    })\n  }\n}\n\nfunction chownFixSync (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid) {\n    try {\n      return orig.call(fs, target, uid, gid)\n    } catch (er) {\n      if (!chownErOk(er)) throw er\n    }\n  }\n}\n\nfunction chownErOk (er) {\n  // if there's no getuid, or if getuid() is something other than 0,\n  // and the error is EINVAL or EPERM, then just ignore it.\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  // When running as root, or if other types of errors are encountered,\n  // then it's strict.\n  if (!er || (!process.getuid || process.getuid() !== 0)\n      && (er.code === \"EINVAL\" || er.code === \"EPERM\")) return true\n}\n\n\n// if lchmod/lchown do not exist, then make them no-ops\nif (!fs.lchmod) {\n  fs.lchmod = function (path, mode, cb) {\n    process.nextTick(cb)\n  }\n  fs.lchmodSync = function () {}\n}\nif (!fs.lchown) {\n  fs.lchown = function (path, uid, gid, cb) {\n    process.nextTick(cb)\n  }\n  fs.lchownSync = function () {}\n}\n\n\n\n// on Windows, A/V software can lock the directory, causing this\n// to fail with an EACCES or EPERM if the directory contains newly\n// created files.  Try again on failure, for up to 1 second.\nif (process.platform === \"win32\") {\n  var rename_ = fs.rename\n  fs.rename = function rename (from, to, cb) {\n    var start = Date.now()\n    rename_(from, to, function CB (er) {\n      if (er\n          && (er.code === \"EACCES\" || er.code === \"EPERM\")\n          && Date.now() - start < 1000) {\n        return rename_(from, to, CB)\n      }\n      cb(er)\n    })\n  }\n}\n\n\n// if read() returns EAGAIN, then just try it again.\nvar read = fs.read\nfs.read = function (fd, buffer, offset, length, position, callback_) {\n  var callback\n  if (callback_ && typeof callback_ === 'function') {\n    var eagCounter = 0\n    callback = function (er, _, __) {\n      if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n        eagCounter ++\n        return read.call(fs, fd, buffer, offset, length, position, callback)\n      }\n      callback_.apply(this, arguments)\n    }\n  }\n  return read.call(fs, fd, buffer, offset, length, position, callback)\n}\n\nvar readSync = fs.readSync\nfs.readSync = function (fd, buffer, offset, length, position) {\n  var eagCounter = 0\n  while (true) {\n    try {\n      return readSync.call(fs, fd, buffer, offset, length, position)\n    } catch (er) {\n      if (er.code === 'EAGAIN' && eagCounter < 10) {\n        eagCounter ++\n        continue\n      }\n      throw er\n    }\n  }\n}\n\n",
              "globals": {
                "fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "constants": {
                  "type": "assign"
                },
                "origCwd": {
                  "type": "assign"
                },
                "process": {
                  "type": "reference"
                },
                "cwd": {
                  "type": "assign"
                },
                "chdir": {
                  "type": "assign"
                },
                "chownFix": {
                  "type": "call"
                },
                "chownFixSync": {
                  "type": "call"
                },
                "chownErOk": {
                  "type": "call"
                },
                "rename_": {
                  "type": "assign"
                },
                "Date": {
                  "type": "reference"
                },
                "read": {
                  "type": "assign"
                },
                "readSync": {
                  "type": "assign"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "constants": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs';\nvar fs = require('__SYSTEM__/fs')\nvar constants = require('__SYSTEM__/constants')\n\nvar origCwd = process.cwd\nvar cwd = null\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\nvar chdir = process.chdir\nprocess.chdir = function(d) {\n  cwd = null\n  chdir.call(process, d)\n}\n\n// (re-)implement some things that are known busted or missing.\n\n// lchmod, broken prior to 0.6.2\n// back-port the fix here.\nif (constants.hasOwnProperty('O_SYMLINK') &&\n    process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n  fs.lchmod = function (path, mode, callback) {\n    callback = callback || noop\n    fs.open( path\n           , constants.O_WRONLY | constants.O_SYMLINK\n           , mode\n           , function (err, fd) {\n      if (err) {\n        callback(err)\n        return\n      }\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      fs.fchmod(fd, mode, function (err) {\n        fs.close(fd, function(err2) {\n          callback(err || err2)\n        })\n      })\n    })\n  }\n\n  fs.lchmodSync = function (path, mode) {\n    var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n    // prefer to return the chmod error, if one occurs,\n    // but still try to close, and report closing errors if they occur.\n    var err, err2\n    try {\n      var ret = fs.fchmodSync(fd, mode)\n    } catch (er) {\n      err = er\n    }\n    try {\n      fs.closeSync(fd)\n    } catch (er) {\n      err2 = er\n    }\n    if (err || err2) throw (err || err2)\n    return ret\n  }\n}\n\n\n// lutimes implementation, or no-op\nif (!fs.lutimes) {\n  if (constants.hasOwnProperty(\"O_SYMLINK\")) {\n    fs.lutimes = function (path, at, mt, cb) {\n      fs.open(path, constants.O_SYMLINK, function (er, fd) {\n        cb = cb || noop\n        if (er) return cb(er)\n        fs.futimes(fd, at, mt, function (er) {\n          fs.close(fd, function (er2) {\n            return cb(er || er2)\n          })\n        })\n      })\n    }\n\n    fs.lutimesSync = function (path, at, mt) {\n      var fd = fs.openSync(path, constants.O_SYMLINK)\n        , err\n        , err2\n        , ret\n\n      try {\n        var ret = fs.futimesSync(fd, at, mt)\n      } catch (er) {\n        err = er\n      }\n      try {\n        fs.closeSync(fd)\n      } catch (er) {\n        err2 = er\n      }\n      if (err || err2) throw (err || err2)\n      return ret\n    }\n\n  } else if (fs.utimensat && constants.hasOwnProperty(\"AT_SYMLINK_NOFOLLOW\")) {\n    // maybe utimensat will be bound soonish?\n    fs.lutimes = function (path, at, mt, cb) {\n      fs.utimensat(path, at, mt, constants.AT_SYMLINK_NOFOLLOW, cb)\n    }\n\n    fs.lutimesSync = function (path, at, mt) {\n      return fs.utimensatSync(path, at, mt, constants.AT_SYMLINK_NOFOLLOW)\n    }\n\n  } else {\n    fs.lutimes = function (_a, _b, _c, cb) { process.nextTick(cb) }\n    fs.lutimesSync = function () {}\n  }\n}\n\n\n// https://github.com/isaacs/node-graceful-fs/issues/4\n// Chown should not fail on einval or eperm if non-root.\n\nfs.chown = chownFix(fs.chown)\nfs.fchown = chownFix(fs.fchown)\nfs.lchown = chownFix(fs.lchown)\n\nfs.chownSync = chownFixSync(fs.chownSync)\nfs.fchownSync = chownFixSync(fs.fchownSync)\nfs.lchownSync = chownFixSync(fs.lchownSync)\n\nfunction chownFix (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid, cb) {\n    return orig.call(fs, target, uid, gid, function (er, res) {\n      if (chownErOk(er)) er = null\n      cb(er, res)\n    })\n  }\n}\n\nfunction chownFixSync (orig) {\n  if (!orig) return orig\n  return function (target, uid, gid) {\n    try {\n      return orig.call(fs, target, uid, gid)\n    } catch (er) {\n      if (!chownErOk(er)) throw er\n    }\n  }\n}\n\nfunction chownErOk (er) {\n  // if there's no getuid, or if getuid() is something other than 0,\n  // and the error is EINVAL or EPERM, then just ignore it.\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  // When running as root, or if other types of errors are encountered,\n  // then it's strict.\n  if (!er || (!process.getuid || process.getuid() !== 0)\n      && (er.code === \"EINVAL\" || er.code === \"EPERM\")) return true\n}\n\n\n// if lchmod/lchown do not exist, then make them no-ops\nif (!fs.lchmod) {\n  fs.lchmod = function (path, mode, cb) {\n    process.nextTick(cb)\n  }\n  fs.lchmodSync = function () {}\n}\nif (!fs.lchown) {\n  fs.lchown = function (path, uid, gid, cb) {\n    process.nextTick(cb)\n  }\n  fs.lchownSync = function () {}\n}\n\n\n\n// on Windows, A/V software can lock the directory, causing this\n// to fail with an EACCES or EPERM if the directory contains newly\n// created files.  Try again on failure, for up to 1 second.\nif (process.platform === \"win32\") {\n  var rename_ = fs.rename\n  fs.rename = function rename (from, to, cb) {\n    var start = Date.now()\n    rename_(from, to, function CB (er) {\n      if (er\n          && (er.code === \"EACCES\" || er.code === \"EPERM\")\n          && Date.now() - start < 1000) {\n        return rename_(from, to, CB)\n      }\n      cb(er)\n    })\n  }\n}\n\n\n// if read() returns EAGAIN, then just try it again.\nvar read = fs.read\nfs.read = function (fd, buffer, offset, length, position, callback_) {\n  var callback\n  if (callback_ && typeof callback_ === 'function') {\n    var eagCounter = 0\n    callback = function (er, _, __) {\n      if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n        eagCounter ++\n        return read.call(fs, fd, buffer, offset, length, position, callback)\n      }\n      callback_.apply(this, arguments)\n    }\n  }\n  return read.call(fs, fd, buffer, offset, length, position, callback)\n}\n\nvar readSync = fs.readSync\nfs.readSync = function (fd, buffer, offset, length, position) {\n  var eagCounter = 0\n  while (true) {\n    try {\n      return readSync.call(fs, fd, buffer, offset, length, position)\n    } catch (er) {\n      if (er.code === 'EAGAIN' && eagCounter < 10) {\n        eagCounter ++\n        continue\n      }\n      throw er\n    }\n  }\n}\n\n\nreturn {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    constants: (typeof constants !== \"undefined\") ? constants : null,\n    origCwd: (typeof origCwd !== \"undefined\") ? origCwd : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    cwd: (typeof cwd !== \"undefined\") ? cwd : null,\n    chdir: (typeof chdir !== \"undefined\") ? chdir : null,\n    chownFix: (typeof chownFix !== \"undefined\") ? chownFix : null,\n    chownFixSync: (typeof chownFixSync !== \"undefined\") ? chownFixSync : null,\n    chownErOk: (typeof chownErOk !== \"undefined\") ? chownErOk : null,\n    rename_: (typeof rename_ !== \"undefined\") ? rename_ : null,\n    Date: (typeof Date !== \"undefined\") ? Date : null,\n    read: (typeof read !== \"undefined\") ? read : null,\n    readSync: (typeof readSync !== \"undefined\") ? readSync : null\n};\n}",
              "bottom": "return {\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    constants: (typeof constants !== \"undefined\") ? constants : null,\n    origCwd: (typeof origCwd !== \"undefined\") ? origCwd : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    cwd: (typeof cwd !== \"undefined\") ? cwd : null,\n    chdir: (typeof chdir !== \"undefined\") ? chdir : null,\n    chownFix: (typeof chownFix !== \"undefined\") ? chownFix : null,\n    chownFixSync: (typeof chownFixSync !== \"undefined\") ? chownFixSync : null,\n    chownErOk: (typeof chownErOk !== \"undefined\") ? chownErOk : null,\n    rename_: (typeof rename_ !== \"undefined\") ? rename_ : null,\n    Date: (typeof Date !== \"undefined\") ? Date : null,\n    read: (typeof read !== \"undefined\") ? read : null,\n    readSync: (typeof readSync !== \"undefined\") ? readSync : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "constants": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/create.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/create",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/create.js",
            "descriptor": {
              "filename": "create.js",
              "filepath": "node_modules/fs-extra/lib/create.js",
              "mtime": 1368545697,
              "code": "\"use strict\"\n\nvar mkdir = require('./mkdir')\n  , path = require('path')\n  , fs = require('fs')\n  , exists = fs.exists || path.exists\n  , existsSync = fs.existsSync || path.existsSync\n\nfunction createFile (file, callback) {\n  function makeFile() {\n    fs.writeFile(file, '', function(err) {\n      if (err)\n        callback(err)\n      else\n        callback(null);\n    })\n  }\n\n  exists(file, function(fileExists) {\n    if (fileExists)\n      return callback(null);\n    else {\n      var dir = path.dirname(file);\n\n      exists(dir, function(dirExists) {\n        if (!dirExists) {\n          mkdir.mkdirs(dir, function(err) {\n            if (err)\n              callback(err)\n            else\n              makeFile();\n          })\n        } else {\n          makeFile();\n        }\n      })\n    }\n  })\n}\n\n\nfunction createFileSync (file) {\n  if (existsSync(file))\n    return;\n\n  var dir = path.dirname(file);\n  if (!existsSync(dir))\n    mkdir.mkdirsSync(dir);\n\n  fs.writeFileSync(file, '');\n}\n\n\nmodule.exports.createFile = createFile;\nmodule.exports.createFileSync = createFileSync;",
              "globals": {
                "mkdir": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "path": {
                  "type": "assign"
                },
                "fs": {
                  "type": "assign"
                },
                "exists": {
                  "type": "assign"
                },
                "existsSync": {
                  "type": "assign"
                },
                "createFile": {
                  "type": "assign"
                },
                "createFileSync": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./mkdir": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar mkdir = require('./mkdir')\n  , path = require('__SYSTEM__/path')\n  , fs = require('__SYSTEM__/fs')\n  , exists = fs.exists || path.exists\n  , existsSync = fs.existsSync || path.existsSync\n\nfunction createFile (file, callback) {\n  function makeFile() {\n    fs.writeFile(file, '', function(err) {\n      if (err)\n        callback(err)\n      else\n        callback(null);\n    })\n  }\n\n  exists(file, function(fileExists) {\n    if (fileExists)\n      return callback(null);\n    else {\n      var dir = path.dirname(file);\n\n      exists(dir, function(dirExists) {\n        if (!dirExists) {\n          mkdir.mkdirs(dir, function(err) {\n            if (err)\n              callback(err)\n            else\n              makeFile();\n          })\n        } else {\n          makeFile();\n        }\n      })\n    }\n  })\n}\n\n\nfunction createFileSync (file) {\n  if (existsSync(file))\n    return;\n\n  var dir = path.dirname(file);\n  if (!existsSync(dir))\n    mkdir.mkdirsSync(dir);\n\n  fs.writeFileSync(file, '');\n}\n\n\nmodule.exports.createFile = createFile;\nmodule.exports.createFileSync = createFileSync;\nreturn {\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    exists: (typeof exists !== \"undefined\") ? exists : null,\n    existsSync: (typeof existsSync !== \"undefined\") ? existsSync : null,\n    createFile: (typeof createFile !== \"undefined\") ? createFile : null,\n    createFileSync: (typeof createFileSync !== \"undefined\") ? createFileSync : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    exists: (typeof exists !== \"undefined\") ? exists : null,\n    existsSync: (typeof existsSync !== \"undefined\") ? existsSync : null,\n    createFile: (typeof createFile !== \"undefined\") ? createFile : null,\n    createFileSync: (typeof createFileSync !== \"undefined\") ? createFileSync : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./mkdir": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/output.js": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/output",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/output.js",
            "descriptor": {
              "filename": "output.js",
              "filepath": "node_modules/fs-extra/lib/output.js",
              "mtime": 1368545747,
              "code": "\"use strict\"\n\nvar mkdir = require('./mkdir')\n  , path = require('path')\n  , fs = require('fs')\n  , exists = fs.exists || path.exists\n  , existsSync = fs.existsSync || path.existsSync\n\nfunction outputFile (file, data, encoding, callback) {\n  if (typeof encoding === 'function') {\n    callback = encoding\n    encoding = 'utf8'\n  }\n\n  var dir = path.dirname(file)\n  exists(dir, function(itDoes) {\n    if (itDoes) return fs.writeFile(file, data, encoding, callback)\n\n    mkdir.mkdirs(dir, function(err) {\n      if (err) return callback(err)\n\n      fs.writeFile(file, data, encoding, callback)\n    })\n  })\n}\n\n\nfunction outputFileSync (file, data, encoding) {\n  var dir = path.dirname(file)\n  if (existsSync(dir)) return fs.writeFileSync.apply(fs, arguments)\n  mkdir.mkdirsSync(dir)\n  fs.writeFileSync.apply(fs, arguments)\n}\n\n\nmodule.exports.outputFile = outputFile;\nmodule.exports.outputFileSync = outputFileSync;",
              "globals": {
                "mkdir": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "path": {
                  "type": "assign"
                },
                "fs": {
                  "type": "assign"
                },
                "exists": {
                  "type": "assign"
                },
                "existsSync": {
                  "type": "assign"
                },
                "outputFile": {
                  "type": "assign"
                },
                "outputFileSync": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./mkdir": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/fs-extra/lib';\n\"use strict\"\n\nvar mkdir = require('./mkdir')\n  , path = require('__SYSTEM__/path')\n  , fs = require('__SYSTEM__/fs')\n  , exists = fs.exists || path.exists\n  , existsSync = fs.existsSync || path.existsSync\n\nfunction outputFile (file, data, encoding, callback) {\n  if (typeof encoding === 'function') {\n    callback = encoding\n    encoding = 'utf8'\n  }\n\n  var dir = path.dirname(file)\n  exists(dir, function(itDoes) {\n    if (itDoes) return fs.writeFile(file, data, encoding, callback)\n\n    mkdir.mkdirs(dir, function(err) {\n      if (err) return callback(err)\n\n      fs.writeFile(file, data, encoding, callback)\n    })\n  })\n}\n\n\nfunction outputFileSync (file, data, encoding) {\n  var dir = path.dirname(file)\n  if (existsSync(dir)) return fs.writeFileSync.apply(fs, arguments)\n  mkdir.mkdirsSync(dir)\n  fs.writeFileSync.apply(fs, arguments)\n}\n\n\nmodule.exports.outputFile = outputFile;\nmodule.exports.outputFileSync = outputFileSync;\nreturn {\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    exists: (typeof exists !== \"undefined\") ? exists : null,\n    existsSync: (typeof existsSync !== \"undefined\") ? existsSync : null,\n    outputFile: (typeof outputFile !== \"undefined\") ? outputFile : null,\n    outputFileSync: (typeof outputFileSync !== \"undefined\") ? outputFileSync : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    mkdir: (typeof mkdir !== \"undefined\") ? mkdir : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    exists: (typeof exists !== \"undefined\") ? exists : null,\n    existsSync: (typeof existsSync !== \"undefined\") ? existsSync : null,\n    outputFile: (typeof outputFile !== \"undefined\") ? outputFile : null,\n    outputFileSync: (typeof outputFileSync !== \"undefined\") ? outputFileSync : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./mkdir": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/index.js": {
            "requireId": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/index.js",
            "memoizeId": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/index.js",
              "mtime": 1367357303,
              "code": "// Copyright 2010-2012 Mikeal Rogers\n//\n//    Licensed under the Apache License, Version 2.0 (the \"License\");\n//    you may not use this file except in compliance with the License.\n//    You may obtain a copy of the License at\n//\n//        http://www.apache.org/licenses/LICENSE-2.0\n//\n//    Unless required by applicable law or agreed to in writing, software\n//    distributed under the License is distributed on an \"AS IS\" BASIS,\n//    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//    See the License for the specific language governing permissions and\n//    limitations under the License.\n\nvar http = require('http')\n  , https = false\n  , tls = false\n  , url = require('url')\n  , util = require('util')\n  , stream = require('stream')\n  , qs = require('qs')\n  , querystring = require('querystring')\n  , crypto = require('crypto')\n\n  , oauth = require('oauth-sign')\n  , hawk = require('hawk')\n  , aws = require('aws-sign')\n  , httpSignature = require('http-signature')\n  , uuid = require('node-uuid')\n  , mime = require('mime')\n  , tunnel = require('tunnel-agent')\n  , safeStringify = require('json-stringify-safe')\n\n  , ForeverAgent = require('forever-agent')\n  , FormData = require('form-data')\n\n  , Cookie = require('cookie-jar')\n  , CookieJar = Cookie.Jar\n  , cookieJar = new CookieJar\n  ;\n\ntry {\n  https = require('https')\n} catch (e) {}\n\ntry {\n  tls = require('tls')\n} catch (e) {}\n\nvar debug\nif (/\\brequest\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    console.error('REQUEST %s', util.format.apply(util, arguments))\n  }\n} else {\n  debug = function() {}\n}\n\nfunction toBase64 (str) {\n  return (new Buffer(str || \"\", \"ascii\")).toString(\"base64\")\n}\n\nfunction md5 (str) {\n  return crypto.createHash('md5').update(str).digest('hex')\n}\n\n// Hacky fix for pre-0.4.4 https\nif (https && !https.Agent) {\n  https.Agent = function (options) {\n    http.Agent.call(this, options)\n  }\n  util.inherits(https.Agent, http.Agent)\n  https.Agent.prototype._getConnection = function (host, port, cb) {\n    var s = tls.connect(port, host, this.options, function () {\n      // do other checks here?\n      if (cb) cb()\n    })\n    return s\n  }\n}\n\nfunction isReadStream (rs) {\n  if (rs.readable && rs.path && rs.mode) {\n    return true\n  }\n}\n\nfunction copy (obj) {\n  var o = {}\n  Object.keys(obj).forEach(function (i) {\n    o[i] = obj[i]\n  })\n  return o\n}\n\nvar isUrl = /^https?:/\n\nvar globalPool = {}\n\nfunction Request (options) {\n  stream.Stream.call(this)\n  this.readable = true\n  this.writable = true\n\n  if (typeof options === 'string') {\n    options = {uri:options}\n  }\n\n  var reserved = Object.keys(Request.prototype)\n  for (var i in options) {\n    if (reserved.indexOf(i) === -1) {\n      this[i] = options[i]\n    } else {\n      if (typeof options[i] === 'function') {\n        delete options[i]\n      }\n    }\n  }\n\n  if (options.method) {\n    this.explicitMethod = true\n  }\n\n  this.init(options)\n}\nutil.inherits(Request, stream.Stream)\nRequest.prototype.init = function (options) {\n  // init() contains all the code to setup the request object.\n  // the actual outgoing request is not started until start() is called\n  // this function is called from both the constructor and on redirect.\n  var self = this\n  if (!options) options = {}\n\n  if (!self.method) self.method = options.method || 'GET'\n  self.localAddress = options.localAddress\n\n  debug(options)\n  if (!self.pool && self.pool !== false) self.pool = globalPool\n  self.dests = self.dests || []\n  self.__isRequestRequest = true\n\n  // Protect against double callback\n  if (!self._callback && self.callback) {\n    self._callback = self.callback\n    self.callback = function () {\n      if (self._callbackCalled) return // Print a warning maybe?\n      self._callbackCalled = true\n      self._callback.apply(self, arguments)\n    }\n    self.on('error', self.callback.bind())\n    self.on('complete', self.callback.bind(self, null))\n  }\n\n  if (self.url) {\n    // People use this property instead all the time so why not just support it.\n    self.uri = self.url\n    delete self.url\n  }\n\n  if (!self.uri) {\n    // this will throw if unhandled but is handleable when in a redirect\n    return self.emit('error', new Error(\"options.uri is a required argument\"))\n  } else {\n    if (typeof self.uri == \"string\") self.uri = url.parse(self.uri)\n  }\n\n  if (self.strictSSL === false) {\n    self.rejectUnauthorized = false\n  }\n\n  if (self.proxy) {\n    if (typeof self.proxy == 'string') self.proxy = url.parse(self.proxy)\n\n    // do the HTTP CONNECT dance using koichik/node-tunnel\n    if (http.globalAgent && self.uri.protocol === \"https:\") {\n      var tunnelFn = self.proxy.protocol === \"http:\"\n                   ? tunnel.httpsOverHttp : tunnel.httpsOverHttps\n\n      var tunnelOptions = { proxy: { host: self.proxy.hostname\n                                   , port: +self.proxy.port\n                                   , proxyAuth: self.proxy.auth\n                                   , headers: { Host: self.uri.hostname + ':' +\n                                        (self.uri.port || self.uri.protocol === 'https:' ? 443 : 80) }}\n                          , rejectUnauthorized: self.rejectUnauthorized\n                          , ca: this.ca }\n\n      self.agent = tunnelFn(tunnelOptions)\n      self.tunnel = true\n    }\n  }\n\n  if (!self.uri.host || !self.uri.pathname) {\n    // Invalid URI: it may generate lot of bad errors, like \"TypeError: Cannot call method 'indexOf' of undefined\" in CookieJar\n    // Detect and reject it as soon as possible\n    var faultyUri = url.format(self.uri)\n    var message = 'Invalid URI \"' + faultyUri + '\"'\n    if (Object.keys(options).length === 0) {\n      // No option ? This can be the sign of a redirect\n      // As this is a case where the user cannot do anything (he didn't call request directly with this URL)\n      // he should be warned that it can be caused by a redirection (can save some hair)\n      message += '. This can be caused by a crappy redirection.'\n    }\n    self.emit('error', new Error(message))\n    return // This error was fatal\n  }\n\n  self._redirectsFollowed = self._redirectsFollowed || 0\n  self.maxRedirects = (self.maxRedirects !== undefined) ? self.maxRedirects : 10\n  self.followRedirect = (self.followRedirect !== undefined) ? self.followRedirect : true\n  self.followAllRedirects = (self.followAllRedirects !== undefined) ? self.followAllRedirects : false\n  if (self.followRedirect || self.followAllRedirects)\n    self.redirects = self.redirects || []\n\n  self.headers = self.headers ? copy(self.headers) : {}\n\n  self.setHost = false\n  if (!(self.headers.host || self.headers.Host)) {\n    self.headers.host = self.uri.hostname\n    if (self.uri.port) {\n      if ( !(self.uri.port === 80 && self.uri.protocol === 'http:') &&\n           !(self.uri.port === 443 && self.uri.protocol === 'https:') )\n      self.headers.host += (':'+self.uri.port)\n    }\n    self.setHost = true\n  }\n\n  self.jar(self._jar || options.jar)\n\n  if (!self.uri.pathname) {self.uri.pathname = '/'}\n  if (!self.uri.port) {\n    if (self.uri.protocol == 'http:') {self.uri.port = 80}\n    else if (self.uri.protocol == 'https:') {self.uri.port = 443}\n  }\n\n  if (self.proxy && !self.tunnel) {\n    self.port = self.proxy.port\n    self.host = self.proxy.hostname\n  } else {\n    self.port = self.uri.port\n    self.host = self.uri.hostname\n  }\n\n  self.clientErrorHandler = function (error) {\n    if (self._aborted) return\n\n    if (self.req && self.req._reusedSocket && error.code === 'ECONNRESET'\n        && self.agent.addRequestNoreuse) {\n      self.agent = { addRequest: self.agent.addRequestNoreuse.bind(self.agent) }\n      self.start()\n      self.req.end()\n      return\n    }\n    if (self.timeout && self.timeoutTimer) {\n      clearTimeout(self.timeoutTimer)\n      self.timeoutTimer = null\n    }\n    self.emit('error', error)\n  }\n\n  self._parserErrorHandler = function (error) {\n    if (this.res) {\n      if (this.res.request) {\n        this.res.request.emit('error', error)\n      } else {\n        this.res.emit('error', error)\n      }\n    } else {\n      this._httpMessage.emit('error', error)\n    }\n  }\n\n  if (options.form) {\n    self.form(options.form)\n  }\n\n  if (options.qs) self.qs(options.qs)\n\n  if (self.uri.path) {\n    self.path = self.uri.path\n  } else {\n    self.path = self.uri.pathname + (self.uri.search || \"\")\n  }\n\n  if (self.path.length === 0) self.path = '/'\n\n\n  // Auth must happen last in case signing is dependent on other headers\n  if (options.oauth) {\n    self.oauth(options.oauth)\n  }\n\n  if (options.aws) {\n    self.aws(options.aws)\n  }\n\n  if (options.hawk) {\n    self.hawk(options.hawk)\n  }\n\n  if (options.httpSignature) {\n    self.httpSignature(options.httpSignature)\n  }\n\n  if (options.auth) {\n    self.auth(\n      (options.auth.user===\"\") ? options.auth.user : (options.auth.user || options.auth.username ),\n      options.auth.pass || options.auth.password,\n      options.auth.sendImmediately)\n  }\n\n  if (self.uri.auth && !self.headers.authorization) {\n    var authPieces = self.uri.auth.split(':').map(function(item){ return querystring.unescape(item) })\n    self.auth(authPieces[0], authPieces.slice(1).join(':'), true)\n  }\n  if (self.proxy && self.proxy.auth && !self.headers['proxy-authorization'] && !self.tunnel) {\n    self.headers['proxy-authorization'] = \"Basic \" + toBase64(self.proxy.auth.split(':').map(function(item){ return querystring.unescape(item)}).join(':'))\n  }\n\n\n  if (self.proxy && !self.tunnel) self.path = (self.uri.protocol + '//' + self.uri.host + self.path)\n\n  if (options.json) {\n    self.json(options.json)\n  } else if (options.multipart) {\n    self.boundary = uuid()\n    self.multipart(options.multipart)\n  }\n\n  if (self.body) {\n    var length = 0\n    if (!Buffer.isBuffer(self.body)) {\n      if (Array.isArray(self.body)) {\n        for (var i = 0; i < self.body.length; i++) {\n          length += self.body[i].length\n        }\n      } else {\n        self.body = new Buffer(self.body)\n        length = self.body.length\n      }\n    } else {\n      length = self.body.length\n    }\n    if (length) {\n      if(!self.headers['content-length'] && !self.headers['Content-Length'])\n      self.headers['content-length'] = length\n    } else {\n      throw new Error('Argument error, options.body.')\n    }\n  }\n\n  var protocol = self.proxy && !self.tunnel ? self.proxy.protocol : self.uri.protocol\n    , defaultModules = {'http:':http, 'https:':https}\n    , httpModules = self.httpModules || {}\n    ;\n  self.httpModule = httpModules[protocol] || defaultModules[protocol]\n\n  if (!self.httpModule) return this.emit('error', new Error(\"Invalid protocol\"))\n\n  if (options.ca) self.ca = options.ca\n\n  if (!self.agent) {\n    if (options.agentOptions) self.agentOptions = options.agentOptions\n\n    if (options.agentClass) {\n      self.agentClass = options.agentClass\n    } else if (options.forever) {\n      self.agentClass = protocol === 'http:' ? ForeverAgent : ForeverAgent.SSL\n    } else {\n      self.agentClass = self.httpModule.Agent\n    }\n  }\n\n  if (self.pool === false) {\n    self.agent = false\n  } else {\n    self.agent = self.agent || self.getAgent()\n    if (self.maxSockets) {\n      // Don't use our pooling if node has the refactored client\n      self.agent.maxSockets = self.maxSockets\n    }\n    if (self.pool.maxSockets) {\n      // Don't use our pooling if node has the refactored client\n      self.agent.maxSockets = self.pool.maxSockets\n    }\n  }\n\n  self.once('pipe', function (src) {\n    if (self.ntick && self._started) throw new Error(\"You cannot pipe to this stream after the outbound request has started.\")\n    self.src = src\n    if (isReadStream(src)) {\n      if (!self.headers['content-type'] && !self.headers['Content-Type'])\n        self.headers['content-type'] = mime.lookup(src.path)\n    } else {\n      if (src.headers) {\n        for (var i in src.headers) {\n          if (!self.headers[i]) {\n            self.headers[i] = src.headers[i]\n          }\n        }\n      }\n      if (self._json && !self.headers['content-type'] && !self.headers['Content-Type'])\n        self.headers['content-type'] = 'application/json'\n      if (src.method && !self.explicitMethod) {\n        self.method = src.method\n      }\n    }\n\n    self.on('pipe', function () {\n      console.error(\"You have already piped to this stream. Pipeing twice is likely to break the request.\")\n    })\n  })\n\n  process.nextTick(function () {\n    if (self._aborted) return\n\n    if (self._form) {\n      self.setHeaders(self._form.getHeaders())\n      self._form.pipe(self)\n    }\n    if (self.body) {\n      if (Array.isArray(self.body)) {\n        self.body.forEach(function (part) {\n          self.write(part)\n        })\n      } else {\n        self.write(self.body)\n      }\n      self.end()\n    } else if (self.requestBodyStream) {\n      console.warn(\"options.requestBodyStream is deprecated, please pass the request object to stream.pipe.\")\n      self.requestBodyStream.pipe(self)\n    } else if (!self.src) {\n      if (self.method !== 'GET' && typeof self.method !== 'undefined') {\n        self.headers['content-length'] = 0\n      }\n      self.end()\n    }\n    self.ntick = true\n  })\n}\n\n// Must call this when following a redirect from https to http or vice versa\n// Attempts to keep everything as identical as possible, but update the\n// httpModule, Tunneling agent, and/or Forever Agent in use.\nRequest.prototype._updateProtocol = function () {\n  var self = this\n  var protocol = self.uri.protocol\n\n  if (protocol === 'https:') {\n    // previously was doing http, now doing https\n    // if it's https, then we might need to tunnel now.\n    if (self.proxy) {\n      self.tunnel = true\n      var tunnelFn = self.proxy.protocol === 'http:'\n                   ? tunnel.httpsOverHttp : tunnel.httpsOverHttps\n      var tunnelOptions = { proxy: { host: self.proxy.hostname\n                                   , port: +self.proxy.port\n                                   , proxyAuth: self.proxy.auth }\n                          , rejectUnauthorized: self.rejectUnauthorized\n                          , ca: self.ca }\n      self.agent = tunnelFn(tunnelOptions)\n      return\n    }\n\n    self.httpModule = https\n    switch (self.agentClass) {\n      case ForeverAgent:\n        self.agentClass = ForeverAgent.SSL\n        break\n      case http.Agent:\n        self.agentClass = https.Agent\n        break\n      default:\n        // nothing we can do.  Just hope for the best.\n        return\n    }\n\n    // if there's an agent, we need to get a new one.\n    if (self.agent) self.agent = self.getAgent()\n\n  } else {\n    // previously was doing https, now doing http\n    // stop any tunneling.\n    if (self.tunnel) self.tunnel = false\n    self.httpModule = http\n    switch (self.agentClass) {\n      case ForeverAgent.SSL:\n        self.agentClass = ForeverAgent\n        break\n      case https.Agent:\n        self.agentClass = http.Agent\n        break\n      default:\n        // nothing we can do.  just hope for the best\n        return\n    }\n\n    // if there's an agent, then get a new one.\n    if (self.agent) {\n      self.agent = null\n      self.agent = self.getAgent()\n    }\n  }\n}\n\nRequest.prototype.getAgent = function () {\n  var Agent = this.agentClass\n  var options = {}\n  if (this.agentOptions) {\n    for (var i in this.agentOptions) {\n      options[i] = this.agentOptions[i]\n    }\n  }\n  if (this.ca) options.ca = this.ca\n  if (typeof this.rejectUnauthorized !== 'undefined') options.rejectUnauthorized = this.rejectUnauthorized\n\n  if (this.cert && this.key) {\n    options.key = this.key\n    options.cert = this.cert\n  }\n\n  var poolKey = ''\n\n  // different types of agents are in different pools\n  if (Agent !== this.httpModule.Agent) {\n    poolKey += Agent.name\n  }\n\n  if (!this.httpModule.globalAgent) {\n    // node 0.4.x\n    options.host = this.host\n    options.port = this.port\n    if (poolKey) poolKey += ':'\n    poolKey += this.host + ':' + this.port\n  }\n\n  // ca option is only relevant if proxy or destination are https\n  var proxy = this.proxy\n  if (typeof proxy === 'string') proxy = url.parse(proxy)\n  var isHttps = (proxy && proxy.protocol === 'https:') || this.uri.protocol === 'https:'\n  if (isHttps) {\n    if (options.ca) {\n      if (poolKey) poolKey += ':'\n      poolKey += options.ca\n    }\n\n    if (typeof options.rejectUnauthorized !== 'undefined') {\n      if (poolKey) poolKey += ':'\n      poolKey += options.rejectUnauthorized\n    }\n\n    if (options.cert)\n      poolKey += options.cert.toString('ascii') + options.key.toString('ascii')\n  }\n\n  if (!poolKey && Agent === this.httpModule.Agent && this.httpModule.globalAgent) {\n    // not doing anything special.  Use the globalAgent\n    return this.httpModule.globalAgent\n  }\n\n  // we're using a stored agent.  Make sure it's protocol-specific\n  poolKey = this.uri.protocol + poolKey\n\n  // already generated an agent for this setting\n  if (this.pool[poolKey]) return this.pool[poolKey]\n\n  return this.pool[poolKey] = new Agent(options)\n}\n\nRequest.prototype.start = function () {\n  // start() is called once we are ready to send the outgoing HTTP request.\n  // this is usually called on the first write(), end() or on nextTick()\n  var self = this\n\n  if (self._aborted) return\n\n  self._started = true\n  self.method = self.method || 'GET'\n  self.href = self.uri.href\n\n  if (self.src && self.src.stat && self.src.stat.size && !self.headers['content-length'] && !self.headers['Content-Length']) {\n    self.headers['content-length'] = self.src.stat.size\n  }\n  if (self._aws) {\n    self.aws(self._aws, true)\n  }\n\n  // We have a method named auth, which is completely different from the http.request\n  // auth option.  If we don't remove it, we're gonna have a bad time.\n  var reqOptions = copy(self)\n  delete reqOptions.auth\n\n  debug('make request', self.uri.href)\n  self.req = self.httpModule.request(reqOptions, self.onResponse.bind(self))\n\n  if (self.timeout && !self.timeoutTimer) {\n    self.timeoutTimer = setTimeout(function () {\n      self.req.abort()\n      var e = new Error(\"ETIMEDOUT\")\n      e.code = \"ETIMEDOUT\"\n      self.emit(\"error\", e)\n    }, self.timeout)\n\n    // Set additional timeout on socket - in case if remote\n    // server freeze after sending headers\n    if (self.req.setTimeout) { // only works on node 0.6+\n      self.req.setTimeout(self.timeout, function () {\n        if (self.req) {\n          self.req.abort()\n          var e = new Error(\"ESOCKETTIMEDOUT\")\n          e.code = \"ESOCKETTIMEDOUT\"\n          self.emit(\"error\", e)\n        }\n      })\n    }\n  }\n\n  self.req.on('error', self.clientErrorHandler)\n  self.req.on('drain', function() {\n    self.emit('drain')\n  })\n  self.on('end', function() {\n    if ( self.req.connection ) self.req.connection.removeListener('error', self._parserErrorHandler)\n  })\n  self.emit('request', self.req)\n}\nRequest.prototype.onResponse = function (response) {\n  var self = this\n  debug('onResponse', self.uri.href, response.statusCode, response.headers)\n  response.on('end', function() {\n    debug('response end', self.uri.href, response.statusCode, response.headers)\n  });\n\n  if (response.connection.listeners('error').indexOf(self._parserErrorHandler) === -1) {\n    response.connection.once('error', self._parserErrorHandler)\n  }\n  if (self._aborted) {\n    debug('aborted', self.uri.href)\n    response.resume()\n    return\n  }\n  if (self._paused) response.pause()\n  else response.resume()\n\n  self.response = response\n  response.request = self\n  response.toJSON = toJSON\n\n  // XXX This is different on 0.10, because SSL is strict by default\n  if (self.httpModule === https &&\n      self.strictSSL &&\n      !response.client.authorized) {\n    debug('strict ssl error', self.uri.href)\n    var sslErr = response.client.authorizationError\n    self.emit('error', new Error('SSL Error: '+ sslErr))\n    return\n  }\n\n  if (self.setHost) delete self.headers.host\n  if (self.timeout && self.timeoutTimer) {\n    clearTimeout(self.timeoutTimer)\n    self.timeoutTimer = null\n  }\n\n  var addCookie = function (cookie) {\n    if (self._jar) self._jar.add(new Cookie(cookie))\n    else cookieJar.add(new Cookie(cookie))\n  }\n\n  if (response.headers['set-cookie'] && (!self._disableCookies)) {\n    if (Array.isArray(response.headers['set-cookie'])) response.headers['set-cookie'].forEach(addCookie)\n    else addCookie(response.headers['set-cookie'])\n  }\n\n  var redirectTo = null\n  if (response.statusCode >= 300 && response.statusCode < 400 && response.headers.location) {\n    debug('redirect', response.headers.location)\n\n    if (self.followAllRedirects) {\n      redirectTo = response.headers.location\n    } else if (self.followRedirect) {\n      switch (self.method) {\n        case 'PATCH':\n        case 'PUT':\n        case 'POST':\n        case 'DELETE':\n          // Do not follow redirects\n          break\n        default:\n          redirectTo = response.headers.location\n          break\n      }\n    }\n  } else if (response.statusCode == 401 && self._hasAuth && !self._sentAuth) {\n    var authHeader = response.headers['www-authenticate']\n    var authVerb = authHeader && authHeader.split(' ')[0]\n    debug('reauth', authVerb)\n\n    switch (authVerb) {\n      case 'Basic':\n        self.auth(self._user, self._pass, true)\n        redirectTo = self.uri\n        break\n\n      case 'Digest':\n        // TODO: More complete implementation of RFC 2617.  For reference:\n        // http://tools.ietf.org/html/rfc2617#section-3\n        // https://github.com/bagder/curl/blob/master/lib/http_digest.c\n\n        var matches = authHeader.match(/([a-z0-9_-]+)=\"([^\"]+)\"/gi)\n        var challenge = {}\n\n        for (var i = 0; i < matches.length; i++) {\n          var eqPos = matches[i].indexOf('=')\n          var key = matches[i].substring(0, eqPos)\n          var quotedValue = matches[i].substring(eqPos + 1)\n          challenge[key] = quotedValue.substring(1, quotedValue.length - 1)\n        }\n\n        var ha1 = md5(self._user + ':' + challenge.realm + ':' + self._pass)\n        var ha2 = md5(self.method + ':' + self.uri.path)\n        var digestResponse = md5(ha1 + ':' + challenge.nonce + ':1::auth:' + ha2)\n        var authValues = {\n          username: self._user,\n          realm: challenge.realm,\n          nonce: challenge.nonce,\n          uri: self.uri.path,\n          qop: challenge.qop,\n          response: digestResponse,\n          nc: 1,\n          cnonce: ''\n        }\n\n        authHeader = []\n        for (var k in authValues) {\n          authHeader.push(k + '=\"' + authValues[k] + '\"')\n        }\n        authHeader = 'Digest ' + authHeader.join(', ')\n        self.setHeader('authorization', authHeader)\n        self._sentAuth = true\n\n        redirectTo = self.uri\n        break\n    }\n  }\n\n  if (redirectTo) {\n    debug('redirect to', redirectTo)\n\n    // ignore any potential response body.  it cannot possibly be useful\n    // to us at this point.\n    if (self._paused) response.resume()\n\n    if (self._redirectsFollowed >= self.maxRedirects) {\n      self.emit('error', new Error(\"Exceeded maxRedirects. Probably stuck in a redirect loop \"+self.uri.href))\n      return\n    }\n    self._redirectsFollowed += 1\n\n    if (!isUrl.test(redirectTo)) {\n      redirectTo = url.resolve(self.uri.href, redirectTo)\n    }\n\n    var uriPrev = self.uri\n    self.uri = url.parse(redirectTo)\n\n    // handle the case where we change protocol from https to http or vice versa\n    if (self.uri.protocol !== uriPrev.protocol) {\n      self._updateProtocol()\n    }\n\n    self.redirects.push(\n      { statusCode : response.statusCode\n      , redirectUri: redirectTo\n      }\n    )\n    if (self.followAllRedirects && response.statusCode != 401) self.method = 'GET'\n    // self.method = 'GET' // Force all redirects to use GET || commented out fixes #215\n    delete self.src\n    delete self.req\n    delete self.agent\n    delete self._started\n    if (response.statusCode != 401) {\n      // Remove parameters from the previous response, unless this is the second request\n      // for a server that requires digest authentication.\n      delete self.body\n      delete self._form\n      if (self.headers) {\n        delete self.headers.host\n        delete self.headers['content-type']\n        delete self.headers['content-length']\n      }\n    }\n\n    self.emit('redirect');\n\n    self.init()\n    return // Ignore the rest of the response\n  } else {\n    self._redirectsFollowed = self._redirectsFollowed || 0\n    // Be a good stream and emit end when the response is finished.\n    // Hack to emit end on close because of a core bug that never fires end\n    response.on('close', function () {\n      if (!self._ended) self.response.emit('end')\n    })\n\n    if (self.encoding) {\n      if (self.dests.length !== 0) {\n        console.error(\"Ingoring encoding parameter as this stream is being piped to another stream which makes the encoding option invalid.\")\n      } else {\n        response.setEncoding(self.encoding)\n      }\n    }\n\n    self.emit('response', response)\n\n    self.dests.forEach(function (dest) {\n      self.pipeDest(dest)\n    })\n\n    response.on(\"data\", function (chunk) {\n      self._destdata = true\n      self.emit(\"data\", chunk)\n    })\n    response.on(\"end\", function (chunk) {\n      self._ended = true\n      self.emit(\"end\", chunk)\n    })\n    response.on(\"close\", function () {self.emit(\"close\")})\n\n    if (self.callback) {\n      var buffer = []\n      var bodyLen = 0\n      self.on(\"data\", function (chunk) {\n        buffer.push(chunk)\n        bodyLen += chunk.length\n      })\n      self.on(\"end\", function () {\n        debug('end event', self.uri.href)\n        if (self._aborted) {\n          debug('aborted', self.uri.href)\n          return\n        }\n\n        if (buffer.length && Buffer.isBuffer(buffer[0])) {\n          debug('has body', self.uri.href, bodyLen)\n          var body = new Buffer(bodyLen)\n          var i = 0\n          buffer.forEach(function (chunk) {\n            chunk.copy(body, i, 0, chunk.length)\n            i += chunk.length\n          })\n          if (self.encoding === null) {\n            response.body = body\n          } else {\n            response.body = body.toString(self.encoding)\n          }\n        } else if (buffer.length) {\n          // The UTF8 BOM [0xEF,0xBB,0xBF] is converted to [0xFE,0xFF] in the JS UTC16/UCS2 representation.\n          // Strip this value out when the encoding is set to 'utf8', as upstream consumers won't expect it and it breaks JSON.parse().\n          if (self.encoding === 'utf8' && buffer[0].length > 0 && buffer[0][0] === \"\\uFEFF\") {\n            buffer[0] = buffer[0].substring(1)\n          }\n          response.body = buffer.join('')\n        }\n\n        if (self._json) {\n          try {\n            response.body = JSON.parse(response.body)\n          } catch (e) {}\n        }\n        debug('emitting complete', self.uri.href)\n        if(response.body == undefined && !self._json) {\n          response.body = \"\";\n        }\n        self.emit('complete', response, response.body)\n      })\n    }\n  }\n  debug('finish init function', self.uri.href)\n}\n\nRequest.prototype.abort = function () {\n  this._aborted = true\n\n  if (this.req) {\n    this.req.abort()\n  }\n  else if (this.response) {\n    this.response.abort()\n  }\n\n  this.emit(\"abort\")\n}\n\nRequest.prototype.pipeDest = function (dest) {\n  var response = this.response\n  // Called after the response is received\n  if (dest.headers) {\n    dest.headers['content-type'] = response.headers['content-type']\n    if (response.headers['content-length']) {\n      dest.headers['content-length'] = response.headers['content-length']\n    }\n  }\n  if (dest.setHeader) {\n    for (var i in response.headers) {\n      dest.setHeader(i, response.headers[i])\n    }\n    dest.statusCode = response.statusCode\n  }\n  if (this.pipefilter) this.pipefilter(response, dest)\n}\n\n// Composable API\nRequest.prototype.setHeader = function (name, value, clobber) {\n  if (clobber === undefined) clobber = true\n  if (clobber || !this.headers.hasOwnProperty(name)) this.headers[name] = value\n  else this.headers[name] += ',' + value\n  return this\n}\nRequest.prototype.setHeaders = function (headers) {\n  for (var i in headers) {this.setHeader(i, headers[i])}\n  return this\n}\nRequest.prototype.qs = function (q, clobber) {\n  var base\n  if (!clobber && this.uri.query) base = qs.parse(this.uri.query)\n  else base = {}\n\n  for (var i in q) {\n    base[i] = q[i]\n  }\n\n  if (qs.stringify(base) === ''){\n    return this\n  }\n\n  this.uri = url.parse(this.uri.href.split('?')[0] + '?' + qs.stringify(base))\n  this.url = this.uri\n  this.path = this.uri.path\n\n  return this\n}\nRequest.prototype.form = function (form) {\n  if (form) {\n    this.headers['content-type'] = 'application/x-www-form-urlencoded; charset=utf-8'\n    this.body = qs.stringify(form).toString('utf8')\n    return this\n  }\n  // create form-data object\n  this._form = new FormData()\n  return this._form\n}\nRequest.prototype.multipart = function (multipart) {\n  var self = this\n  self.body = []\n\n  if (!self.headers['content-type']) {\n    self.headers['content-type'] = 'multipart/related; boundary=' + self.boundary\n  } else {\n    self.headers['content-type'] = self.headers['content-type'].split(';')[0] + '; boundary=' + self.boundary\n  }\n\n  if (!multipart.forEach) throw new Error('Argument error, options.multipart.')\n\n  if (self.preambleCRLF) {\n    self.body.push(new Buffer('\\r\\n'))\n  }\n\n  multipart.forEach(function (part) {\n    var body = part.body\n    if(body == null) throw Error('Body attribute missing in multipart.')\n    delete part.body\n    var preamble = '--' + self.boundary + '\\r\\n'\n    Object.keys(part).forEach(function (key) {\n      preamble += key + ': ' + part[key] + '\\r\\n'\n    })\n    preamble += '\\r\\n'\n    self.body.push(new Buffer(preamble))\n    self.body.push(new Buffer(body))\n    self.body.push(new Buffer('\\r\\n'))\n  })\n  self.body.push(new Buffer('--' + self.boundary + '--'))\n  return self\n}\nRequest.prototype.json = function (val) {\n  var self = this;\n  var setAcceptHeader = function() {\n  \tif (!self.headers['accept'] && !self.headers['Accept']) {\n\t\t\t  self.setHeader('accept', 'application/json')\n\t\t}\n\t}\n  setAcceptHeader();\n  this._json = true\n  if (typeof val === 'boolean') {\n    if (typeof this.body === 'object') {\n      setAcceptHeader();\n      this.body = safeStringify(this.body)\n      self.setHeader('content-type', 'application/json')\n    }\n  } else {\n    setAcceptHeader();\n    this.body = safeStringify(val)\n    self.setHeader('content-type', 'application/json')\n  }\n  return this\n}\nfunction getHeader(name, headers) {\n    var result, re, match\n    Object.keys(headers).forEach(function (key) {\n        re = new RegExp(name, 'i')\n        match = key.match(re)\n        if (match) result = headers[key]\n    })\n    return result\n}\nRequest.prototype.auth = function (user, pass, sendImmediately) {\n  if (typeof user !== 'string' || (pass !== undefined && typeof pass !== 'string')) {\n    throw new Error('auth() received invalid user or password')\n  }\n  this._user = user\n  this._pass = pass\n  this._hasAuth = true\n  if (sendImmediately || typeof sendImmediately == 'undefined') {\n    this.setHeader('authorization', 'Basic ' + toBase64(user + ':' + pass))\n    this._sentAuth = true\n  }\n  return this\n}\nRequest.prototype.aws = function (opts, now) {\n  if (!now) {\n    this._aws = opts\n    return this\n  }\n  var date = new Date()\n  this.setHeader('date', date.toUTCString())\n  var auth =\n    { key: opts.key\n    , secret: opts.secret\n    , verb: this.method.toUpperCase()\n    , date: date\n    , contentType: getHeader('content-type', this.headers) || ''\n    , md5: getHeader('content-md5', this.headers) || ''\n    , amazonHeaders: aws.canonicalizeHeaders(this.headers)\n    }\n  if (opts.bucket && this.path) {\n    auth.resource = '/' + opts.bucket + this.path\n  } else if (opts.bucket && !this.path) {\n    auth.resource = '/' + opts.bucket\n  } else if (!opts.bucket && this.path) {\n    auth.resource = this.path\n  } else if (!opts.bucket && !this.path) {\n    auth.resource = '/'\n  }\n  auth.resource = aws.canonicalizeResource(auth.resource)\n  this.setHeader('authorization', aws.authorization(auth))\n\n  return this\n}\nRequest.prototype.httpSignature = function (opts) {\n  var req = this\n  httpSignature.signRequest({\n    getHeader: function(header) {\n      return getHeader(header, req.headers)\n    },\n    setHeader: function(header, value) {\n      req.setHeader(header, value)\n    },\n    method: this.method,\n    path: this.path\n  }, opts)\n  debug('httpSignature authorization', getHeader('authorization', this.headers))\n\n  return this\n}\n\nRequest.prototype.hawk = function (opts) {\n  this.headers.Authorization = hawk.client.header(this.uri, this.method, opts).field\n}\n\nRequest.prototype.oauth = function (_oauth) {\n  var form\n  if (this.headers['content-type'] &&\n      this.headers['content-type'].slice(0, 'application/x-www-form-urlencoded'.length) ===\n        'application/x-www-form-urlencoded'\n     ) {\n    form = qs.parse(this.body)\n  }\n  if (this.uri.query) {\n    form = qs.parse(this.uri.query)\n  }\n  if (!form) form = {}\n  var oa = {}\n  for (var i in form) oa[i] = form[i]\n  for (var i in _oauth) oa['oauth_'+i] = _oauth[i]\n  if (!oa.oauth_version) oa.oauth_version = '1.0'\n  if (!oa.oauth_timestamp) oa.oauth_timestamp = Math.floor( Date.now() / 1000 ).toString()\n  if (!oa.oauth_nonce) oa.oauth_nonce = uuid().replace(/-/g, '')\n\n  oa.oauth_signature_method = 'HMAC-SHA1'\n\n  var consumer_secret = oa.oauth_consumer_secret\n  delete oa.oauth_consumer_secret\n  var token_secret = oa.oauth_token_secret\n  delete oa.oauth_token_secret\n  var timestamp = oa.oauth_timestamp\n\n  var baseurl = this.uri.protocol + '//' + this.uri.host + this.uri.pathname\n  var signature = oauth.hmacsign(this.method, baseurl, oa, consumer_secret, token_secret)\n\n  // oa.oauth_signature = signature\n  for (var i in form) {\n    if ( i.slice(0, 'oauth_') in _oauth) {\n      // skip\n    } else {\n      delete oa['oauth_'+i]\n      if (i !== 'x_auth_mode') delete oa[i]\n    }\n  }\n  oa.oauth_timestamp = timestamp\n  this.headers.Authorization =\n    'OAuth '+Object.keys(oa).sort().map(function (i) {return i+'=\"'+oauth.rfc3986(oa[i])+'\"'}).join(',')\n  this.headers.Authorization += ',oauth_signature=\"' + oauth.rfc3986(signature) + '\"'\n  return this\n}\nRequest.prototype.jar = function (jar) {\n  var cookies\n\n  if (this._redirectsFollowed === 0) {\n    this.originalCookieHeader = this.headers.cookie\n  }\n\n  if (jar === false) {\n    // disable cookies\n    cookies = false\n    this._disableCookies = true\n  } else if (jar) {\n    // fetch cookie from the user defined cookie jar\n    cookies = jar.get({ url: this.uri.href })\n  } else {\n    // fetch cookie from the global cookie jar\n    cookies = cookieJar.get({ url: this.uri.href })\n  }\n\n  if (cookies && cookies.length) {\n    var cookieString = cookies.map(function (c) {\n      return c.name + \"=\" + c.value\n    }).join(\"; \")\n\n    if (this.originalCookieHeader) {\n      // Don't overwrite existing Cookie header\n      this.headers.cookie = this.originalCookieHeader + '; ' + cookieString\n    } else {\n      this.headers.cookie = cookieString\n    }\n  }\n  this._jar = jar\n  return this\n}\n\n\n// Stream API\nRequest.prototype.pipe = function (dest, opts) {\n  if (this.response) {\n    if (this._destdata) {\n      throw new Error(\"You cannot pipe after data has been emitted from the response.\")\n    } else if (this._ended) {\n      throw new Error(\"You cannot pipe after the response has been ended.\")\n    } else {\n      stream.Stream.prototype.pipe.call(this, dest, opts)\n      this.pipeDest(dest)\n      return dest\n    }\n  } else {\n    this.dests.push(dest)\n    stream.Stream.prototype.pipe.call(this, dest, opts)\n    return dest\n  }\n}\nRequest.prototype.write = function () {\n  if (!this._started) this.start()\n  return this.req.write.apply(this.req, arguments)\n}\nRequest.prototype.end = function (chunk) {\n  if (chunk) this.write(chunk)\n  if (!this._started) this.start()\n  this.req.end()\n}\nRequest.prototype.pause = function () {\n  if (!this.response) this._paused = true\n  else this.response.pause.apply(this.response, arguments)\n}\nRequest.prototype.resume = function () {\n  if (!this.response) this._paused = false\n  else this.response.resume.apply(this.response, arguments)\n}\nRequest.prototype.destroy = function () {\n  if (!this._ended) this.end()\n  else if (this.response) this.response.destroy()\n}\n\n// organize params for patch, post, put, head, del\nfunction initParams(uri, options, callback) {\n  if ((typeof options === 'function') && !callback) callback = options\n  if (options && typeof options === 'object') {\n    options.uri = uri\n  } else if (typeof uri === 'string') {\n    options = {uri:uri}\n  } else {\n    options = uri\n    uri = options.uri\n  }\n  return { uri: uri, options: options, callback: callback }\n}\n\nfunction request (uri, options, callback) {\n  if (typeof uri === 'undefined') throw new Error('undefined is not a valid uri or options object.')\n  if ((typeof options === 'function') && !callback) callback = options\n  if (options && typeof options === 'object') {\n    options.uri = uri\n  } else if (typeof uri === 'string') {\n    options = {uri:uri}\n  } else {\n    options = uri\n  }\n\n  options = copy(options)\n\n  if (callback) options.callback = callback\n  var r = new Request(options)\n  return r\n}\n\nmodule.exports = request\n\nrequest.debug = process.env.NODE_DEBUG && /request/.test(process.env.NODE_DEBUG)\n\nrequest.initParams = initParams\n\nrequest.defaults = function (options, requester) {\n  var def = function (method) {\n    var d = function (uri, opts, callback) {\n      var params = initParams(uri, opts, callback)\n      for (var i in options) {\n        if (params.options[i] === undefined) params.options[i] = options[i]\n      }\n      if(typeof requester === 'function') {\n        if(method === request) {\n          method = requester\n        } else {\n          params.options._requester = requester\n        }\n      }\n      return method(params.options, params.callback)\n    }\n    return d\n  }\n  var de = def(request)\n  de.get = def(request.get)\n  de.patch = def(request.patch)\n  de.post = def(request.post)\n  de.put = def(request.put)\n  de.head = def(request.head)\n  de.del = def(request.del)\n  de.cookie = def(request.cookie)\n  de.jar = request.jar\n  return de\n}\n\nrequest.forever = function (agentOptions, optionsArg) {\n  var options = {}\n  if (optionsArg) {\n    for (option in optionsArg) {\n      options[option] = optionsArg[option]\n    }\n  }\n  if (agentOptions) options.agentOptions = agentOptions\n  options.forever = true\n  return request.defaults(options)\n}\n\nrequest.get = request\nrequest.post = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'POST'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.put = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'PUT'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.patch = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'PATCH'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.head = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'HEAD'\n  if (params.options.body ||\n      params.options.requestBodyStream ||\n      (params.options.json && typeof params.options.json !== 'boolean') ||\n      params.options.multipart) {\n    throw new Error(\"HTTP HEAD requests MUST NOT include a request body.\")\n  }\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.del = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'DELETE'\n  if(typeof params.options._requester === 'function') {\n    request = params.options._requester\n  }\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.jar = function () {\n  return new CookieJar\n}\nrequest.cookie = function (str) {\n  if (str && str.uri) str = str.uri\n  if (typeof str !== 'string') throw new Error(\"The cookie function only accepts STRING as param\")\n  return new Cookie(str)\n}\n\n// Safe toJSON\n\nfunction getSafe (self, uuid) {\n  if (typeof self === 'object' || typeof self === 'function') var safe = {}\n  if (Array.isArray(self)) var safe = []\n\n  var recurse = []\n\n  Object.defineProperty(self, uuid, {})\n\n  var attrs = Object.keys(self).filter(function (i) {\n    if (i === uuid) return false\n    if ( (typeof self[i] !== 'object' && typeof self[i] !== 'function') || self[i] === null) return true\n    return !(Object.getOwnPropertyDescriptor(self[i], uuid))\n  })\n\n\n  for (var i=0;i<attrs.length;i++) {\n    if ( (typeof self[attrs[i]] !== 'object' && typeof self[attrs[i]] !== 'function') ||\n          self[attrs[i]] === null\n        ) {\n      safe[attrs[i]] = self[attrs[i]]\n    } else {\n      recurse.push(attrs[i])\n      Object.defineProperty(self[attrs[i]], uuid, {})\n    }\n  }\n\n  for (var i=0;i<recurse.length;i++) {\n    safe[recurse[i]] = getSafe(self[recurse[i]], uuid)\n  }\n\n  return safe\n}\n\nfunction toJSON () {\n  return getSafe(this, '__' + (((1+Math.random())*0x10000)|0).toString(16))\n}\n\nRequest.prototype.toJSON = toJSON\n",
              "globals": {
                "http": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "https": {
                  "type": "assign"
                },
                "tls": {
                  "type": "assign"
                },
                "url": {
                  "type": "assign"
                },
                "util": {
                  "type": "assign"
                },
                "stream": {
                  "type": "assign"
                },
                "qs": {
                  "type": "assign"
                },
                "querystring": {
                  "type": "assign"
                },
                "crypto": {
                  "type": "assign"
                },
                "oauth": {
                  "type": "assign"
                },
                "hawk": {
                  "type": "assign"
                },
                "aws": {
                  "type": "assign"
                },
                "httpSignature": {
                  "type": "assign"
                },
                "uuid": {
                  "type": "assign"
                },
                "mime": {
                  "type": "assign"
                },
                "tunnel": {
                  "type": "assign"
                },
                "safeStringify": {
                  "type": "assign"
                },
                "ForeverAgent": {
                  "type": "assign"
                },
                "FormData": {
                  "type": "assign"
                },
                "Cookie": {
                  "type": "assign"
                },
                "CookieJar": {
                  "type": "assign"
                },
                "cookieJar": {
                  "type": "assign"
                },
                "debug": {
                  "type": "assign"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "toBase64": {
                  "type": "assign"
                },
                "md5": {
                  "type": "assign"
                },
                "isReadStream": {
                  "type": "assign"
                },
                "copy": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "isUrl": {
                  "type": "assign"
                },
                "globalPool": {
                  "type": "assign"
                },
                "Request": {
                  "type": "assign"
                },
                "clearTimeout": {
                  "type": "call"
                },
                "Buffer": {
                  "type": "reference"
                },
                "Array": {
                  "type": "reference"
                },
                "setTimeout": {
                  "type": "call"
                },
                "JSON": {
                  "type": "reference"
                },
                "getHeader": {
                  "type": "assign"
                },
                "Date": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "initParams": {
                  "type": "assign"
                },
                "request": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "getSafe": {
                  "type": "assign"
                },
                "toJSON": {
                  "type": "assign"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "http": {
                    "where": "inline"
                  },
                  "url": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  },
                  "stream": {
                    "where": "inline"
                  },
                  "qs": {
                    "where": "inline"
                  },
                  "querystring": {
                    "where": "inline"
                  },
                  "crypto": {
                    "where": "inline"
                  },
                  "oauth-sign": {
                    "where": "inline"
                  },
                  "hawk": {
                    "where": "inline"
                  },
                  "aws-sign": {
                    "where": "inline"
                  },
                  "http-signature": {
                    "where": "inline"
                  },
                  "node-uuid": {
                    "where": "inline"
                  },
                  "mime": {
                    "where": "inline"
                  },
                  "tunnel-agent": {
                    "where": "inline"
                  },
                  "json-stringify-safe": {
                    "where": "inline"
                  },
                  "forever-agent": {
                    "where": "inline"
                  },
                  "form-data": {
                    "where": "inline"
                  },
                  "cookie-jar": {
                    "where": "inline"
                  },
                  "https": {
                    "where": "inline"
                  },
                  "tls": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request';\n// Copyright 2010-2012 Mikeal Rogers\n//\n//    Licensed under the Apache License, Version 2.0 (the \"License\");\n//    you may not use this file except in compliance with the License.\n//    You may obtain a copy of the License at\n//\n//        http://www.apache.org/licenses/LICENSE-2.0\n//\n//    Unless required by applicable law or agreed to in writing, software\n//    distributed under the License is distributed on an \"AS IS\" BASIS,\n//    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//    See the License for the specific language governing permissions and\n//    limitations under the License.\n\nvar http = require('__SYSTEM__/http')\n  , https = false\n  , tls = false\n  , url = require('__SYSTEM__/url')\n  , util = require('__SYSTEM__/util')\n  , stream = require('__SYSTEM__/stream')\n  , qs = require('qs')\n  , querystring = require('__SYSTEM__/querystring')\n  , crypto = require('__SYSTEM__/crypto')\n\n  , oauth = require('oauth-sign')\n  , hawk = require('hawk')\n  , aws = require('aws-sign')\n  , httpSignature = require('http-signature')\n  , uuid = require('node-uuid')\n  , mime = require('mime')\n  , tunnel = require('tunnel-agent')\n  , safeStringify = require('json-stringify-safe')\n\n  , ForeverAgent = require('forever-agent')\n  , FormData = require('form-data')\n\n  , Cookie = require('cookie-jar')\n  , CookieJar = Cookie.Jar\n  , cookieJar = new CookieJar\n  ;\n\ntry {\n  https = require('__SYSTEM__/https')\n} catch (e) {}\n\ntry {\n  tls = require('__SYSTEM__/tls')\n} catch (e) {}\n\nvar debug\nif (/\\brequest\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    console.error('REQUEST %s', util.format.apply(util, arguments))\n  }\n} else {\n  debug = function() {}\n}\n\nfunction toBase64 (str) {\n  return (new Buffer(str || \"\", \"ascii\")).toString(\"base64\")\n}\n\nfunction md5 (str) {\n  return crypto.createHash('md5').update(str).digest('hex')\n}\n\n// Hacky fix for pre-0.4.4 https\nif (https && !https.Agent) {\n  https.Agent = function (options) {\n    http.Agent.call(this, options)\n  }\n  util.inherits(https.Agent, http.Agent)\n  https.Agent.prototype._getConnection = function (host, port, cb) {\n    var s = tls.connect(port, host, this.options, function () {\n      // do other checks here?\n      if (cb) cb()\n    })\n    return s\n  }\n}\n\nfunction isReadStream (rs) {\n  if (rs.readable && rs.path && rs.mode) {\n    return true\n  }\n}\n\nfunction copy (obj) {\n  var o = {}\n  Object.keys(obj).forEach(function (i) {\n    o[i] = obj[i]\n  })\n  return o\n}\n\nvar isUrl = /^https?:/\n\nvar globalPool = {}\n\nfunction Request (options) {\n  stream.Stream.call(this)\n  this.readable = true\n  this.writable = true\n\n  if (typeof options === 'string') {\n    options = {uri:options}\n  }\n\n  var reserved = Object.keys(Request.prototype)\n  for (var i in options) {\n    if (reserved.indexOf(i) === -1) {\n      this[i] = options[i]\n    } else {\n      if (typeof options[i] === 'function') {\n        delete options[i]\n      }\n    }\n  }\n\n  if (options.method) {\n    this.explicitMethod = true\n  }\n\n  this.init(options)\n}\nutil.inherits(Request, stream.Stream)\nRequest.prototype.init = function (options) {\n  // init() contains all the code to setup the request object.\n  // the actual outgoing request is not started until start() is called\n  // this function is called from both the constructor and on redirect.\n  var self = this\n  if (!options) options = {}\n\n  if (!self.method) self.method = options.method || 'GET'\n  self.localAddress = options.localAddress\n\n  debug(options)\n  if (!self.pool && self.pool !== false) self.pool = globalPool\n  self.dests = self.dests || []\n  self.__isRequestRequest = true\n\n  // Protect against double callback\n  if (!self._callback && self.callback) {\n    self._callback = self.callback\n    self.callback = function () {\n      if (self._callbackCalled) return // Print a warning maybe?\n      self._callbackCalled = true\n      self._callback.apply(self, arguments)\n    }\n    self.on('error', self.callback.bind())\n    self.on('complete', self.callback.bind(self, null))\n  }\n\n  if (self.url) {\n    // People use this property instead all the time so why not just support it.\n    self.uri = self.url\n    delete self.url\n  }\n\n  if (!self.uri) {\n    // this will throw if unhandled but is handleable when in a redirect\n    return self.emit('error', new Error(\"options.uri is a required argument\"))\n  } else {\n    if (typeof self.uri == \"string\") self.uri = url.parse(self.uri)\n  }\n\n  if (self.strictSSL === false) {\n    self.rejectUnauthorized = false\n  }\n\n  if (self.proxy) {\n    if (typeof self.proxy == 'string') self.proxy = url.parse(self.proxy)\n\n    // do the HTTP CONNECT dance using koichik/node-tunnel\n    if (http.globalAgent && self.uri.protocol === \"https:\") {\n      var tunnelFn = self.proxy.protocol === \"http:\"\n                   ? tunnel.httpsOverHttp : tunnel.httpsOverHttps\n\n      var tunnelOptions = { proxy: { host: self.proxy.hostname\n                                   , port: +self.proxy.port\n                                   , proxyAuth: self.proxy.auth\n                                   , headers: { Host: self.uri.hostname + ':' +\n                                        (self.uri.port || self.uri.protocol === 'https:' ? 443 : 80) }}\n                          , rejectUnauthorized: self.rejectUnauthorized\n                          , ca: this.ca }\n\n      self.agent = tunnelFn(tunnelOptions)\n      self.tunnel = true\n    }\n  }\n\n  if (!self.uri.host || !self.uri.pathname) {\n    // Invalid URI: it may generate lot of bad errors, like \"TypeError: Cannot call method 'indexOf' of undefined\" in CookieJar\n    // Detect and reject it as soon as possible\n    var faultyUri = url.format(self.uri)\n    var message = 'Invalid URI \"' + faultyUri + '\"'\n    if (Object.keys(options).length === 0) {\n      // No option ? This can be the sign of a redirect\n      // As this is a case where the user cannot do anything (he didn't call request directly with this URL)\n      // he should be warned that it can be caused by a redirection (can save some hair)\n      message += '. This can be caused by a crappy redirection.'\n    }\n    self.emit('error', new Error(message))\n    return // This error was fatal\n  }\n\n  self._redirectsFollowed = self._redirectsFollowed || 0\n  self.maxRedirects = (self.maxRedirects !== undefined) ? self.maxRedirects : 10\n  self.followRedirect = (self.followRedirect !== undefined) ? self.followRedirect : true\n  self.followAllRedirects = (self.followAllRedirects !== undefined) ? self.followAllRedirects : false\n  if (self.followRedirect || self.followAllRedirects)\n    self.redirects = self.redirects || []\n\n  self.headers = self.headers ? copy(self.headers) : {}\n\n  self.setHost = false\n  if (!(self.headers.host || self.headers.Host)) {\n    self.headers.host = self.uri.hostname\n    if (self.uri.port) {\n      if ( !(self.uri.port === 80 && self.uri.protocol === 'http:') &&\n           !(self.uri.port === 443 && self.uri.protocol === 'https:') )\n      self.headers.host += (':'+self.uri.port)\n    }\n    self.setHost = true\n  }\n\n  self.jar(self._jar || options.jar)\n\n  if (!self.uri.pathname) {self.uri.pathname = '/'}\n  if (!self.uri.port) {\n    if (self.uri.protocol == 'http:') {self.uri.port = 80}\n    else if (self.uri.protocol == 'https:') {self.uri.port = 443}\n  }\n\n  if (self.proxy && !self.tunnel) {\n    self.port = self.proxy.port\n    self.host = self.proxy.hostname\n  } else {\n    self.port = self.uri.port\n    self.host = self.uri.hostname\n  }\n\n  self.clientErrorHandler = function (error) {\n    if (self._aborted) return\n\n    if (self.req && self.req._reusedSocket && error.code === 'ECONNRESET'\n        && self.agent.addRequestNoreuse) {\n      self.agent = { addRequest: self.agent.addRequestNoreuse.bind(self.agent) }\n      self.start()\n      self.req.end()\n      return\n    }\n    if (self.timeout && self.timeoutTimer) {\n      clearTimeout(self.timeoutTimer)\n      self.timeoutTimer = null\n    }\n    self.emit('error', error)\n  }\n\n  self._parserErrorHandler = function (error) {\n    if (this.res) {\n      if (this.res.request) {\n        this.res.request.emit('error', error)\n      } else {\n        this.res.emit('error', error)\n      }\n    } else {\n      this._httpMessage.emit('error', error)\n    }\n  }\n\n  if (options.form) {\n    self.form(options.form)\n  }\n\n  if (options.qs) self.qs(options.qs)\n\n  if (self.uri.path) {\n    self.path = self.uri.path\n  } else {\n    self.path = self.uri.pathname + (self.uri.search || \"\")\n  }\n\n  if (self.path.length === 0) self.path = '/'\n\n\n  // Auth must happen last in case signing is dependent on other headers\n  if (options.oauth) {\n    self.oauth(options.oauth)\n  }\n\n  if (options.aws) {\n    self.aws(options.aws)\n  }\n\n  if (options.hawk) {\n    self.hawk(options.hawk)\n  }\n\n  if (options.httpSignature) {\n    self.httpSignature(options.httpSignature)\n  }\n\n  if (options.auth) {\n    self.auth(\n      (options.auth.user===\"\") ? options.auth.user : (options.auth.user || options.auth.username ),\n      options.auth.pass || options.auth.password,\n      options.auth.sendImmediately)\n  }\n\n  if (self.uri.auth && !self.headers.authorization) {\n    var authPieces = self.uri.auth.split(':').map(function(item){ return querystring.unescape(item) })\n    self.auth(authPieces[0], authPieces.slice(1).join(':'), true)\n  }\n  if (self.proxy && self.proxy.auth && !self.headers['proxy-authorization'] && !self.tunnel) {\n    self.headers['proxy-authorization'] = \"Basic \" + toBase64(self.proxy.auth.split(':').map(function(item){ return querystring.unescape(item)}).join(':'))\n  }\n\n\n  if (self.proxy && !self.tunnel) self.path = (self.uri.protocol + '//' + self.uri.host + self.path)\n\n  if (options.json) {\n    self.json(options.json)\n  } else if (options.multipart) {\n    self.boundary = uuid()\n    self.multipart(options.multipart)\n  }\n\n  if (self.body) {\n    var length = 0\n    if (!Buffer.isBuffer(self.body)) {\n      if (Array.isArray(self.body)) {\n        for (var i = 0; i < self.body.length; i++) {\n          length += self.body[i].length\n        }\n      } else {\n        self.body = new Buffer(self.body)\n        length = self.body.length\n      }\n    } else {\n      length = self.body.length\n    }\n    if (length) {\n      if(!self.headers['content-length'] && !self.headers['Content-Length'])\n      self.headers['content-length'] = length\n    } else {\n      throw new Error('Argument error, options.body.')\n    }\n  }\n\n  var protocol = self.proxy && !self.tunnel ? self.proxy.protocol : self.uri.protocol\n    , defaultModules = {'http:':http, 'https:':https}\n    , httpModules = self.httpModules || {}\n    ;\n  self.httpModule = httpModules[protocol] || defaultModules[protocol]\n\n  if (!self.httpModule) return this.emit('error', new Error(\"Invalid protocol\"))\n\n  if (options.ca) self.ca = options.ca\n\n  if (!self.agent) {\n    if (options.agentOptions) self.agentOptions = options.agentOptions\n\n    if (options.agentClass) {\n      self.agentClass = options.agentClass\n    } else if (options.forever) {\n      self.agentClass = protocol === 'http:' ? ForeverAgent : ForeverAgent.SSL\n    } else {\n      self.agentClass = self.httpModule.Agent\n    }\n  }\n\n  if (self.pool === false) {\n    self.agent = false\n  } else {\n    self.agent = self.agent || self.getAgent()\n    if (self.maxSockets) {\n      // Don't use our pooling if node has the refactored client\n      self.agent.maxSockets = self.maxSockets\n    }\n    if (self.pool.maxSockets) {\n      // Don't use our pooling if node has the refactored client\n      self.agent.maxSockets = self.pool.maxSockets\n    }\n  }\n\n  self.once('pipe', function (src) {\n    if (self.ntick && self._started) throw new Error(\"You cannot pipe to this stream after the outbound request has started.\")\n    self.src = src\n    if (isReadStream(src)) {\n      if (!self.headers['content-type'] && !self.headers['Content-Type'])\n        self.headers['content-type'] = mime.lookup(src.path)\n    } else {\n      if (src.headers) {\n        for (var i in src.headers) {\n          if (!self.headers[i]) {\n            self.headers[i] = src.headers[i]\n          }\n        }\n      }\n      if (self._json && !self.headers['content-type'] && !self.headers['Content-Type'])\n        self.headers['content-type'] = 'application/json'\n      if (src.method && !self.explicitMethod) {\n        self.method = src.method\n      }\n    }\n\n    self.on('pipe', function () {\n      console.error(\"You have already piped to this stream. Pipeing twice is likely to break the request.\")\n    })\n  })\n\n  process.nextTick(function () {\n    if (self._aborted) return\n\n    if (self._form) {\n      self.setHeaders(self._form.getHeaders())\n      self._form.pipe(self)\n    }\n    if (self.body) {\n      if (Array.isArray(self.body)) {\n        self.body.forEach(function (part) {\n          self.write(part)\n        })\n      } else {\n        self.write(self.body)\n      }\n      self.end()\n    } else if (self.requestBodyStream) {\n      console.warn(\"options.requestBodyStream is deprecated, please pass the request object to stream.pipe.\")\n      self.requestBodyStream.pipe(self)\n    } else if (!self.src) {\n      if (self.method !== 'GET' && typeof self.method !== 'undefined') {\n        self.headers['content-length'] = 0\n      }\n      self.end()\n    }\n    self.ntick = true\n  })\n}\n\n// Must call this when following a redirect from https to http or vice versa\n// Attempts to keep everything as identical as possible, but update the\n// httpModule, Tunneling agent, and/or Forever Agent in use.\nRequest.prototype._updateProtocol = function () {\n  var self = this\n  var protocol = self.uri.protocol\n\n  if (protocol === 'https:') {\n    // previously was doing http, now doing https\n    // if it's https, then we might need to tunnel now.\n    if (self.proxy) {\n      self.tunnel = true\n      var tunnelFn = self.proxy.protocol === 'http:'\n                   ? tunnel.httpsOverHttp : tunnel.httpsOverHttps\n      var tunnelOptions = { proxy: { host: self.proxy.hostname\n                                   , port: +self.proxy.port\n                                   , proxyAuth: self.proxy.auth }\n                          , rejectUnauthorized: self.rejectUnauthorized\n                          , ca: self.ca }\n      self.agent = tunnelFn(tunnelOptions)\n      return\n    }\n\n    self.httpModule = https\n    switch (self.agentClass) {\n      case ForeverAgent:\n        self.agentClass = ForeverAgent.SSL\n        break\n      case http.Agent:\n        self.agentClass = https.Agent\n        break\n      default:\n        // nothing we can do.  Just hope for the best.\n        return\n    }\n\n    // if there's an agent, we need to get a new one.\n    if (self.agent) self.agent = self.getAgent()\n\n  } else {\n    // previously was doing https, now doing http\n    // stop any tunneling.\n    if (self.tunnel) self.tunnel = false\n    self.httpModule = http\n    switch (self.agentClass) {\n      case ForeverAgent.SSL:\n        self.agentClass = ForeverAgent\n        break\n      case https.Agent:\n        self.agentClass = http.Agent\n        break\n      default:\n        // nothing we can do.  just hope for the best\n        return\n    }\n\n    // if there's an agent, then get a new one.\n    if (self.agent) {\n      self.agent = null\n      self.agent = self.getAgent()\n    }\n  }\n}\n\nRequest.prototype.getAgent = function () {\n  var Agent = this.agentClass\n  var options = {}\n  if (this.agentOptions) {\n    for (var i in this.agentOptions) {\n      options[i] = this.agentOptions[i]\n    }\n  }\n  if (this.ca) options.ca = this.ca\n  if (typeof this.rejectUnauthorized !== 'undefined') options.rejectUnauthorized = this.rejectUnauthorized\n\n  if (this.cert && this.key) {\n    options.key = this.key\n    options.cert = this.cert\n  }\n\n  var poolKey = ''\n\n  // different types of agents are in different pools\n  if (Agent !== this.httpModule.Agent) {\n    poolKey += Agent.name\n  }\n\n  if (!this.httpModule.globalAgent) {\n    // node 0.4.x\n    options.host = this.host\n    options.port = this.port\n    if (poolKey) poolKey += ':'\n    poolKey += this.host + ':' + this.port\n  }\n\n  // ca option is only relevant if proxy or destination are https\n  var proxy = this.proxy\n  if (typeof proxy === 'string') proxy = url.parse(proxy)\n  var isHttps = (proxy && proxy.protocol === 'https:') || this.uri.protocol === 'https:'\n  if (isHttps) {\n    if (options.ca) {\n      if (poolKey) poolKey += ':'\n      poolKey += options.ca\n    }\n\n    if (typeof options.rejectUnauthorized !== 'undefined') {\n      if (poolKey) poolKey += ':'\n      poolKey += options.rejectUnauthorized\n    }\n\n    if (options.cert)\n      poolKey += options.cert.toString('ascii') + options.key.toString('ascii')\n  }\n\n  if (!poolKey && Agent === this.httpModule.Agent && this.httpModule.globalAgent) {\n    // not doing anything special.  Use the globalAgent\n    return this.httpModule.globalAgent\n  }\n\n  // we're using a stored agent.  Make sure it's protocol-specific\n  poolKey = this.uri.protocol + poolKey\n\n  // already generated an agent for this setting\n  if (this.pool[poolKey]) return this.pool[poolKey]\n\n  return this.pool[poolKey] = new Agent(options)\n}\n\nRequest.prototype.start = function () {\n  // start() is called once we are ready to send the outgoing HTTP request.\n  // this is usually called on the first write(), end() or on nextTick()\n  var self = this\n\n  if (self._aborted) return\n\n  self._started = true\n  self.method = self.method || 'GET'\n  self.href = self.uri.href\n\n  if (self.src && self.src.stat && self.src.stat.size && !self.headers['content-length'] && !self.headers['Content-Length']) {\n    self.headers['content-length'] = self.src.stat.size\n  }\n  if (self._aws) {\n    self.aws(self._aws, true)\n  }\n\n  // We have a method named auth, which is completely different from the http.request\n  // auth option.  If we don't remove it, we're gonna have a bad time.\n  var reqOptions = copy(self)\n  delete reqOptions.auth\n\n  debug('make request', self.uri.href)\n  self.req = self.httpModule.request(reqOptions, self.onResponse.bind(self))\n\n  if (self.timeout && !self.timeoutTimer) {\n    self.timeoutTimer = setTimeout(function () {\n      self.req.abort()\n      var e = new Error(\"ETIMEDOUT\")\n      e.code = \"ETIMEDOUT\"\n      self.emit(\"error\", e)\n    }, self.timeout)\n\n    // Set additional timeout on socket - in case if remote\n    // server freeze after sending headers\n    if (self.req.setTimeout) { // only works on node 0.6+\n      self.req.setTimeout(self.timeout, function () {\n        if (self.req) {\n          self.req.abort()\n          var e = new Error(\"ESOCKETTIMEDOUT\")\n          e.code = \"ESOCKETTIMEDOUT\"\n          self.emit(\"error\", e)\n        }\n      })\n    }\n  }\n\n  self.req.on('error', self.clientErrorHandler)\n  self.req.on('drain', function() {\n    self.emit('drain')\n  })\n  self.on('end', function() {\n    if ( self.req.connection ) self.req.connection.removeListener('error', self._parserErrorHandler)\n  })\n  self.emit('request', self.req)\n}\nRequest.prototype.onResponse = function (response) {\n  var self = this\n  debug('onResponse', self.uri.href, response.statusCode, response.headers)\n  response.on('end', function() {\n    debug('response end', self.uri.href, response.statusCode, response.headers)\n  });\n\n  if (response.connection.listeners('error').indexOf(self._parserErrorHandler) === -1) {\n    response.connection.once('error', self._parserErrorHandler)\n  }\n  if (self._aborted) {\n    debug('aborted', self.uri.href)\n    response.resume()\n    return\n  }\n  if (self._paused) response.pause()\n  else response.resume()\n\n  self.response = response\n  response.request = self\n  response.toJSON = toJSON\n\n  // XXX This is different on 0.10, because SSL is strict by default\n  if (self.httpModule === https &&\n      self.strictSSL &&\n      !response.client.authorized) {\n    debug('strict ssl error', self.uri.href)\n    var sslErr = response.client.authorizationError\n    self.emit('error', new Error('SSL Error: '+ sslErr))\n    return\n  }\n\n  if (self.setHost) delete self.headers.host\n  if (self.timeout && self.timeoutTimer) {\n    clearTimeout(self.timeoutTimer)\n    self.timeoutTimer = null\n  }\n\n  var addCookie = function (cookie) {\n    if (self._jar) self._jar.add(new Cookie(cookie))\n    else cookieJar.add(new Cookie(cookie))\n  }\n\n  if (response.headers['set-cookie'] && (!self._disableCookies)) {\n    if (Array.isArray(response.headers['set-cookie'])) response.headers['set-cookie'].forEach(addCookie)\n    else addCookie(response.headers['set-cookie'])\n  }\n\n  var redirectTo = null\n  if (response.statusCode >= 300 && response.statusCode < 400 && response.headers.location) {\n    debug('redirect', response.headers.location)\n\n    if (self.followAllRedirects) {\n      redirectTo = response.headers.location\n    } else if (self.followRedirect) {\n      switch (self.method) {\n        case 'PATCH':\n        case 'PUT':\n        case 'POST':\n        case 'DELETE':\n          // Do not follow redirects\n          break\n        default:\n          redirectTo = response.headers.location\n          break\n      }\n    }\n  } else if (response.statusCode == 401 && self._hasAuth && !self._sentAuth) {\n    var authHeader = response.headers['www-authenticate']\n    var authVerb = authHeader && authHeader.split(' ')[0]\n    debug('reauth', authVerb)\n\n    switch (authVerb) {\n      case 'Basic':\n        self.auth(self._user, self._pass, true)\n        redirectTo = self.uri\n        break\n\n      case 'Digest':\n        // TODO: More complete implementation of RFC 2617.  For reference:\n        // http://tools.ietf.org/html/rfc2617#section-3\n        // https://github.com/bagder/curl/blob/master/lib/http_digest.c\n\n        var matches = authHeader.match(/([a-z0-9_-]+)=\"([^\"]+)\"/gi)\n        var challenge = {}\n\n        for (var i = 0; i < matches.length; i++) {\n          var eqPos = matches[i].indexOf('=')\n          var key = matches[i].substring(0, eqPos)\n          var quotedValue = matches[i].substring(eqPos + 1)\n          challenge[key] = quotedValue.substring(1, quotedValue.length - 1)\n        }\n\n        var ha1 = md5(self._user + ':' + challenge.realm + ':' + self._pass)\n        var ha2 = md5(self.method + ':' + self.uri.path)\n        var digestResponse = md5(ha1 + ':' + challenge.nonce + ':1::auth:' + ha2)\n        var authValues = {\n          username: self._user,\n          realm: challenge.realm,\n          nonce: challenge.nonce,\n          uri: self.uri.path,\n          qop: challenge.qop,\n          response: digestResponse,\n          nc: 1,\n          cnonce: ''\n        }\n\n        authHeader = []\n        for (var k in authValues) {\n          authHeader.push(k + '=\"' + authValues[k] + '\"')\n        }\n        authHeader = 'Digest ' + authHeader.join(', ')\n        self.setHeader('authorization', authHeader)\n        self._sentAuth = true\n\n        redirectTo = self.uri\n        break\n    }\n  }\n\n  if (redirectTo) {\n    debug('redirect to', redirectTo)\n\n    // ignore any potential response body.  it cannot possibly be useful\n    // to us at this point.\n    if (self._paused) response.resume()\n\n    if (self._redirectsFollowed >= self.maxRedirects) {\n      self.emit('error', new Error(\"Exceeded maxRedirects. Probably stuck in a redirect loop \"+self.uri.href))\n      return\n    }\n    self._redirectsFollowed += 1\n\n    if (!isUrl.test(redirectTo)) {\n      redirectTo = url.resolve(self.uri.href, redirectTo)\n    }\n\n    var uriPrev = self.uri\n    self.uri = url.parse(redirectTo)\n\n    // handle the case where we change protocol from https to http or vice versa\n    if (self.uri.protocol !== uriPrev.protocol) {\n      self._updateProtocol()\n    }\n\n    self.redirects.push(\n      { statusCode : response.statusCode\n      , redirectUri: redirectTo\n      }\n    )\n    if (self.followAllRedirects && response.statusCode != 401) self.method = 'GET'\n    // self.method = 'GET' // Force all redirects to use GET || commented out fixes #215\n    delete self.src\n    delete self.req\n    delete self.agent\n    delete self._started\n    if (response.statusCode != 401) {\n      // Remove parameters from the previous response, unless this is the second request\n      // for a server that requires digest authentication.\n      delete self.body\n      delete self._form\n      if (self.headers) {\n        delete self.headers.host\n        delete self.headers['content-type']\n        delete self.headers['content-length']\n      }\n    }\n\n    self.emit('redirect');\n\n    self.init()\n    return // Ignore the rest of the response\n  } else {\n    self._redirectsFollowed = self._redirectsFollowed || 0\n    // Be a good stream and emit end when the response is finished.\n    // Hack to emit end on close because of a core bug that never fires end\n    response.on('close', function () {\n      if (!self._ended) self.response.emit('end')\n    })\n\n    if (self.encoding) {\n      if (self.dests.length !== 0) {\n        console.error(\"Ingoring encoding parameter as this stream is being piped to another stream which makes the encoding option invalid.\")\n      } else {\n        response.setEncoding(self.encoding)\n      }\n    }\n\n    self.emit('response', response)\n\n    self.dests.forEach(function (dest) {\n      self.pipeDest(dest)\n    })\n\n    response.on(\"data\", function (chunk) {\n      self._destdata = true\n      self.emit(\"data\", chunk)\n    })\n    response.on(\"end\", function (chunk) {\n      self._ended = true\n      self.emit(\"end\", chunk)\n    })\n    response.on(\"close\", function () {self.emit(\"close\")})\n\n    if (self.callback) {\n      var buffer = []\n      var bodyLen = 0\n      self.on(\"data\", function (chunk) {\n        buffer.push(chunk)\n        bodyLen += chunk.length\n      })\n      self.on(\"end\", function () {\n        debug('end event', self.uri.href)\n        if (self._aborted) {\n          debug('aborted', self.uri.href)\n          return\n        }\n\n        if (buffer.length && Buffer.isBuffer(buffer[0])) {\n          debug('has body', self.uri.href, bodyLen)\n          var body = new Buffer(bodyLen)\n          var i = 0\n          buffer.forEach(function (chunk) {\n            chunk.copy(body, i, 0, chunk.length)\n            i += chunk.length\n          })\n          if (self.encoding === null) {\n            response.body = body\n          } else {\n            response.body = body.toString(self.encoding)\n          }\n        } else if (buffer.length) {\n          // The UTF8 BOM [0xEF,0xBB,0xBF] is converted to [0xFE,0xFF] in the JS UTC16/UCS2 representation.\n          // Strip this value out when the encoding is set to 'utf8', as upstream consumers won't expect it and it breaks JSON.parse().\n          if (self.encoding === 'utf8' && buffer[0].length > 0 && buffer[0][0] === \"\\uFEFF\") {\n            buffer[0] = buffer[0].substring(1)\n          }\n          response.body = buffer.join('')\n        }\n\n        if (self._json) {\n          try {\n            response.body = JSON.parse(response.body)\n          } catch (e) {}\n        }\n        debug('emitting complete', self.uri.href)\n        if(response.body == undefined && !self._json) {\n          response.body = \"\";\n        }\n        self.emit('complete', response, response.body)\n      })\n    }\n  }\n  debug('finish init function', self.uri.href)\n}\n\nRequest.prototype.abort = function () {\n  this._aborted = true\n\n  if (this.req) {\n    this.req.abort()\n  }\n  else if (this.response) {\n    this.response.abort()\n  }\n\n  this.emit(\"abort\")\n}\n\nRequest.prototype.pipeDest = function (dest) {\n  var response = this.response\n  // Called after the response is received\n  if (dest.headers) {\n    dest.headers['content-type'] = response.headers['content-type']\n    if (response.headers['content-length']) {\n      dest.headers['content-length'] = response.headers['content-length']\n    }\n  }\n  if (dest.setHeader) {\n    for (var i in response.headers) {\n      dest.setHeader(i, response.headers[i])\n    }\n    dest.statusCode = response.statusCode\n  }\n  if (this.pipefilter) this.pipefilter(response, dest)\n}\n\n// Composable API\nRequest.prototype.setHeader = function (name, value, clobber) {\n  if (clobber === undefined) clobber = true\n  if (clobber || !this.headers.hasOwnProperty(name)) this.headers[name] = value\n  else this.headers[name] += ',' + value\n  return this\n}\nRequest.prototype.setHeaders = function (headers) {\n  for (var i in headers) {this.setHeader(i, headers[i])}\n  return this\n}\nRequest.prototype.qs = function (q, clobber) {\n  var base\n  if (!clobber && this.uri.query) base = qs.parse(this.uri.query)\n  else base = {}\n\n  for (var i in q) {\n    base[i] = q[i]\n  }\n\n  if (qs.stringify(base) === ''){\n    return this\n  }\n\n  this.uri = url.parse(this.uri.href.split('?')[0] + '?' + qs.stringify(base))\n  this.url = this.uri\n  this.path = this.uri.path\n\n  return this\n}\nRequest.prototype.form = function (form) {\n  if (form) {\n    this.headers['content-type'] = 'application/x-www-form-urlencoded; charset=utf-8'\n    this.body = qs.stringify(form).toString('utf8')\n    return this\n  }\n  // create form-data object\n  this._form = new FormData()\n  return this._form\n}\nRequest.prototype.multipart = function (multipart) {\n  var self = this\n  self.body = []\n\n  if (!self.headers['content-type']) {\n    self.headers['content-type'] = 'multipart/related; boundary=' + self.boundary\n  } else {\n    self.headers['content-type'] = self.headers['content-type'].split(';')[0] + '; boundary=' + self.boundary\n  }\n\n  if (!multipart.forEach) throw new Error('Argument error, options.multipart.')\n\n  if (self.preambleCRLF) {\n    self.body.push(new Buffer('\\r\\n'))\n  }\n\n  multipart.forEach(function (part) {\n    var body = part.body\n    if(body == null) throw Error('Body attribute missing in multipart.')\n    delete part.body\n    var preamble = '--' + self.boundary + '\\r\\n'\n    Object.keys(part).forEach(function (key) {\n      preamble += key + ': ' + part[key] + '\\r\\n'\n    })\n    preamble += '\\r\\n'\n    self.body.push(new Buffer(preamble))\n    self.body.push(new Buffer(body))\n    self.body.push(new Buffer('\\r\\n'))\n  })\n  self.body.push(new Buffer('--' + self.boundary + '--'))\n  return self\n}\nRequest.prototype.json = function (val) {\n  var self = this;\n  var setAcceptHeader = function() {\n  \tif (!self.headers['accept'] && !self.headers['Accept']) {\n\t\t\t  self.setHeader('accept', 'application/json')\n\t\t}\n\t}\n  setAcceptHeader();\n  this._json = true\n  if (typeof val === 'boolean') {\n    if (typeof this.body === 'object') {\n      setAcceptHeader();\n      this.body = safeStringify(this.body)\n      self.setHeader('content-type', 'application/json')\n    }\n  } else {\n    setAcceptHeader();\n    this.body = safeStringify(val)\n    self.setHeader('content-type', 'application/json')\n  }\n  return this\n}\nfunction getHeader(name, headers) {\n    var result, re, match\n    Object.keys(headers).forEach(function (key) {\n        re = new RegExp(name, 'i')\n        match = key.match(re)\n        if (match) result = headers[key]\n    })\n    return result\n}\nRequest.prototype.auth = function (user, pass, sendImmediately) {\n  if (typeof user !== 'string' || (pass !== undefined && typeof pass !== 'string')) {\n    throw new Error('auth() received invalid user or password')\n  }\n  this._user = user\n  this._pass = pass\n  this._hasAuth = true\n  if (sendImmediately || typeof sendImmediately == 'undefined') {\n    this.setHeader('authorization', 'Basic ' + toBase64(user + ':' + pass))\n    this._sentAuth = true\n  }\n  return this\n}\nRequest.prototype.aws = function (opts, now) {\n  if (!now) {\n    this._aws = opts\n    return this\n  }\n  var date = new Date()\n  this.setHeader('date', date.toUTCString())\n  var auth =\n    { key: opts.key\n    , secret: opts.secret\n    , verb: this.method.toUpperCase()\n    , date: date\n    , contentType: getHeader('content-type', this.headers) || ''\n    , md5: getHeader('content-md5', this.headers) || ''\n    , amazonHeaders: aws.canonicalizeHeaders(this.headers)\n    }\n  if (opts.bucket && this.path) {\n    auth.resource = '/' + opts.bucket + this.path\n  } else if (opts.bucket && !this.path) {\n    auth.resource = '/' + opts.bucket\n  } else if (!opts.bucket && this.path) {\n    auth.resource = this.path\n  } else if (!opts.bucket && !this.path) {\n    auth.resource = '/'\n  }\n  auth.resource = aws.canonicalizeResource(auth.resource)\n  this.setHeader('authorization', aws.authorization(auth))\n\n  return this\n}\nRequest.prototype.httpSignature = function (opts) {\n  var req = this\n  httpSignature.signRequest({\n    getHeader: function(header) {\n      return getHeader(header, req.headers)\n    },\n    setHeader: function(header, value) {\n      req.setHeader(header, value)\n    },\n    method: this.method,\n    path: this.path\n  }, opts)\n  debug('httpSignature authorization', getHeader('authorization', this.headers))\n\n  return this\n}\n\nRequest.prototype.hawk = function (opts) {\n  this.headers.Authorization = hawk.client.header(this.uri, this.method, opts).field\n}\n\nRequest.prototype.oauth = function (_oauth) {\n  var form\n  if (this.headers['content-type'] &&\n      this.headers['content-type'].slice(0, 'application/x-www-form-urlencoded'.length) ===\n        'application/x-www-form-urlencoded'\n     ) {\n    form = qs.parse(this.body)\n  }\n  if (this.uri.query) {\n    form = qs.parse(this.uri.query)\n  }\n  if (!form) form = {}\n  var oa = {}\n  for (var i in form) oa[i] = form[i]\n  for (var i in _oauth) oa['oauth_'+i] = _oauth[i]\n  if (!oa.oauth_version) oa.oauth_version = '1.0'\n  if (!oa.oauth_timestamp) oa.oauth_timestamp = Math.floor( Date.now() / 1000 ).toString()\n  if (!oa.oauth_nonce) oa.oauth_nonce = uuid().replace(/-/g, '')\n\n  oa.oauth_signature_method = 'HMAC-SHA1'\n\n  var consumer_secret = oa.oauth_consumer_secret\n  delete oa.oauth_consumer_secret\n  var token_secret = oa.oauth_token_secret\n  delete oa.oauth_token_secret\n  var timestamp = oa.oauth_timestamp\n\n  var baseurl = this.uri.protocol + '//' + this.uri.host + this.uri.pathname\n  var signature = oauth.hmacsign(this.method, baseurl, oa, consumer_secret, token_secret)\n\n  // oa.oauth_signature = signature\n  for (var i in form) {\n    if ( i.slice(0, 'oauth_') in _oauth) {\n      // skip\n    } else {\n      delete oa['oauth_'+i]\n      if (i !== 'x_auth_mode') delete oa[i]\n    }\n  }\n  oa.oauth_timestamp = timestamp\n  this.headers.Authorization =\n    'OAuth '+Object.keys(oa).sort().map(function (i) {return i+'=\"'+oauth.rfc3986(oa[i])+'\"'}).join(',')\n  this.headers.Authorization += ',oauth_signature=\"' + oauth.rfc3986(signature) + '\"'\n  return this\n}\nRequest.prototype.jar = function (jar) {\n  var cookies\n\n  if (this._redirectsFollowed === 0) {\n    this.originalCookieHeader = this.headers.cookie\n  }\n\n  if (jar === false) {\n    // disable cookies\n    cookies = false\n    this._disableCookies = true\n  } else if (jar) {\n    // fetch cookie from the user defined cookie jar\n    cookies = jar.get({ url: this.uri.href })\n  } else {\n    // fetch cookie from the global cookie jar\n    cookies = cookieJar.get({ url: this.uri.href })\n  }\n\n  if (cookies && cookies.length) {\n    var cookieString = cookies.map(function (c) {\n      return c.name + \"=\" + c.value\n    }).join(\"; \")\n\n    if (this.originalCookieHeader) {\n      // Don't overwrite existing Cookie header\n      this.headers.cookie = this.originalCookieHeader + '; ' + cookieString\n    } else {\n      this.headers.cookie = cookieString\n    }\n  }\n  this._jar = jar\n  return this\n}\n\n\n// Stream API\nRequest.prototype.pipe = function (dest, opts) {\n  if (this.response) {\n    if (this._destdata) {\n      throw new Error(\"You cannot pipe after data has been emitted from the response.\")\n    } else if (this._ended) {\n      throw new Error(\"You cannot pipe after the response has been ended.\")\n    } else {\n      stream.Stream.prototype.pipe.call(this, dest, opts)\n      this.pipeDest(dest)\n      return dest\n    }\n  } else {\n    this.dests.push(dest)\n    stream.Stream.prototype.pipe.call(this, dest, opts)\n    return dest\n  }\n}\nRequest.prototype.write = function () {\n  if (!this._started) this.start()\n  return this.req.write.apply(this.req, arguments)\n}\nRequest.prototype.end = function (chunk) {\n  if (chunk) this.write(chunk)\n  if (!this._started) this.start()\n  this.req.end()\n}\nRequest.prototype.pause = function () {\n  if (!this.response) this._paused = true\n  else this.response.pause.apply(this.response, arguments)\n}\nRequest.prototype.resume = function () {\n  if (!this.response) this._paused = false\n  else this.response.resume.apply(this.response, arguments)\n}\nRequest.prototype.destroy = function () {\n  if (!this._ended) this.end()\n  else if (this.response) this.response.destroy()\n}\n\n// organize params for patch, post, put, head, del\nfunction initParams(uri, options, callback) {\n  if ((typeof options === 'function') && !callback) callback = options\n  if (options && typeof options === 'object') {\n    options.uri = uri\n  } else if (typeof uri === 'string') {\n    options = {uri:uri}\n  } else {\n    options = uri\n    uri = options.uri\n  }\n  return { uri: uri, options: options, callback: callback }\n}\n\nfunction request (uri, options, callback) {\n  if (typeof uri === 'undefined') throw new Error('undefined is not a valid uri or options object.')\n  if ((typeof options === 'function') && !callback) callback = options\n  if (options && typeof options === 'object') {\n    options.uri = uri\n  } else if (typeof uri === 'string') {\n    options = {uri:uri}\n  } else {\n    options = uri\n  }\n\n  options = copy(options)\n\n  if (callback) options.callback = callback\n  var r = new Request(options)\n  return r\n}\n\nmodule.exports = request\n\nrequest.debug = process.env.NODE_DEBUG && /request/.test(process.env.NODE_DEBUG)\n\nrequest.initParams = initParams\n\nrequest.defaults = function (options, requester) {\n  var def = function (method) {\n    var d = function (uri, opts, callback) {\n      var params = initParams(uri, opts, callback)\n      for (var i in options) {\n        if (params.options[i] === undefined) params.options[i] = options[i]\n      }\n      if(typeof requester === 'function') {\n        if(method === request) {\n          method = requester\n        } else {\n          params.options._requester = requester\n        }\n      }\n      return method(params.options, params.callback)\n    }\n    return d\n  }\n  var de = def(request)\n  de.get = def(request.get)\n  de.patch = def(request.patch)\n  de.post = def(request.post)\n  de.put = def(request.put)\n  de.head = def(request.head)\n  de.del = def(request.del)\n  de.cookie = def(request.cookie)\n  de.jar = request.jar\n  return de\n}\n\nrequest.forever = function (agentOptions, optionsArg) {\n  var options = {}\n  if (optionsArg) {\n    for (option in optionsArg) {\n      options[option] = optionsArg[option]\n    }\n  }\n  if (agentOptions) options.agentOptions = agentOptions\n  options.forever = true\n  return request.defaults(options)\n}\n\nrequest.get = request\nrequest.post = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'POST'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.put = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'PUT'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.patch = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'PATCH'\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.head = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'HEAD'\n  if (params.options.body ||\n      params.options.requestBodyStream ||\n      (params.options.json && typeof params.options.json !== 'boolean') ||\n      params.options.multipart) {\n    throw new Error(\"HTTP HEAD requests MUST NOT include a request body.\")\n  }\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.del = function (uri, options, callback) {\n  var params = initParams(uri, options, callback)\n  params.options.method = 'DELETE'\n  if(typeof params.options._requester === 'function') {\n    request = params.options._requester\n  }\n  return request(params.uri || null, params.options, params.callback)\n}\nrequest.jar = function () {\n  return new CookieJar\n}\nrequest.cookie = function (str) {\n  if (str && str.uri) str = str.uri\n  if (typeof str !== 'string') throw new Error(\"The cookie function only accepts STRING as param\")\n  return new Cookie(str)\n}\n\n// Safe toJSON\n\nfunction getSafe (self, uuid) {\n  if (typeof self === 'object' || typeof self === 'function') var safe = {}\n  if (Array.isArray(self)) var safe = []\n\n  var recurse = []\n\n  Object.defineProperty(self, uuid, {})\n\n  var attrs = Object.keys(self).filter(function (i) {\n    if (i === uuid) return false\n    if ( (typeof self[i] !== 'object' && typeof self[i] !== 'function') || self[i] === null) return true\n    return !(Object.getOwnPropertyDescriptor(self[i], uuid))\n  })\n\n\n  for (var i=0;i<attrs.length;i++) {\n    if ( (typeof self[attrs[i]] !== 'object' && typeof self[attrs[i]] !== 'function') ||\n          self[attrs[i]] === null\n        ) {\n      safe[attrs[i]] = self[attrs[i]]\n    } else {\n      recurse.push(attrs[i])\n      Object.defineProperty(self[attrs[i]], uuid, {})\n    }\n  }\n\n  for (var i=0;i<recurse.length;i++) {\n    safe[recurse[i]] = getSafe(self[recurse[i]], uuid)\n  }\n\n  return safe\n}\n\nfunction toJSON () {\n  return getSafe(this, '__' + (((1+Math.random())*0x10000)|0).toString(16))\n}\n\nRequest.prototype.toJSON = toJSON\n\nreturn {\n    http: (typeof http !== \"undefined\") ? http : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    https: (typeof https !== \"undefined\") ? https : null,\n    tls: (typeof tls !== \"undefined\") ? tls : null,\n    url: (typeof url !== \"undefined\") ? url : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    stream: (typeof stream !== \"undefined\") ? stream : null,\n    qs: (typeof qs !== \"undefined\") ? qs : null,\n    querystring: (typeof querystring !== \"undefined\") ? querystring : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    oauth: (typeof oauth !== \"undefined\") ? oauth : null,\n    hawk: (typeof hawk !== \"undefined\") ? hawk : null,\n    aws: (typeof aws !== \"undefined\") ? aws : null,\n    httpSignature: (typeof httpSignature !== \"undefined\") ? httpSignature : null,\n    uuid: (typeof uuid !== \"undefined\") ? uuid : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    tunnel: (typeof tunnel !== \"undefined\") ? tunnel : null,\n    safeStringify: (typeof safeStringify !== \"undefined\") ? safeStringify : null,\n    ForeverAgent: (typeof ForeverAgent !== \"undefined\") ? ForeverAgent : null,\n    FormData: (typeof FormData !== \"undefined\") ? FormData : null,\n    Cookie: (typeof Cookie !== \"undefined\") ? Cookie : null,\n    CookieJar: (typeof CookieJar !== \"undefined\") ? CookieJar : null,\n    cookieJar: (typeof cookieJar !== \"undefined\") ? cookieJar : null,\n    debug: (typeof debug !== \"undefined\") ? debug : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    toBase64: (typeof toBase64 !== \"undefined\") ? toBase64 : null,\n    md5: (typeof md5 !== \"undefined\") ? md5 : null,\n    isReadStream: (typeof isReadStream !== \"undefined\") ? isReadStream : null,\n    copy: (typeof copy !== \"undefined\") ? copy : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    isUrl: (typeof isUrl !== \"undefined\") ? isUrl : null,\n    globalPool: (typeof globalPool !== \"undefined\") ? globalPool : null,\n    Request: (typeof Request !== \"undefined\") ? Request : null,\n    clearTimeout: (typeof clearTimeout !== \"undefined\") ? clearTimeout : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    Array: (typeof Array !== \"undefined\") ? Array : null,\n    setTimeout: (typeof setTimeout !== \"undefined\") ? setTimeout : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null,\n    getHeader: (typeof getHeader !== \"undefined\") ? getHeader : null,\n    Date: (typeof Date !== \"undefined\") ? Date : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null,\n    initParams: (typeof initParams !== \"undefined\") ? initParams : null,\n    request: (typeof request !== \"undefined\") ? request : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    getSafe: (typeof getSafe !== \"undefined\") ? getSafe : null,\n    toJSON: (typeof toJSON !== \"undefined\") ? toJSON : null\n};\n}",
              "bottom": "return {\n    http: (typeof http !== \"undefined\") ? http : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    https: (typeof https !== \"undefined\") ? https : null,\n    tls: (typeof tls !== \"undefined\") ? tls : null,\n    url: (typeof url !== \"undefined\") ? url : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    stream: (typeof stream !== \"undefined\") ? stream : null,\n    qs: (typeof qs !== \"undefined\") ? qs : null,\n    querystring: (typeof querystring !== \"undefined\") ? querystring : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    oauth: (typeof oauth !== \"undefined\") ? oauth : null,\n    hawk: (typeof hawk !== \"undefined\") ? hawk : null,\n    aws: (typeof aws !== \"undefined\") ? aws : null,\n    httpSignature: (typeof httpSignature !== \"undefined\") ? httpSignature : null,\n    uuid: (typeof uuid !== \"undefined\") ? uuid : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    tunnel: (typeof tunnel !== \"undefined\") ? tunnel : null,\n    safeStringify: (typeof safeStringify !== \"undefined\") ? safeStringify : null,\n    ForeverAgent: (typeof ForeverAgent !== \"undefined\") ? ForeverAgent : null,\n    FormData: (typeof FormData !== \"undefined\") ? FormData : null,\n    Cookie: (typeof Cookie !== \"undefined\") ? Cookie : null,\n    CookieJar: (typeof CookieJar !== \"undefined\") ? CookieJar : null,\n    cookieJar: (typeof cookieJar !== \"undefined\") ? cookieJar : null,\n    debug: (typeof debug !== \"undefined\") ? debug : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    toBase64: (typeof toBase64 !== \"undefined\") ? toBase64 : null,\n    md5: (typeof md5 !== \"undefined\") ? md5 : null,\n    isReadStream: (typeof isReadStream !== \"undefined\") ? isReadStream : null,\n    copy: (typeof copy !== \"undefined\") ? copy : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    isUrl: (typeof isUrl !== \"undefined\") ? isUrl : null,\n    globalPool: (typeof globalPool !== \"undefined\") ? globalPool : null,\n    Request: (typeof Request !== \"undefined\") ? Request : null,\n    clearTimeout: (typeof clearTimeout !== \"undefined\") ? clearTimeout : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    Array: (typeof Array !== \"undefined\") ? Array : null,\n    setTimeout: (typeof setTimeout !== \"undefined\") ? setTimeout : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null,\n    getHeader: (typeof getHeader !== \"undefined\") ? getHeader : null,\n    Date: (typeof Date !== \"undefined\") ? Date : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null,\n    initParams: (typeof initParams !== \"undefined\") ? initParams : null,\n    request: (typeof request !== \"undefined\") ? request : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    getSafe: (typeof getSafe !== \"undefined\") ? getSafe : null,\n    toJSON: (typeof toJSON !== \"undefined\") ? toJSON : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "http": {
                  "where": "inline"
                },
                "url": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                },
                "stream": {
                  "where": "inline"
                },
                "qs": {
                  "where": "inline"
                },
                "querystring": {
                  "where": "inline"
                },
                "crypto": {
                  "where": "inline"
                },
                "oauth-sign": {
                  "where": "inline"
                },
                "hawk": {
                  "where": "inline"
                },
                "aws-sign": {
                  "where": "inline"
                },
                "http-signature": {
                  "where": "inline"
                },
                "node-uuid": {
                  "where": "inline"
                },
                "mime": {
                  "where": "inline"
                },
                "tunnel-agent": {
                  "where": "inline"
                },
                "json-stringify-safe": {
                  "where": "inline"
                },
                "forever-agent": {
                  "where": "inline"
                },
                "form-data": {
                  "where": "inline"
                },
                "cookie-jar": {
                  "where": "inline"
                },
                "https": {
                  "where": "inline"
                },
                "tls": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/index.js": {
            "requireId": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/index.js",
            "memoizeId": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/qs/index.js",
              "mtime": 1368459125,
              "code": "/**\n * Object#toString() ref for stringify().\n */\n\nvar toString = Object.prototype.toString;\n\n/**\n * Object#hasOwnProperty ref\n */\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\n/**\n * Array#indexOf shim.\n */\n\nvar indexOf = typeof Array.prototype.indexOf === 'function'\n  ? function(arr, el) { return arr.indexOf(el); }\n  : function(arr, el) {\n      for (var i = 0; i < arr.length; i++) {\n        if (arr[i] === el) return i;\n      }\n      return -1;\n    };\n\n/**\n * Array.isArray shim.\n */\n\nvar isArray = Array.isArray || function(arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n/**\n * Object.keys shim.\n */\n\nvar objectKeys = Object.keys || function(obj) {\n  var ret = [];\n  for (var key in obj) ret.push(key);\n  return ret;\n};\n\n/**\n * Array#forEach shim.\n */\n\nvar forEach = typeof Array.prototype.forEach === 'function'\n  ? function(arr, fn) { return arr.forEach(fn); }\n  : function(arr, fn) {\n      for (var i = 0; i < arr.length; i++) fn(arr[i]);\n    };\n\n/**\n * Array#reduce shim.\n */\n\nvar reduce = function(arr, fn, initial) {\n  if (typeof arr.reduce === 'function') return arr.reduce(fn, initial);\n  var res = initial;\n  for (var i = 0; i < arr.length; i++) res = fn(res, arr[i]);\n  return res;\n};\n\n/**\n * Create a nullary object if possible\n */\n\nfunction createObject() {\n  return Object.create\n    ? Object.create(null)\n    : {};\n}\n\n/**\n * Cache non-integer test regexp.\n */\n\nvar isint = /^[0-9]+$/;\n\nfunction promote(parent, key) {\n  if (parent[key].length == 0) return parent[key] = createObject();\n  var t = createObject();\n  for (var i in parent[key]) {\n    if (hasOwnProperty.call(parent[key], i)) {\n      t[i] = parent[key][i];\n    }\n  }\n  parent[key] = t;\n  return t;\n}\n\nfunction parse(parts, parent, key, val) {\n  var part = parts.shift();\n  // end\n  if (!part) {\n    if (isArray(parent[key])) {\n      parent[key].push(val);\n    } else if ('object' == typeof parent[key]) {\n      parent[key] = val;\n    } else if ('undefined' == typeof parent[key]) {\n      parent[key] = val;\n    } else {\n      parent[key] = [parent[key], val];\n    }\n    // array\n  } else {\n    var obj = parent[key] = parent[key] || [];\n    if (']' == part) {\n      if (isArray(obj)) {\n        if ('' != val) obj.push(val);\n      } else if ('object' == typeof obj) {\n        obj[objectKeys(obj).length] = val;\n      } else {\n        obj = parent[key] = [parent[key], val];\n      }\n      // prop\n    } else if (~indexOf(part, ']')) {\n      part = part.substr(0, part.length - 1);\n      if (!isint.test(part) && isArray(obj)) obj = promote(parent, key);\n      parse(parts, obj, part, val);\n      // key\n    } else {\n      if (!isint.test(part) && isArray(obj)) obj = promote(parent, key);\n      parse(parts, obj, part, val);\n    }\n  }\n}\n\n/**\n * Merge parent key/val pair.\n */\n\nfunction merge(parent, key, val){\n  if (~indexOf(key, ']')) {\n    var parts = key.split('[')\n      , len = parts.length\n      , last = len - 1;\n    parse(parts, parent, 'base', val);\n    // optimize\n  } else {\n    if (!isint.test(key) && isArray(parent.base)) {\n      var t = createObject();\n      for (var k in parent.base) t[k] = parent.base[k];\n      parent.base = t;\n    }\n    set(parent.base, key, val);\n  }\n\n  return parent;\n}\n\n/**\n * Compact sparse arrays.\n */\n\nfunction compact(obj) {\n  if ('object' != typeof obj) return obj;\n\n  if (isArray(obj)) {\n    var ret = [];\n\n    for (var i in obj) {\n      if (hasOwnProperty.call(obj, i)) {\n        ret.push(obj[i]);\n      }\n    }\n\n    return ret;\n  }\n\n  for (var key in obj) {\n    obj[key] = compact(obj[key]);\n  }\n\n  return obj;\n}\n\n/**\n * Restore Object.prototype.\n * see pull-request #58\n */\n\nfunction restoreProto(obj) {\n  if (!Object.create) return obj;\n  if (isArray(obj)) return obj;\n  if (obj && 'object' != typeof obj) return obj;\n\n  for (var key in obj) {\n    if (hasOwnProperty.call(obj, key)) {\n      obj[key] = restoreProto(obj[key]);\n    }\n  }\n\n  obj.__proto__ = Object.prototype;\n  return obj;\n}\n\n/**\n * Parse the given obj.\n */\n\nfunction parseObject(obj){\n  var ret = { base: {} };\n\n  forEach(objectKeys(obj), function(name){\n    merge(ret, name, obj[name]);\n  });\n\n  return compact(ret.base);\n}\n\n/**\n * Parse the given str.\n */\n\nfunction parseString(str){\n  var ret = reduce(String(str).split('&'), function(ret, pair){\n    var eql = indexOf(pair, '=')\n      , brace = lastBraceInKey(pair)\n      , key = pair.substr(0, brace || eql)\n      , val = pair.substr(brace || eql, pair.length)\n      , val = val.substr(indexOf(val, '=') + 1, val.length);\n\n    // ?foo\n    if ('' == key) key = pair, val = '';\n    if ('' == key) return ret;\n\n    return merge(ret, decode(key), decode(val));\n  }, { base: createObject() }).base;\n\n  return restoreProto(compact(ret));\n}\n\n/**\n * Parse the given query `str` or `obj`, returning an object.\n *\n * @param {String} str | {Object} obj\n * @return {Object}\n * @api public\n */\n\nexports.parse = function(str){\n  if (null == str || '' == str) return {};\n  return 'object' == typeof str\n    ? parseObject(str)\n    : parseString(str);\n};\n\n/**\n * Turn the given `obj` into a query string\n *\n * @param {Object} obj\n * @return {String}\n * @api public\n */\n\nvar stringify = exports.stringify = function(obj, prefix) {\n  if (isArray(obj)) {\n    return stringifyArray(obj, prefix);\n  } else if ('[object Object]' == toString.call(obj)) {\n    return stringifyObject(obj, prefix);\n  } else if ('string' == typeof obj) {\n    return stringifyString(obj, prefix);\n  } else {\n    return prefix + '=' + encodeURIComponent(String(obj));\n  }\n};\n\n/**\n * Stringify the given `str`.\n *\n * @param {String} str\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyString(str, prefix) {\n  if (!prefix) throw new TypeError('stringify expects an object');\n  return prefix + '=' + encodeURIComponent(str);\n}\n\n/**\n * Stringify the given `arr`.\n *\n * @param {Array} arr\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyArray(arr, prefix) {\n  var ret = [];\n  if (!prefix) throw new TypeError('stringify expects an object');\n  for (var i = 0; i < arr.length; i++) {\n    ret.push(stringify(arr[i], prefix + '[' + i + ']'));\n  }\n  return ret.join('&');\n}\n\n/**\n * Stringify the given `obj`.\n *\n * @param {Object} obj\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyObject(obj, prefix) {\n  var ret = []\n    , keys = objectKeys(obj)\n    , key;\n\n  for (var i = 0, len = keys.length; i < len; ++i) {\n    key = keys[i];\n    if ('' == key) continue;\n    if (null == obj[key]) {\n      ret.push(encodeURIComponent(key) + '=');\n    } else {\n      ret.push(stringify(obj[key], prefix\n        ? prefix + '[' + encodeURIComponent(key) + ']'\n        : encodeURIComponent(key)));\n    }\n  }\n\n  return ret.join('&');\n}\n\n/**\n * Set `obj`'s `key` to `val` respecting\n * the weird and wonderful syntax of a qs,\n * where \"foo=bar&foo=baz\" becomes an array.\n *\n * @param {Object} obj\n * @param {String} key\n * @param {String} val\n * @api private\n */\n\nfunction set(obj, key, val) {\n  var v = obj[key];\n  if (undefined === v) {\n    obj[key] = val;\n  } else if (isArray(v)) {\n    v.push(val);\n  } else {\n    obj[key] = [v, val];\n  }\n}\n\n/**\n * Locate last brace in `str` within the key.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction lastBraceInKey(str) {\n  var len = str.length\n    , brace\n    , c;\n  for (var i = 0; i < len; ++i) {\n    c = str[i];\n    if (']' == c) brace = false;\n    if ('[' == c) brace = true;\n    if ('=' == c && !brace) return i;\n  }\n}\n\n/**\n * Decode `str`.\n *\n * @param {String} str\n * @return {String}\n * @api private\n */\n\nfunction decode(str) {\n  try {\n    return decodeURIComponent(str.replace(/\\+/g, ' '));\n  } catch (err) {\n    return str;\n  }\n}\n",
              "globals": {
                "Object": {
                  "type": "reference"
                },
                "indexOf": {
                  "type": "assign"
                },
                "Array": {
                  "type": "reference"
                },
                "isArray": {
                  "type": "assign"
                },
                "objectKeys": {
                  "type": "assign"
                },
                "forEach": {
                  "type": "assign"
                },
                "reduce": {
                  "type": "assign"
                },
                "createObject": {
                  "type": "assign"
                },
                "isint": {
                  "type": "assign"
                },
                "promote": {
                  "type": "assign"
                },
                "parse": {
                  "type": "assign"
                },
                "merge": {
                  "type": "assign"
                },
                "set": {
                  "type": "call"
                },
                "compact": {
                  "type": "assign"
                },
                "restoreProto": {
                  "type": "assign"
                },
                "parseObject": {
                  "type": "assign"
                },
                "parseString": {
                  "type": "assign"
                },
                "String": {
                  "type": "call"
                },
                "lastBraceInKey": {
                  "type": "call"
                },
                "decode": {
                  "type": "call"
                },
                "exports": {
                  "type": "reference"
                },
                "stringify": {
                  "type": "assign"
                },
                "stringifyArray": {
                  "type": "call"
                },
                "stringifyObject": {
                  "type": "call"
                },
                "stringifyString": {
                  "type": "call"
                },
                "encodeURIComponent": {
                  "type": "call"
                },
                "decodeURIComponent": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/qs';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/qs';\n/**\n * Object#toString() ref for stringify().\n */\n\nvar toString = Object.prototype.toString;\n\n/**\n * Object#hasOwnProperty ref\n */\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\n/**\n * Array#indexOf shim.\n */\n\nvar indexOf = typeof Array.prototype.indexOf === 'function'\n  ? function(arr, el) { return arr.indexOf(el); }\n  : function(arr, el) {\n      for (var i = 0; i < arr.length; i++) {\n        if (arr[i] === el) return i;\n      }\n      return -1;\n    };\n\n/**\n * Array.isArray shim.\n */\n\nvar isArray = Array.isArray || function(arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n/**\n * Object.keys shim.\n */\n\nvar objectKeys = Object.keys || function(obj) {\n  var ret = [];\n  for (var key in obj) ret.push(key);\n  return ret;\n};\n\n/**\n * Array#forEach shim.\n */\n\nvar forEach = typeof Array.prototype.forEach === 'function'\n  ? function(arr, fn) { return arr.forEach(fn); }\n  : function(arr, fn) {\n      for (var i = 0; i < arr.length; i++) fn(arr[i]);\n    };\n\n/**\n * Array#reduce shim.\n */\n\nvar reduce = function(arr, fn, initial) {\n  if (typeof arr.reduce === 'function') return arr.reduce(fn, initial);\n  var res = initial;\n  for (var i = 0; i < arr.length; i++) res = fn(res, arr[i]);\n  return res;\n};\n\n/**\n * Create a nullary object if possible\n */\n\nfunction createObject() {\n  return Object.create\n    ? Object.create(null)\n    : {};\n}\n\n/**\n * Cache non-integer test regexp.\n */\n\nvar isint = /^[0-9]+$/;\n\nfunction promote(parent, key) {\n  if (parent[key].length == 0) return parent[key] = createObject();\n  var t = createObject();\n  for (var i in parent[key]) {\n    if (hasOwnProperty.call(parent[key], i)) {\n      t[i] = parent[key][i];\n    }\n  }\n  parent[key] = t;\n  return t;\n}\n\nfunction parse(parts, parent, key, val) {\n  var part = parts.shift();\n  // end\n  if (!part) {\n    if (isArray(parent[key])) {\n      parent[key].push(val);\n    } else if ('object' == typeof parent[key]) {\n      parent[key] = val;\n    } else if ('undefined' == typeof parent[key]) {\n      parent[key] = val;\n    } else {\n      parent[key] = [parent[key], val];\n    }\n    // array\n  } else {\n    var obj = parent[key] = parent[key] || [];\n    if (']' == part) {\n      if (isArray(obj)) {\n        if ('' != val) obj.push(val);\n      } else if ('object' == typeof obj) {\n        obj[objectKeys(obj).length] = val;\n      } else {\n        obj = parent[key] = [parent[key], val];\n      }\n      // prop\n    } else if (~indexOf(part, ']')) {\n      part = part.substr(0, part.length - 1);\n      if (!isint.test(part) && isArray(obj)) obj = promote(parent, key);\n      parse(parts, obj, part, val);\n      // key\n    } else {\n      if (!isint.test(part) && isArray(obj)) obj = promote(parent, key);\n      parse(parts, obj, part, val);\n    }\n  }\n}\n\n/**\n * Merge parent key/val pair.\n */\n\nfunction merge(parent, key, val){\n  if (~indexOf(key, ']')) {\n    var parts = key.split('[')\n      , len = parts.length\n      , last = len - 1;\n    parse(parts, parent, 'base', val);\n    // optimize\n  } else {\n    if (!isint.test(key) && isArray(parent.base)) {\n      var t = createObject();\n      for (var k in parent.base) t[k] = parent.base[k];\n      parent.base = t;\n    }\n    set(parent.base, key, val);\n  }\n\n  return parent;\n}\n\n/**\n * Compact sparse arrays.\n */\n\nfunction compact(obj) {\n  if ('object' != typeof obj) return obj;\n\n  if (isArray(obj)) {\n    var ret = [];\n\n    for (var i in obj) {\n      if (hasOwnProperty.call(obj, i)) {\n        ret.push(obj[i]);\n      }\n    }\n\n    return ret;\n  }\n\n  for (var key in obj) {\n    obj[key] = compact(obj[key]);\n  }\n\n  return obj;\n}\n\n/**\n * Restore Object.prototype.\n * see pull-request #58\n */\n\nfunction restoreProto(obj) {\n  if (!Object.create) return obj;\n  if (isArray(obj)) return obj;\n  if (obj && 'object' != typeof obj) return obj;\n\n  for (var key in obj) {\n    if (hasOwnProperty.call(obj, key)) {\n      obj[key] = restoreProto(obj[key]);\n    }\n  }\n\n  obj.__proto__ = Object.prototype;\n  return obj;\n}\n\n/**\n * Parse the given obj.\n */\n\nfunction parseObject(obj){\n  var ret = { base: {} };\n\n  forEach(objectKeys(obj), function(name){\n    merge(ret, name, obj[name]);\n  });\n\n  return compact(ret.base);\n}\n\n/**\n * Parse the given str.\n */\n\nfunction parseString(str){\n  var ret = reduce(String(str).split('&'), function(ret, pair){\n    var eql = indexOf(pair, '=')\n      , brace = lastBraceInKey(pair)\n      , key = pair.substr(0, brace || eql)\n      , val = pair.substr(brace || eql, pair.length)\n      , val = val.substr(indexOf(val, '=') + 1, val.length);\n\n    // ?foo\n    if ('' == key) key = pair, val = '';\n    if ('' == key) return ret;\n\n    return merge(ret, decode(key), decode(val));\n  }, { base: createObject() }).base;\n\n  return restoreProto(compact(ret));\n}\n\n/**\n * Parse the given query `str` or `obj`, returning an object.\n *\n * @param {String} str | {Object} obj\n * @return {Object}\n * @api public\n */\n\nexports.parse = function(str){\n  if (null == str || '' == str) return {};\n  return 'object' == typeof str\n    ? parseObject(str)\n    : parseString(str);\n};\n\n/**\n * Turn the given `obj` into a query string\n *\n * @param {Object} obj\n * @return {String}\n * @api public\n */\n\nvar stringify = exports.stringify = function(obj, prefix) {\n  if (isArray(obj)) {\n    return stringifyArray(obj, prefix);\n  } else if ('[object Object]' == toString.call(obj)) {\n    return stringifyObject(obj, prefix);\n  } else if ('string' == typeof obj) {\n    return stringifyString(obj, prefix);\n  } else {\n    return prefix + '=' + encodeURIComponent(String(obj));\n  }\n};\n\n/**\n * Stringify the given `str`.\n *\n * @param {String} str\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyString(str, prefix) {\n  if (!prefix) throw new TypeError('stringify expects an object');\n  return prefix + '=' + encodeURIComponent(str);\n}\n\n/**\n * Stringify the given `arr`.\n *\n * @param {Array} arr\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyArray(arr, prefix) {\n  var ret = [];\n  if (!prefix) throw new TypeError('stringify expects an object');\n  for (var i = 0; i < arr.length; i++) {\n    ret.push(stringify(arr[i], prefix + '[' + i + ']'));\n  }\n  return ret.join('&');\n}\n\n/**\n * Stringify the given `obj`.\n *\n * @param {Object} obj\n * @param {String} prefix\n * @return {String}\n * @api private\n */\n\nfunction stringifyObject(obj, prefix) {\n  var ret = []\n    , keys = objectKeys(obj)\n    , key;\n\n  for (var i = 0, len = keys.length; i < len; ++i) {\n    key = keys[i];\n    if ('' == key) continue;\n    if (null == obj[key]) {\n      ret.push(encodeURIComponent(key) + '=');\n    } else {\n      ret.push(stringify(obj[key], prefix\n        ? prefix + '[' + encodeURIComponent(key) + ']'\n        : encodeURIComponent(key)));\n    }\n  }\n\n  return ret.join('&');\n}\n\n/**\n * Set `obj`'s `key` to `val` respecting\n * the weird and wonderful syntax of a qs,\n * where \"foo=bar&foo=baz\" becomes an array.\n *\n * @param {Object} obj\n * @param {String} key\n * @param {String} val\n * @api private\n */\n\nfunction set(obj, key, val) {\n  var v = obj[key];\n  if (undefined === v) {\n    obj[key] = val;\n  } else if (isArray(v)) {\n    v.push(val);\n  } else {\n    obj[key] = [v, val];\n  }\n}\n\n/**\n * Locate last brace in `str` within the key.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction lastBraceInKey(str) {\n  var len = str.length\n    , brace\n    , c;\n  for (var i = 0; i < len; ++i) {\n    c = str[i];\n    if (']' == c) brace = false;\n    if ('[' == c) brace = true;\n    if ('=' == c && !brace) return i;\n  }\n}\n\n/**\n * Decode `str`.\n *\n * @param {String} str\n * @return {String}\n * @api private\n */\n\nfunction decode(str) {\n  try {\n    return decodeURIComponent(str.replace(/\\+/g, ' '));\n  } catch (err) {\n    return str;\n  }\n}\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/index.js": {
            "requireId": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/index.js",
            "memoizeId": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/oauth-sign/index.js",
              "mtime": 1362169119,
              "code": "var crypto = require('crypto')\n  , qs = require('querystring')\n  ;\n\nfunction sha1 (key, body) {\n  return crypto.createHmac('sha1', key).update(body).digest('base64')\n}\n\nfunction rfc3986 (str) {\n  return encodeURIComponent(str)\n    .replace(/!/g,'%21')\n    .replace(/\\*/g,'%2A')\n    .replace(/\\(/g,'%28')\n    .replace(/\\)/g,'%29')\n    .replace(/'/g,'%27')\n    ;\n}\n\nfunction hmacsign (httpMethod, base_uri, params, consumer_secret, token_secret) {\n  // adapted from https://dev.twitter.com/docs/auth/oauth and \n  // https://dev.twitter.com/docs/auth/creating-signature\n\n  var querystring = Object.keys(params).sort().map(function(key){\n    // big WTF here with the escape + encoding but it's what twitter wants\n    return escape(rfc3986(key)) + \"%3D\" + escape(rfc3986(params[key]))\n  }).join('%26')\n\n  var base = [\n    httpMethod ? httpMethod.toUpperCase() : 'GET',\n    rfc3986(base_uri),\n    querystring\n  ].join('&')\n\n  var key = [\n    consumer_secret,\n    token_secret || ''\n  ].map(rfc3986).join('&')\n\n  return sha1(key, base)\n}\n\nexports.hmacsign = hmacsign\nexports.rfc3986 = rfc3986\n",
              "globals": {
                "crypto": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "qs": {
                  "type": "assign"
                },
                "sha1": {
                  "type": "assign"
                },
                "rfc3986": {
                  "type": "assign"
                },
                "encodeURIComponent": {
                  "type": "call"
                },
                "hmacsign": {
                  "type": "assign"
                },
                "escape": {
                  "type": "call"
                },
                "Object": {
                  "type": "reference"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "crypto": {
                    "where": "inline"
                  },
                  "querystring": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/oauth-sign';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/oauth-sign';\nvar crypto = require('__SYSTEM__/crypto')\n  , qs = require('__SYSTEM__/querystring')\n  ;\n\nfunction sha1 (key, body) {\n  return crypto.createHmac('sha1', key).update(body).digest('base64')\n}\n\nfunction rfc3986 (str) {\n  return encodeURIComponent(str)\n    .replace(/!/g,'%21')\n    .replace(/\\*/g,'%2A')\n    .replace(/\\(/g,'%28')\n    .replace(/\\)/g,'%29')\n    .replace(/'/g,'%27')\n    ;\n}\n\nfunction hmacsign (httpMethod, base_uri, params, consumer_secret, token_secret) {\n  // adapted from https://dev.twitter.com/docs/auth/oauth and \n  // https://dev.twitter.com/docs/auth/creating-signature\n\n  var querystring = Object.keys(params).sort().map(function(key){\n    // big WTF here with the escape + encoding but it's what twitter wants\n    return escape(rfc3986(key)) + \"%3D\" + escape(rfc3986(params[key]))\n  }).join('%26')\n\n  var base = [\n    httpMethod ? httpMethod.toUpperCase() : 'GET',\n    rfc3986(base_uri),\n    querystring\n  ].join('&')\n\n  var key = [\n    consumer_secret,\n    token_secret || ''\n  ].map(rfc3986).join('&')\n\n  return sha1(key, base)\n}\n\nexports.hmacsign = hmacsign\nexports.rfc3986 = rfc3986\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "crypto": {
                  "where": "inline"
                },
                "querystring": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/index.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/index.js",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/index.js",
              "mtime": 1365188840,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/index.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/index",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/lib/index.js",
              "mtime": 1365312498,
              "code": "// Export sub-modules\r\n\r\nexports.error = exports.Error = require('boom');\r\nexports.sntp = require('sntp');\r\nexports.server = require('./server');\r\nexports.client = require('./client');\r\nexports.crypto = require('./crypto');\r\nexports.utils = require('./utils');\r\n\r\nexports.uri = {\r\n    authenticate: exports.server.authenticateBewit,\r\n    getBewit: exports.client.getBewit\r\n};\r\n\r\n\r\n",
              "globals": {
                "exports": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "boom": {
                    "where": "inline"
                  },
                  "sntp": {
                    "where": "inline"
                  },
                  "./server": {
                    "where": "inline"
                  },
                  "./client": {
                    "where": "inline"
                  },
                  "./crypto": {
                    "where": "inline"
                  },
                  "./utils": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';\n// Export sub-modules\r\n\r\nexports.error = exports.Error = require('boom');\r\nexports.sntp = require('sntp');\r\nexports.server = require('./server');\r\nexports.client = require('./client');\r\nexports.crypto = require('./crypto');\r\nexports.utils = require('./utils');\r\n\r\nexports.uri = {\r\n    authenticate: exports.server.authenticateBewit,\r\n    getBewit: exports.client.getBewit\r\n};\r\n\r\n\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "boom": {
                  "where": "inline"
                },
                "sntp": {
                  "where": "inline"
                },
                "./server": {
                  "where": "inline"
                },
                "./client": {
                  "where": "inline"
                },
                "./crypto": {
                  "where": "inline"
                },
                "./utils": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/index.js": {
            "requireId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/index.js",
            "memoizeId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/boom/index.js",
              "mtime": 1365488312,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/lib/index.js": {
            "requireId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/lib/index",
            "memoizeId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/boom/lib/index.js",
              "mtime": 1369144077,
              "code": "// Load modules\n\nvar Http = require('http');\nvar NodeUtil = require('util');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\n\nexports = module.exports = internals.Boom = function (/* (new Error) or (code, message) */) {\n\n    var self = this;\n\n    Hoek.assert(this.constructor === internals.Boom, 'Error must be instantiated using new');\n\n    Error.call(this);\n    this.isBoom = true;\n\n    this.response = {\n        code: 0,\n        payload: {},\n        headers: {}\n        // type: 'content-type'\n    };\n\n    if (arguments[0] instanceof Error) {\n\n        // Error\n\n        var error = arguments[0];\n\n        this.data = error;\n        this.response.code = error.code || 500;\n        if (error.message) {\n            this.message = error.message;\n        }\n    }\n    else {\n\n        // code, message\n\n        var code = arguments[0];\n        var message = arguments[1];\n\n        Hoek.assert(!isNaN(parseFloat(code)) && isFinite(code) && code >= 400, 'First argument must be a number (400+)');\n\n        this.response.code = code;\n        if (message) {\n            this.message = message;\n        }\n    }\n\n    // Response format\n\n    this.reformat();\n\n    return this;\n};\n\nNodeUtil.inherits(internals.Boom, Error);\n\n\ninternals.Boom.prototype.reformat = function () {\n\n    this.response.payload.code = this.response.code;\n    this.response.payload.error = Http.STATUS_CODES[this.response.code] || 'Unknown';\n    if (this.message) {\n        this.response.payload.message = Hoek.escapeHtml(this.message);         // Prevent XSS from error message\n    }\n};\n\n\n// Utilities\n\ninternals.Boom.badRequest = function (message) {\n\n    return new internals.Boom(400, message);\n};\n\n\ninternals.Boom.unauthorized = function (message, scheme, attributes) {          // Or function (message, wwwAuthenticate[])\n\n    var err = new internals.Boom(401, message);\n\n    if (!scheme) {\n        return err;\n    }\n\n    var wwwAuthenticate = '';\n\n    if (typeof scheme === 'string') {\n\n        // function (message, scheme, attributes)\n\n        wwwAuthenticate = scheme;\n        if (attributes) {\n            var names = Object.keys(attributes);\n            for (var i = 0, il = names.length; i < il; ++i) {\n                if (i) {\n                    wwwAuthenticate += ',';\n                }\n\n                var value = attributes[names[i]];\n                if (value === null ||\n                    value === undefined) {              // Value can be zero\n\n                    value = '';\n                }\n                wwwAuthenticate += ' ' + names[i] + '=\"' + Hoek.escapeHeaderAttribute(value.toString()) + '\"';\n            }\n        }\n\n        if (message) {\n            if (attributes) {\n                wwwAuthenticate += ',';\n            }\n            wwwAuthenticate += ' error=\"' + Hoek.escapeHeaderAttribute(message) + '\"';\n        }\n        else {\n            err.isMissing = true;\n        }\n    }\n    else {\n\n        // function (message, wwwAuthenticate[])\n\n        var wwwArray = scheme;\n        for (var i = 0, il = wwwArray.length; i < il; ++i) {\n            if (i) {\n                wwwAuthenticate += ', ';\n            }\n\n            wwwAuthenticate += wwwArray[i];\n        }\n    }\n\n    err.response.headers['WWW-Authenticate'] = wwwAuthenticate;\n\n    return err;\n};\n\n\ninternals.Boom.clientTimeout = function (message) {\n\n    return new internals.Boom(408, message);\n};\n\n\ninternals.Boom.serverTimeout = function (message) {\n\n    return new internals.Boom(503, message);\n};\n\n\ninternals.Boom.forbidden = function (message) {\n\n    return new internals.Boom(403, message);\n};\n\n\ninternals.Boom.notFound = function (message) {\n\n    return new internals.Boom(404, message);\n};\n\n\ninternals.Boom.internal = function (message, data) {\n\n    var err = new internals.Boom(500, message);\n\n    if (data && data.stack) {\n        err.trace = data.stack.split('\\n');\n        err.outterTrace = Hoek.displayStack(1);\n    }\n    else {\n        err.trace = Hoek.displayStack(1);\n    }\n\n    err.data = data;\n    err.response.payload.message = 'An internal server error occurred';                     // Hide actual error from user\n\n    return err;\n};\n\n\ninternals.Boom.passThrough = function (code, payload, contentType, headers) {\n\n    var err = new internals.Boom(500, 'Pass-through');                                      // 500 code is only used to initialize\n\n    err.data = {\n        code: code,\n        payload: payload,\n        type: contentType\n    };\n\n    err.response.code = code;\n    err.response.type = contentType;\n    err.response.headers = headers;\n    err.response.payload = payload;\n\n    return err;\n};\n\n\n",
              "globals": {
                "Http": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "NodeUtil": {
                  "type": "assign"
                },
                "Hoek": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "Error": {
                  "type": "reference"
                },
                "isNaN": {
                  "type": "call"
                },
                "parseFloat": {
                  "type": "call"
                },
                "isFinite": {
                  "type": "call"
                },
                "Object": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "http": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  },
                  "hoek": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/lib';\n// Load modules\n\nvar Http = require('__SYSTEM__/http');\nvar NodeUtil = require('__SYSTEM__/util');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\n\nexports = module.exports = internals.Boom = function (/* (new Error) or (code, message) */) {\n\n    var self = this;\n\n    Hoek.assert(this.constructor === internals.Boom, 'Error must be instantiated using new');\n\n    Error.call(this);\n    this.isBoom = true;\n\n    this.response = {\n        code: 0,\n        payload: {},\n        headers: {}\n        // type: 'content-type'\n    };\n\n    if (arguments[0] instanceof Error) {\n\n        // Error\n\n        var error = arguments[0];\n\n        this.data = error;\n        this.response.code = error.code || 500;\n        if (error.message) {\n            this.message = error.message;\n        }\n    }\n    else {\n\n        // code, message\n\n        var code = arguments[0];\n        var message = arguments[1];\n\n        Hoek.assert(!isNaN(parseFloat(code)) && isFinite(code) && code >= 400, 'First argument must be a number (400+)');\n\n        this.response.code = code;\n        if (message) {\n            this.message = message;\n        }\n    }\n\n    // Response format\n\n    this.reformat();\n\n    return this;\n};\n\nNodeUtil.inherits(internals.Boom, Error);\n\n\ninternals.Boom.prototype.reformat = function () {\n\n    this.response.payload.code = this.response.code;\n    this.response.payload.error = Http.STATUS_CODES[this.response.code] || 'Unknown';\n    if (this.message) {\n        this.response.payload.message = Hoek.escapeHtml(this.message);         // Prevent XSS from error message\n    }\n};\n\n\n// Utilities\n\ninternals.Boom.badRequest = function (message) {\n\n    return new internals.Boom(400, message);\n};\n\n\ninternals.Boom.unauthorized = function (message, scheme, attributes) {          // Or function (message, wwwAuthenticate[])\n\n    var err = new internals.Boom(401, message);\n\n    if (!scheme) {\n        return err;\n    }\n\n    var wwwAuthenticate = '';\n\n    if (typeof scheme === 'string') {\n\n        // function (message, scheme, attributes)\n\n        wwwAuthenticate = scheme;\n        if (attributes) {\n            var names = Object.keys(attributes);\n            for (var i = 0, il = names.length; i < il; ++i) {\n                if (i) {\n                    wwwAuthenticate += ',';\n                }\n\n                var value = attributes[names[i]];\n                if (value === null ||\n                    value === undefined) {              // Value can be zero\n\n                    value = '';\n                }\n                wwwAuthenticate += ' ' + names[i] + '=\"' + Hoek.escapeHeaderAttribute(value.toString()) + '\"';\n            }\n        }\n\n        if (message) {\n            if (attributes) {\n                wwwAuthenticate += ',';\n            }\n            wwwAuthenticate += ' error=\"' + Hoek.escapeHeaderAttribute(message) + '\"';\n        }\n        else {\n            err.isMissing = true;\n        }\n    }\n    else {\n\n        // function (message, wwwAuthenticate[])\n\n        var wwwArray = scheme;\n        for (var i = 0, il = wwwArray.length; i < il; ++i) {\n            if (i) {\n                wwwAuthenticate += ', ';\n            }\n\n            wwwAuthenticate += wwwArray[i];\n        }\n    }\n\n    err.response.headers['WWW-Authenticate'] = wwwAuthenticate;\n\n    return err;\n};\n\n\ninternals.Boom.clientTimeout = function (message) {\n\n    return new internals.Boom(408, message);\n};\n\n\ninternals.Boom.serverTimeout = function (message) {\n\n    return new internals.Boom(503, message);\n};\n\n\ninternals.Boom.forbidden = function (message) {\n\n    return new internals.Boom(403, message);\n};\n\n\ninternals.Boom.notFound = function (message) {\n\n    return new internals.Boom(404, message);\n};\n\n\ninternals.Boom.internal = function (message, data) {\n\n    var err = new internals.Boom(500, message);\n\n    if (data && data.stack) {\n        err.trace = data.stack.split('\\n');\n        err.outterTrace = Hoek.displayStack(1);\n    }\n    else {\n        err.trace = Hoek.displayStack(1);\n    }\n\n    err.data = data;\n    err.response.payload.message = 'An internal server error occurred';                     // Hide actual error from user\n\n    return err;\n};\n\n\ninternals.Boom.passThrough = function (code, payload, contentType, headers) {\n\n    var err = new internals.Boom(500, 'Pass-through');                                      // 500 code is only used to initialize\n\n    err.data = {\n        code: code,\n        payload: payload,\n        type: contentType\n    };\n\n    err.response.code = code;\n    err.response.type = contentType;\n    err.response.headers = headers;\n    err.response.payload = payload;\n\n    return err;\n};\n\n\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "http": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                },
                "hoek": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/index.js": {
            "requireId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/index.js",
            "memoizeId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/index.js",
              "mtime": 1368629552,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/index.js": {
            "requireId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/index",
            "memoizeId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib/index.js",
              "mtime": 1368653676,
              "code": "// Load modules\r\n\r\nvar Fs = require('fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        for (var i = 0, il = source.length; i < il; ++i) {\r\n            target.push(source[i]);\r\n        }\r\n\r\n        return target;\r\n    }\r\n\r\n    var keys = Object.keys(source);\r\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\r\n        var key = keys[k];\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2, justFirst) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            if (justFirst) {\r\n                return array2[i];\r\n            }\r\n\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return (justFirst ? null : common);\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    for (var i = 0, il = path.length; i < il; ++i) {\r\n        if (ref) {\r\n            ref = ref[path[i]];\r\n        }\r\n    }\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    for (var i = 0, il = stack.length; i < il; ++i) {\r\n        var item = stack[i];\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n\r\n    for (var i = 0, il = trace.length; i < il; ++i) {\r\n        var row = trace[i];\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    }\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    var files = Fs.readdirSync(path);\r\n    for (i = 0, il = files.length; i < il; ++i) {\r\n        var filename = files[i];\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n",
              "globals": {
                "Fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Escape": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Object": {
                  "type": "reference"
                },
                "Array": {
                  "type": "reference"
                },
                "Error": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "JSON": {
                  "type": "reference"
                },
                "Date": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "./escape": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib';\n// Load modules\r\n\r\nvar Fs = require('__SYSTEM__/fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        for (var i = 0, il = source.length; i < il; ++i) {\r\n            target.push(source[i]);\r\n        }\r\n\r\n        return target;\r\n    }\r\n\r\n    var keys = Object.keys(source);\r\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\r\n        var key = keys[k];\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2, justFirst) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            if (justFirst) {\r\n                return array2[i];\r\n            }\r\n\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return (justFirst ? null : common);\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    for (var i = 0, il = path.length; i < il; ++i) {\r\n        if (ref) {\r\n            ref = ref[path[i]];\r\n        }\r\n    }\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    for (var i = 0, il = stack.length; i < il; ++i) {\r\n        var item = stack[i];\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n\r\n    for (var i = 0, il = trace.length; i < il; ++i) {\r\n        var row = trace[i];\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    }\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    var files = Fs.readdirSync(path);\r\n    for (i = 0, il = files.length; i < il; ++i) {\r\n        var filename = files[i];\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "./escape": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/escape.js": {
            "requireId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/escape",
            "memoizeId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/lib/escape.js",
            "descriptor": {
              "filename": "escape.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib/escape.js",
              "mtime": 1368629552,
              "code": "// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\nexports.escapeJavaScript = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeJavaScriptChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\nexports.escapeHtml = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeHtmlChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\ninternals.escapeJavaScriptChar = function (charCode) {\r\n\r\n    if (charCode >= 256) {\r\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '\\\\x' + internals.padLeft(hexValue, 2);\r\n};\r\n\r\n\r\ninternals.escapeHtmlChar = function (charCode) {\r\n\r\n    var namedEscape = internals.namedHtml[charCode];\r\n    if (typeof namedEscape !== 'undefined') {\r\n        return namedEscape;\r\n    }\r\n\r\n    if (charCode >= 256) {\r\n        return '&#' + charCode + ';';\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\r\n};\r\n\r\n\r\ninternals.padLeft = function (str, len) {\r\n\r\n    while (str.length < len) {\r\n        str = '0' + str;\r\n    }\r\n\r\n    return str;\r\n};\r\n\r\n\r\ninternals.isSafe = function (charCode) {\r\n\r\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\r\n};\r\n\r\n\r\ninternals.namedHtml = {\r\n    '38': '&amp;',\r\n    '60': '&lt;',\r\n    '62': '&gt;',\r\n    '34': '&quot;',\r\n    '160': '&nbsp;',\r\n    '162': '&cent;',\r\n    '163': '&pound;',\r\n    '164': '&curren;',\r\n    '169': '&copy;',\r\n    '174': '&reg;'\r\n};\r\n\r\n\r\ninternals.safeCharCodes = (function () {\r\n\r\n    var safe = {};\r\n\r\n    for (var i = 32; i < 123; ++i) {\r\n\r\n        if ((i >= 97 && i <= 122) ||         // a-z\r\n            (i >= 65 && i <= 90) ||          // A-Z\r\n            (i >= 48 && i <= 57) ||          // 0-9\r\n            i === 32 ||                      // space\r\n            i === 46 ||                      // .\r\n            i === 44 ||                      // ,\r\n            i === 45 ||                      // -\r\n            i === 58 ||                      // :\r\n            i === 95) {                      // _\r\n\r\n            safe[i] = null;\r\n        }\r\n    }\r\n\r\n    return safe;\r\n}());",
              "globals": {
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "i": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/lib';\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\nexports.escapeJavaScript = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeJavaScriptChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\nexports.escapeHtml = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeHtmlChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\ninternals.escapeJavaScriptChar = function (charCode) {\r\n\r\n    if (charCode >= 256) {\r\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '\\\\x' + internals.padLeft(hexValue, 2);\r\n};\r\n\r\n\r\ninternals.escapeHtmlChar = function (charCode) {\r\n\r\n    var namedEscape = internals.namedHtml[charCode];\r\n    if (typeof namedEscape !== 'undefined') {\r\n        return namedEscape;\r\n    }\r\n\r\n    if (charCode >= 256) {\r\n        return '&#' + charCode + ';';\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\r\n};\r\n\r\n\r\ninternals.padLeft = function (str, len) {\r\n\r\n    while (str.length < len) {\r\n        str = '0' + str;\r\n    }\r\n\r\n    return str;\r\n};\r\n\r\n\r\ninternals.isSafe = function (charCode) {\r\n\r\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\r\n};\r\n\r\n\r\ninternals.namedHtml = {\r\n    '38': '&amp;',\r\n    '60': '&lt;',\r\n    '62': '&gt;',\r\n    '34': '&quot;',\r\n    '160': '&nbsp;',\r\n    '162': '&cent;',\r\n    '163': '&pound;',\r\n    '164': '&curren;',\r\n    '169': '&copy;',\r\n    '174': '&reg;'\r\n};\r\n\r\n\r\ninternals.safeCharCodes = (function () {\r\n\r\n    var safe = {};\r\n\r\n    for (var i = 32; i < 123; ++i) {\r\n\r\n        if ((i >= 97 && i <= 122) ||         // a-z\r\n            (i >= 65 && i <= 90) ||          // A-Z\r\n            (i >= 48 && i <= 57) ||          // 0-9\r\n            i === 32 ||                      // space\r\n            i === 46 ||                      // .\r\n            i === 44 ||                      // ,\r\n            i === 45 ||                      // -\r\n            i === 58 ||                      // :\r\n            i === 95) {                      // _\r\n\r\n            safe[i] = null;\r\n        }\r\n    }\r\n\r\n    return safe;\r\n}());\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/index.js": {
            "requireId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/index.js",
            "memoizeId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/sntp/index.js",
              "mtime": 1365306274,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/lib/index.js": {
            "requireId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/lib/index",
            "memoizeId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/sntp/lib/index.js",
              "mtime": 1369144574,
              "code": "// Load modules\n\nvar Dgram = require('dgram');\nvar Dns = require('dns');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\n\nexports.time = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var settings = Hoek.clone(options);\n    settings.host = settings.host || 'pool.ntp.org';\n    settings.port = settings.port || 123;\n    settings.resolveReference = settings.resolveReference || false;\n\n    // Declare variables used by callback\n\n    var timeoutId = 0;\n    var sent = 0;\n\n    // Ensure callback is only called once\n\n    var isFinished = false;\n    var finish = function (err, result) {\n\n        if (timeoutId) {\n            clearTimeout(timeoutId);\n            timeoutId = 0;\n        }\n\n        if (!isFinished) {\n            isFinished = true;\n            socket.removeAllListeners();\n            socket.close();\n            return callback(err, result);\n        }\n    };\n\n    // Create UDP socket\n\n    var socket = Dgram.createSocket('udp4');\n\n    socket.once('error', function (err) {\n\n        return finish(err);\n    });\n\n    // Listen to incoming messages\n\n    socket.on('message', function (buffer, rinfo) {\n\n        var received = Date.now();\n\n        var message = new internals.NtpMessage(buffer);\n        if (!message.isValid) {\n            return finish(new Error('Invalid server response'), message);\n        }\n\n        if (message.originateTimestamp !== sent) {\n            return finish(new Error('Wrong originate timestamp'), message);\n        }\n\n        // Timestamp Name          ID   When Generated\n        // ------------------------------------------------------------\n        // Originate Timestamp     T1   time request sent by client\n        // Receive Timestamp       T2   time request received by server\n        // Transmit Timestamp      T3   time reply sent by server\n        // Destination Timestamp   T4   time reply received by client\n        //\n        // The roundtrip delay d and system clock offset t are defined as:\n        //\n        // d = (T4 - T1) - (T3 - T2)     t = ((T2 - T1) + (T3 - T4)) / 2\n\n        var T1 = message.originateTimestamp;\n        var T2 = message.receiveTimestamp;\n        var T3 = message.transmitTimestamp;\n        var T4 = received;\n\n        message.d = (T4 - T1) - (T3 - T2);\n        message.t = ((T2 - T1) + (T3 - T4)) / 2;\n        message.receivedLocally = received;\n\n        if (!settings.resolveReference ||\n            message.stratum !== 'secondary') {\n\n            return finish(null, message);\n        }\n\n        // Resolve reference IP address\n\n        Dns.reverse(message.referenceId, function (err, domains) {\n\n            if (!err) {\n                message.referenceHost = domains[0];\n            }\n\n            return finish(null, message);\n        });\n    });\n\n    // Set timeout\n\n    if (settings.timeout) {\n        timeoutId = setTimeout(function () {\n\n            timeoutId = 0;\n            return finish(new Error('Timeout'));\n        }, settings.timeout);\n    }\n\n    // Construct NTP message\n\n    var message = new Buffer(48);\n    for (var i = 0; i < 48; i++) {                      // Zero message\n        message[i] = 0;\n    }\n\n    message[0] = (0 << 6) + (4 << 3) + (3 << 0)         // Set version number to 4 and Mode to 3 (client)\n    sent = Date.now();\n    internals.fromMsecs(sent, message, 40);               // Set transmit timestamp (returns as originate)\n\n    // Send NTP request\n\n    socket.send(message, 0, message.length, settings.port, settings.host, function (err, bytes) {\n\n        if (err ||\n            bytes !== 48) {\n\n            return finish(err || new Error('Could not send entire message'));\n        }\n    });\n};\n\n\ninternals.NtpMessage = function (buffer) {\n\n    this.isValid = false;\n\n    // Validate\n\n    if (buffer.length !== 48) {\n        return;\n    }\n\n    // Leap indicator\n\n    var li = (buffer[0] >> 6);\n    switch (li) {\n        case 0: this.leapIndicator = 'no-warning'; break;\n        case 1: this.leapIndicator = 'last-minute-61'; break;\n        case 2: this.leapIndicator = 'last-minute-59'; break;\n        case 3: this.leapIndicator = 'alarm'; break;\n    }\n\n    // Version\n\n    var vn = ((buffer[0] & 0x38) >> 3);\n    this.version = vn;\n\n    // Mode\n\n    var mode = (buffer[0] & 0x7);\n    switch (mode) {\n        case 1: this.mode = 'symmetric-active'; break;\n        case 2: this.mode = 'symmetric-passive'; break;\n        case 3: this.mode = 'client'; break;\n        case 4: this.mode = 'server'; break;\n        case 5: this.mode = 'broadcast'; break;\n        case 0:\n        case 6:\n        case 7: this.mode = 'reserved'; break;\n    }\n\n    // Stratum\n\n    var stratum = buffer[1];\n    if (stratum === 0) {\n        this.stratum = 'death';\n    }\n    else if (stratum === 1) {\n        this.stratum = 'primary';\n    }\n    else if (stratum <= 15) {\n        this.stratum = 'secondary';\n    }\n    else {\n        this.stratum = 'reserved';\n    }\n\n    // Poll interval (msec)\n\n    this.pollInterval = Math.round(Math.pow(2, buffer[2])) * 1000;\n\n    // Precision (msecs)\n\n    this.precision = Math.pow(2, buffer[3]) * 1000;\n\n    // Root delay (msecs)\n\n    var rootDelay = 256 * (256 * (256 * buffer[4] + buffer[5]) + buffer[6]) + buffer[7];\n    this.rootDelay = 1000 * (rootDelay / 0x10000);\n\n    // Root dispersion (msecs)\n\n    this.rootDispersion = ((buffer[8] << 8) + buffer[9] + ((buffer[10] << 8) + buffer[11]) / Math.pow(2, 16)) * 1000;\n\n    // Reference identifier\n\n    this.referenceId = '';\n    switch (this.stratum) {\n        case 'death':\n        case 'primary':\n            this.referenceId = String.fromCharCode(buffer[12]) + String.fromCharCode(buffer[13]) + String.fromCharCode(buffer[14]) + String.fromCharCode(buffer[15]);\n            break;\n        case 'secondary':\n            this.referenceId = '' + buffer[12] + '.' + buffer[13] + '.' + buffer[14] + '.' + buffer[15];\n            break;\n    }\n\n    // Reference timestamp\n\n    this.referenceTimestamp = internals.toMsecs(buffer, 16);\n\n    // Originate timestamp\n\n    this.originateTimestamp = internals.toMsecs(buffer, 24);\n\n    // Receive timestamp\n\n    this.receiveTimestamp = internals.toMsecs(buffer, 32);\n\n    // Transmit timestamp\n\n    this.transmitTimestamp = internals.toMsecs(buffer, 40);\n\n    // Validate\n\n    if (this.version === 4 &&\n        this.stratum !== 'reserved' &&\n        this.mode === 'server' &&\n        this.originateTimestamp &&\n        this.receiveTimestamp &&\n        this.transmitTimestamp) {\n\n        this.isValid = true;\n    }\n\n    return this;\n};\n\n\ninternals.toMsecs = function (buffer, offset) {\n\n    var seconds = 0;\n    var fraction = 0;\n\n    for (var i = 0; i < 4; ++i) {\n        seconds = (seconds * 256) + buffer[offset + i];\n    }\n\n    for (i = 4; i < 8; ++i) {\n        fraction = (fraction * 256) + buffer[offset + i];\n    }\n\n    return ((seconds - 2208988800 + (fraction / Math.pow(2, 32))) * 1000);\n};\n\n\ninternals.fromMsecs = function (ts, buffer, offset) {\n\n    var seconds = Math.floor(ts / 1000) + 2208988800;\n    var fraction = Math.round((ts % 1000) / 1000 * Math.pow(2, 32));\n\n    buffer[offset + 0] = (seconds & 0xFF000000) >> 24;\n    buffer[offset + 1] = (seconds & 0x00FF0000) >> 16;\n    buffer[offset + 2] = (seconds & 0x0000FF00) >> 8;\n    buffer[offset + 3] = (seconds & 0x000000FF);\n\n    buffer[offset + 4] = (fraction & 0xFF000000) >> 24;\n    buffer[offset + 5] = (fraction & 0x00FF0000) >> 16;\n    buffer[offset + 6] = (fraction & 0x0000FF00) >> 8;\n    buffer[offset + 7] = (fraction & 0x000000FF);\n};\n\n\n// Offset singleton\n\ninternals.last = {\n    offset: 0,\n    expires: 0,\n    host: '',\n    port: 0\n};\n\n\nexports.offset = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var now = Date.now();\n    var clockSyncRefresh = options.clockSyncRefresh || 24 * 60 * 60 * 1000;                    // Daily\n\n    if (internals.last.offset &&\n        internals.last.host === options.host &&\n        internals.last.port === options.port &&\n        now < internals.last.expires) {\n\n        process.nextTick(function () {\n                \n            callback(null, internals.last.offset);\n        });\n\n        return;\n    }\n\n    exports.time(options, function (err, time) {\n\n        if (err) {\n            return callback(err, 0);\n        }\n\n        internals.last = {\n            offset: Math.round(time.t),\n            expires: now + clockSyncRefresh,\n            host: options.host,\n            port: options.port\n        };\n\n        return callback(null, internals.last.offset);\n    });\n};\n\n\n// Now singleton\n\ninternals.now = {\n    intervalId: 0\n};\n\n\nexports.start = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    if (internals.now.intervalId) {\n        process.nextTick(function () {\n            \n            callback();\n        });\n        \n        return;\n    }\n\n    exports.offset(options, function (err, offset) {\n\n        internals.now.intervalId = setInterval(function () {\n\n            exports.offset(options, function () { });\n        }, options.clockSyncRefresh || 24 * 60 * 60 * 1000);                                // Daily\n\n        return callback();\n    });\n};\n\n\nexports.stop = function () {\n\n    if (!internals.now.intervalId) {\n        return;\n    }\n\n    clearInterval(internals.now.intervalId);\n    internals.now.intervalId = 0;\n};\n\n\nexports.isLive = function () {\n\n    return !!internals.now.intervalId;\n};\n\n\nexports.now = function () {\n\n    var now = Date.now();\n    if (!exports.isLive() ||\n        now >= internals.last.expires) {\n\n        return now;\n    }\n\n    return now + internals.last.offset;\n};\n\n",
              "globals": {
                "Dgram": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Dns": {
                  "type": "assign"
                },
                "Hoek": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "clearTimeout": {
                  "type": "call"
                },
                "Date": {
                  "type": "reference"
                },
                "setTimeout": {
                  "type": "call"
                },
                "Math": {
                  "type": "reference"
                },
                "String": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "setInterval": {
                  "type": "call"
                },
                "clearInterval": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "dgram": {
                    "where": "inline"
                  },
                  "dns": {
                    "where": "inline"
                  },
                  "hoek": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/lib';\n// Load modules\n\nvar Dgram = require('__SYSTEM__/dgram');\nvar Dns = require('__SYSTEM__/dns');\nvar Hoek = require('hoek');\n\n\n// Declare internals\n\nvar internals = {};\n\n\nexports.time = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var settings = Hoek.clone(options);\n    settings.host = settings.host || 'pool.ntp.org';\n    settings.port = settings.port || 123;\n    settings.resolveReference = settings.resolveReference || false;\n\n    // Declare variables used by callback\n\n    var timeoutId = 0;\n    var sent = 0;\n\n    // Ensure callback is only called once\n\n    var isFinished = false;\n    var finish = function (err, result) {\n\n        if (timeoutId) {\n            clearTimeout(timeoutId);\n            timeoutId = 0;\n        }\n\n        if (!isFinished) {\n            isFinished = true;\n            socket.removeAllListeners();\n            socket.close();\n            return callback(err, result);\n        }\n    };\n\n    // Create UDP socket\n\n    var socket = Dgram.createSocket('udp4');\n\n    socket.once('error', function (err) {\n\n        return finish(err);\n    });\n\n    // Listen to incoming messages\n\n    socket.on('message', function (buffer, rinfo) {\n\n        var received = Date.now();\n\n        var message = new internals.NtpMessage(buffer);\n        if (!message.isValid) {\n            return finish(new Error('Invalid server response'), message);\n        }\n\n        if (message.originateTimestamp !== sent) {\n            return finish(new Error('Wrong originate timestamp'), message);\n        }\n\n        // Timestamp Name          ID   When Generated\n        // ------------------------------------------------------------\n        // Originate Timestamp     T1   time request sent by client\n        // Receive Timestamp       T2   time request received by server\n        // Transmit Timestamp      T3   time reply sent by server\n        // Destination Timestamp   T4   time reply received by client\n        //\n        // The roundtrip delay d and system clock offset t are defined as:\n        //\n        // d = (T4 - T1) - (T3 - T2)     t = ((T2 - T1) + (T3 - T4)) / 2\n\n        var T1 = message.originateTimestamp;\n        var T2 = message.receiveTimestamp;\n        var T3 = message.transmitTimestamp;\n        var T4 = received;\n\n        message.d = (T4 - T1) - (T3 - T2);\n        message.t = ((T2 - T1) + (T3 - T4)) / 2;\n        message.receivedLocally = received;\n\n        if (!settings.resolveReference ||\n            message.stratum !== 'secondary') {\n\n            return finish(null, message);\n        }\n\n        // Resolve reference IP address\n\n        Dns.reverse(message.referenceId, function (err, domains) {\n\n            if (!err) {\n                message.referenceHost = domains[0];\n            }\n\n            return finish(null, message);\n        });\n    });\n\n    // Set timeout\n\n    if (settings.timeout) {\n        timeoutId = setTimeout(function () {\n\n            timeoutId = 0;\n            return finish(new Error('Timeout'));\n        }, settings.timeout);\n    }\n\n    // Construct NTP message\n\n    var message = new Buffer(48);\n    for (var i = 0; i < 48; i++) {                      // Zero message\n        message[i] = 0;\n    }\n\n    message[0] = (0 << 6) + (4 << 3) + (3 << 0)         // Set version number to 4 and Mode to 3 (client)\n    sent = Date.now();\n    internals.fromMsecs(sent, message, 40);               // Set transmit timestamp (returns as originate)\n\n    // Send NTP request\n\n    socket.send(message, 0, message.length, settings.port, settings.host, function (err, bytes) {\n\n        if (err ||\n            bytes !== 48) {\n\n            return finish(err || new Error('Could not send entire message'));\n        }\n    });\n};\n\n\ninternals.NtpMessage = function (buffer) {\n\n    this.isValid = false;\n\n    // Validate\n\n    if (buffer.length !== 48) {\n        return;\n    }\n\n    // Leap indicator\n\n    var li = (buffer[0] >> 6);\n    switch (li) {\n        case 0: this.leapIndicator = 'no-warning'; break;\n        case 1: this.leapIndicator = 'last-minute-61'; break;\n        case 2: this.leapIndicator = 'last-minute-59'; break;\n        case 3: this.leapIndicator = 'alarm'; break;\n    }\n\n    // Version\n\n    var vn = ((buffer[0] & 0x38) >> 3);\n    this.version = vn;\n\n    // Mode\n\n    var mode = (buffer[0] & 0x7);\n    switch (mode) {\n        case 1: this.mode = 'symmetric-active'; break;\n        case 2: this.mode = 'symmetric-passive'; break;\n        case 3: this.mode = 'client'; break;\n        case 4: this.mode = 'server'; break;\n        case 5: this.mode = 'broadcast'; break;\n        case 0:\n        case 6:\n        case 7: this.mode = 'reserved'; break;\n    }\n\n    // Stratum\n\n    var stratum = buffer[1];\n    if (stratum === 0) {\n        this.stratum = 'death';\n    }\n    else if (stratum === 1) {\n        this.stratum = 'primary';\n    }\n    else if (stratum <= 15) {\n        this.stratum = 'secondary';\n    }\n    else {\n        this.stratum = 'reserved';\n    }\n\n    // Poll interval (msec)\n\n    this.pollInterval = Math.round(Math.pow(2, buffer[2])) * 1000;\n\n    // Precision (msecs)\n\n    this.precision = Math.pow(2, buffer[3]) * 1000;\n\n    // Root delay (msecs)\n\n    var rootDelay = 256 * (256 * (256 * buffer[4] + buffer[5]) + buffer[6]) + buffer[7];\n    this.rootDelay = 1000 * (rootDelay / 0x10000);\n\n    // Root dispersion (msecs)\n\n    this.rootDispersion = ((buffer[8] << 8) + buffer[9] + ((buffer[10] << 8) + buffer[11]) / Math.pow(2, 16)) * 1000;\n\n    // Reference identifier\n\n    this.referenceId = '';\n    switch (this.stratum) {\n        case 'death':\n        case 'primary':\n            this.referenceId = String.fromCharCode(buffer[12]) + String.fromCharCode(buffer[13]) + String.fromCharCode(buffer[14]) + String.fromCharCode(buffer[15]);\n            break;\n        case 'secondary':\n            this.referenceId = '' + buffer[12] + '.' + buffer[13] + '.' + buffer[14] + '.' + buffer[15];\n            break;\n    }\n\n    // Reference timestamp\n\n    this.referenceTimestamp = internals.toMsecs(buffer, 16);\n\n    // Originate timestamp\n\n    this.originateTimestamp = internals.toMsecs(buffer, 24);\n\n    // Receive timestamp\n\n    this.receiveTimestamp = internals.toMsecs(buffer, 32);\n\n    // Transmit timestamp\n\n    this.transmitTimestamp = internals.toMsecs(buffer, 40);\n\n    // Validate\n\n    if (this.version === 4 &&\n        this.stratum !== 'reserved' &&\n        this.mode === 'server' &&\n        this.originateTimestamp &&\n        this.receiveTimestamp &&\n        this.transmitTimestamp) {\n\n        this.isValid = true;\n    }\n\n    return this;\n};\n\n\ninternals.toMsecs = function (buffer, offset) {\n\n    var seconds = 0;\n    var fraction = 0;\n\n    for (var i = 0; i < 4; ++i) {\n        seconds = (seconds * 256) + buffer[offset + i];\n    }\n\n    for (i = 4; i < 8; ++i) {\n        fraction = (fraction * 256) + buffer[offset + i];\n    }\n\n    return ((seconds - 2208988800 + (fraction / Math.pow(2, 32))) * 1000);\n};\n\n\ninternals.fromMsecs = function (ts, buffer, offset) {\n\n    var seconds = Math.floor(ts / 1000) + 2208988800;\n    var fraction = Math.round((ts % 1000) / 1000 * Math.pow(2, 32));\n\n    buffer[offset + 0] = (seconds & 0xFF000000) >> 24;\n    buffer[offset + 1] = (seconds & 0x00FF0000) >> 16;\n    buffer[offset + 2] = (seconds & 0x0000FF00) >> 8;\n    buffer[offset + 3] = (seconds & 0x000000FF);\n\n    buffer[offset + 4] = (fraction & 0xFF000000) >> 24;\n    buffer[offset + 5] = (fraction & 0x00FF0000) >> 16;\n    buffer[offset + 6] = (fraction & 0x0000FF00) >> 8;\n    buffer[offset + 7] = (fraction & 0x000000FF);\n};\n\n\n// Offset singleton\n\ninternals.last = {\n    offset: 0,\n    expires: 0,\n    host: '',\n    port: 0\n};\n\n\nexports.offset = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    var now = Date.now();\n    var clockSyncRefresh = options.clockSyncRefresh || 24 * 60 * 60 * 1000;                    // Daily\n\n    if (internals.last.offset &&\n        internals.last.host === options.host &&\n        internals.last.port === options.port &&\n        now < internals.last.expires) {\n\n        process.nextTick(function () {\n                \n            callback(null, internals.last.offset);\n        });\n\n        return;\n    }\n\n    exports.time(options, function (err, time) {\n\n        if (err) {\n            return callback(err, 0);\n        }\n\n        internals.last = {\n            offset: Math.round(time.t),\n            expires: now + clockSyncRefresh,\n            host: options.host,\n            port: options.port\n        };\n\n        return callback(null, internals.last.offset);\n    });\n};\n\n\n// Now singleton\n\ninternals.now = {\n    intervalId: 0\n};\n\n\nexports.start = function (options, callback) {\n\n    if (arguments.length !== 2) {\n        callback = arguments[0];\n        options = {};\n    }\n\n    if (internals.now.intervalId) {\n        process.nextTick(function () {\n            \n            callback();\n        });\n        \n        return;\n    }\n\n    exports.offset(options, function (err, offset) {\n\n        internals.now.intervalId = setInterval(function () {\n\n            exports.offset(options, function () { });\n        }, options.clockSyncRefresh || 24 * 60 * 60 * 1000);                                // Daily\n\n        return callback();\n    });\n};\n\n\nexports.stop = function () {\n\n    if (!internals.now.intervalId) {\n        return;\n    }\n\n    clearInterval(internals.now.intervalId);\n    internals.now.intervalId = 0;\n};\n\n\nexports.isLive = function () {\n\n    return !!internals.now.intervalId;\n};\n\n\nexports.now = function () {\n\n    var now = Date.now();\n    if (!exports.isLive() ||\n        now >= internals.last.expires) {\n\n        return now;\n    }\n\n    return now + internals.last.offset;\n};\n\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "dgram": {
                  "where": "inline"
                },
                "dns": {
                  "where": "inline"
                },
                "hoek": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/index.js": {
            "requireId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/index.js",
            "memoizeId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/index.js",
              "mtime": 1368629552,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/index.js": {
            "requireId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/index",
            "memoizeId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib/index.js",
              "mtime": 1368653676,
              "code": "// Load modules\r\n\r\nvar Fs = require('fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        for (var i = 0, il = source.length; i < il; ++i) {\r\n            target.push(source[i]);\r\n        }\r\n\r\n        return target;\r\n    }\r\n\r\n    var keys = Object.keys(source);\r\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\r\n        var key = keys[k];\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2, justFirst) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            if (justFirst) {\r\n                return array2[i];\r\n            }\r\n\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return (justFirst ? null : common);\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    for (var i = 0, il = path.length; i < il; ++i) {\r\n        if (ref) {\r\n            ref = ref[path[i]];\r\n        }\r\n    }\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    for (var i = 0, il = stack.length; i < il; ++i) {\r\n        var item = stack[i];\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n\r\n    for (var i = 0, il = trace.length; i < il; ++i) {\r\n        var row = trace[i];\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    }\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    var files = Fs.readdirSync(path);\r\n    for (i = 0, il = files.length; i < il; ++i) {\r\n        var filename = files[i];\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n",
              "globals": {
                "Fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Escape": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Object": {
                  "type": "reference"
                },
                "Array": {
                  "type": "reference"
                },
                "Error": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "JSON": {
                  "type": "reference"
                },
                "Date": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "./escape": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib';\n// Load modules\r\n\r\nvar Fs = require('__SYSTEM__/fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        for (var i = 0, il = source.length; i < il; ++i) {\r\n            target.push(source[i]);\r\n        }\r\n\r\n        return target;\r\n    }\r\n\r\n    var keys = Object.keys(source);\r\n    for (var k = 0, kl = keys.length; k < kl; ++k) {\r\n        var key = keys[k];\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2, justFirst) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            if (justFirst) {\r\n                return array2[i];\r\n            }\r\n\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return (justFirst ? null : common);\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    for (var i = 0, il = path.length; i < il; ++i) {\r\n        if (ref) {\r\n            ref = ref[path[i]];\r\n        }\r\n    }\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    for (var i = 0, il = stack.length; i < il; ++i) {\r\n        var item = stack[i];\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n\r\n    for (var i = 0, il = trace.length; i < il; ++i) {\r\n        var row = trace[i];\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    }\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    var files = Fs.readdirSync(path);\r\n    for (i = 0, il = files.length; i < il; ++i) {\r\n        var filename = files[i];\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "./escape": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/escape.js": {
            "requireId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/escape",
            "memoizeId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/lib/escape.js",
            "descriptor": {
              "filename": "escape.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib/escape.js",
              "mtime": 1368629552,
              "code": "// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\nexports.escapeJavaScript = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeJavaScriptChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\nexports.escapeHtml = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeHtmlChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\ninternals.escapeJavaScriptChar = function (charCode) {\r\n\r\n    if (charCode >= 256) {\r\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '\\\\x' + internals.padLeft(hexValue, 2);\r\n};\r\n\r\n\r\ninternals.escapeHtmlChar = function (charCode) {\r\n\r\n    var namedEscape = internals.namedHtml[charCode];\r\n    if (typeof namedEscape !== 'undefined') {\r\n        return namedEscape;\r\n    }\r\n\r\n    if (charCode >= 256) {\r\n        return '&#' + charCode + ';';\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\r\n};\r\n\r\n\r\ninternals.padLeft = function (str, len) {\r\n\r\n    while (str.length < len) {\r\n        str = '0' + str;\r\n    }\r\n\r\n    return str;\r\n};\r\n\r\n\r\ninternals.isSafe = function (charCode) {\r\n\r\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\r\n};\r\n\r\n\r\ninternals.namedHtml = {\r\n    '38': '&amp;',\r\n    '60': '&lt;',\r\n    '62': '&gt;',\r\n    '34': '&quot;',\r\n    '160': '&nbsp;',\r\n    '162': '&cent;',\r\n    '163': '&pound;',\r\n    '164': '&curren;',\r\n    '169': '&copy;',\r\n    '174': '&reg;'\r\n};\r\n\r\n\r\ninternals.safeCharCodes = (function () {\r\n\r\n    var safe = {};\r\n\r\n    for (var i = 32; i < 123; ++i) {\r\n\r\n        if ((i >= 97 && i <= 122) ||         // a-z\r\n            (i >= 65 && i <= 90) ||          // A-Z\r\n            (i >= 48 && i <= 57) ||          // 0-9\r\n            i === 32 ||                      // space\r\n            i === 46 ||                      // .\r\n            i === 44 ||                      // ,\r\n            i === 45 ||                      // -\r\n            i === 58 ||                      // :\r\n            i === 95) {                      // _\r\n\r\n            safe[i] = null;\r\n        }\r\n    }\r\n\r\n    return safe;\r\n}());",
              "globals": {
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "i": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/lib';\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\nexports.escapeJavaScript = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeJavaScriptChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\nexports.escapeHtml = function (input) {\r\n\r\n    if (!input) {\r\n        return '';\r\n    }\r\n\r\n    var escaped = '';\r\n\r\n    for (var i = 0, il = input.length; i < il; ++i) {\r\n\r\n        var charCode = input.charCodeAt(i);\r\n\r\n        if (internals.isSafe(charCode)) {\r\n            escaped += input[i];\r\n        }\r\n        else {\r\n            escaped += internals.escapeHtmlChar(charCode);\r\n        }\r\n    }\r\n\r\n    return escaped;\r\n};\r\n\r\n\r\ninternals.escapeJavaScriptChar = function (charCode) {\r\n\r\n    if (charCode >= 256) {\r\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '\\\\x' + internals.padLeft(hexValue, 2);\r\n};\r\n\r\n\r\ninternals.escapeHtmlChar = function (charCode) {\r\n\r\n    var namedEscape = internals.namedHtml[charCode];\r\n    if (typeof namedEscape !== 'undefined') {\r\n        return namedEscape;\r\n    }\r\n\r\n    if (charCode >= 256) {\r\n        return '&#' + charCode + ';';\r\n    }\r\n\r\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\r\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\r\n};\r\n\r\n\r\ninternals.padLeft = function (str, len) {\r\n\r\n    while (str.length < len) {\r\n        str = '0' + str;\r\n    }\r\n\r\n    return str;\r\n};\r\n\r\n\r\ninternals.isSafe = function (charCode) {\r\n\r\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\r\n};\r\n\r\n\r\ninternals.namedHtml = {\r\n    '38': '&amp;',\r\n    '60': '&lt;',\r\n    '62': '&gt;',\r\n    '34': '&quot;',\r\n    '160': '&nbsp;',\r\n    '162': '&cent;',\r\n    '163': '&pound;',\r\n    '164': '&curren;',\r\n    '169': '&copy;',\r\n    '174': '&reg;'\r\n};\r\n\r\n\r\ninternals.safeCharCodes = (function () {\r\n\r\n    var safe = {};\r\n\r\n    for (var i = 32; i < 123; ++i) {\r\n\r\n        if ((i >= 97 && i <= 122) ||         // a-z\r\n            (i >= 65 && i <= 90) ||          // A-Z\r\n            (i >= 48 && i <= 57) ||          // 0-9\r\n            i === 32 ||                      // space\r\n            i === 46 ||                      // .\r\n            i === 44 ||                      // ,\r\n            i === 45 ||                      // -\r\n            i === 58 ||                      // :\r\n            i === 95) {                      // _\r\n\r\n            safe[i] = null;\r\n        }\r\n    }\r\n\r\n    return safe;\r\n}());\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/server.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/server",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/server.js",
            "descriptor": {
              "filename": "server.js",
              "filepath": "node_modules/request/node_modules/hawk/lib/server.js",
              "mtime": 1365791465,
              "code": "// Load modules\r\n\r\nvar Boom = require('boom');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Hawk authentication\r\n\r\n/*\r\n   req:                 node's HTTP request object or an object as follows:\r\n  \r\n                        var request = {\r\n                            method: 'GET',\r\n                            url: '/resource/4?a=1&b=2',\r\n                            host: 'example.com',\r\n                            port: 8080,\r\n                            authorization: 'Hawk id=\"dh37fgj492je\", ts=\"1353832234\", nonce=\"j4h3g2\", ext=\"some-app-ext-data\", mac=\"6R4rV5iE+NPoym+WwjeHzjAGXUtLNIxmo1vpMofpLAE=\"'\r\n                        };\r\n  \r\n   credentialsFunc:     required function to lookup the set of Hawk credentials based on the provided credentials id.\r\n                        The credentials include the MAC key, MAC algorithm, and other attributes (such as username)\r\n                        needed by the application. This function is the equivalent of verifying the username and\r\n                        password in Basic authentication.\r\n  \r\n                        var credentialsFunc = function (id, callback) {\r\n    \r\n                            // Lookup credentials in database\r\n                            db.lookup(id, function (err, item) {\r\n    \r\n                                if (err || !item) {\r\n                                    return callback(err);\r\n                                }\r\n    \r\n                                var credentials = {\r\n                                    // Required\r\n                                    key: item.key,\r\n                                    algorithm: item.algorithm,\r\n                                    // Application specific\r\n                                    user: item.user\r\n                                };\r\n    \r\n                                return callback(null, credentials);\r\n                            });\r\n                        };\r\n  \r\n   options: {\r\n\r\n        hostHeaderName:        optional header field name, used to override the default 'Host' header when used\r\n                               behind a cache of a proxy. Apache2 changes the value of the 'Host' header while preserving\r\n                               the original (which is what the module must verify) in the 'x-forwarded-host' header field.\r\n                               Only used when passed a node Http.ServerRequest object.\r\n  \r\n        nonceFunc:             optional nonce validation function. The function signature is function(nonce, ts, callback)\r\n                               where 'callback' must be called using the signature function(err).\r\n  \r\n        timestampSkewSec:      optional number of seconds of permitted clock skew for incoming timestamps. Defaults to 60 seconds.\r\n                               Provides a +/- skew which means actual allowed window is double the number of seconds.\r\n  \r\n        localtimeOffsetMsec:   optional local clock time offset express in a number of milliseconds (positive or negative).\r\n                               Defaults to 0.\r\n  \r\n        payload:               optional payload for validation. The client calculates the hash value and includes it via the 'hash'\r\n                               header attribute. The server always ensures the value provided has been included in the request\r\n                               MAC. When this option is provided, it validates the hash value itself. Validation is done by calculating\r\n                               a hash value over the entire payload (assuming it has already be normalized to the same format and\r\n                               encoding used by the client to calculate the hash on request). If the payload is not available at the time\r\n                               of authentication, the authenticatePayload() method can be used by passing it the credentials and\r\n                               attributes.hash returned in the authenticate callback.\r\n    }\r\n\r\n    callback: function (err, credentials, artifacts) { }\r\n */\r\n\r\nexports.authenticate = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Utils.nextTick(callback);\r\n    \r\n    // Default options\r\n\r\n    options.nonceFunc = options.nonceFunc || function (nonce, ts, nonceCallback) { return nonceCallback(); };   // No validation\r\n    options.timestampSkewSec = options.timestampSkewSec || 60;                                                  // 60 seconds\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);                 // Measure now before any other processing\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Parse HTTP Authorization header\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(request.authorization);\r\n    if (attributes instanceof Error) {\r\n        return callback(attributes);\r\n    }\r\n\r\n    // Construct artifacts container\r\n\r\n    var artifacts = {\r\n        method: request.method,\r\n        host: request.host,\r\n        port: request.port,\r\n        resource: request.url,\r\n        ts: attributes.ts,\r\n        nonce: attributes.nonce,\r\n        hash: attributes.hash,\r\n        ext: attributes.ext,\r\n        app: attributes.app,\r\n        dlg: attributes.dlg,\r\n        mac: attributes.mac,\r\n        id: attributes.id\r\n    };\r\n\r\n    // Verify required header attributes\r\n\r\n    if (!attributes.id ||\r\n        !attributes.ts ||\r\n        !attributes.nonce ||\r\n        !attributes.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing attributes'), null, artifacts);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(attributes.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, artifacts);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, artifacts);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, artifacts);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, artifacts);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n        if (!Cryptiles.fixedTimeComparison(mac, attributes.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, artifacts);\r\n        }\r\n\r\n        // Check payload hash\r\n\r\n        if (options.payload !== null &&\r\n            options.payload !== undefined) {       // '' is valid\r\n\r\n            if (!attributes.hash) {\r\n                return callback(Boom.unauthorized('Missing required payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            var hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, request.contentType);\r\n            if (!Cryptiles.fixedTimeComparison(hash, attributes.hash)) {\r\n                return callback(Boom.unauthorized('Bad payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n        }\r\n\r\n        // Check nonce\r\n\r\n        options.nonceFunc(attributes.nonce, attributes.ts, function (err) {\r\n\r\n            if (err) {\r\n                return callback(Boom.unauthorized('Invalid nonce', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            // Check timestamp staleness\r\n\r\n            if (Math.abs((attributes.ts * 1000) - now) > (options.timestampSkewSec * 1000)) {\r\n                var fresh = Math.floor((Utils.now() + (options.localtimeOffsetMsec || 0)) / 1000);            // Get fresh now\r\n                var tsm = Crypto.calculateTsMac(fresh, credentials);\r\n                return callback(Boom.unauthorized('Stale timestamp', 'Hawk', { ts: fresh, tsm: tsm }), credentials, artifacts);\r\n            }\r\n\r\n            // Successful authentication\r\n\r\n            return callback(null, credentials, artifacts);\r\n        });\r\n    });\r\n};\r\n\r\n\r\n// Authenticate payload hash - used when payload cannot be provided during authenticate()\r\n\r\n/*\r\n    payload:        raw request payload\r\n    credentials:    from authenticate callback\r\n    artifacts:      from authenticate callback\r\n    contentType:    req.headers['content-type']\r\n*/\r\n\r\nexports.authenticatePayload = function (payload, credentials, artifacts, contentType) {\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(payload, credentials.algorithm, contentType);\r\n    return Cryptiles.fixedTimeComparison(calculatedHash, artifacts.hash);\r\n};\r\n\r\n\r\n// Generate a Server-Authorization header for a given response\r\n\r\n/*\r\n    credentials: {},                                        // Object received from authenticate()\r\n    artifacts: {}                                           // Object received from authenticate(); 'mac', 'hash', and 'ext' - ignored\r\n    options: {\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV='                     // Pre-calculated payload hash\r\n    }\r\n*/\r\n\r\nexports.header = function (credentials, artifacts, options) {\r\n\r\n    // Prepare inputs\r\n\r\n    options = options || {};\r\n\r\n    if (!artifacts ||\r\n        typeof artifacts !== 'object' ||\r\n        typeof options !== 'object') {\r\n\r\n        return '';\r\n    }\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    delete artifacts.mac;\r\n    artifacts.hash = options.hash;\r\n    artifacts.ext = options.ext;\r\n\r\n    // Validate credentials\r\n\r\n    if (!credentials ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        options.hasOwnProperty('payload')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var header = 'Hawk mac=\"' + mac + '\"' +\r\n                 (artifacts.hash ? ', hash=\"' + artifacts.hash + '\"' : '');\r\n\r\n    if (artifacts.ext !== null &&\r\n        artifacts.ext !== undefined &&\r\n        artifacts.ext !== '') {                       // Other falsey values allowed\r\n\r\n        header += ', ext=\"' + Utils.escapeHeaderAttribute(artifacts.ext) + '\"';\r\n    }\r\n\r\n    return header;\r\n};\r\n\r\n\r\n/*\r\n * Arguments and options are the same as index.js with the exception that the only supported options are:\r\n * 'hostHeaderName', 'localtimeOffsetMsec'\r\n */\r\n\r\nexports.authenticateBewit = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Utils.nextTick(callback);\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Extract bewit\r\n\r\n    //                                 1     2             3           4     \r\n    var resource = request.url.match(/^(\\/.*)([\\?&])bewit\\=([^&$]*)(?:&(.+))?$/);\r\n    if (!resource) {\r\n        return callback(Boom.unauthorized(null, 'Hawk'));\r\n    }\r\n\r\n    // Bewit not empty\r\n\r\n    if (!resource[3]) {\r\n        return callback(Boom.unauthorized('Empty bewit', 'Hawk'));\r\n    }\r\n\r\n    // Verify method is GET\r\n\r\n    if (request.method !== 'GET' &&\r\n        request.method !== 'HEAD') {\r\n\r\n        return callback(Boom.unauthorized('Invalid method', 'Hawk'));\r\n    }\r\n\r\n    // No other authentication\r\n\r\n    if (request.authorization) {\r\n        return callback(Boom.badRequest('Multiple authentications', 'Hawk'));\r\n    }\r\n\r\n    // Parse bewit\r\n\r\n    var bewitString = Utils.base64urlDecode(resource[3]);\r\n    if (bewitString instanceof Error) {\r\n        return callback(Boom.badRequest('Invalid bewit encoding'));\r\n    }\r\n\r\n    // Bewit format: id\\exp\\mac\\ext ('\\' is used because it is a reserved header attribute character)\r\n\r\n    var bewitParts = bewitString.split('\\\\');\r\n    if (!bewitParts ||\r\n        bewitParts.length !== 4) {\r\n\r\n        return callback(Boom.badRequest('Invalid bewit structure'));\r\n    }\r\n\r\n    var bewit = {\r\n        id: bewitParts[0],\r\n        exp: parseInt(bewitParts[1], 10),\r\n        mac: bewitParts[2],\r\n        ext: bewitParts[3] || ''\r\n    };\r\n\r\n    if (!bewit.id ||\r\n        !bewit.exp ||\r\n        !bewit.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing bewit attributes'));\r\n    }\r\n\r\n    // Construct URL without bewit\r\n\r\n    var url = resource[1];\r\n    if (resource[4]) {\r\n        url += resource[2] + resource[4];\r\n    }\r\n\r\n    // Check expiration\r\n\r\n    if (bewit.exp * 1000 <= now) {\r\n        return callback(Boom.unauthorized('Access expired', 'Hawk'), null, bewit);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(bewit.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, bewit.ext);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, bewit);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, bewit);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, bewit);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('bewit', credentials, {\r\n            ts: bewit.exp,\r\n            nonce: '',\r\n            method: 'GET',\r\n            resource: url,\r\n            host: request.host,\r\n            port: request.port,\r\n            ext: bewit.ext\r\n        });\r\n\r\n        if (!Cryptiles.fixedTimeComparison(mac, bewit.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, bewit);\r\n        }\r\n\r\n        // Successful authentication\r\n\r\n        return callback(null, credentials, bewit);\r\n    });\r\n};\r\n",
              "globals": {
                "Boom": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Hoek": {
                  "type": "assign"
                },
                "Cryptiles": {
                  "type": "assign"
                },
                "Crypto": {
                  "type": "assign"
                },
                "Utils": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "parseInt": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "boom": {
                    "where": "inline"
                  },
                  "hoek": {
                    "where": "inline"
                  },
                  "cryptiles": {
                    "where": "inline"
                  },
                  "./crypto": {
                    "where": "inline"
                  },
                  "./utils": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';\n// Load modules\r\n\r\nvar Boom = require('boom');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Hawk authentication\r\n\r\n/*\r\n   req:                 node's HTTP request object or an object as follows:\r\n  \r\n                        var request = {\r\n                            method: 'GET',\r\n                            url: '/resource/4?a=1&b=2',\r\n                            host: 'example.com',\r\n                            port: 8080,\r\n                            authorization: 'Hawk id=\"dh37fgj492je\", ts=\"1353832234\", nonce=\"j4h3g2\", ext=\"some-app-ext-data\", mac=\"6R4rV5iE+NPoym+WwjeHzjAGXUtLNIxmo1vpMofpLAE=\"'\r\n                        };\r\n  \r\n   credentialsFunc:     required function to lookup the set of Hawk credentials based on the provided credentials id.\r\n                        The credentials include the MAC key, MAC algorithm, and other attributes (such as username)\r\n                        needed by the application. This function is the equivalent of verifying the username and\r\n                        password in Basic authentication.\r\n  \r\n                        var credentialsFunc = function (id, callback) {\r\n    \r\n                            // Lookup credentials in database\r\n                            db.lookup(id, function (err, item) {\r\n    \r\n                                if (err || !item) {\r\n                                    return callback(err);\r\n                                }\r\n    \r\n                                var credentials = {\r\n                                    // Required\r\n                                    key: item.key,\r\n                                    algorithm: item.algorithm,\r\n                                    // Application specific\r\n                                    user: item.user\r\n                                };\r\n    \r\n                                return callback(null, credentials);\r\n                            });\r\n                        };\r\n  \r\n   options: {\r\n\r\n        hostHeaderName:        optional header field name, used to override the default 'Host' header when used\r\n                               behind a cache of a proxy. Apache2 changes the value of the 'Host' header while preserving\r\n                               the original (which is what the module must verify) in the 'x-forwarded-host' header field.\r\n                               Only used when passed a node Http.ServerRequest object.\r\n  \r\n        nonceFunc:             optional nonce validation function. The function signature is function(nonce, ts, callback)\r\n                               where 'callback' must be called using the signature function(err).\r\n  \r\n        timestampSkewSec:      optional number of seconds of permitted clock skew for incoming timestamps. Defaults to 60 seconds.\r\n                               Provides a +/- skew which means actual allowed window is double the number of seconds.\r\n  \r\n        localtimeOffsetMsec:   optional local clock time offset express in a number of milliseconds (positive or negative).\r\n                               Defaults to 0.\r\n  \r\n        payload:               optional payload for validation. The client calculates the hash value and includes it via the 'hash'\r\n                               header attribute. The server always ensures the value provided has been included in the request\r\n                               MAC. When this option is provided, it validates the hash value itself. Validation is done by calculating\r\n                               a hash value over the entire payload (assuming it has already be normalized to the same format and\r\n                               encoding used by the client to calculate the hash on request). If the payload is not available at the time\r\n                               of authentication, the authenticatePayload() method can be used by passing it the credentials and\r\n                               attributes.hash returned in the authenticate callback.\r\n    }\r\n\r\n    callback: function (err, credentials, artifacts) { }\r\n */\r\n\r\nexports.authenticate = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Utils.nextTick(callback);\r\n    \r\n    // Default options\r\n\r\n    options.nonceFunc = options.nonceFunc || function (nonce, ts, nonceCallback) { return nonceCallback(); };   // No validation\r\n    options.timestampSkewSec = options.timestampSkewSec || 60;                                                  // 60 seconds\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);                 // Measure now before any other processing\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Parse HTTP Authorization header\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(request.authorization);\r\n    if (attributes instanceof Error) {\r\n        return callback(attributes);\r\n    }\r\n\r\n    // Construct artifacts container\r\n\r\n    var artifacts = {\r\n        method: request.method,\r\n        host: request.host,\r\n        port: request.port,\r\n        resource: request.url,\r\n        ts: attributes.ts,\r\n        nonce: attributes.nonce,\r\n        hash: attributes.hash,\r\n        ext: attributes.ext,\r\n        app: attributes.app,\r\n        dlg: attributes.dlg,\r\n        mac: attributes.mac,\r\n        id: attributes.id\r\n    };\r\n\r\n    // Verify required header attributes\r\n\r\n    if (!attributes.id ||\r\n        !attributes.ts ||\r\n        !attributes.nonce ||\r\n        !attributes.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing attributes'), null, artifacts);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(attributes.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, artifacts);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, artifacts);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, artifacts);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, artifacts);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n        if (!Cryptiles.fixedTimeComparison(mac, attributes.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, artifacts);\r\n        }\r\n\r\n        // Check payload hash\r\n\r\n        if (options.payload !== null &&\r\n            options.payload !== undefined) {       // '' is valid\r\n\r\n            if (!attributes.hash) {\r\n                return callback(Boom.unauthorized('Missing required payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            var hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, request.contentType);\r\n            if (!Cryptiles.fixedTimeComparison(hash, attributes.hash)) {\r\n                return callback(Boom.unauthorized('Bad payload hash', 'Hawk'), credentials, artifacts);\r\n            }\r\n        }\r\n\r\n        // Check nonce\r\n\r\n        options.nonceFunc(attributes.nonce, attributes.ts, function (err) {\r\n\r\n            if (err) {\r\n                return callback(Boom.unauthorized('Invalid nonce', 'Hawk'), credentials, artifacts);\r\n            }\r\n\r\n            // Check timestamp staleness\r\n\r\n            if (Math.abs((attributes.ts * 1000) - now) > (options.timestampSkewSec * 1000)) {\r\n                var fresh = Math.floor((Utils.now() + (options.localtimeOffsetMsec || 0)) / 1000);            // Get fresh now\r\n                var tsm = Crypto.calculateTsMac(fresh, credentials);\r\n                return callback(Boom.unauthorized('Stale timestamp', 'Hawk', { ts: fresh, tsm: tsm }), credentials, artifacts);\r\n            }\r\n\r\n            // Successful authentication\r\n\r\n            return callback(null, credentials, artifacts);\r\n        });\r\n    });\r\n};\r\n\r\n\r\n// Authenticate payload hash - used when payload cannot be provided during authenticate()\r\n\r\n/*\r\n    payload:        raw request payload\r\n    credentials:    from authenticate callback\r\n    artifacts:      from authenticate callback\r\n    contentType:    req.headers['content-type']\r\n*/\r\n\r\nexports.authenticatePayload = function (payload, credentials, artifacts, contentType) {\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(payload, credentials.algorithm, contentType);\r\n    return Cryptiles.fixedTimeComparison(calculatedHash, artifacts.hash);\r\n};\r\n\r\n\r\n// Generate a Server-Authorization header for a given response\r\n\r\n/*\r\n    credentials: {},                                        // Object received from authenticate()\r\n    artifacts: {}                                           // Object received from authenticate(); 'mac', 'hash', and 'ext' - ignored\r\n    options: {\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV='                     // Pre-calculated payload hash\r\n    }\r\n*/\r\n\r\nexports.header = function (credentials, artifacts, options) {\r\n\r\n    // Prepare inputs\r\n\r\n    options = options || {};\r\n\r\n    if (!artifacts ||\r\n        typeof artifacts !== 'object' ||\r\n        typeof options !== 'object') {\r\n\r\n        return '';\r\n    }\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    delete artifacts.mac;\r\n    artifacts.hash = options.hash;\r\n    artifacts.ext = options.ext;\r\n\r\n    // Validate credentials\r\n\r\n    if (!credentials ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        options.hasOwnProperty('payload')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var header = 'Hawk mac=\"' + mac + '\"' +\r\n                 (artifacts.hash ? ', hash=\"' + artifacts.hash + '\"' : '');\r\n\r\n    if (artifacts.ext !== null &&\r\n        artifacts.ext !== undefined &&\r\n        artifacts.ext !== '') {                       // Other falsey values allowed\r\n\r\n        header += ', ext=\"' + Utils.escapeHeaderAttribute(artifacts.ext) + '\"';\r\n    }\r\n\r\n    return header;\r\n};\r\n\r\n\r\n/*\r\n * Arguments and options are the same as index.js with the exception that the only supported options are:\r\n * 'hostHeaderName', 'localtimeOffsetMsec'\r\n */\r\n\r\nexports.authenticateBewit = function (req, credentialsFunc, options, callback) {\r\n\r\n    callback = Utils.nextTick(callback);\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);\r\n\r\n    // Convert node Http request object to a request configuration object\r\n\r\n    var request = Utils.parseRequest(req, options);\r\n    if (request instanceof Error) {\r\n        return callback(Boom.badRequest(request.message));\r\n    }\r\n\r\n    // Extract bewit\r\n\r\n    //                                 1     2             3           4     \r\n    var resource = request.url.match(/^(\\/.*)([\\?&])bewit\\=([^&$]*)(?:&(.+))?$/);\r\n    if (!resource) {\r\n        return callback(Boom.unauthorized(null, 'Hawk'));\r\n    }\r\n\r\n    // Bewit not empty\r\n\r\n    if (!resource[3]) {\r\n        return callback(Boom.unauthorized('Empty bewit', 'Hawk'));\r\n    }\r\n\r\n    // Verify method is GET\r\n\r\n    if (request.method !== 'GET' &&\r\n        request.method !== 'HEAD') {\r\n\r\n        return callback(Boom.unauthorized('Invalid method', 'Hawk'));\r\n    }\r\n\r\n    // No other authentication\r\n\r\n    if (request.authorization) {\r\n        return callback(Boom.badRequest('Multiple authentications', 'Hawk'));\r\n    }\r\n\r\n    // Parse bewit\r\n\r\n    var bewitString = Utils.base64urlDecode(resource[3]);\r\n    if (bewitString instanceof Error) {\r\n        return callback(Boom.badRequest('Invalid bewit encoding'));\r\n    }\r\n\r\n    // Bewit format: id\\exp\\mac\\ext ('\\' is used because it is a reserved header attribute character)\r\n\r\n    var bewitParts = bewitString.split('\\\\');\r\n    if (!bewitParts ||\r\n        bewitParts.length !== 4) {\r\n\r\n        return callback(Boom.badRequest('Invalid bewit structure'));\r\n    }\r\n\r\n    var bewit = {\r\n        id: bewitParts[0],\r\n        exp: parseInt(bewitParts[1], 10),\r\n        mac: bewitParts[2],\r\n        ext: bewitParts[3] || ''\r\n    };\r\n\r\n    if (!bewit.id ||\r\n        !bewit.exp ||\r\n        !bewit.mac) {\r\n\r\n        return callback(Boom.badRequest('Missing bewit attributes'));\r\n    }\r\n\r\n    // Construct URL without bewit\r\n\r\n    var url = resource[1];\r\n    if (resource[4]) {\r\n        url += resource[2] + resource[4];\r\n    }\r\n\r\n    // Check expiration\r\n\r\n    if (bewit.exp * 1000 <= now) {\r\n        return callback(Boom.unauthorized('Access expired', 'Hawk'), null, bewit);\r\n    }\r\n\r\n    // Fetch Hawk credentials\r\n\r\n    credentialsFunc(bewit.id, function (err, credentials) {\r\n\r\n        if (err) {\r\n            return callback(err, credentials || null, bewit.ext);\r\n        }\r\n\r\n        if (!credentials) {\r\n            return callback(Boom.unauthorized('Unknown credentials', 'Hawk'), null, bewit);\r\n        }\r\n\r\n        if (!credentials.key ||\r\n            !credentials.algorithm) {\r\n\r\n            return callback(Boom.internal('Invalid credentials'), credentials, bewit);\r\n        }\r\n\r\n        if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n            return callback(Boom.internal('Unknown algorithm'), credentials, bewit);\r\n        }\r\n\r\n        // Calculate MAC\r\n\r\n        var mac = Crypto.calculateMac('bewit', credentials, {\r\n            ts: bewit.exp,\r\n            nonce: '',\r\n            method: 'GET',\r\n            resource: url,\r\n            host: request.host,\r\n            port: request.port,\r\n            ext: bewit.ext\r\n        });\r\n\r\n        if (!Cryptiles.fixedTimeComparison(mac, bewit.mac)) {\r\n            return callback(Boom.unauthorized('Bad mac', 'Hawk'), credentials, bewit);\r\n        }\r\n\r\n        // Successful authentication\r\n\r\n        return callback(null, credentials, bewit);\r\n    });\r\n};\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "boom": {
                  "where": "inline"
                },
                "hoek": {
                  "where": "inline"
                },
                "cryptiles": {
                  "where": "inline"
                },
                "./crypto": {
                  "where": "inline"
                },
                "./utils": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "f7d6999ac201573ce8335e058ee0439994171772-hoek/index.js": {
            "requireId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/index.js",
            "memoizeId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/hoek/index.js",
              "mtime": 1365188840,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/index.js": {
            "requireId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/index",
            "memoizeId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/hoek/lib/index.js",
              "mtime": 1367686190,
              "code": "// Load modules\r\n\r\nvar Fs = require('fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        source.forEach(function (item) {\r\n\r\n            target.push(item);\r\n        });\r\n\r\n        return target;\r\n    }\r\n\r\n    Object.keys(source).forEach(function (key) {\r\n\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    });\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return common;\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    path.forEach(function (level) {\r\n\r\n        if (ref) {\r\n            ref = ref[level];\r\n        }\r\n    });\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    stack.forEach(function (item) {\r\n\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    });\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n    trace.forEach(function (row) {\r\n\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    });\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    Fs.readdirSync(path).forEach(function (filename) {\r\n\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    });\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n",
              "globals": {
                "Fs": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Escape": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Object": {
                  "type": "reference"
                },
                "Array": {
                  "type": "reference"
                },
                "Error": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "JSON": {
                  "type": "reference"
                },
                "Date": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "fs": {
                    "where": "inline"
                  },
                  "./escape": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek/lib';\n// Load modules\r\n\r\nvar Fs = require('__SYSTEM__/fs');\r\nvar Escape = require('./escape');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Clone object or array\r\n\r\nexports.clone = function (obj, seen) {\r\n\r\n    if (typeof obj !== 'object' ||\r\n        obj === null) {\r\n\r\n        return obj;\r\n    }\r\n\r\n    seen = seen || { orig: [], copy: [] };\r\n\r\n    var lookup = seen.orig.indexOf(obj);\r\n    if (lookup !== -1) {\r\n        return seen.copy[lookup];\r\n    }\r\n\r\n    var newObj = (obj instanceof Array) ? [] : {};\r\n\r\n    seen.orig.push(obj);\r\n    seen.copy.push(newObj);\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (obj[i] instanceof Buffer) {\r\n                newObj[i] = new Buffer(obj[i]);\r\n            }\r\n            else if (obj[i] instanceof Date) {\r\n                newObj[i] = new Date(obj[i].getTime());\r\n            }\r\n            else if (obj[i] instanceof RegExp) {\r\n                var flags = '' + (obj[i].global ? 'g' : '') + (obj[i].ignoreCase ? 'i' : '') + (obj[i].multiline ? 'm' : '');\r\n                newObj[i] = new RegExp(obj[i].source, flags);\r\n            }\r\n            else {\r\n                newObj[i] = exports.clone(obj[i], seen);\r\n            }\r\n        }\r\n    }\r\n\r\n    return newObj;\r\n};\r\n\r\n\r\n// Merge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\nexports.merge = function (target, source, isNullOverride /* = true */, isMergeArrays /* = true */) {\r\n\r\n    exports.assert(target && typeof target == 'object', 'Invalid target value: must be an object');\r\n    exports.assert(source === null || source === undefined || typeof source === 'object', 'Invalid source value: must be null, undefined, or an object');\r\n\r\n    if (!source) {\r\n        return target;\r\n    }\r\n\r\n    if (source instanceof Array) {\r\n        exports.assert(target instanceof Array, 'Cannot merge array onto an object');\r\n        if (isMergeArrays === false) {                                                  // isMergeArrays defaults to true\r\n            target.length = 0;                                                          // Must not change target assignment\r\n        }\r\n\r\n        source.forEach(function (item) {\r\n\r\n            target.push(item);\r\n        });\r\n\r\n        return target;\r\n    }\r\n\r\n    Object.keys(source).forEach(function (key) {\r\n\r\n        var value = source[key];\r\n        if (value &&\r\n            typeof value === 'object') {\r\n\r\n            if (!target[key] ||\r\n                typeof target[key] !== 'object') {\r\n\r\n                target[key] = exports.clone(value);\r\n            }\r\n            else {\r\n                exports.merge(target[key], source[key], isNullOverride, isMergeArrays);\r\n            }\r\n        }\r\n        else {\r\n            if (value !== null && value !== undefined) {            // Explicit to preserve empty strings\r\n                target[key] = value;\r\n            }\r\n            else if (isNullOverride !== false) {                    // Defaults to true\r\n                target[key] = value;\r\n            }\r\n        }\r\n    });\r\n\r\n    return target;\r\n};\r\n\r\n\r\n// Apply options to a copy of the defaults\r\n\r\nexports.applyToDefaults = function (defaults, options) {\r\n\r\n    exports.assert(defaults && typeof defaults == 'object', 'Invalid defaults value: must be an object');\r\n    exports.assert(!options || options === true || typeof options === 'object', 'Invalid options value: must be true, falsy or an object');\r\n\r\n    if (!options) {                                                 // If no options, return null\r\n        return null;\r\n    }\r\n\r\n    var copy = exports.clone(defaults);\r\n\r\n    if (options === true) {                                         // If options is set to true, use defaults\r\n        return copy;\r\n    }\r\n\r\n    return exports.merge(copy, options, false, false);\r\n};\r\n\r\n\r\n// Remove duplicate items from array\r\n\r\nexports.unique = function (array, key) {\r\n\r\n    var index = {};\r\n    var result = [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        var id = (key ? array[i][key] : array[i]);\r\n        if (index[id] !== true) {\r\n\r\n            result.push(array[i]);\r\n            index[id] = true;\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Convert array into object\r\n\r\nexports.mapToObject = function (array, key) {\r\n\r\n    if (!array) {\r\n        return null;\r\n    }\r\n\r\n    var obj = {};\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (key) {\r\n            if (array[i][key]) {\r\n                obj[array[i][key]] = true;\r\n            }\r\n        }\r\n        else {\r\n            obj[array[i]] = true;\r\n        }\r\n    }\r\n\r\n    return obj;\r\n};\r\n\r\n\r\n// Find the common unique items in two arrays\r\n\r\nexports.intersect = function (array1, array2) {\r\n\r\n    if (!array1 || !array2) {\r\n        return [];\r\n    }\r\n\r\n    var common = [];\r\n    var hash = (array1 instanceof Array ? exports.mapToObject(array1) : array1);\r\n    var found = {};\r\n    for (var i = 0, il = array2.length; i < il; ++i) {\r\n        if (hash[array2[i]] && !found[array2[i]]) {\r\n            common.push(array2[i]);\r\n            found[array2[i]] = true;\r\n        }\r\n    }\r\n\r\n    return common;\r\n};\r\n\r\n\r\n// Find which keys are present\r\n\r\nexports.matchKeys = function (obj, keys) {\r\n\r\n    var matched = [];\r\n    for (var i = 0, il = keys.length; i < il; ++i) {\r\n        if (obj.hasOwnProperty(keys[i])) {\r\n            matched.push(keys[i]);\r\n        }\r\n    }\r\n    return matched;\r\n};\r\n\r\n\r\n// Flatten array\r\n\r\nexports.flatten = function (array, target) {\r\n\r\n    var result = target || [];\r\n\r\n    for (var i = 0, il = array.length; i < il; ++i) {\r\n        if (Array.isArray(array[i])) {\r\n            exports.flatten(array[i], result);\r\n        }\r\n        else {\r\n            result.push(array[i]);\r\n        }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Remove keys\r\n\r\nexports.removeKeys = function (object, keys) {\r\n\r\n    for (var i = 0, il = keys.length; i < il; i++) {\r\n        delete object[keys[i]];\r\n    }\r\n};\r\n\r\n\r\n// Convert an object key chain string ('a.b.c') to reference (object[a][b][c])\r\n\r\nexports.reach = function (obj, chain) {\r\n\r\n    var path = chain.split('.');\r\n    var ref = obj;\r\n    path.forEach(function (level) {\r\n\r\n        if (ref) {\r\n            ref = ref[level];\r\n        }\r\n    });\r\n\r\n    return ref;\r\n};\r\n\r\n\r\n// Inherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\nexports.inheritAsync = function (self, obj, keys) {\r\n\r\n    keys = keys || null;\r\n\r\n    for (var i in obj) {\r\n        if (obj.hasOwnProperty(i)) {\r\n            if (keys instanceof Array &&\r\n                keys.indexOf(i) < 0) {\r\n\r\n                continue;\r\n            }\r\n\r\n            self.prototype[i] = (function (fn) {\r\n\r\n                return function (next) {\r\n\r\n                    var result = null;\r\n                    try {\r\n                        result = fn();\r\n                    }\r\n                    catch (err) {\r\n                        return next(err);\r\n                    }\r\n\r\n                    return next(null, result);\r\n                };\r\n            })(obj[i]);\r\n        }\r\n    }\r\n};\r\n\r\n\r\nexports.formatStack = function (stack) {\r\n\r\n    var trace = [];\r\n    stack.forEach(function (item) {\r\n\r\n        trace.push([item.getFileName(), item.getLineNumber(), item.getColumnNumber(), item.getFunctionName(), item.isConstructor()]);\r\n    });\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.formatTrace = function (trace) {\r\n\r\n    var display = [];\r\n    trace.forEach(function (row) {\r\n\r\n        display.push((row[4] ? 'new ' : '') + row[3] + ' (' + row[0] + ':' + row[1] + ':' + row[2] + ')');\r\n    });\r\n\r\n    return display;\r\n};\r\n\r\n\r\nexports.callStack = function (slice) {\r\n\r\n    // http://code.google.com/p/v8/wiki/JavaScriptStackTraceApi\r\n\r\n    var v8 = Error.prepareStackTrace;\r\n    Error.prepareStackTrace = function (err, stack) {\r\n\r\n        return stack;\r\n    };\r\n\r\n    var capture = {};\r\n    Error.captureStackTrace(capture, arguments.callee);\r\n    var stack = capture.stack;\r\n\r\n    Error.prepareStackTrace = v8;\r\n\r\n    var trace = exports.formatStack(stack);\r\n\r\n    if (slice) {\r\n        return trace.slice(slice);\r\n    }\r\n\r\n    return trace;\r\n};\r\n\r\n\r\nexports.displayStack = function (slice) {\r\n\r\n    var trace = exports.callStack(slice === undefined ? 1 : slice + 1);\r\n\r\n    return exports.formatTrace(trace);\r\n};\r\n\r\n\r\nexports.abortThrow = false;\r\n\r\n\r\nexports.abort = function (message, hideStack) {\r\n\r\n    if (process.env.NODE_ENV === 'test' || exports.abortThrow === true) {\r\n        throw new Error(message || 'Unknown error');\r\n    }\r\n\r\n    var stack = '';\r\n    if (!hideStack) {\r\n        stack = exports.displayStack(1).join('\\n\\t');\r\n    }\r\n    console.log('ABORT: ' + message + '\\n\\t' + stack);\r\n    process.exit(1);\r\n};\r\n\r\n\r\nexports.assert = function (condition /*, msg1, msg2, msg3 */) {\r\n\r\n    if (condition) {\r\n        return;\r\n    }\r\n\r\n    var msgs = Array.prototype.slice.call(arguments, 1);\r\n    msgs = msgs.map(function (msg) {\r\n\r\n        return typeof msg === 'string' ? msg : msg instanceof Error ? msg.message : JSON.stringify(msg);\r\n    });\r\n    throw new Error(msgs.join(' ') || 'Unknown error');\r\n};\r\n\r\n\r\nexports.loadDirModules = function (path, excludeFiles, target) {      // target(filename, name, capName)\r\n\r\n    var exclude = {};\r\n    for (var i = 0, il = excludeFiles.length; i < il; ++i) {\r\n        exclude[excludeFiles[i] + '.js'] = true;\r\n    }\r\n\r\n    Fs.readdirSync(path).forEach(function (filename) {\r\n\r\n        if (/\\.js$/.test(filename) &&\r\n            !exclude[filename]) {\r\n\r\n            var name = filename.substr(0, filename.lastIndexOf('.'));\r\n            var capName = name.charAt(0).toUpperCase() + name.substr(1).toLowerCase();\r\n\r\n            if (typeof target !== 'function') {\r\n                target[capName] = require(path + '/' + name);\r\n            }\r\n            else {\r\n                target(path + '/' + name, name, capName);\r\n            }\r\n        }\r\n    });\r\n};\r\n\r\n\r\nexports.rename = function (obj, from, to) {\r\n\r\n    obj[to] = obj[from];\r\n    delete obj[from];\r\n};\r\n\r\n\r\nexports.Timer = function () {\r\n\r\n    this.reset();\r\n};\r\n\r\n\r\nexports.Timer.prototype.reset = function () {\r\n\r\n    this.ts = Date.now();\r\n};\r\n\r\n\r\nexports.Timer.prototype.elapsed = function () {\r\n\r\n    return Date.now() - this.ts;\r\n};\r\n\r\n\r\n// Load and parse package.json process root or given directory\r\n\r\nexports.loadPackage = function (dir) {\r\n\r\n    var result = {};\r\n    var filepath = (dir || process.env.PWD) + '/package.json';\r\n    if (Fs.existsSync(filepath)) {\r\n        try {\r\n            result = JSON.parse(Fs.readFileSync(filepath));\r\n        }\r\n        catch (e) { }\r\n    }\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Escape string for Regex construction\r\n\r\nexports.escapeRegex = function (string) {\r\n\r\n    // Escape ^$.*+-?=!:|\\/()[]{},\r\n    return string.replace(/[\\^\\$\\.\\*\\+\\-\\?\\=\\!\\:\\|\\\\\\/\\(\\)\\[\\]\\{\\}\\,]/g, '\\\\$&');\r\n};\r\n\r\n\r\n// Return an error as first argument of a callback\r\n\r\nexports.toss = function (condition /*, [message], next */) {\r\n\r\n    var message = (arguments.length === 3 ? arguments[1] : '');\r\n    var next = (arguments.length === 3 ? arguments[2] : arguments[1]);\r\n\r\n    var err = (message instanceof Error ? message : (message ? new Error(message) : (condition instanceof Error ? condition : new Error())));\r\n\r\n    if (condition instanceof Error ||\r\n        !condition) {\r\n\r\n        return next(err);\r\n    }\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) encode\r\n\r\nexports.base64urlEncode = function (value) {\r\n\r\n    return (new Buffer(value, 'binary')).toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\r\n};\r\n\r\n\r\n// Base64url (RFC 4648) decode\r\n\r\nexports.base64urlDecode = function (encoded) {\r\n\r\n    if (encoded &&\r\n        !encoded.match(/^[\\w\\-]*$/)) {\r\n\r\n        return new Error('Invalid character');\r\n    }\r\n\r\n    try {\r\n        return (new Buffer(encoded.replace(/-/g, '+').replace(/:/g, '/'), 'base64')).toString('binary');\r\n    }\r\n    catch (err) {\r\n        return err;\r\n    }\r\n};\r\n\r\n\r\n// Escape attribute value for use in HTTP header\r\n\r\nexports.escapeHeaderAttribute = function (attribute) {\r\n\r\n    // Allowed value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9, \\, \"\r\n\r\n    exports.assert(attribute.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~\\\"\\\\]*$/), 'Bad attribute value (' + attribute + ')');\r\n\r\n    return attribute.replace(/\\\\/g, '\\\\\\\\').replace(/\\\"/g, '\\\\\"');                             // Escape quotes and slash\r\n};\r\n\r\n\r\nexports.escapeHtml = function (string) {\r\n\r\n    return Escape.escapeHtml(string);\r\n};\r\n\r\n\r\nexports.escapeJavaScript = function (string) {\r\n\r\n    return Escape.escapeJavaScript(string);\r\n};\r\n\r\n\r\n/*\r\nvar event = {\r\n    timestamp: now.getTime(),\r\n    tags: ['tag'],\r\n    data: { some: 'data' }\r\n};\r\n*/\r\n\r\nexports.consoleFunc = console.log;\r\n\r\nexports.printEvent = function (event) {\r\n\r\n    var pad = function (value) {\r\n\r\n        return (value < 10 ? '0' : '') + value;\r\n    };\r\n\r\n    var now = new Date(event.timestamp);\r\n    var timestring = (now.getYear() - 100).toString() +\r\n        pad(now.getMonth() + 1) +\r\n        pad(now.getDate()) +\r\n        '/' +\r\n        pad(now.getHours()) +\r\n        pad(now.getMinutes()) +\r\n        pad(now.getSeconds()) +\r\n        '.' +\r\n        now.getMilliseconds();\r\n\r\n    var data = event.data;\r\n    if (typeof event.data !== 'string') {\r\n        try {\r\n            data = JSON.stringify(event.data);\r\n        }\r\n        catch (e) {\r\n            data = 'JSON Error: ' + e.message;\r\n        }\r\n    }\r\n\r\n    var output = timestring + ', ' + event.tags[0] + ', ' + data;\r\n    exports.consoleFunc(output);\r\n};\r\n\r\n\r\nexports.nextTick = function (callback) {\r\n\r\n    return function () {\r\n\r\n        var args = arguments;\r\n        process.nextTick(function () {\r\n\r\n            callback.apply(null, args);\r\n        });\r\n    };\r\n};\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "fs": {
                  "where": "inline"
                },
                "./escape": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/escape.js": {
            "requireId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/escape",
            "memoizeId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/lib/escape.js",
            "descriptor": {
              "filename": "escape.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/hoek/lib/escape.js",
              "mtime": 1365188900,
              "code": "// Declare internals\n\nvar internals = {};\n\n\nexports.escapeJavaScript = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeJavaScriptChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\nexports.escapeHtml = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeHtmlChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\ninternals.escapeJavaScriptChar = function (charCode) {\n\n    if (charCode >= 256) {\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '\\\\x' + internals.padLeft(hexValue, 2);\n};\n\n\ninternals.escapeHtmlChar = function (charCode) {\n\n    var namedEscape = internals.namedHtml[charCode];\n    if (typeof namedEscape !== 'undefined') {\n        return namedEscape;\n    }\n\n    if (charCode >= 256) {\n        return '&#' + charCode + ';';\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\n};\n\n\ninternals.padLeft = function (str, len) {\n\n    while (str.length < len) {\n        str = '0' + str;\n    }\n\n    return str;\n};\n\n\ninternals.isSafe = function (charCode) {\n\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\n};\n\n\ninternals.namedHtml = {\n    '38': '&amp;',\n    '60': '&lt;',\n    '62': '&gt;',\n    '34': '&quot;',\n    '160': '&nbsp;',\n    '162': '&cent;',\n    '163': '&pound;',\n    '164': '&curren;',\n    '169': '&copy;',\n    '174': '&reg;'\n};\n\n\ninternals.safeCharCodes = (function () {\n\n    var safe = {};\n\n    for (var i = 32; i < 123; ++i) {\n\n        if ((i >= 97 && i <= 122) ||         // a-z\n            (i >= 65 && i <= 90) ||          // A-Z\n            (i >= 48 && i <= 57) ||          // 0-9\n            i === 32 ||                      // space\n            i === 46 ||                      // .\n            i === 44 ||                      // ,\n            i === 45 ||                      // -\n            i === 58 ||                      // :\n            i === 95) {                      // _\n\n            safe[i] = null;\n        }\n    }\n\n    return safe;\n}());",
              "globals": {
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "i": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/hoek/lib';\n// Declare internals\n\nvar internals = {};\n\n\nexports.escapeJavaScript = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeJavaScriptChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\nexports.escapeHtml = function (input) {\n\n    if (!input) {\n        return '';\n    }\n\n    var escaped = '';\n\n    for (var i = 0, il = input.length; i < il; ++i) {\n\n        var charCode = input.charCodeAt(i);\n\n        if (internals.isSafe(charCode)) {\n            escaped += input[i];\n        }\n        else {\n            escaped += internals.escapeHtmlChar(charCode);\n        }\n    }\n\n    return escaped;\n};\n\n\ninternals.escapeJavaScriptChar = function (charCode) {\n\n    if (charCode >= 256) {\n        return '\\\\u' + internals.padLeft('' + charCode, 4);\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '\\\\x' + internals.padLeft(hexValue, 2);\n};\n\n\ninternals.escapeHtmlChar = function (charCode) {\n\n    var namedEscape = internals.namedHtml[charCode];\n    if (typeof namedEscape !== 'undefined') {\n        return namedEscape;\n    }\n\n    if (charCode >= 256) {\n        return '&#' + charCode + ';';\n    }\n\n    var hexValue = new Buffer(String.fromCharCode(charCode), 'ascii').toString('hex');\n    return '&#x' + internals.padLeft(hexValue, 2) + ';';\n};\n\n\ninternals.padLeft = function (str, len) {\n\n    while (str.length < len) {\n        str = '0' + str;\n    }\n\n    return str;\n};\n\n\ninternals.isSafe = function (charCode) {\n\n    return (typeof internals.safeCharCodes[charCode] !== 'undefined');\n};\n\n\ninternals.namedHtml = {\n    '38': '&amp;',\n    '60': '&lt;',\n    '62': '&gt;',\n    '34': '&quot;',\n    '160': '&nbsp;',\n    '162': '&cent;',\n    '163': '&pound;',\n    '164': '&curren;',\n    '169': '&copy;',\n    '174': '&reg;'\n};\n\n\ninternals.safeCharCodes = (function () {\n\n    var safe = {};\n\n    for (var i = 32; i < 123; ++i) {\n\n        if ((i >= 97 && i <= 122) ||         // a-z\n            (i >= 65 && i <= 90) ||          // A-Z\n            (i >= 48 && i <= 57) ||          // 0-9\n            i === 32 ||                      // space\n            i === 46 ||                      // .\n            i === 44 ||                      // ,\n            i === 45 ||                      // -\n            i === 58 ||                      // :\n            i === 95) {                      // _\n\n            safe[i] = null;\n        }\n    }\n\n    return safe;\n}());\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/index.js": {
            "requireId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/index.js",
            "memoizeId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/cryptiles/index.js",
              "mtime": 1372866517,
              "code": "module.exports = require('./lib');",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "require": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./lib": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/cryptiles';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/cryptiles';\nmodule.exports = require('./lib');\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    require: (typeof require !== \"undefined\") ? require : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./lib": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/lib/index.js": {
            "requireId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/lib/index",
            "memoizeId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/hawk/node_modules/cryptiles/lib/index.js",
              "mtime": 1372866517,
              "code": "// Load modules\n\nvar Crypto = require('crypto');\nvar Boom = require('boom');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Generate a cryptographically strong pseudo-random data\n\nexports.randomString = function (size) {\n\n    var buffer = exports.randomBits((size + 1) * 6);\n    if (buffer instanceof Error) {\n        return buffer;\n    }\n\n    var string = buffer.toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\n    return string.slice(0, size);\n};\n\n\nexports.randomBits = function (bits) {\n\n    if (!bits ||\n        bits < 0) {\n\n        return Boom.internal('Invalid random bits count');\n    }\n\n    var bytes = Math.ceil(bits / 8);\n    try {\n        return Crypto.randomBytes(bytes);\n    }\n    catch (err) {\n        return Boom.internal('Failed generating random bits: ' + err.message);\n    }\n};\n\n\n// Compare two strings using fixed time algorithm (to prevent time-based analysis of MAC digest match)\n\nexports.fixedTimeComparison = function (a, b) {\n\n    if (typeof a !== 'string' ||\n        typeof b !== 'string') {\n\n        return false;\n    }\n\n    var mismatch = (a.length === b.length ? 0 : 1);\n    if (mismatch) {\n        b = a;\n    }\n\n    for (var i = 0, il = a.length; i < il; ++i) {\n        var ac = a.charCodeAt(i);\n        var bc = b.charCodeAt(i);\n        mismatch += (ac === bc ? 0 : 1);\n    }\n\n    return (mismatch === 0);\n};\n\n\n",
              "globals": {
                "Crypto": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Boom": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "i": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "crypto": {
                    "where": "inline"
                  },
                  "boom": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/cryptiles/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/node_modules/cryptiles/lib';\n// Load modules\n\nvar Crypto = require('__SYSTEM__/crypto');\nvar Boom = require('boom');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Generate a cryptographically strong pseudo-random data\n\nexports.randomString = function (size) {\n\n    var buffer = exports.randomBits((size + 1) * 6);\n    if (buffer instanceof Error) {\n        return buffer;\n    }\n\n    var string = buffer.toString('base64').replace(/\\+/g, '-').replace(/\\//g, '_').replace(/\\=/g, '');\n    return string.slice(0, size);\n};\n\n\nexports.randomBits = function (bits) {\n\n    if (!bits ||\n        bits < 0) {\n\n        return Boom.internal('Invalid random bits count');\n    }\n\n    var bytes = Math.ceil(bits / 8);\n    try {\n        return Crypto.randomBytes(bytes);\n    }\n    catch (err) {\n        return Boom.internal('Failed generating random bits: ' + err.message);\n    }\n};\n\n\n// Compare two strings using fixed time algorithm (to prevent time-based analysis of MAC digest match)\n\nexports.fixedTimeComparison = function (a, b) {\n\n    if (typeof a !== 'string' ||\n        typeof b !== 'string') {\n\n        return false;\n    }\n\n    var mismatch = (a.length === b.length ? 0 : 1);\n    if (mismatch) {\n        b = a;\n    }\n\n    for (var i = 0, il = a.length; i < il; ++i) {\n        var ac = a.charCodeAt(i);\n        var bc = b.charCodeAt(i);\n        mismatch += (ac === bc ? 0 : 1);\n    }\n\n    return (mismatch === 0);\n};\n\n\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "crypto": {
                  "where": "inline"
                },
                "boom": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/crypto.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/crypto",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/crypto.js",
            "descriptor": {
              "filename": "crypto.js",
              "filepath": "node_modules/request/node_modules/hawk/lib/crypto.js",
              "mtime": 1365791934,
              "code": "// Load modules\r\n\r\nvar Crypto = require('crypto');\r\nvar Url = require('url');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// MAC normalization format version\r\n\r\nexports.headerVersion = '1';                        // Prevent comparison of mac values generated with different normalized string formats\r\n\r\n\r\n// Supported HMAC algorithms\r\n\r\nexports.algorithms = ['sha1', 'sha256'];\r\n\r\n\r\n// Calculate the request MAC\r\n\r\n/*\r\n    type: 'header',                                 // 'header', 'bewit', 'response'\r\n    credentials: {\r\n        key: 'aoijedoaijsdlaksjdl',\r\n        algorithm: 'sha256'                         // 'sha1', 'sha256'\r\n    },\r\n    options: {\r\n        method: 'GET',\r\n        resource: '/resource?a=1&b=2',\r\n        host: 'example.com',\r\n        port: 8080,\r\n        ts: 1357718381034,\r\n        nonce: 'd3d345f',\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV/OhB3y+NdwoCr6RShbVkE=',\r\n        ext: 'app-specific-data',\r\n        app: 'hf48hd83qwkj',                        // Application id (Oz)\r\n        dlg: 'd8djwekds9cj'                         // Delegated by application id (Oz), requires options.app\r\n    }\r\n*/\r\n\r\nexports.calculateMac = function (type, credentials, options) {\r\n\r\n    var normalized = exports.generateNormalizedString(type, options);\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key).update(normalized);\r\n    var digest = hmac.digest('base64');\r\n    return digest;\r\n};\r\n\r\n\r\nexports.generateNormalizedString = function (type, options) {\r\n\r\n    var normalized = 'hawk.' + exports.headerVersion + '.' + type + '\\n' +\r\n                     options.ts + '\\n' +\r\n                     options.nonce + '\\n' +\r\n                     options.method.toUpperCase() + '\\n' +\r\n                     options.resource + '\\n' +\r\n                     options.host.toLowerCase() + '\\n' +\r\n                     options.port + '\\n' +\r\n                     (options.hash || '') + '\\n';\r\n\r\n    if (options.ext) {\r\n        normalized += options.ext.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\n');\r\n    }\r\n\r\n    normalized += '\\n';\r\n\r\n    if (options.app) {\r\n        normalized += options.app + '\\n' +\r\n                      (options.dlg || '') + '\\n';\r\n    }\r\n\r\n    return normalized;\r\n};\r\n\r\n\r\nexports.calculatePayloadHash = function (payload, algorithm, contentType) {\r\n\r\n    var hash = exports.initializePayloadHash(algorithm, contentType);\r\n    hash.update(payload || '');\r\n    return exports.finalizePayloadHash(hash);\r\n};\r\n\r\n\r\nexports.initializePayloadHash = function (algorithm, contentType) {\r\n\r\n    var hash = Crypto.createHash(algorithm);\r\n    hash.update('hawk.' + exports.headerVersion + '.payload\\n');\r\n    hash.update(Utils.parseContentType(contentType) + '\\n');\r\n    return hash;\r\n};\r\n\r\n\r\nexports.finalizePayloadHash = function (hash) {\r\n\r\n    hash.update('\\n');\r\n    return hash.digest('base64');\r\n};\r\n\r\n\r\nexports.calculateTsMac = function (ts, credentials) {\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key);\r\n    hmac.update('hawk.' + exports.headerVersion + '.ts\\n' + ts + '\\n');\r\n    return hmac.digest('base64');\r\n};\r\n\r\n",
              "globals": {
                "Crypto": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Url": {
                  "type": "assign"
                },
                "Utils": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "crypto": {
                    "where": "inline"
                  },
                  "url": {
                    "where": "inline"
                  },
                  "./utils": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';\n// Load modules\r\n\r\nvar Crypto = require('__SYSTEM__/crypto');\r\nvar Url = require('__SYSTEM__/url');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// MAC normalization format version\r\n\r\nexports.headerVersion = '1';                        // Prevent comparison of mac values generated with different normalized string formats\r\n\r\n\r\n// Supported HMAC algorithms\r\n\r\nexports.algorithms = ['sha1', 'sha256'];\r\n\r\n\r\n// Calculate the request MAC\r\n\r\n/*\r\n    type: 'header',                                 // 'header', 'bewit', 'response'\r\n    credentials: {\r\n        key: 'aoijedoaijsdlaksjdl',\r\n        algorithm: 'sha256'                         // 'sha1', 'sha256'\r\n    },\r\n    options: {\r\n        method: 'GET',\r\n        resource: '/resource?a=1&b=2',\r\n        host: 'example.com',\r\n        port: 8080,\r\n        ts: 1357718381034,\r\n        nonce: 'd3d345f',\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV/OhB3y+NdwoCr6RShbVkE=',\r\n        ext: 'app-specific-data',\r\n        app: 'hf48hd83qwkj',                        // Application id (Oz)\r\n        dlg: 'd8djwekds9cj'                         // Delegated by application id (Oz), requires options.app\r\n    }\r\n*/\r\n\r\nexports.calculateMac = function (type, credentials, options) {\r\n\r\n    var normalized = exports.generateNormalizedString(type, options);\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key).update(normalized);\r\n    var digest = hmac.digest('base64');\r\n    return digest;\r\n};\r\n\r\n\r\nexports.generateNormalizedString = function (type, options) {\r\n\r\n    var normalized = 'hawk.' + exports.headerVersion + '.' + type + '\\n' +\r\n                     options.ts + '\\n' +\r\n                     options.nonce + '\\n' +\r\n                     options.method.toUpperCase() + '\\n' +\r\n                     options.resource + '\\n' +\r\n                     options.host.toLowerCase() + '\\n' +\r\n                     options.port + '\\n' +\r\n                     (options.hash || '') + '\\n';\r\n\r\n    if (options.ext) {\r\n        normalized += options.ext.replace('\\\\', '\\\\\\\\').replace('\\n', '\\\\n');\r\n    }\r\n\r\n    normalized += '\\n';\r\n\r\n    if (options.app) {\r\n        normalized += options.app + '\\n' +\r\n                      (options.dlg || '') + '\\n';\r\n    }\r\n\r\n    return normalized;\r\n};\r\n\r\n\r\nexports.calculatePayloadHash = function (payload, algorithm, contentType) {\r\n\r\n    var hash = exports.initializePayloadHash(algorithm, contentType);\r\n    hash.update(payload || '');\r\n    return exports.finalizePayloadHash(hash);\r\n};\r\n\r\n\r\nexports.initializePayloadHash = function (algorithm, contentType) {\r\n\r\n    var hash = Crypto.createHash(algorithm);\r\n    hash.update('hawk.' + exports.headerVersion + '.payload\\n');\r\n    hash.update(Utils.parseContentType(contentType) + '\\n');\r\n    return hash;\r\n};\r\n\r\n\r\nexports.finalizePayloadHash = function (hash) {\r\n\r\n    hash.update('\\n');\r\n    return hash.digest('base64');\r\n};\r\n\r\n\r\nexports.calculateTsMac = function (ts, credentials) {\r\n\r\n    var hmac = Crypto.createHmac(credentials.algorithm, credentials.key);\r\n    hmac.update('hawk.' + exports.headerVersion + '.ts\\n' + ts + '\\n');\r\n    return hmac.digest('base64');\r\n};\r\n\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "crypto": {
                  "where": "inline"
                },
                "url": {
                  "where": "inline"
                },
                "./utils": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/utils.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/utils",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/utils.js",
            "descriptor": {
              "filename": "utils.js",
              "filepath": "node_modules/request/node_modules/hawk/lib/utils.js",
              "mtime": 1365752437,
              "code": "// Load modules\n\nvar Hoek = require('hoek');\nvar Sntp = require('sntp');\nvar Boom = require('boom');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Import Hoek Utilities\n\ninternals.import = function () {\n\n    for (var i in Hoek) {\n        if (Hoek.hasOwnProperty(i)) {\n            exports[i] = Hoek[i];\n        }\n    }\n};\n\ninternals.import();\n\n\n// Hawk version\n\nexports.version = function () {\n\n    return exports.loadPackage(__dirname + '/..').version;\n};\n\n\n// Extract host and port from request\n\nexports.parseHost = function (req, hostHeaderName) {\n\n    hostHeaderName = (hostHeaderName ? hostHeaderName.toLowerCase() : 'host');\n    var hostHeader = req.headers[hostHeaderName];\n    if (!hostHeader) {\n        return null;\n    }\n\n    var hostHeaderRegex = /^(?:(?:\\r\\n)?[\\t ])*([^:]+)(?::(\\d+))?(?:(?:\\r\\n)?[\\t ])*$/;     // Does not support IPv6\n    var hostParts = hostHeader.match(hostHeaderRegex);\n\n    if (!hostParts ||\n        hostParts.length !== 3 ||\n        !hostParts[1]) {\n\n        return null;\n    }\n\n    return {\n        name: hostParts[1],\n        port: (hostParts[2] ? hostParts[2] : (req.connection && req.connection.encrypted ? 443 : 80))\n    };\n};\n\n\n// Parse Content-Type header content\n\nexports.parseContentType = function (header) {\n\n    if (!header) {\n        return '';\n    }\n\n    return header.split(';')[0].trim().toLowerCase();\n};\n\n\n// Convert node's  to request configuration object\n\nexports.parseRequest = function (req, options) {\n\n    if (!req.headers) {\n        return req;\n    }\n\n    // Obtain host and port information\n\n    var host = exports.parseHost(req, options.hostHeaderName);\n    if (!host) {\n        return new Error('Invalid Host header');\n    }\n\n    var request = {\n        method: req.method,\n        url: req.url,\n        host: host.name,\n        port: host.port,\n        authorization: req.headers.authorization,\n        contentType: req.headers['content-type'] || ''\n    };\n\n    return request;\n};\n\n\nexports.now = function () {\n\n    return Sntp.now();\n};\n\n\n// Parse Hawk HTTP Authorization header\n\nexports.parseAuthorizationHeader = function (header, keys) {\n\n    keys = keys || ['id', 'ts', 'nonce', 'hash', 'ext', 'mac', 'app', 'dlg'];\n\n    if (!header) {\n        return Boom.unauthorized(null, 'Hawk');\n    }\n\n    var headerParts = header.match(/^(\\w+)(?:\\s+(.*))?$/);       // Header: scheme[ something]\n    if (!headerParts) {\n        return Boom.badRequest('Invalid header syntax');\n    }\n\n    var scheme = headerParts[1];\n    if (scheme.toLowerCase() !== 'hawk') {\n        return Boom.unauthorized(null, 'Hawk');\n    }\n\n    var attributesString = headerParts[2];\n    if (!attributesString) {\n        return Boom.badRequest('Invalid header syntax');\n    }\n\n    var attributes = {};\n    var errorMessage = '';\n    var verify = attributesString.replace(/(\\w+)=\"([^\"\\\\]*)\"\\s*(?:,\\s*|$)/g, function ($0, $1, $2) {\n\n        // Check valid attribute names\n\n        if (keys.indexOf($1) === -1) {\n            errorMessage = 'Unknown attribute: ' + $1;\n            return;\n        }\n\n        // Allowed attribute value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9\n\n        if ($2.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~]+$/) === null) {\n            errorMessage = 'Bad attribute value: ' + $1;\n            return;\n        }\n\n        // Check for duplicates\n\n        if (attributes.hasOwnProperty($1)) {\n            errorMessage = 'Duplicate attribute: ' + $1;\n            return;\n        }\n\n        attributes[$1] = $2;\n        return '';\n    });\n\n    if (verify !== '') {\n        return Boom.badRequest(errorMessage || 'Bad header format');\n    }\n\n    return attributes;\n};\n\n\nexports.unauthorized = function (message) {\n\n    return Boom.unauthorized(message, 'Hawk');\n};\n\n",
              "globals": {
                "Hoek": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Sntp": {
                  "type": "assign"
                },
                "Boom": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "hoek": {
                    "where": "inline"
                  },
                  "sntp": {
                    "where": "inline"
                  },
                  "boom": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';\n// Load modules\n\nvar Hoek = require('hoek');\nvar Sntp = require('sntp');\nvar Boom = require('boom');\n\n\n// Declare internals\n\nvar internals = {};\n\n\n// Import Hoek Utilities\n\ninternals.import = function () {\n\n    for (var i in Hoek) {\n        if (Hoek.hasOwnProperty(i)) {\n            exports[i] = Hoek[i];\n        }\n    }\n};\n\ninternals.import();\n\n\n// Hawk version\n\nexports.version = function () {\n\n    return exports.loadPackage(__dirname + '/..').version;\n};\n\n\n// Extract host and port from request\n\nexports.parseHost = function (req, hostHeaderName) {\n\n    hostHeaderName = (hostHeaderName ? hostHeaderName.toLowerCase() : 'host');\n    var hostHeader = req.headers[hostHeaderName];\n    if (!hostHeader) {\n        return null;\n    }\n\n    var hostHeaderRegex = /^(?:(?:\\r\\n)?[\\t ])*([^:]+)(?::(\\d+))?(?:(?:\\r\\n)?[\\t ])*$/;     // Does not support IPv6\n    var hostParts = hostHeader.match(hostHeaderRegex);\n\n    if (!hostParts ||\n        hostParts.length !== 3 ||\n        !hostParts[1]) {\n\n        return null;\n    }\n\n    return {\n        name: hostParts[1],\n        port: (hostParts[2] ? hostParts[2] : (req.connection && req.connection.encrypted ? 443 : 80))\n    };\n};\n\n\n// Parse Content-Type header content\n\nexports.parseContentType = function (header) {\n\n    if (!header) {\n        return '';\n    }\n\n    return header.split(';')[0].trim().toLowerCase();\n};\n\n\n// Convert node's  to request configuration object\n\nexports.parseRequest = function (req, options) {\n\n    if (!req.headers) {\n        return req;\n    }\n\n    // Obtain host and port information\n\n    var host = exports.parseHost(req, options.hostHeaderName);\n    if (!host) {\n        return new Error('Invalid Host header');\n    }\n\n    var request = {\n        method: req.method,\n        url: req.url,\n        host: host.name,\n        port: host.port,\n        authorization: req.headers.authorization,\n        contentType: req.headers['content-type'] || ''\n    };\n\n    return request;\n};\n\n\nexports.now = function () {\n\n    return Sntp.now();\n};\n\n\n// Parse Hawk HTTP Authorization header\n\nexports.parseAuthorizationHeader = function (header, keys) {\n\n    keys = keys || ['id', 'ts', 'nonce', 'hash', 'ext', 'mac', 'app', 'dlg'];\n\n    if (!header) {\n        return Boom.unauthorized(null, 'Hawk');\n    }\n\n    var headerParts = header.match(/^(\\w+)(?:\\s+(.*))?$/);       // Header: scheme[ something]\n    if (!headerParts) {\n        return Boom.badRequest('Invalid header syntax');\n    }\n\n    var scheme = headerParts[1];\n    if (scheme.toLowerCase() !== 'hawk') {\n        return Boom.unauthorized(null, 'Hawk');\n    }\n\n    var attributesString = headerParts[2];\n    if (!attributesString) {\n        return Boom.badRequest('Invalid header syntax');\n    }\n\n    var attributes = {};\n    var errorMessage = '';\n    var verify = attributesString.replace(/(\\w+)=\"([^\"\\\\]*)\"\\s*(?:,\\s*|$)/g, function ($0, $1, $2) {\n\n        // Check valid attribute names\n\n        if (keys.indexOf($1) === -1) {\n            errorMessage = 'Unknown attribute: ' + $1;\n            return;\n        }\n\n        // Allowed attribute value characters: !#$%&'()*+,-./:;<=>?@[]^_`{|}~ and space, a-z, A-Z, 0-9\n\n        if ($2.match(/^[ \\w\\!#\\$%&'\\(\\)\\*\\+,\\-\\.\\/\\:;<\\=>\\?@\\[\\]\\^`\\{\\|\\}~]+$/) === null) {\n            errorMessage = 'Bad attribute value: ' + $1;\n            return;\n        }\n\n        // Check for duplicates\n\n        if (attributes.hasOwnProperty($1)) {\n            errorMessage = 'Duplicate attribute: ' + $1;\n            return;\n        }\n\n        attributes[$1] = $2;\n        return '';\n    });\n\n    if (verify !== '') {\n        return Boom.badRequest(errorMessage || 'Bad header format');\n    }\n\n    return attributes;\n};\n\n\nexports.unauthorized = function (message) {\n\n    return Boom.unauthorized(message, 'Hawk');\n};\n\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "hoek": {
                  "where": "inline"
                },
                "sntp": {
                  "where": "inline"
                },
                "boom": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/client.js": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/client",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/lib/client.js",
            "descriptor": {
              "filename": "client.js",
              "filepath": "node_modules/request/node_modules/hawk/lib/client.js",
              "mtime": 1365791465,
              "code": "// Load modules\r\n\r\nvar Url = require('url');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Generate an Authorization header for a given request\r\n\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    method: HTTP verb (e.g. 'GET', 'POST')\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                                 // 'sha1', 'sha256'\r\n        },\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        timestamp: Date.now(),                              // A pre-calculated timestamp\r\n        nonce: '2334f34f',                                  // A pre-generated nonce\r\n        localtimeOffsetMsec: 400,                           // Time offset to sync with server time (ignored if timestamp provided)\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV=',                    // Pre-calculated payload hash\r\n        app: '24s23423f34dx',                               // Oz application id\r\n        dlg: '234sz34tww3sd'                                // Oz delegated-by application id\r\n    }\r\n*/\r\n\r\nexports.header = function (uri, method, options) {\r\n\r\n    var result = {\r\n        field: '',\r\n        artifacts: {}\r\n    };\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri || (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !method || typeof method !== 'string' ||\r\n        !options || typeof options !== 'object') {\r\n\r\n        return result;\r\n    }\r\n\r\n    // Application time\r\n\r\n    var timestamp = options.timestamp || Math.floor((Utils.now() + (options.localtimeOffsetMsec || 0)) / 1000)\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return result;\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return result;\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var artifacts = {\r\n        ts: timestamp,\r\n        nonce: options.nonce || Cryptiles.randomString(6),\r\n        method: method,\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        hash: options.hash,\r\n        ext: options.ext,\r\n        app: options.app,\r\n        dlg: options.dlg\r\n    };\r\n\r\n    result.artifacts = artifacts;\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        options.hasOwnProperty('payload')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var hasExt = artifacts.ext !== null && artifacts.ext !== undefined && artifacts.ext !== '';       // Other falsey values allowed\r\n    var header = 'Hawk id=\"' + credentials.id +\r\n                 '\", ts=\"' + artifacts.ts +\r\n                 '\", nonce=\"' + artifacts.nonce +\r\n                 (artifacts.hash ? '\", hash=\"' + artifacts.hash : '') +\r\n                 (hasExt ? '\", ext=\"' + Utils.escapeHeaderAttribute(artifacts.ext) : '') +\r\n                 '\", mac=\"' + mac + '\"';\r\n\r\n    if (artifacts.app) {\r\n        header += ', app=\"' + artifacts.app +\r\n                  (artifacts.dlg ? '\", dlg=\"' + artifacts.dlg : '') + '\"';\r\n    }\r\n\r\n    result.field = header;\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Validate server response\r\n\r\n/*\r\n    res:        node's response object\r\n    artifacts:  object recieved from header().artifacts\r\n    options: {\r\n        payload:    optional payload received\r\n        required:   specifies if a Server-Authorization header is required. Defaults to 'false'\r\n    }\r\n*/\r\n\r\nexports.authenticate = function (res, credentials, artifacts, options) {\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    options = options || {};\r\n\r\n    if (res.headers['www-authenticate']) {\r\n\r\n        // Parse HTTP WWW-Authenticate header\r\n\r\n        var attributes = Utils.parseAuthorizationHeader(res.headers['www-authenticate'], ['ts', 'tsm', 'error']);\r\n        if (attributes instanceof Error) {\r\n            return false;\r\n        }\r\n\r\n        if (attributes.ts) {\r\n            var tsm = Crypto.calculateTsMac(attributes.ts, credentials);\r\n            if (tsm !== attributes.tsm) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n\r\n    // Parse HTTP Server-Authorization header\r\n\r\n    if (!res.headers['server-authorization'] &&\r\n        !options.required) {\r\n\r\n        return true;\r\n    }\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(res.headers['server-authorization'], ['mac', 'ext', 'hash']);\r\n    if (attributes instanceof Error) {\r\n        return false;\r\n    }\r\n\r\n    artifacts.ext = attributes.ext;\r\n    artifacts.hash = attributes.hash;\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n    if (mac !== attributes.mac) {\r\n        return false;\r\n    }\r\n\r\n    if (!options.hasOwnProperty('payload')) {\r\n        return true;\r\n    }\r\n\r\n    if (!attributes.hash) {\r\n        return false;\r\n    }\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, res.headers['content-type']);\r\n    return (calculatedHash === attributes.hash);\r\n};\r\n\r\n\r\n// Generate a bewit value for a given URI\r\n\r\n/*\r\n * credentials is an object with the following keys: 'id, 'key', 'algorithm'.\r\n * options is an object with the following optional keys: 'ext', 'localtimeOffsetMsec'\r\n */\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                             // 'sha1', 'sha256'\r\n        },\r\n        ttlSec: 60 * 60,                                    // TTL in seconds\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        localtimeOffsetMsec: 400                            // Time offset to sync with server time\r\n    };\r\n*/\r\n\r\nexports.getBewit = function (uri, options) {\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri ||\r\n        (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !options ||\r\n        typeof options !== 'object' ||\r\n        !options.ttlSec) {\r\n\r\n        return '';\r\n    }\r\n\r\n    options.ext = (options.ext === null || options.ext === undefined ? '' : options.ext);       // Zero is valid value\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var exp = Math.floor(now / 1000) + options.ttlSec;\r\n    var mac = Crypto.calculateMac('bewit', credentials, {\r\n        ts: exp,\r\n        nonce: '',\r\n        method: 'GET',\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        ext: options.ext\r\n    });\r\n\r\n    // Construct bewit: id\\exp\\mac\\ext\r\n\r\n    var bewit = credentials.id + '\\\\' + exp + '\\\\' + mac + '\\\\' + options.ext;\r\n    return Utils.base64urlEncode(bewit);\r\n};\r\n\r\n",
              "globals": {
                "Url": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Hoek": {
                  "type": "assign"
                },
                "Cryptiles": {
                  "type": "assign"
                },
                "Crypto": {
                  "type": "assign"
                },
                "Utils": {
                  "type": "assign"
                },
                "internals": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "url": {
                    "where": "inline"
                  },
                  "hoek": {
                    "where": "inline"
                  },
                  "cryptiles": {
                    "where": "inline"
                  },
                  "./crypto": {
                    "where": "inline"
                  },
                  "./utils": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/hawk/lib';\n// Load modules\r\n\r\nvar Url = require('__SYSTEM__/url');\r\nvar Hoek = require('hoek');\r\nvar Cryptiles = require('cryptiles');\r\nvar Crypto = require('./crypto');\r\nvar Utils = require('./utils');\r\n\r\n\r\n// Declare internals\r\n\r\nvar internals = {};\r\n\r\n\r\n// Generate an Authorization header for a given request\r\n\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    method: HTTP verb (e.g. 'GET', 'POST')\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                                 // 'sha1', 'sha256'\r\n        },\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        timestamp: Date.now(),                              // A pre-calculated timestamp\r\n        nonce: '2334f34f',                                  // A pre-generated nonce\r\n        localtimeOffsetMsec: 400,                           // Time offset to sync with server time (ignored if timestamp provided)\r\n        payload: '{\"some\":\"payload\"}',                      // UTF-8 encoded string for body hash generation (ignored if hash provided)\r\n        contentType: 'application/json',                    // Payload content-type (ignored if hash provided)\r\n        hash: 'U4MKKSmiVxk37JCCrAVIjV=',                    // Pre-calculated payload hash\r\n        app: '24s23423f34dx',                               // Oz application id\r\n        dlg: '234sz34tww3sd'                                // Oz delegated-by application id\r\n    }\r\n*/\r\n\r\nexports.header = function (uri, method, options) {\r\n\r\n    var result = {\r\n        field: '',\r\n        artifacts: {}\r\n    };\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri || (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !method || typeof method !== 'string' ||\r\n        !options || typeof options !== 'object') {\r\n\r\n        return result;\r\n    }\r\n\r\n    // Application time\r\n\r\n    var timestamp = options.timestamp || Math.floor((Utils.now() + (options.localtimeOffsetMsec || 0)) / 1000)\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        // Invalid credential object\r\n        return result;\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return result;\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var artifacts = {\r\n        ts: timestamp,\r\n        nonce: options.nonce || Cryptiles.randomString(6),\r\n        method: method,\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        hash: options.hash,\r\n        ext: options.ext,\r\n        app: options.app,\r\n        dlg: options.dlg\r\n    };\r\n\r\n    result.artifacts = artifacts;\r\n\r\n    // Calculate payload hash\r\n\r\n    if (!artifacts.hash &&\r\n        options.hasOwnProperty('payload')) {\r\n\r\n        artifacts.hash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, options.contentType);\r\n    }\r\n\r\n    var mac = Crypto.calculateMac('header', credentials, artifacts);\r\n\r\n    // Construct header\r\n\r\n    var hasExt = artifacts.ext !== null && artifacts.ext !== undefined && artifacts.ext !== '';       // Other falsey values allowed\r\n    var header = 'Hawk id=\"' + credentials.id +\r\n                 '\", ts=\"' + artifacts.ts +\r\n                 '\", nonce=\"' + artifacts.nonce +\r\n                 (artifacts.hash ? '\", hash=\"' + artifacts.hash : '') +\r\n                 (hasExt ? '\", ext=\"' + Utils.escapeHeaderAttribute(artifacts.ext) : '') +\r\n                 '\", mac=\"' + mac + '\"';\r\n\r\n    if (artifacts.app) {\r\n        header += ', app=\"' + artifacts.app +\r\n                  (artifacts.dlg ? '\", dlg=\"' + artifacts.dlg : '') + '\"';\r\n    }\r\n\r\n    result.field = header;\r\n\r\n    return result;\r\n};\r\n\r\n\r\n// Validate server response\r\n\r\n/*\r\n    res:        node's response object\r\n    artifacts:  object recieved from header().artifacts\r\n    options: {\r\n        payload:    optional payload received\r\n        required:   specifies if a Server-Authorization header is required. Defaults to 'false'\r\n    }\r\n*/\r\n\r\nexports.authenticate = function (res, credentials, artifacts, options) {\r\n\r\n    artifacts = Hoek.clone(artifacts);\r\n    options = options || {};\r\n\r\n    if (res.headers['www-authenticate']) {\r\n\r\n        // Parse HTTP WWW-Authenticate header\r\n\r\n        var attributes = Utils.parseAuthorizationHeader(res.headers['www-authenticate'], ['ts', 'tsm', 'error']);\r\n        if (attributes instanceof Error) {\r\n            return false;\r\n        }\r\n\r\n        if (attributes.ts) {\r\n            var tsm = Crypto.calculateTsMac(attributes.ts, credentials);\r\n            if (tsm !== attributes.tsm) {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n\r\n    // Parse HTTP Server-Authorization header\r\n\r\n    if (!res.headers['server-authorization'] &&\r\n        !options.required) {\r\n\r\n        return true;\r\n    }\r\n\r\n    var attributes = Utils.parseAuthorizationHeader(res.headers['server-authorization'], ['mac', 'ext', 'hash']);\r\n    if (attributes instanceof Error) {\r\n        return false;\r\n    }\r\n\r\n    artifacts.ext = attributes.ext;\r\n    artifacts.hash = attributes.hash;\r\n\r\n    var mac = Crypto.calculateMac('response', credentials, artifacts);\r\n    if (mac !== attributes.mac) {\r\n        return false;\r\n    }\r\n\r\n    if (!options.hasOwnProperty('payload')) {\r\n        return true;\r\n    }\r\n\r\n    if (!attributes.hash) {\r\n        return false;\r\n    }\r\n\r\n    var calculatedHash = Crypto.calculatePayloadHash(options.payload, credentials.algorithm, res.headers['content-type']);\r\n    return (calculatedHash === attributes.hash);\r\n};\r\n\r\n\r\n// Generate a bewit value for a given URI\r\n\r\n/*\r\n * credentials is an object with the following keys: 'id, 'key', 'algorithm'.\r\n * options is an object with the following optional keys: 'ext', 'localtimeOffsetMsec'\r\n */\r\n/*\r\n    uri: 'http://example.com/resource?a=b' or object from Url.parse()\r\n    options: {\r\n\r\n        // Required\r\n\r\n        credentials: {\r\n            id: 'dh37fgj492je',\r\n            key: 'aoijedoaijsdlaksjdl',\r\n            algorithm: 'sha256'                             // 'sha1', 'sha256'\r\n        },\r\n        ttlSec: 60 * 60,                                    // TTL in seconds\r\n\r\n        // Optional\r\n\r\n        ext: 'application-specific',                        // Application specific data sent via the ext attribute\r\n        localtimeOffsetMsec: 400                            // Time offset to sync with server time\r\n    };\r\n*/\r\n\r\nexports.getBewit = function (uri, options) {\r\n\r\n    // Validate inputs\r\n\r\n    if (!uri ||\r\n        (typeof uri !== 'string' && typeof uri !== 'object') ||\r\n        !options ||\r\n        typeof options !== 'object' ||\r\n        !options.ttlSec) {\r\n\r\n        return '';\r\n    }\r\n\r\n    options.ext = (options.ext === null || options.ext === undefined ? '' : options.ext);       // Zero is valid value\r\n\r\n    // Application time\r\n\r\n    var now = Utils.now() + (options.localtimeOffsetMsec || 0);\r\n\r\n    // Validate credentials\r\n\r\n    var credentials = options.credentials;\r\n    if (!credentials ||\r\n        !credentials.id ||\r\n        !credentials.key ||\r\n        !credentials.algorithm) {\r\n\r\n        return '';\r\n    }\r\n\r\n    if (Crypto.algorithms.indexOf(credentials.algorithm) === -1) {\r\n        return '';\r\n    }\r\n\r\n    // Parse URI\r\n\r\n    if (typeof uri === 'string') {\r\n        uri = Url.parse(uri);\r\n    }\r\n\r\n    // Calculate signature\r\n\r\n    var exp = Math.floor(now / 1000) + options.ttlSec;\r\n    var mac = Crypto.calculateMac('bewit', credentials, {\r\n        ts: exp,\r\n        nonce: '',\r\n        method: 'GET',\r\n        resource: uri.pathname + (uri.search || ''),                            // Maintain trailing '?'\r\n        host: uri.hostname,\r\n        port: uri.port || (uri.protocol === 'http:' ? 80 : 443),\r\n        ext: options.ext\r\n    });\r\n\r\n    // Construct bewit: id\\exp\\mac\\ext\r\n\r\n    var bewit = credentials.id + '\\\\' + exp + '\\\\' + mac + '\\\\' + options.ext;\r\n    return Utils.base64urlEncode(bewit);\r\n};\r\n\r\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "url": {
                  "where": "inline"
                },
                "hoek": {
                  "where": "inline"
                },
                "cryptiles": {
                  "where": "inline"
                },
                "./crypto": {
                  "where": "inline"
                },
                "./utils": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/index.js": {
            "requireId": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/index.js",
            "memoizeId": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/aws-sign/index.js",
              "mtime": 1362168282,
              "code": "\n/*!\n * knox - auth\n * Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n */\n\nvar crypto = require('crypto')\n  , parse = require('url').parse\n  ;\n\n/**\n * Valid keys.\n */\n\nvar keys = \n  [ 'acl'\n  , 'location'\n  , 'logging'\n  , 'notification'\n  , 'partNumber'\n  , 'policy'\n  , 'requestPayment'\n  , 'torrent'\n  , 'uploadId'\n  , 'uploads'\n  , 'versionId'\n  , 'versioning'\n  , 'versions'\n  , 'website'\n  ]\n\n/**\n * Return an \"Authorization\" header value with the given `options`\n * in the form of \"AWS <key>:<signature>\"\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction authorization (options) {\n  return 'AWS ' + options.key + ':' + sign(options)\n}\n\nmodule.exports = authorization\nmodule.exports.authorization = authorization\n\n/**\n * Simple HMAC-SHA1 Wrapper\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */ \n\nfunction hmacSha1 (options) {\n  return crypto.createHmac('sha1', options.secret).update(options.message).digest('base64')\n}\n\nmodule.exports.hmacSha1 = hmacSha1\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction sign (options) {\n  options.message = stringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.sign = sign\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n *\n * Specifically to be used with S3 presigned URLs\n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction signQuery (options) {\n  options.message = queryStringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.signQuery= signQuery\n\n/**\n * Return a string for sign() with the given `options`.\n *\n * Spec:\n * \n *    <verb>\\n\n *    <md5>\\n\n *    <content-type>\\n\n *    <date>\\n\n *    [headers\\n]\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction stringToSign (options) {\n  var headers = options.amazonHeaders || ''\n  if (headers) headers += '\\n'\n  var r = \n    [ options.verb\n    , options.md5\n    , options.contentType\n    , options.date.toUTCString()\n    , headers + options.resource\n    ]\n  return r.join('\\n')\n}\nmodule.exports.queryStringToSign = stringToSign\n\n/**\n * Return a string for sign() with the given `options`, but is meant exclusively\n * for S3 presigned URLs\n *\n * Spec:\n * \n *    <date>\\n\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction queryStringToSign (options){\n  return 'GET\\n\\n\\n' + options.date + '\\n' + options.resource\n}\nmodule.exports.queryStringToSign = queryStringToSign\n\n/**\n * Perform the following:\n *\n *  - ignore non-amazon headers\n *  - lowercase fields\n *  - sort lexicographically\n *  - trim whitespace between \":\"\n *  - join with newline\n *\n * @param {Object} headers\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeHeaders (headers) {\n  var buf = []\n    , fields = Object.keys(headers)\n    ;\n  for (var i = 0, len = fields.length; i < len; ++i) {\n    var field = fields[i]\n      , val = headers[field]\n      , field = field.toLowerCase()\n      ;\n    if (0 !== field.indexOf('x-amz')) continue\n    buf.push(field + ':' + val)\n  }\n  return buf.sort().join('\\n')\n}\nmodule.exports.canonicalizeHeaders = canonicalizeHeaders\n\n/**\n * Perform the following:\n *\n *  - ignore non sub-resources\n *  - sort lexicographically\n *\n * @param {String} resource\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeResource (resource) {\n  var url = parse(resource, true)\n    , path = url.pathname\n    , buf = []\n    ;\n\n  Object.keys(url.query).forEach(function(key){\n    if (!~keys.indexOf(key)) return\n    var val = '' == url.query[key] ? '' : '=' + encodeURIComponent(url.query[key])\n    buf.push(key + val)\n  })\n\n  return path + (buf.length ? '?' + buf.sort().join('&') : '')\n}\nmodule.exports.canonicalizeResource = canonicalizeResource\n",
              "globals": {
                "crypto": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "parse": {
                  "type": "assign"
                },
                "keys": {
                  "type": "assign"
                },
                "authorization": {
                  "type": "assign"
                },
                "sign": {
                  "type": "call"
                },
                "module": {
                  "type": "reference"
                },
                "hmacSha1": {
                  "type": "assign"
                },
                "stringToSign": {
                  "type": "call"
                },
                "signQuery": {
                  "type": "assign"
                },
                "queryStringToSign": {
                  "type": "call"
                },
                "canonicalizeHeaders": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "canonicalizeResource": {
                  "type": "assign"
                },
                "encodeURIComponent": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "crypto": {
                    "where": "inline"
                  },
                  "url": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/aws-sign';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/aws-sign';\n\n/*!\n * knox - auth\n * Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n */\n\nvar crypto = require('__SYSTEM__/crypto')\n  , parse = require('__SYSTEM__/url').parse\n  ;\n\n/**\n * Valid keys.\n */\n\nvar keys = \n  [ 'acl'\n  , 'location'\n  , 'logging'\n  , 'notification'\n  , 'partNumber'\n  , 'policy'\n  , 'requestPayment'\n  , 'torrent'\n  , 'uploadId'\n  , 'uploads'\n  , 'versionId'\n  , 'versioning'\n  , 'versions'\n  , 'website'\n  ]\n\n/**\n * Return an \"Authorization\" header value with the given `options`\n * in the form of \"AWS <key>:<signature>\"\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction authorization (options) {\n  return 'AWS ' + options.key + ':' + sign(options)\n}\n\nmodule.exports = authorization\nmodule.exports.authorization = authorization\n\n/**\n * Simple HMAC-SHA1 Wrapper\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */ \n\nfunction hmacSha1 (options) {\n  return crypto.createHmac('sha1', options.secret).update(options.message).digest('base64')\n}\n\nmodule.exports.hmacSha1 = hmacSha1\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction sign (options) {\n  options.message = stringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.sign = sign\n\n/**\n * Create a base64 sha1 HMAC for `options`. \n *\n * Specifically to be used with S3 presigned URLs\n * \n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction signQuery (options) {\n  options.message = queryStringToSign(options)\n  return hmacSha1(options)\n}\nmodule.exports.signQuery= signQuery\n\n/**\n * Return a string for sign() with the given `options`.\n *\n * Spec:\n * \n *    <verb>\\n\n *    <md5>\\n\n *    <content-type>\\n\n *    <date>\\n\n *    [headers\\n]\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction stringToSign (options) {\n  var headers = options.amazonHeaders || ''\n  if (headers) headers += '\\n'\n  var r = \n    [ options.verb\n    , options.md5\n    , options.contentType\n    , options.date.toUTCString()\n    , headers + options.resource\n    ]\n  return r.join('\\n')\n}\nmodule.exports.queryStringToSign = stringToSign\n\n/**\n * Return a string for sign() with the given `options`, but is meant exclusively\n * for S3 presigned URLs\n *\n * Spec:\n * \n *    <date>\\n\n *    <resource>\n *\n * @param {Object} options\n * @return {String}\n * @api private\n */\n\nfunction queryStringToSign (options){\n  return 'GET\\n\\n\\n' + options.date + '\\n' + options.resource\n}\nmodule.exports.queryStringToSign = queryStringToSign\n\n/**\n * Perform the following:\n *\n *  - ignore non-amazon headers\n *  - lowercase fields\n *  - sort lexicographically\n *  - trim whitespace between \":\"\n *  - join with newline\n *\n * @param {Object} headers\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeHeaders (headers) {\n  var buf = []\n    , fields = Object.keys(headers)\n    ;\n  for (var i = 0, len = fields.length; i < len; ++i) {\n    var field = fields[i]\n      , val = headers[field]\n      , field = field.toLowerCase()\n      ;\n    if (0 !== field.indexOf('x-amz')) continue\n    buf.push(field + ':' + val)\n  }\n  return buf.sort().join('\\n')\n}\nmodule.exports.canonicalizeHeaders = canonicalizeHeaders\n\n/**\n * Perform the following:\n *\n *  - ignore non sub-resources\n *  - sort lexicographically\n *\n * @param {String} resource\n * @return {String}\n * @api private\n */\n\nfunction canonicalizeResource (resource) {\n  var url = parse(resource, true)\n    , path = url.pathname\n    , buf = []\n    ;\n\n  Object.keys(url.query).forEach(function(key){\n    if (!~keys.indexOf(key)) return\n    var val = '' == url.query[key] ? '' : '=' + encodeURIComponent(url.query[key])\n    buf.push(key + val)\n  })\n\n  return path + (buf.length ? '?' + buf.sort().join('&') : '')\n}\nmodule.exports.canonicalizeResource = canonicalizeResource\n\nreturn {\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    parse: (typeof parse !== \"undefined\") ? parse : null,\n    keys: (typeof keys !== \"undefined\") ? keys : null,\n    authorization: (typeof authorization !== \"undefined\") ? authorization : null,\n    sign: (typeof sign !== \"undefined\") ? sign : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    hmacSha1: (typeof hmacSha1 !== \"undefined\") ? hmacSha1 : null,\n    stringToSign: (typeof stringToSign !== \"undefined\") ? stringToSign : null,\n    signQuery: (typeof signQuery !== \"undefined\") ? signQuery : null,\n    queryStringToSign: (typeof queryStringToSign !== \"undefined\") ? queryStringToSign : null,\n    canonicalizeHeaders: (typeof canonicalizeHeaders !== \"undefined\") ? canonicalizeHeaders : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    canonicalizeResource: (typeof canonicalizeResource !== \"undefined\") ? canonicalizeResource : null,\n    encodeURIComponent: (typeof encodeURIComponent !== \"undefined\") ? encodeURIComponent : null\n};\n}",
              "bottom": "return {\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    parse: (typeof parse !== \"undefined\") ? parse : null,\n    keys: (typeof keys !== \"undefined\") ? keys : null,\n    authorization: (typeof authorization !== \"undefined\") ? authorization : null,\n    sign: (typeof sign !== \"undefined\") ? sign : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    hmacSha1: (typeof hmacSha1 !== \"undefined\") ? hmacSha1 : null,\n    stringToSign: (typeof stringToSign !== \"undefined\") ? stringToSign : null,\n    signQuery: (typeof signQuery !== \"undefined\") ? signQuery : null,\n    queryStringToSign: (typeof queryStringToSign !== \"undefined\") ? queryStringToSign : null,\n    canonicalizeHeaders: (typeof canonicalizeHeaders !== \"undefined\") ? canonicalizeHeaders : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    canonicalizeResource: (typeof canonicalizeResource !== \"undefined\") ? canonicalizeResource : null,\n    encodeURIComponent: (typeof encodeURIComponent !== \"undefined\") ? encodeURIComponent : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "crypto": {
                  "where": "inline"
                },
                "url": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/index.js": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/index.js",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/http-signature/lib/index.js",
              "mtime": 1358971386,
              "code": "// Copyright 2011 Joyent, Inc.  All rights reserved.\n\nvar parser = require('./parser');\nvar signer = require('./signer');\nvar verify = require('./verify');\nvar util = require('./util');\n\n\n\n///--- API\n\nmodule.exports = {\n\n  parse: parser.parseRequest,\n  parseRequest: parser.parseRequest,\n\n  sign: signer.signRequest,\n  signRequest: signer.signRequest,\n\n  sshKeyToPEM: util.sshKeyToPEM,\n  sshKeyFingerprint: util.fingerprint,\n\n  verify: verify.verifySignature,\n  verifySignature: verify.verifySignature\n};\n",
              "globals": {
                "parser": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "signer": {
                  "type": "assign"
                },
                "verify": {
                  "type": "assign"
                },
                "util": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./parser": {
                    "where": "inline"
                  },
                  "./signer": {
                    "where": "inline"
                  },
                  "./verify": {
                    "where": "inline"
                  },
                  "./util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';\n// Copyright 2011 Joyent, Inc.  All rights reserved.\n\nvar parser = require('./parser');\nvar signer = require('./signer');\nvar verify = require('./verify');\nvar util = require('./util');\n\n\n\n///--- API\n\nmodule.exports = {\n\n  parse: parser.parseRequest,\n  parseRequest: parser.parseRequest,\n\n  sign: signer.signRequest,\n  signRequest: signer.signRequest,\n\n  sshKeyToPEM: util.sshKeyToPEM,\n  sshKeyFingerprint: util.fingerprint,\n\n  verify: verify.verifySignature,\n  verifySignature: verify.verifySignature\n};\n\nreturn {\n    parser: (typeof parser !== \"undefined\") ? parser : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    signer: (typeof signer !== \"undefined\") ? signer : null,\n    verify: (typeof verify !== \"undefined\") ? verify : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    parser: (typeof parser !== \"undefined\") ? parser : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    signer: (typeof signer !== \"undefined\") ? signer : null,\n    verify: (typeof verify !== \"undefined\") ? verify : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./parser": {
                  "where": "inline"
                },
                "./signer": {
                  "where": "inline"
                },
                "./verify": {
                  "where": "inline"
                },
                "./util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/parser.js": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/parser",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/parser.js",
            "descriptor": {
              "filename": "parser.js",
              "filepath": "node_modules/request/node_modules/http-signature/lib/parser.js",
              "mtime": 1360599652,
              "code": "// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar util = require('util');\n\n\n\n///--- Globals\n\nvar Algorithms = {\n  'rsa-sha1': true,\n  'rsa-sha256': true,\n  'rsa-sha512': true,\n  'dsa-sha1': true,\n  'hmac-sha1': true,\n  'hmac-sha256': true,\n  'hmac-sha512': true\n};\n\nvar State = {\n  New: 0,\n  Params: 1,\n  Signature: 2\n};\n\nvar ParamsState = {\n  Name: 0,\n  Value: 1\n};\n\n\n\n///--- Specific Errors\n\nfunction HttpSignatureError(message, caller) {\n  if (Error.captureStackTrace)\n    Error.captureStackTrace(this, caller || HttpSignatureError);\n\n  this.message = message;\n  this.name = caller.name;\n}\nutil.inherits(HttpSignatureError, Error);\n\nfunction ExpiredRequestError(message) {\n  HttpSignatureError.call(this, message, ExpiredRequestError);\n}\nutil.inherits(ExpiredRequestError, HttpSignatureError);\n\n\nfunction InvalidHeaderError(message) {\n  HttpSignatureError.call(this, message, InvalidHeaderError);\n}\nutil.inherits(InvalidHeaderError, HttpSignatureError);\n\n\nfunction InvalidParamsError(message) {\n  HttpSignatureError.call(this, message, InvalidParamsError);\n}\nutil.inherits(InvalidParamsError, HttpSignatureError);\n\n\nfunction MissingHeaderError(message) {\n  HttpSignatureError.call(this, message, MissingHeaderError);\n}\nutil.inherits(MissingHeaderError, HttpSignatureError);\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Parses the 'Authorization' header out of an http.ServerRequest object.\n   *\n   * Note that this API will fully validate the Authorization header, and throw\n   * on any error.  It will not however check the signature, or the keyId format\n   * as those are specific to your environment.  You can use the options object\n   * to pass in extra constraints.\n   *\n   * As a response object you can expect this:\n   *\n   *     {\n   *       \"scheme\": \"Signature\",\n   *       \"params\": {\n   *         \"keyId\": \"foo\",\n   *         \"algorithm\": \"rsa-sha256\",\n   *         \"headers\": [\n   *           \"date\" or \"x-date\",\n   *           \"content-md5\"\n   *         ]\n   *       },\n   *       \"signature\": \"base64\",\n   *       \"signingString\": \"ready to be passed to crypto.verify()\"\n   *     }\n   *\n   * @param {Object} request an http.ServerRequest.\n   * @param {Object} options an optional options object with:\n   *                   - clockSkew: allowed clock skew in seconds (default 300).\n   *                   - headers: required header names (def: date or x-date)\n   *                   - algorithms: algorithms to support (default: all).\n   * @return {Object} parsed out object (see above).\n   * @throws {TypeError} on invalid input.\n   * @throws {InvalidHeaderError} on an invalid Authorization header error.\n   * @throws {InvalidParamsError} if the params in the scheme are invalid.\n   * @throws {MissingHeaderError} if the params indicate a header not present,\n   *                              either in the request headers from the params,\n   *                              or not in the params from a required header\n   *                              in options.\n   * @throws {ExpiredRequestError} if the value of date or x-date exceeds skew.\n   */\n  parseRequest: function parseRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(request.headers, 'request.headers');\n    if (options === undefined) {\n      options = {};\n    }\n    if (options.headers === undefined) {\n      options.headers = [request.headers['x-date'] ? 'x-date' : 'date'];\n    }\n    assert.object(options, 'options');\n    assert.arrayOfString(options.headers, 'options.headers');\n    assert.optionalNumber(options.clockSkew, 'options.clockSkew');\n\n    if (!request.headers.authorization)\n      throw new MissingHeaderError('no authorization header present in ' +\n                                   'the request');\n\n    options.clockSkew = options.clockSkew || 300;\n\n\n    var i = 0;\n    var state = State.New;\n    var substate = ParamsState.Name;\n    var tmpName = '';\n    var tmpValue = '';\n\n    var parsed = {\n      scheme: '',\n      params: {},\n      signature: '',\n      signingString: '',\n\n      get algorithm() {\n        return this.params.algorithm.toUpperCase();\n      },\n\n      get keyId() {\n        return this.params.keyId;\n      }\n\n    };\n\n    var authz = request.headers.authorization;\n    for (i = 0; i < authz.length; i++) {\n      var c = authz.charAt(i);\n\n      switch (Number(state)) {\n\n      case State.New:\n        if (c !== ' ') parsed.scheme += c;\n        else state = State.Params;\n        break;\n\n      case State.Params:\n        switch (Number(substate)) {\n\n        case ParamsState.Name:\n          if (c === '\"') {\n            parsed.params[tmpName] = '';\n            tmpValue = '';\n            substate = ParamsState.Value;\n          } else if (c === ' ') {\n            state = State.Signature;\n          } else if (c !== '=' && c !== ',') {\n            tmpName += c;\n          }\n          break;\n\n        case ParamsState.Value:\n          if (c === '\"') {\n            parsed.params[tmpName] = tmpValue;\n            tmpName = '';\n            substate = ParamsState.Name;\n          } else {\n            tmpValue += c;\n          }\n          break;\n\n        default:\n          throw new Error('Invalid substate');\n        }\n        break;\n\n\n      case State.Signature:\n        parsed.signature += c;\n        break;\n\n      default:\n        throw new Error('Invalid substate');\n      }\n\n    }\n\n    if (!parsed.params.headers || parsed.params.headers === '') {\n      if (request.headers['x-date']) {\n        parsed.params.headers = ['x-date'];\n      } else {\n        parsed.params.headers = ['date'];\n      }\n    } else {\n      parsed.params.headers = parsed.params.headers.split(' ');\n    }\n\n    // Minimally validate the parsed object\n    if (!parsed.scheme || parsed.scheme !== 'Signature')\n      throw new InvalidHeaderError('scheme was not \"Signature\"');\n\n    if (!parsed.params.keyId)\n      throw new InvalidHeaderError('keyId was not specified');\n\n    if (!parsed.params.algorithm)\n      throw new InvalidHeaderError('algorithm was not specified');\n\n    if (!parsed.signature)\n      throw new InvalidHeaderError('signature was empty');\n\n    // Check the algorithm against the official list\n    parsed.params.algorithm = parsed.params.algorithm.toLowerCase();\n    if (!Algorithms[parsed.params.algorithm])\n      throw new InvalidParamsError(parsed.params.algorithm +\n                                   ' is not supported');\n\n    // Build the signingString\n    for (i = 0; i < parsed.params.headers.length; i++) {\n      var h = parsed.params.headers[i].toLowerCase();\n      parsed.params.headers[i] = h;\n\n      var value;\n      if (h !== 'request-line') {\n        value = request.headers[h];\n        if (!value)\n          throw new MissingHeaderError(h + ' was not in the request');\n      } else {\n        value =\n          request.method + ' ' + request.url + ' HTTP/' + request.httpVersion;\n      }\n\n      parsed.signingString += value;\n      if ((i + 1) < parsed.params.headers.length)\n        parsed.signingString += '\\n';\n    }\n\n    // Check against the constraints\n    var date;\n    if (request.headers.date || request.headers['x-date']) {\n        if (request.headers['x-date']) {\n          date = new Date(request.headers['x-date']);\n        } else {\n          date = new Date(request.headers.date);\n        }\n      var now = new Date();\n      var skew = Math.abs(now.getTime() - date.getTime());\n\n      if (skew > options.clockSkew * 1000) {\n        throw new ExpiredRequestError('clock skew of ' +\n                                      (skew / 1000) +\n                                      's was greater than ' +\n                                      options.clockSkew + 's');\n      }\n    }\n\n    options.headers.forEach(function (hdr) {\n      // Remember that we already checked any headers in the params\n      // were in the request, so if this passes we're good.\n      if (parsed.params.headers.indexOf(hdr) < 0)\n        throw new MissingHeaderError(hdr + ' was not a signed header');\n    });\n\n    if (options.algorithms) {\n      if (options.algorithms.indexOf(parsed.params.algorithm) === -1)\n        throw new InvalidParamsError(parsed.params.algorithm +\n                                     ' is not a supported algorithm');\n    }\n\n    return parsed;\n  }\n\n};\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "util": {
                  "type": "assign"
                },
                "Algorithms": {
                  "type": "assign"
                },
                "State": {
                  "type": "assign"
                },
                "ParamsState": {
                  "type": "assign"
                },
                "HttpSignatureError": {
                  "type": "assign"
                },
                "Error": {
                  "type": "reference"
                },
                "ExpiredRequestError": {
                  "type": "assign"
                },
                "InvalidHeaderError": {
                  "type": "assign"
                },
                "InvalidParamsError": {
                  "type": "assign"
                },
                "MissingHeaderError": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "Number": {
                  "type": "call"
                },
                "Math": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert-plus": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';\n// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar util = require('__SYSTEM__/util');\n\n\n\n///--- Globals\n\nvar Algorithms = {\n  'rsa-sha1': true,\n  'rsa-sha256': true,\n  'rsa-sha512': true,\n  'dsa-sha1': true,\n  'hmac-sha1': true,\n  'hmac-sha256': true,\n  'hmac-sha512': true\n};\n\nvar State = {\n  New: 0,\n  Params: 1,\n  Signature: 2\n};\n\nvar ParamsState = {\n  Name: 0,\n  Value: 1\n};\n\n\n\n///--- Specific Errors\n\nfunction HttpSignatureError(message, caller) {\n  if (Error.captureStackTrace)\n    Error.captureStackTrace(this, caller || HttpSignatureError);\n\n  this.message = message;\n  this.name = caller.name;\n}\nutil.inherits(HttpSignatureError, Error);\n\nfunction ExpiredRequestError(message) {\n  HttpSignatureError.call(this, message, ExpiredRequestError);\n}\nutil.inherits(ExpiredRequestError, HttpSignatureError);\n\n\nfunction InvalidHeaderError(message) {\n  HttpSignatureError.call(this, message, InvalidHeaderError);\n}\nutil.inherits(InvalidHeaderError, HttpSignatureError);\n\n\nfunction InvalidParamsError(message) {\n  HttpSignatureError.call(this, message, InvalidParamsError);\n}\nutil.inherits(InvalidParamsError, HttpSignatureError);\n\n\nfunction MissingHeaderError(message) {\n  HttpSignatureError.call(this, message, MissingHeaderError);\n}\nutil.inherits(MissingHeaderError, HttpSignatureError);\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Parses the 'Authorization' header out of an http.ServerRequest object.\n   *\n   * Note that this API will fully validate the Authorization header, and throw\n   * on any error.  It will not however check the signature, or the keyId format\n   * as those are specific to your environment.  You can use the options object\n   * to pass in extra constraints.\n   *\n   * As a response object you can expect this:\n   *\n   *     {\n   *       \"scheme\": \"Signature\",\n   *       \"params\": {\n   *         \"keyId\": \"foo\",\n   *         \"algorithm\": \"rsa-sha256\",\n   *         \"headers\": [\n   *           \"date\" or \"x-date\",\n   *           \"content-md5\"\n   *         ]\n   *       },\n   *       \"signature\": \"base64\",\n   *       \"signingString\": \"ready to be passed to crypto.verify()\"\n   *     }\n   *\n   * @param {Object} request an http.ServerRequest.\n   * @param {Object} options an optional options object with:\n   *                   - clockSkew: allowed clock skew in seconds (default 300).\n   *                   - headers: required header names (def: date or x-date)\n   *                   - algorithms: algorithms to support (default: all).\n   * @return {Object} parsed out object (see above).\n   * @throws {TypeError} on invalid input.\n   * @throws {InvalidHeaderError} on an invalid Authorization header error.\n   * @throws {InvalidParamsError} if the params in the scheme are invalid.\n   * @throws {MissingHeaderError} if the params indicate a header not present,\n   *                              either in the request headers from the params,\n   *                              or not in the params from a required header\n   *                              in options.\n   * @throws {ExpiredRequestError} if the value of date or x-date exceeds skew.\n   */\n  parseRequest: function parseRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(request.headers, 'request.headers');\n    if (options === undefined) {\n      options = {};\n    }\n    if (options.headers === undefined) {\n      options.headers = [request.headers['x-date'] ? 'x-date' : 'date'];\n    }\n    assert.object(options, 'options');\n    assert.arrayOfString(options.headers, 'options.headers');\n    assert.optionalNumber(options.clockSkew, 'options.clockSkew');\n\n    if (!request.headers.authorization)\n      throw new MissingHeaderError('no authorization header present in ' +\n                                   'the request');\n\n    options.clockSkew = options.clockSkew || 300;\n\n\n    var i = 0;\n    var state = State.New;\n    var substate = ParamsState.Name;\n    var tmpName = '';\n    var tmpValue = '';\n\n    var parsed = {\n      scheme: '',\n      params: {},\n      signature: '',\n      signingString: '',\n\n      get algorithm() {\n        return this.params.algorithm.toUpperCase();\n      },\n\n      get keyId() {\n        return this.params.keyId;\n      }\n\n    };\n\n    var authz = request.headers.authorization;\n    for (i = 0; i < authz.length; i++) {\n      var c = authz.charAt(i);\n\n      switch (Number(state)) {\n\n      case State.New:\n        if (c !== ' ') parsed.scheme += c;\n        else state = State.Params;\n        break;\n\n      case State.Params:\n        switch (Number(substate)) {\n\n        case ParamsState.Name:\n          if (c === '\"') {\n            parsed.params[tmpName] = '';\n            tmpValue = '';\n            substate = ParamsState.Value;\n          } else if (c === ' ') {\n            state = State.Signature;\n          } else if (c !== '=' && c !== ',') {\n            tmpName += c;\n          }\n          break;\n\n        case ParamsState.Value:\n          if (c === '\"') {\n            parsed.params[tmpName] = tmpValue;\n            tmpName = '';\n            substate = ParamsState.Name;\n          } else {\n            tmpValue += c;\n          }\n          break;\n\n        default:\n          throw new Error('Invalid substate');\n        }\n        break;\n\n\n      case State.Signature:\n        parsed.signature += c;\n        break;\n\n      default:\n        throw new Error('Invalid substate');\n      }\n\n    }\n\n    if (!parsed.params.headers || parsed.params.headers === '') {\n      if (request.headers['x-date']) {\n        parsed.params.headers = ['x-date'];\n      } else {\n        parsed.params.headers = ['date'];\n      }\n    } else {\n      parsed.params.headers = parsed.params.headers.split(' ');\n    }\n\n    // Minimally validate the parsed object\n    if (!parsed.scheme || parsed.scheme !== 'Signature')\n      throw new InvalidHeaderError('scheme was not \"Signature\"');\n\n    if (!parsed.params.keyId)\n      throw new InvalidHeaderError('keyId was not specified');\n\n    if (!parsed.params.algorithm)\n      throw new InvalidHeaderError('algorithm was not specified');\n\n    if (!parsed.signature)\n      throw new InvalidHeaderError('signature was empty');\n\n    // Check the algorithm against the official list\n    parsed.params.algorithm = parsed.params.algorithm.toLowerCase();\n    if (!Algorithms[parsed.params.algorithm])\n      throw new InvalidParamsError(parsed.params.algorithm +\n                                   ' is not supported');\n\n    // Build the signingString\n    for (i = 0; i < parsed.params.headers.length; i++) {\n      var h = parsed.params.headers[i].toLowerCase();\n      parsed.params.headers[i] = h;\n\n      var value;\n      if (h !== 'request-line') {\n        value = request.headers[h];\n        if (!value)\n          throw new MissingHeaderError(h + ' was not in the request');\n      } else {\n        value =\n          request.method + ' ' + request.url + ' HTTP/' + request.httpVersion;\n      }\n\n      parsed.signingString += value;\n      if ((i + 1) < parsed.params.headers.length)\n        parsed.signingString += '\\n';\n    }\n\n    // Check against the constraints\n    var date;\n    if (request.headers.date || request.headers['x-date']) {\n        if (request.headers['x-date']) {\n          date = new Date(request.headers['x-date']);\n        } else {\n          date = new Date(request.headers.date);\n        }\n      var now = new Date();\n      var skew = Math.abs(now.getTime() - date.getTime());\n\n      if (skew > options.clockSkew * 1000) {\n        throw new ExpiredRequestError('clock skew of ' +\n                                      (skew / 1000) +\n                                      's was greater than ' +\n                                      options.clockSkew + 's');\n      }\n    }\n\n    options.headers.forEach(function (hdr) {\n      // Remember that we already checked any headers in the params\n      // were in the request, so if this passes we're good.\n      if (parsed.params.headers.indexOf(hdr) < 0)\n        throw new MissingHeaderError(hdr + ' was not a signed header');\n    });\n\n    if (options.algorithms) {\n      if (options.algorithms.indexOf(parsed.params.algorithm) === -1)\n        throw new InvalidParamsError(parsed.params.algorithm +\n                                     ' is not a supported algorithm');\n    }\n\n    return parsed;\n  }\n\n};\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    Algorithms: (typeof Algorithms !== \"undefined\") ? Algorithms : null,\n    State: (typeof State !== \"undefined\") ? State : null,\n    ParamsState: (typeof ParamsState !== \"undefined\") ? ParamsState : null,\n    HttpSignatureError: (typeof HttpSignatureError !== \"undefined\") ? HttpSignatureError : null,\n    Error: (typeof Error !== \"undefined\") ? Error : null,\n    ExpiredRequestError: (typeof ExpiredRequestError !== \"undefined\") ? ExpiredRequestError : null,\n    InvalidHeaderError: (typeof InvalidHeaderError !== \"undefined\") ? InvalidHeaderError : null,\n    InvalidParamsError: (typeof InvalidParamsError !== \"undefined\") ? InvalidParamsError : null,\n    MissingHeaderError: (typeof MissingHeaderError !== \"undefined\") ? MissingHeaderError : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    Number: (typeof Number !== \"undefined\") ? Number : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    Algorithms: (typeof Algorithms !== \"undefined\") ? Algorithms : null,\n    State: (typeof State !== \"undefined\") ? State : null,\n    ParamsState: (typeof ParamsState !== \"undefined\") ? ParamsState : null,\n    HttpSignatureError: (typeof HttpSignatureError !== \"undefined\") ? HttpSignatureError : null,\n    Error: (typeof Error !== \"undefined\") ? Error : null,\n    ExpiredRequestError: (typeof ExpiredRequestError !== \"undefined\") ? ExpiredRequestError : null,\n    InvalidHeaderError: (typeof InvalidHeaderError !== \"undefined\") ? InvalidHeaderError : null,\n    InvalidParamsError: (typeof InvalidParamsError !== \"undefined\") ? InvalidParamsError : null,\n    MissingHeaderError: (typeof MissingHeaderError !== \"undefined\") ? MissingHeaderError : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    Number: (typeof Number !== \"undefined\") ? Number : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert-plus": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/assert.js": {
            "requireId": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/assert.js",
            "memoizeId": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/assert.js",
            "descriptor": {
              "filename": "assert.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/assert-plus/assert.js",
              "mtime": 1348004643,
              "code": "// Copyright (c) 2012, Mark Cavage. All rights reserved.\n\nvar assert = require('assert');\nvar Stream = require('stream').Stream;\nvar util = require('util');\n\n\n\n///--- Globals\n\nvar NDEBUG = process.env.NODE_NDEBUG || false;\n\n\n\n///--- Messages\n\nvar ARRAY_TYPE_REQUIRED = '%s ([%s]) required';\nvar TYPE_REQUIRED = '%s (%s) is required';\n\n\n\n///--- Internal\n\nfunction capitalize(str) {\n        return (str.charAt(0).toUpperCase() + str.slice(1));\n}\n\nfunction uncapitalize(str) {\n        return (str.charAt(0).toLowerCase() + str.slice(1));\n}\n\nfunction _() {\n        return (util.format.apply(util, arguments));\n}\n\n\nfunction _assert(arg, type, name, stackFunc) {\n        if (!NDEBUG) {\n                name = name || type;\n                stackFunc = stackFunc || _assert.caller;\n                var t = typeof (arg);\n\n                if (t !== type) {\n                        throw new assert.AssertionError({\n                                message: _(TYPE_REQUIRED, name, type),\n                                actual: t,\n                                expected: type,\n                                operator: '===',\n                                stackStartFunction: stackFunc\n                        });\n                }\n        }\n}\n\n\n\n///--- API\n\nfunction array(arr, type, name) {\n        if (!NDEBUG) {\n                name = name || type;\n\n                if (!Array.isArray(arr)) {\n                        throw new assert.AssertionError({\n                                message: _(ARRAY_TYPE_REQUIRED, name, type),\n                                actual: typeof (arr),\n                                expected: 'array',\n                                operator: 'Array.isArray',\n                                stackStartFunction: array.caller\n                        });\n                }\n\n                for (var i = 0; i < arr.length; i++) {\n                        _assert(arr[i], type, name, array);\n                }\n        }\n}\n\n\nfunction bool(arg, name) {\n        _assert(arg, 'boolean', name, bool);\n}\n\n\nfunction buffer(arg, name) {\n        if (!Buffer.isBuffer(arg)) {\n                throw new assert.AssertionError({\n                        message: _(TYPE_REQUIRED, name, type),\n                        actual: typeof (arg),\n                        expected: 'buffer',\n                        operator: 'Buffer.isBuffer',\n                        stackStartFunction: buffer\n                });\n        }\n}\n\n\nfunction func(arg, name) {\n        _assert(arg, 'function', name);\n}\n\n\nfunction number(arg, name) {\n        _assert(arg, 'number', name);\n}\n\n\nfunction object(arg, name) {\n        _assert(arg, 'object', name);\n}\n\n\nfunction stream(arg, name) {\n        if (!(arg instanceof Stream)) {\n                throw new assert.AssertionError({\n                        message: _(TYPE_REQUIRED, name, type),\n                        actual: typeof (arg),\n                        expected: 'Stream',\n                        operator: 'instanceof',\n                        stackStartFunction: buffer\n                });\n        }\n}\n\n\nfunction string(arg, name) {\n        _assert(arg, 'string', name);\n}\n\n\n\n///--- Exports\n\nmodule.exports = {\n        bool: bool,\n        buffer: buffer,\n        func: func,\n        number: number,\n        object: object,\n        stream: stream,\n        string: string\n};\n\n\nObject.keys(module.exports).forEach(function (k) {\n        if (k === 'buffer')\n                return;\n\n        var name = 'arrayOf' + capitalize(k);\n\n        if (k === 'bool')\n                k = 'boolean';\n        if (k === 'func')\n                k = 'function';\n        module.exports[name] = function (arg, name) {\n                array(arg, k, name);\n        };\n});\n\nObject.keys(module.exports).forEach(function (k) {\n        var _name = 'optional' + capitalize(k);\n        var s = uncapitalize(k.replace('arrayOf', ''));\n        if (s === 'bool')\n                s = 'boolean';\n        if (s === 'func')\n                s = 'function';\n\n        if (k.indexOf('arrayOf') !== -1) {\n          module.exports[_name] = function (arg, name) {\n                  if (!NDEBUG && arg !== undefined) {\n                          array(arg, s, name);\n                  }\n          };\n        } else {\n          module.exports[_name] = function (arg, name) {\n                  if (!NDEBUG && arg !== undefined) {\n                          _assert(arg, s, name);\n                  }\n          };\n        }\n});\n\n\n// Reexport built-in assertions\nObject.keys(assert).forEach(function (k) {\n        if (k === 'AssertionError') {\n                module.exports[k] = assert[k];\n                return;\n        }\n\n        module.exports[k] = function () {\n                if (!NDEBUG) {\n                        assert[k].apply(assert[k], arguments);\n                }\n        };\n});\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Stream": {
                  "type": "assign"
                },
                "util": {
                  "type": "assign"
                },
                "NDEBUG": {
                  "type": "assign"
                },
                "process": {
                  "type": "reference"
                },
                "ARRAY_TYPE_REQUIRED": {
                  "type": "assign"
                },
                "TYPE_REQUIRED": {
                  "type": "assign"
                },
                "capitalize": {
                  "type": "assign"
                },
                "uncapitalize": {
                  "type": "assign"
                },
                "_": {
                  "type": "assign"
                },
                "_assert": {
                  "type": "assign"
                },
                "array": {
                  "type": "assign"
                },
                "Array": {
                  "type": "reference"
                },
                "bool": {
                  "type": "assign"
                },
                "buffer": {
                  "type": "assign"
                },
                "Buffer": {
                  "type": "reference"
                },
                "func": {
                  "type": "assign"
                },
                "number": {
                  "type": "assign"
                },
                "object": {
                  "type": "assign"
                },
                "stream": {
                  "type": "assign"
                },
                "string": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "Object": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  },
                  "stream": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/assert-plus';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/assert-plus';\n// Copyright (c) 2012, Mark Cavage. All rights reserved.\n\nvar assert = require('__SYSTEM__/assert');\nvar Stream = require('__SYSTEM__/stream').Stream;\nvar util = require('__SYSTEM__/util');\n\n\n\n///--- Globals\n\nvar NDEBUG = process.env.NODE_NDEBUG || false;\n\n\n\n///--- Messages\n\nvar ARRAY_TYPE_REQUIRED = '%s ([%s]) required';\nvar TYPE_REQUIRED = '%s (%s) is required';\n\n\n\n///--- Internal\n\nfunction capitalize(str) {\n        return (str.charAt(0).toUpperCase() + str.slice(1));\n}\n\nfunction uncapitalize(str) {\n        return (str.charAt(0).toLowerCase() + str.slice(1));\n}\n\nfunction _() {\n        return (util.format.apply(util, arguments));\n}\n\n\nfunction _assert(arg, type, name, stackFunc) {\n        if (!NDEBUG) {\n                name = name || type;\n                stackFunc = stackFunc || _assert.caller;\n                var t = typeof (arg);\n\n                if (t !== type) {\n                        throw new assert.AssertionError({\n                                message: _(TYPE_REQUIRED, name, type),\n                                actual: t,\n                                expected: type,\n                                operator: '===',\n                                stackStartFunction: stackFunc\n                        });\n                }\n        }\n}\n\n\n\n///--- API\n\nfunction array(arr, type, name) {\n        if (!NDEBUG) {\n                name = name || type;\n\n                if (!Array.isArray(arr)) {\n                        throw new assert.AssertionError({\n                                message: _(ARRAY_TYPE_REQUIRED, name, type),\n                                actual: typeof (arr),\n                                expected: 'array',\n                                operator: 'Array.isArray',\n                                stackStartFunction: array.caller\n                        });\n                }\n\n                for (var i = 0; i < arr.length; i++) {\n                        _assert(arr[i], type, name, array);\n                }\n        }\n}\n\n\nfunction bool(arg, name) {\n        _assert(arg, 'boolean', name, bool);\n}\n\n\nfunction buffer(arg, name) {\n        if (!Buffer.isBuffer(arg)) {\n                throw new assert.AssertionError({\n                        message: _(TYPE_REQUIRED, name, type),\n                        actual: typeof (arg),\n                        expected: 'buffer',\n                        operator: 'Buffer.isBuffer',\n                        stackStartFunction: buffer\n                });\n        }\n}\n\n\nfunction func(arg, name) {\n        _assert(arg, 'function', name);\n}\n\n\nfunction number(arg, name) {\n        _assert(arg, 'number', name);\n}\n\n\nfunction object(arg, name) {\n        _assert(arg, 'object', name);\n}\n\n\nfunction stream(arg, name) {\n        if (!(arg instanceof Stream)) {\n                throw new assert.AssertionError({\n                        message: _(TYPE_REQUIRED, name, type),\n                        actual: typeof (arg),\n                        expected: 'Stream',\n                        operator: 'instanceof',\n                        stackStartFunction: buffer\n                });\n        }\n}\n\n\nfunction string(arg, name) {\n        _assert(arg, 'string', name);\n}\n\n\n\n///--- Exports\n\nmodule.exports = {\n        bool: bool,\n        buffer: buffer,\n        func: func,\n        number: number,\n        object: object,\n        stream: stream,\n        string: string\n};\n\n\nObject.keys(module.exports).forEach(function (k) {\n        if (k === 'buffer')\n                return;\n\n        var name = 'arrayOf' + capitalize(k);\n\n        if (k === 'bool')\n                k = 'boolean';\n        if (k === 'func')\n                k = 'function';\n        module.exports[name] = function (arg, name) {\n                array(arg, k, name);\n        };\n});\n\nObject.keys(module.exports).forEach(function (k) {\n        var _name = 'optional' + capitalize(k);\n        var s = uncapitalize(k.replace('arrayOf', ''));\n        if (s === 'bool')\n                s = 'boolean';\n        if (s === 'func')\n                s = 'function';\n\n        if (k.indexOf('arrayOf') !== -1) {\n          module.exports[_name] = function (arg, name) {\n                  if (!NDEBUG && arg !== undefined) {\n                          array(arg, s, name);\n                  }\n          };\n        } else {\n          module.exports[_name] = function (arg, name) {\n                  if (!NDEBUG && arg !== undefined) {\n                          _assert(arg, s, name);\n                  }\n          };\n        }\n});\n\n\n// Reexport built-in assertions\nObject.keys(assert).forEach(function (k) {\n        if (k === 'AssertionError') {\n                module.exports[k] = assert[k];\n                return;\n        }\n\n        module.exports[k] = function () {\n                if (!NDEBUG) {\n                        assert[k].apply(assert[k], arguments);\n                }\n        };\n});\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    NDEBUG: (typeof NDEBUG !== \"undefined\") ? NDEBUG : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    ARRAY_TYPE_REQUIRED: (typeof ARRAY_TYPE_REQUIRED !== \"undefined\") ? ARRAY_TYPE_REQUIRED : null,\n    TYPE_REQUIRED: (typeof TYPE_REQUIRED !== \"undefined\") ? TYPE_REQUIRED : null,\n    capitalize: (typeof capitalize !== \"undefined\") ? capitalize : null,\n    uncapitalize: (typeof uncapitalize !== \"undefined\") ? uncapitalize : null,\n    _: (typeof _ !== \"undefined\") ? _ : null,\n    _assert: (typeof _assert !== \"undefined\") ? _assert : null,\n    array: (typeof array !== \"undefined\") ? array : null,\n    Array: (typeof Array !== \"undefined\") ? Array : null,\n    bool: (typeof bool !== \"undefined\") ? bool : null,\n    buffer: (typeof buffer !== \"undefined\") ? buffer : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    func: (typeof func !== \"undefined\") ? func : null,\n    number: (typeof number !== \"undefined\") ? number : null,\n    object: (typeof object !== \"undefined\") ? object : null,\n    stream: (typeof stream !== \"undefined\") ? stream : null,\n    string: (typeof string !== \"undefined\") ? string : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    NDEBUG: (typeof NDEBUG !== \"undefined\") ? NDEBUG : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    ARRAY_TYPE_REQUIRED: (typeof ARRAY_TYPE_REQUIRED !== \"undefined\") ? ARRAY_TYPE_REQUIRED : null,\n    TYPE_REQUIRED: (typeof TYPE_REQUIRED !== \"undefined\") ? TYPE_REQUIRED : null,\n    capitalize: (typeof capitalize !== \"undefined\") ? capitalize : null,\n    uncapitalize: (typeof uncapitalize !== \"undefined\") ? uncapitalize : null,\n    _: (typeof _ !== \"undefined\") ? _ : null,\n    _assert: (typeof _assert !== \"undefined\") ? _assert : null,\n    array: (typeof array !== \"undefined\") ? array : null,\n    Array: (typeof Array !== \"undefined\") ? Array : null,\n    bool: (typeof bool !== \"undefined\") ? bool : null,\n    buffer: (typeof buffer !== \"undefined\") ? buffer : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    func: (typeof func !== \"undefined\") ? func : null,\n    number: (typeof number !== \"undefined\") ? number : null,\n    object: (typeof object !== \"undefined\") ? object : null,\n    stream: (typeof stream !== \"undefined\") ? stream : null,\n    string: (typeof string !== \"undefined\") ? string : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                },
                "stream": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/signer.js": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/signer",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/signer.js",
            "descriptor": {
              "filename": "signer.js",
              "filepath": "node_modules/request/node_modules/http-signature/lib/signer.js",
              "mtime": 1358971386,
              "code": "// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\nvar http = require('http');\n\nvar sprintf = require('util').format;\n\n\n\n///--- Globals\n\nvar Algorithms = {\n  'rsa-sha1': true,\n  'rsa-sha256': true,\n  'rsa-sha512': true,\n  'dsa-sha1': true,\n  'hmac-sha1': true,\n  'hmac-sha256': true,\n  'hmac-sha512': true\n};\n\nvar Authorization = 'Signature keyId=\"%s\",algorithm=\"%s\",headers=\"%s\" %s';\n\n\n\n///--- Specific Errors\n\nfunction MissingHeaderError(message) {\n    this.name = 'MissingHeaderError';\n    this.message = message;\n    this.stack = (new Error()).stack;\n}\nMissingHeaderError.prototype = new Error();\n\n\nfunction InvalidAlgorithmError(message) {\n    this.name = 'InvalidAlgorithmError';\n    this.message = message;\n    this.stack = (new Error()).stack;\n}\nInvalidAlgorithmError.prototype = new Error();\n\n\n\n///--- Internal Functions\n\nfunction _pad(val) {\n  if (parseInt(val, 10) < 10) {\n    val = '0' + val;\n  }\n  return val;\n}\n\n\nfunction _rfc1123() {\n  var date = new Date();\n\n  var months = ['Jan',\n                'Feb',\n                'Mar',\n                'Apr',\n                'May',\n                'Jun',\n                'Jul',\n                'Aug',\n                'Sep',\n                'Oct',\n                'Nov',\n                'Dec'];\n  var days = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'];\n  return days[date.getUTCDay()] + ', ' +\n    _pad(date.getUTCDate()) + ' ' +\n    months[date.getUTCMonth()] + ' ' +\n    date.getUTCFullYear() + ' ' +\n    _pad(date.getUTCHours()) + ':' +\n    _pad(date.getUTCMinutes()) + ':' +\n    _pad(date.getUTCSeconds()) +\n    ' GMT';\n}\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Adds an 'Authorization' header to an http.ClientRequest object.\n   *\n   * Note that this API will add a Date header if it's not already set. Any\n   * other headers in the options.headers array MUST be present, or this\n   * will throw.\n   *\n   * You shouldn't need to check the return type; it's just there if you want\n   * to be pedantic.\n   *\n   * @param {Object} request an instance of http.ClientRequest.\n   * @param {Object} options signing parameters object:\n   *                   - {String} keyId required.\n   *                   - {String} key required (either a PEM or HMAC key).\n   *                   - {Array} headers optional; defaults to ['date'].\n   *                   - {String} algorithm optional; defaults to 'rsa-sha256'.\n   * @return {Boolean} true if Authorization (and optionally Date) were added.\n   * @throws {TypeError} on bad parameter types (input).\n   * @throws {InvalidAlgorithmError} if algorithm was bad.\n   * @throws {MissingHeaderError} if a header to be signed was specified but\n   *                              was not present.\n   */\n  signRequest: function signRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(options, 'options');\n    assert.optionalString(options.algorithm, 'options.algorithm');\n    assert.string(options.keyId, 'options.keyId');\n    assert.optionalArrayOfString(options.headers, 'options.headers');\n\n    if (!request.getHeader('Date'))\n      request.setHeader('Date', _rfc1123());\n    if (!options.headers)\n      options.headers = ['date'];\n    if (!options.algorithm)\n      options.algorithm = 'rsa-sha256';\n\n    options.algorithm = options.algorithm.toLowerCase();\n\n    if (!Algorithms[options.algorithm])\n      throw new InvalidAlgorithmError(options.algorithm + ' is not supported');\n\n    var i;\n    var stringToSign = '';\n    for (i = 0; i < options.headers.length; i++) {\n      if (typeof (options.headers[i]) !== 'string')\n        throw new TypeError('options.headers must be an array of Strings');\n\n      var h = options.headers[i].toLowerCase();\n      request.getHeader(h);\n\n      var value = request.getHeader(h);\n      if (!value) {\n        if (h === 'request-line') {\n          value = request.method + ' ' + request.path + ' HTTP/1.1';\n        } else {\n          throw new MissingHeaderError(h + ' was not in the request');\n        }\n      }\n\n      stringToSign += value;\n      if ((i + 1) < options.headers.length)\n        stringToSign += '\\n';\n    }\n\n    var alg = options.algorithm.match(/(hmac|rsa)-(\\w+)/);\n    var signature;\n    if (alg[1] === 'hmac') {\n      var hmac = crypto.createHmac(alg[2].toUpperCase(), options.key);\n      hmac.update(stringToSign);\n      signature = hmac.digest('base64');\n    } else {\n      var signer = crypto.createSign(options.algorithm.toUpperCase());\n      signer.update(stringToSign);\n      signature = signer.sign(options.key, 'base64');\n    }\n\n    request.setHeader('Authorization', sprintf(Authorization,\n                                               options.keyId,\n                                               options.algorithm,\n                                               options.headers.join(' '),\n                                               signature));\n\n    return true;\n  }\n\n};\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "crypto": {
                  "type": "assign"
                },
                "http": {
                  "type": "assign"
                },
                "sprintf": {
                  "type": "assign"
                },
                "Algorithms": {
                  "type": "assign"
                },
                "Authorization": {
                  "type": "assign"
                },
                "MissingHeaderError": {
                  "type": "assign"
                },
                "InvalidAlgorithmError": {
                  "type": "assign"
                },
                "_pad": {
                  "type": "assign"
                },
                "parseInt": {
                  "type": "call"
                },
                "_rfc1123": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert-plus": {
                    "where": "inline"
                  },
                  "crypto": {
                    "where": "inline"
                  },
                  "http": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';\n// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('__SYSTEM__/crypto');\nvar http = require('__SYSTEM__/http');\n\nvar sprintf = require('__SYSTEM__/util').format;\n\n\n\n///--- Globals\n\nvar Algorithms = {\n  'rsa-sha1': true,\n  'rsa-sha256': true,\n  'rsa-sha512': true,\n  'dsa-sha1': true,\n  'hmac-sha1': true,\n  'hmac-sha256': true,\n  'hmac-sha512': true\n};\n\nvar Authorization = 'Signature keyId=\"%s\",algorithm=\"%s\",headers=\"%s\" %s';\n\n\n\n///--- Specific Errors\n\nfunction MissingHeaderError(message) {\n    this.name = 'MissingHeaderError';\n    this.message = message;\n    this.stack = (new Error()).stack;\n}\nMissingHeaderError.prototype = new Error();\n\n\nfunction InvalidAlgorithmError(message) {\n    this.name = 'InvalidAlgorithmError';\n    this.message = message;\n    this.stack = (new Error()).stack;\n}\nInvalidAlgorithmError.prototype = new Error();\n\n\n\n///--- Internal Functions\n\nfunction _pad(val) {\n  if (parseInt(val, 10) < 10) {\n    val = '0' + val;\n  }\n  return val;\n}\n\n\nfunction _rfc1123() {\n  var date = new Date();\n\n  var months = ['Jan',\n                'Feb',\n                'Mar',\n                'Apr',\n                'May',\n                'Jun',\n                'Jul',\n                'Aug',\n                'Sep',\n                'Oct',\n                'Nov',\n                'Dec'];\n  var days = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'];\n  return days[date.getUTCDay()] + ', ' +\n    _pad(date.getUTCDate()) + ' ' +\n    months[date.getUTCMonth()] + ' ' +\n    date.getUTCFullYear() + ' ' +\n    _pad(date.getUTCHours()) + ':' +\n    _pad(date.getUTCMinutes()) + ':' +\n    _pad(date.getUTCSeconds()) +\n    ' GMT';\n}\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Adds an 'Authorization' header to an http.ClientRequest object.\n   *\n   * Note that this API will add a Date header if it's not already set. Any\n   * other headers in the options.headers array MUST be present, or this\n   * will throw.\n   *\n   * You shouldn't need to check the return type; it's just there if you want\n   * to be pedantic.\n   *\n   * @param {Object} request an instance of http.ClientRequest.\n   * @param {Object} options signing parameters object:\n   *                   - {String} keyId required.\n   *                   - {String} key required (either a PEM or HMAC key).\n   *                   - {Array} headers optional; defaults to ['date'].\n   *                   - {String} algorithm optional; defaults to 'rsa-sha256'.\n   * @return {Boolean} true if Authorization (and optionally Date) were added.\n   * @throws {TypeError} on bad parameter types (input).\n   * @throws {InvalidAlgorithmError} if algorithm was bad.\n   * @throws {MissingHeaderError} if a header to be signed was specified but\n   *                              was not present.\n   */\n  signRequest: function signRequest(request, options) {\n    assert.object(request, 'request');\n    assert.object(options, 'options');\n    assert.optionalString(options.algorithm, 'options.algorithm');\n    assert.string(options.keyId, 'options.keyId');\n    assert.optionalArrayOfString(options.headers, 'options.headers');\n\n    if (!request.getHeader('Date'))\n      request.setHeader('Date', _rfc1123());\n    if (!options.headers)\n      options.headers = ['date'];\n    if (!options.algorithm)\n      options.algorithm = 'rsa-sha256';\n\n    options.algorithm = options.algorithm.toLowerCase();\n\n    if (!Algorithms[options.algorithm])\n      throw new InvalidAlgorithmError(options.algorithm + ' is not supported');\n\n    var i;\n    var stringToSign = '';\n    for (i = 0; i < options.headers.length; i++) {\n      if (typeof (options.headers[i]) !== 'string')\n        throw new TypeError('options.headers must be an array of Strings');\n\n      var h = options.headers[i].toLowerCase();\n      request.getHeader(h);\n\n      var value = request.getHeader(h);\n      if (!value) {\n        if (h === 'request-line') {\n          value = request.method + ' ' + request.path + ' HTTP/1.1';\n        } else {\n          throw new MissingHeaderError(h + ' was not in the request');\n        }\n      }\n\n      stringToSign += value;\n      if ((i + 1) < options.headers.length)\n        stringToSign += '\\n';\n    }\n\n    var alg = options.algorithm.match(/(hmac|rsa)-(\\w+)/);\n    var signature;\n    if (alg[1] === 'hmac') {\n      var hmac = crypto.createHmac(alg[2].toUpperCase(), options.key);\n      hmac.update(stringToSign);\n      signature = hmac.digest('base64');\n    } else {\n      var signer = crypto.createSign(options.algorithm.toUpperCase());\n      signer.update(stringToSign);\n      signature = signer.sign(options.key, 'base64');\n    }\n\n    request.setHeader('Authorization', sprintf(Authorization,\n                                               options.keyId,\n                                               options.algorithm,\n                                               options.headers.join(' '),\n                                               signature));\n\n    return true;\n  }\n\n};\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    http: (typeof http !== \"undefined\") ? http : null,\n    sprintf: (typeof sprintf !== \"undefined\") ? sprintf : null,\n    Algorithms: (typeof Algorithms !== \"undefined\") ? Algorithms : null,\n    Authorization: (typeof Authorization !== \"undefined\") ? Authorization : null,\n    MissingHeaderError: (typeof MissingHeaderError !== \"undefined\") ? MissingHeaderError : null,\n    InvalidAlgorithmError: (typeof InvalidAlgorithmError !== \"undefined\") ? InvalidAlgorithmError : null,\n    _pad: (typeof _pad !== \"undefined\") ? _pad : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null,\n    _rfc1123: (typeof _rfc1123 !== \"undefined\") ? _rfc1123 : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    http: (typeof http !== \"undefined\") ? http : null,\n    sprintf: (typeof sprintf !== \"undefined\") ? sprintf : null,\n    Algorithms: (typeof Algorithms !== \"undefined\") ? Algorithms : null,\n    Authorization: (typeof Authorization !== \"undefined\") ? Authorization : null,\n    MissingHeaderError: (typeof MissingHeaderError !== \"undefined\") ? MissingHeaderError : null,\n    InvalidAlgorithmError: (typeof InvalidAlgorithmError !== \"undefined\") ? InvalidAlgorithmError : null,\n    _pad: (typeof _pad !== \"undefined\") ? _pad : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null,\n    _rfc1123: (typeof _rfc1123 !== \"undefined\") ? _rfc1123 : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert-plus": {
                  "where": "inline"
                },
                "crypto": {
                  "where": "inline"
                },
                "http": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/verify.js": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/verify",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/verify.js",
            "descriptor": {
              "filename": "verify.js",
              "filepath": "node_modules/request/node_modules/http-signature/lib/verify.js",
              "mtime": 1358971386,
              "code": "// Copyright 2011 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Simply wraps up the node crypto operations for you, and returns\n   * true or false.  You are expected to pass in an object that was\n   * returned from `parse()`.\n   *\n   * @param {Object} parsedSignature the object you got from `parse`.\n   * @param {String} key either an RSA private key PEM or HMAC secret.\n   * @return {Boolean} true if valid, false otherwise.\n   * @throws {TypeError} if you pass in bad arguments.\n   */\n  verifySignature: function verifySignature(parsedSignature, key) {\n    assert.object(parsedSignature, 'parsedSignature');\n    assert.string(key, 'key');\n\n    var alg = parsedSignature.algorithm.match(/(HMAC|RSA|DSA)-(\\w+)/);\n    if (!alg || alg.length !== 3)\n      throw new TypeError('parsedSignature: unsupported algorithm ' +\n                          parsedSignature.algorithm);\n\n    if (alg[1] === 'HMAC') {\n      var hmac = crypto.createHmac(alg[2].toLowerCase(), key);\n      hmac.update(parsedSignature.signingString);\n      return (hmac.digest('base64') === parsedSignature.signature);\n    } else {\n      var verify = crypto.createVerify(alg[0]);\n      verify.update(parsedSignature.signingString);\n      return verify.verify(key, parsedSignature.signature, 'base64');\n    }\n  }\n\n};\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "crypto": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert-plus": {
                    "where": "inline"
                  },
                  "crypto": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';\n// Copyright 2011 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('__SYSTEM__/crypto');\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  /**\n   * Simply wraps up the node crypto operations for you, and returns\n   * true or false.  You are expected to pass in an object that was\n   * returned from `parse()`.\n   *\n   * @param {Object} parsedSignature the object you got from `parse`.\n   * @param {String} key either an RSA private key PEM or HMAC secret.\n   * @return {Boolean} true if valid, false otherwise.\n   * @throws {TypeError} if you pass in bad arguments.\n   */\n  verifySignature: function verifySignature(parsedSignature, key) {\n    assert.object(parsedSignature, 'parsedSignature');\n    assert.string(key, 'key');\n\n    var alg = parsedSignature.algorithm.match(/(HMAC|RSA|DSA)-(\\w+)/);\n    if (!alg || alg.length !== 3)\n      throw new TypeError('parsedSignature: unsupported algorithm ' +\n                          parsedSignature.algorithm);\n\n    if (alg[1] === 'HMAC') {\n      var hmac = crypto.createHmac(alg[2].toLowerCase(), key);\n      hmac.update(parsedSignature.signingString);\n      return (hmac.digest('base64') === parsedSignature.signature);\n    } else {\n      var verify = crypto.createVerify(alg[0]);\n      verify.update(parsedSignature.signingString);\n      return verify.verify(key, parsedSignature.signature, 'base64');\n    }\n  }\n\n};\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert-plus": {
                  "where": "inline"
                },
                "crypto": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/util.js": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/util",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/util.js",
            "descriptor": {
              "filename": "util.js",
              "filepath": "node_modules/request/node_modules/http-signature/lib/util.js",
              "mtime": 1358971386,
              "code": "// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('crypto');\n\nvar asn1 = require('asn1');\nvar ctype = require('ctype');\n\n\n\n///--- Helpers\n\nfunction readNext(buffer, offset) {\n  var len = ctype.ruint32(buffer, 'big', offset);\n  offset += 4;\n\n  var newOffset = offset + len;\n\n  return {\n    data: buffer.slice(offset, newOffset),\n    offset: newOffset\n  };\n}\n\n\nfunction writeInt(writer, buffer) {\n  writer.writeByte(0x02); // ASN1.Integer\n  writer.writeLength(buffer.length);\n\n  for (var i = 0; i < buffer.length; i++)\n    writer.writeByte(buffer[i]);\n\n  return writer;\n}\n\n\nfunction rsaToPEM(key) {\n  var buffer;\n  var der;\n  var exponent;\n  var i;\n  var modulus;\n  var newKey = '';\n  var offset = 0;\n  var type;\n  var tmp;\n\n  try {\n    buffer = new Buffer(key.split(' ')[1], 'base64');\n\n    tmp = readNext(buffer, offset);\n    type = tmp.data.toString();\n    offset = tmp.offset;\n\n    if (type !== 'ssh-rsa')\n      throw new Error('Invalid ssh key type: ' + type);\n\n    tmp = readNext(buffer, offset);\n    exponent = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    modulus = tmp.data;\n  } catch (e) {\n    throw new Error('Invalid ssh key: ' + key);\n  }\n\n  // DER is a subset of BER\n  der = new asn1.BerWriter();\n\n  der.startSequence();\n\n  der.startSequence();\n  der.writeOID('1.2.840.113549.1.1.1');\n  der.writeNull();\n  der.endSequence();\n\n  der.startSequence(0x03); // bit string\n  der.writeByte(0x00);\n\n  // Actual key\n  der.startSequence();\n  writeInt(der, modulus);\n  writeInt(der, exponent);\n  der.endSequence();\n\n  // bit string\n  der.endSequence();\n\n  der.endSequence();\n\n  tmp = der.buffer.toString('base64');\n  for (i = 0; i < tmp.length; i++) {\n    if ((i % 64) === 0)\n      newKey += '\\n';\n    newKey += tmp.charAt(i);\n  }\n\n  if (!/\\\\n$/.test(newKey))\n    newKey += '\\n';\n\n  return '-----BEGIN PUBLIC KEY-----' + newKey + '-----END PUBLIC KEY-----\\n';\n}\n\n\nfunction dsaToPEM(key) {\n  var buffer;\n  var offset = 0;\n  var tmp;\n  var der;\n  var newKey = '';\n\n  var type;\n  var p;\n  var q;\n  var g;\n  var y;\n\n  try {\n    buffer = new Buffer(key.split(' ')[1], 'base64');\n\n    tmp = readNext(buffer, offset);\n    type = tmp.data.toString();\n    offset = tmp.offset;\n\n    /* JSSTYLED */\n    if (!/^ssh-ds[as].*/.test(type))\n      throw new Error('Invalid ssh key type: ' + type);\n\n    tmp = readNext(buffer, offset);\n    p = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    q = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    g = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    y = tmp.data;\n  } catch (e) {\n    console.log(e.stack);\n    throw new Error('Invalid ssh key: ' + key);\n  }\n\n  // DER is a subset of BER\n  der = new asn1.BerWriter();\n\n  der.startSequence();\n\n  der.startSequence();\n  der.writeOID('1.2.840.10040.4.1');\n\n  der.startSequence();\n  writeInt(der, p);\n  writeInt(der, q);\n  writeInt(der, g);\n  der.endSequence();\n\n  der.endSequence();\n\n  der.startSequence(0x03); // bit string\n  der.writeByte(0x00);\n  writeInt(der, y);\n  der.endSequence();\n\n  der.endSequence();\n\n  tmp = der.buffer.toString('base64');\n  for (var i = 0; i < tmp.length; i++) {\n    if ((i % 64) === 0)\n      newKey += '\\n';\n    newKey += tmp.charAt(i);\n  }\n\n  if (!/\\\\n$/.test(newKey))\n    newKey += '\\n';\n\n  return '-----BEGIN PUBLIC KEY-----' + newKey + '-----END PUBLIC KEY-----\\n';\n}\n\n\n///--- API\n\nmodule.exports = {\n\n  /**\n   * Converts an OpenSSH public key (rsa only) to a PKCS#8 PEM file.\n   *\n   * The intent of this module is to interoperate with OpenSSL only,\n   * specifically the node crypto module's `verify` method.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} PEM encoded form of the RSA public key.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} on invalid ssh key formatted data.\n   */\n  sshKeyToPEM: function sshKeyToPEM(key) {\n    assert.string(key, 'ssh_key');\n\n    /* JSSTYLED */\n    if (/^ssh-rsa.*/.test(key))\n      return rsaToPEM(key);\n\n    /* JSSTYLED */\n    if (/^ssh-ds[as].*/.test(key))\n      return dsaToPEM(key);\n\n    throw new Error('Only RSA and DSA public keys are allowed');\n  },\n\n\n  /**\n   * Generates an OpenSSH fingerprint from an ssh public key.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} key fingerprint.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} if what you passed doesn't look like an ssh public key.\n   */\n  fingerprint: function fingerprint(key) {\n    assert.string(key, 'ssh_key');\n\n    var pieces = key.split(' ');\n    if (!pieces || !pieces.length || pieces.length < 2)\n      throw new Error('invalid ssh key');\n\n    var data = new Buffer(pieces[1], 'base64');\n\n    var hash = crypto.createHash('md5');\n    hash.update(data);\n    var digest = hash.digest('hex');\n\n    var fp = '';\n    for (var i = 0; i < digest.length; i++) {\n      if (i && i % 2 === 0)\n        fp += ':';\n\n      fp += digest[i];\n    }\n\n    return fp;\n  }\n\n\n};\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "crypto": {
                  "type": "assign"
                },
                "asn1": {
                  "type": "assign"
                },
                "ctype": {
                  "type": "assign"
                },
                "readNext": {
                  "type": "assign"
                },
                "writeInt": {
                  "type": "assign"
                },
                "rsaToPEM": {
                  "type": "assign"
                },
                "dsaToPEM": {
                  "type": "assign"
                },
                "console": {
                  "type": "reference"
                },
                "i": {
                  "type": "reference"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert-plus": {
                    "where": "inline"
                  },
                  "crypto": {
                    "where": "inline"
                  },
                  "asn1": {
                    "where": "inline"
                  },
                  "ctype": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/lib';\n// Copyright 2012 Joyent, Inc.  All rights reserved.\n\nvar assert = require('assert-plus');\nvar crypto = require('__SYSTEM__/crypto');\n\nvar asn1 = require('asn1');\nvar ctype = require('ctype');\n\n\n\n///--- Helpers\n\nfunction readNext(buffer, offset) {\n  var len = ctype.ruint32(buffer, 'big', offset);\n  offset += 4;\n\n  var newOffset = offset + len;\n\n  return {\n    data: buffer.slice(offset, newOffset),\n    offset: newOffset\n  };\n}\n\n\nfunction writeInt(writer, buffer) {\n  writer.writeByte(0x02); // ASN1.Integer\n  writer.writeLength(buffer.length);\n\n  for (var i = 0; i < buffer.length; i++)\n    writer.writeByte(buffer[i]);\n\n  return writer;\n}\n\n\nfunction rsaToPEM(key) {\n  var buffer;\n  var der;\n  var exponent;\n  var i;\n  var modulus;\n  var newKey = '';\n  var offset = 0;\n  var type;\n  var tmp;\n\n  try {\n    buffer = new Buffer(key.split(' ')[1], 'base64');\n\n    tmp = readNext(buffer, offset);\n    type = tmp.data.toString();\n    offset = tmp.offset;\n\n    if (type !== 'ssh-rsa')\n      throw new Error('Invalid ssh key type: ' + type);\n\n    tmp = readNext(buffer, offset);\n    exponent = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    modulus = tmp.data;\n  } catch (e) {\n    throw new Error('Invalid ssh key: ' + key);\n  }\n\n  // DER is a subset of BER\n  der = new asn1.BerWriter();\n\n  der.startSequence();\n\n  der.startSequence();\n  der.writeOID('1.2.840.113549.1.1.1');\n  der.writeNull();\n  der.endSequence();\n\n  der.startSequence(0x03); // bit string\n  der.writeByte(0x00);\n\n  // Actual key\n  der.startSequence();\n  writeInt(der, modulus);\n  writeInt(der, exponent);\n  der.endSequence();\n\n  // bit string\n  der.endSequence();\n\n  der.endSequence();\n\n  tmp = der.buffer.toString('base64');\n  for (i = 0; i < tmp.length; i++) {\n    if ((i % 64) === 0)\n      newKey += '\\n';\n    newKey += tmp.charAt(i);\n  }\n\n  if (!/\\\\n$/.test(newKey))\n    newKey += '\\n';\n\n  return '-----BEGIN PUBLIC KEY-----' + newKey + '-----END PUBLIC KEY-----\\n';\n}\n\n\nfunction dsaToPEM(key) {\n  var buffer;\n  var offset = 0;\n  var tmp;\n  var der;\n  var newKey = '';\n\n  var type;\n  var p;\n  var q;\n  var g;\n  var y;\n\n  try {\n    buffer = new Buffer(key.split(' ')[1], 'base64');\n\n    tmp = readNext(buffer, offset);\n    type = tmp.data.toString();\n    offset = tmp.offset;\n\n    /* JSSTYLED */\n    if (!/^ssh-ds[as].*/.test(type))\n      throw new Error('Invalid ssh key type: ' + type);\n\n    tmp = readNext(buffer, offset);\n    p = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    q = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    g = tmp.data;\n    offset = tmp.offset;\n\n    tmp = readNext(buffer, offset);\n    y = tmp.data;\n  } catch (e) {\n    console.log(e.stack);\n    throw new Error('Invalid ssh key: ' + key);\n  }\n\n  // DER is a subset of BER\n  der = new asn1.BerWriter();\n\n  der.startSequence();\n\n  der.startSequence();\n  der.writeOID('1.2.840.10040.4.1');\n\n  der.startSequence();\n  writeInt(der, p);\n  writeInt(der, q);\n  writeInt(der, g);\n  der.endSequence();\n\n  der.endSequence();\n\n  der.startSequence(0x03); // bit string\n  der.writeByte(0x00);\n  writeInt(der, y);\n  der.endSequence();\n\n  der.endSequence();\n\n  tmp = der.buffer.toString('base64');\n  for (var i = 0; i < tmp.length; i++) {\n    if ((i % 64) === 0)\n      newKey += '\\n';\n    newKey += tmp.charAt(i);\n  }\n\n  if (!/\\\\n$/.test(newKey))\n    newKey += '\\n';\n\n  return '-----BEGIN PUBLIC KEY-----' + newKey + '-----END PUBLIC KEY-----\\n';\n}\n\n\n///--- API\n\nmodule.exports = {\n\n  /**\n   * Converts an OpenSSH public key (rsa only) to a PKCS#8 PEM file.\n   *\n   * The intent of this module is to interoperate with OpenSSL only,\n   * specifically the node crypto module's `verify` method.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} PEM encoded form of the RSA public key.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} on invalid ssh key formatted data.\n   */\n  sshKeyToPEM: function sshKeyToPEM(key) {\n    assert.string(key, 'ssh_key');\n\n    /* JSSTYLED */\n    if (/^ssh-rsa.*/.test(key))\n      return rsaToPEM(key);\n\n    /* JSSTYLED */\n    if (/^ssh-ds[as].*/.test(key))\n      return dsaToPEM(key);\n\n    throw new Error('Only RSA and DSA public keys are allowed');\n  },\n\n\n  /**\n   * Generates an OpenSSH fingerprint from an ssh public key.\n   *\n   * @param {String} key an OpenSSH public key.\n   * @return {String} key fingerprint.\n   * @throws {TypeError} on bad input.\n   * @throws {Error} if what you passed doesn't look like an ssh public key.\n   */\n  fingerprint: function fingerprint(key) {\n    assert.string(key, 'ssh_key');\n\n    var pieces = key.split(' ');\n    if (!pieces || !pieces.length || pieces.length < 2)\n      throw new Error('invalid ssh key');\n\n    var data = new Buffer(pieces[1], 'base64');\n\n    var hash = crypto.createHash('md5');\n    hash.update(data);\n    var digest = hash.digest('hex');\n\n    var fp = '';\n    for (var i = 0; i < digest.length; i++) {\n      if (i && i % 2 === 0)\n        fp += ':';\n\n      fp += digest[i];\n    }\n\n    return fp;\n  }\n\n\n};\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    asn1: (typeof asn1 !== \"undefined\") ? asn1 : null,\n    ctype: (typeof ctype !== \"undefined\") ? ctype : null,\n    readNext: (typeof readNext !== \"undefined\") ? readNext : null,\n    writeInt: (typeof writeInt !== \"undefined\") ? writeInt : null,\n    rsaToPEM: (typeof rsaToPEM !== \"undefined\") ? rsaToPEM : null,\n    dsaToPEM: (typeof dsaToPEM !== \"undefined\") ? dsaToPEM : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    i: (typeof i !== \"undefined\") ? i : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    crypto: (typeof crypto !== \"undefined\") ? crypto : null,\n    asn1: (typeof asn1 !== \"undefined\") ? asn1 : null,\n    ctype: (typeof ctype !== \"undefined\") ? ctype : null,\n    readNext: (typeof readNext !== \"undefined\") ? readNext : null,\n    writeInt: (typeof writeInt !== \"undefined\") ? writeInt : null,\n    rsaToPEM: (typeof rsaToPEM !== \"undefined\") ? rsaToPEM : null,\n    dsaToPEM: (typeof dsaToPEM !== \"undefined\") ? dsaToPEM : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    i: (typeof i !== \"undefined\") ? i : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert-plus": {
                  "where": "inline"
                },
                "crypto": {
                  "where": "inline"
                },
                "asn1": {
                  "where": "inline"
                },
                "ctype": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/index.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/index.js",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/index.js",
              "mtime": 1311378978,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n// If you have no idea what ASN.1 or BER is, see this:\n// ftp://ftp.rsa.com/pub/pkcs/ascii/layman.asc\n\nvar Ber = require('./ber/index');\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  Ber: Ber,\n\n  BerReader: Ber.Reader,\n\n  BerWriter: Ber.Writer\n\n};\n",
              "globals": {
                "Ber": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./ber/index": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n// If you have no idea what ASN.1 or BER is, see this:\n// ftp://ftp.rsa.com/pub/pkcs/ascii/layman.asc\n\nvar Ber = require('./ber/index');\n\n\n\n///--- Exported API\n\nmodule.exports = {\n\n  Ber: Ber,\n\n  BerReader: Ber.Reader,\n\n  BerWriter: Ber.Writer\n\n};\n\nreturn {\n    Ber: (typeof Ber !== \"undefined\") ? Ber : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    Ber: (typeof Ber !== \"undefined\") ? Ber : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./ber/index": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/index.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/index",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber/index.js",
              "mtime": 1311127161,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar errors = require('./errors');\nvar types = require('./types');\n\nvar Reader = require('./reader');\nvar Writer = require('./writer');\n\n\n///--- Exports\n\nmodule.exports = {\n\n  Reader: Reader,\n\n  Writer: Writer\n\n};\n\nfor (var t in types) {\n  if (types.hasOwnProperty(t))\n    module.exports[t] = types[t];\n}\nfor (var e in errors) {\n  if (errors.hasOwnProperty(e))\n    module.exports[e] = errors[e];\n}\n",
              "globals": {
                "errors": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "types": {
                  "type": "assign"
                },
                "Reader": {
                  "type": "assign"
                },
                "Writer": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "t": {
                  "type": "assign"
                },
                "e": {
                  "type": "assign"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./errors": {
                    "where": "inline"
                  },
                  "./types": {
                    "where": "inline"
                  },
                  "./reader": {
                    "where": "inline"
                  },
                  "./writer": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar errors = require('./errors');\nvar types = require('./types');\n\nvar Reader = require('./reader');\nvar Writer = require('./writer');\n\n\n///--- Exports\n\nmodule.exports = {\n\n  Reader: Reader,\n\n  Writer: Writer\n\n};\n\nfor (var t in types) {\n  if (types.hasOwnProperty(t))\n    module.exports[t] = types[t];\n}\nfor (var e in errors) {\n  if (errors.hasOwnProperty(e))\n    module.exports[e] = errors[e];\n}\n\nreturn {\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    types: (typeof types !== \"undefined\") ? types : null,\n    Reader: (typeof Reader !== \"undefined\") ? Reader : null,\n    Writer: (typeof Writer !== \"undefined\") ? Writer : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    t: (typeof t !== \"undefined\") ? t : null,\n    e: (typeof e !== \"undefined\") ? e : null\n};\n}",
              "bottom": "return {\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    types: (typeof types !== \"undefined\") ? types : null,\n    Reader: (typeof Reader !== \"undefined\") ? Reader : null,\n    Writer: (typeof Writer !== \"undefined\") ? Writer : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    t: (typeof t !== \"undefined\") ? t : null,\n    e: (typeof e !== \"undefined\") ? e : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "./errors": {
                  "where": "inline"
                },
                "./types": {
                  "where": "inline"
                },
                "./reader": {
                  "where": "inline"
                },
                "./writer": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/errors.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/errors",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/errors.js",
            "descriptor": {
              "filename": "errors.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber/errors.js",
              "mtime": 1311378950,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n\n  newInvalidAsn1Error: function(msg) {\n    var e = new Error();\n    e.name = 'InvalidAsn1Error';\n    e.message = msg || '';\n    return e;\n  }\n\n};\n",
              "globals": {
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n\n  newInvalidAsn1Error: function(msg) {\n    var e = new Error();\n    e.name = 'InvalidAsn1Error';\n    e.message = msg || '';\n    return e;\n  }\n\n};\n\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/types.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/types",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/types.js",
            "descriptor": {
              "filename": "types.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber/types.js",
              "mtime": 1325868994,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n  EOC: 0,\n  Boolean: 1,\n  Integer: 2,\n  BitString: 3,\n  OctetString: 4,\n  Null: 5,\n  OID: 6,\n  ObjectDescriptor: 7,\n  External: 8,\n  Real: 9, // float\n  Enumeration: 10,\n  PDV: 11,\n  Utf8String: 12,\n  RelativeOID: 13,\n  Sequence: 16,\n  Set: 17,\n  NumericString: 18,\n  PrintableString: 19,\n  T61String: 20,\n  VideotexString: 21,\n  IA5String: 22,\n  UTCTime: 23,\n  GeneralizedTime: 24,\n  GraphicString: 25,\n  VisibleString: 26,\n  GeneralString: 28,\n  UniversalString: 29,\n  CharacterString: 30,\n  BMPString: 31,\n  Constructor: 32,\n  Context: 128\n};\n",
              "globals": {
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\n\nmodule.exports = {\n  EOC: 0,\n  Boolean: 1,\n  Integer: 2,\n  BitString: 3,\n  OctetString: 4,\n  Null: 5,\n  OID: 6,\n  ObjectDescriptor: 7,\n  External: 8,\n  Real: 9, // float\n  Enumeration: 10,\n  PDV: 11,\n  Utf8String: 12,\n  RelativeOID: 13,\n  Sequence: 16,\n  Set: 17,\n  NumericString: 18,\n  PrintableString: 19,\n  T61String: 20,\n  VideotexString: 21,\n  IA5String: 22,\n  UTCTime: 23,\n  GeneralizedTime: 24,\n  GraphicString: 25,\n  VisibleString: 26,\n  GeneralString: 28,\n  UniversalString: 29,\n  CharacterString: 30,\n  BMPString: 31,\n  Constructor: 32,\n  Context: 128\n};\n\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/reader.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/reader",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/reader.js",
            "descriptor": {
              "filename": "reader.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber/reader.js",
              "mtime": 1325869045,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('assert');\n\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\n\n\n///--- API\n\nfunction Reader(data) {\n  if (!data || !Buffer.isBuffer(data))\n    throw new TypeError('data must be a node Buffer');\n\n  this._buf = data;\n  this._size = data.length;\n\n  // These hold the \"current\" state\n  this._len = 0;\n  this._offset = 0;\n\n  var self = this;\n  this.__defineGetter__('length', function() { return self._len; });\n  this.__defineGetter__('offset', function() { return self._offset; });\n  this.__defineGetter__('remain', function() {\n    return self._size - self._offset;\n  });\n  this.__defineGetter__('buffer', function() {\n    return self._buf.slice(self._offset);\n  });\n}\n\n\n/**\n * Reads a single byte and advances offset; you can pass in `true` to make this\n * a \"peek\" operation (i.e., get the byte, but don't advance the offset).\n *\n * @param {Boolean} peek true means don't move offset.\n * @return {Number} the next byte, null if not enough data.\n */\nReader.prototype.readByte = function(peek) {\n  if (this._size - this._offset < 1)\n    return null;\n\n  var b = this._buf[this._offset] & 0xff;\n\n  if (!peek)\n    this._offset += 1;\n\n  return b;\n};\n\n\nReader.prototype.peek = function() {\n  return this.readByte(true);\n};\n\n\n/**\n * Reads a (potentially) variable length off the BER buffer.  This call is\n * not really meant to be called directly, as callers have to manipulate\n * the internal buffer afterwards.\n *\n * As a result of this call, you can call `Reader.length`, until the\n * next thing called that does a readLength.\n *\n * @return {Number} the amount of offset to advance the buffer.\n * @throws {InvalidAsn1Error} on bad ASN.1\n */\nReader.prototype.readLength = function(offset) {\n  if (offset === undefined)\n    offset = this._offset;\n\n  if (offset >= this._size)\n    return null;\n\n  var lenB = this._buf[offset++] & 0xff;\n  if (lenB === null)\n    return null;\n\n  if ((lenB & 0x80) == 0x80) {\n    lenB &= 0x7f;\n\n    if (lenB == 0)\n      throw newInvalidAsn1Error('Indefinite length not supported');\n\n    if (lenB > 4)\n      throw newInvalidAsn1Error('encoding too long');\n\n    if (this._size - offset < lenB)\n      return null;\n\n    this._len = 0;\n    for (var i = 0; i < lenB; i++)\n      this._len = (this._len << 8) + (this._buf[offset++] & 0xff);\n\n  } else {\n    // Wasn't a variable length\n    this._len = lenB;\n  }\n\n  return offset;\n};\n\n\n/**\n * Parses the next sequence in this BER buffer.\n *\n * To get the length of the sequence, call `Reader.length`.\n *\n * @return {Number} the sequence's tag.\n */\nReader.prototype.readSequence = function(tag) {\n  var seq = this.peek();\n  if (seq === null)\n    return null;\n  if (tag !== undefined && tag !== seq)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + seq.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  this._offset = o;\n  return seq;\n};\n\n\nReader.prototype.readInt = function() {\n  return this._readTag(ASN1.Integer);\n};\n\n\nReader.prototype.readBoolean = function() {\n  return (this._readTag(ASN1.Boolean) === 0 ? false : true);\n};\n\n\nReader.prototype.readEnumeration = function() {\n  return this._readTag(ASN1.Enumeration);\n};\n\n\nReader.prototype.readString = function(tag, retbuf) {\n  if (!tag)\n    tag = ASN1.OctetString;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  if (this.length === 0)\n    return '';\n\n  var str = this._buf.slice(this._offset, this._offset + this.length);\n  this._offset += this.length;\n\n  return retbuf ? str : str.toString('utf8');\n};\n\nReader.prototype.readOID = function(tag) {\n  if (!tag)\n    tag = ASN1.OID;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  var values = [];\n  var value = 0;\n\n  for (var i = 0; i < this.length; i++) {\n    var byte = this._buf[this._offset++] & 0xff;\n\n    value <<= 7;\n    value += byte & 0x7f;\n    if ((byte & 0x80) == 0) {\n      values.push(value);\n      value = 0;\n    }\n  }\n\n  value = values.shift();\n  values.unshift(value % 40);\n  values.unshift((value / 40) >> 0);\n\n  return values.join('.');\n};\n\n\nReader.prototype._readTag = function(tag) {\n  assert.ok(tag !== undefined);\n\n  var b = this.peek();\n\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > 4)\n    throw newInvalidAsn1Error('Integer too long: ' + this.length);\n\n  if (this.length > this._size - o)\n    return null;\n  this._offset = o;\n\n  var fb = this._buf[this._offset++];\n  var value = 0;\n\n  value = fb & 0x7F;\n  for (var i = 1; i < this.length; i++) {\n    value <<= 8;\n    value |= (this._buf[this._offset++] & 0xff);\n  }\n\n  if ((fb & 0x80) == 0x80)\n    value = -value;\n\n  return value;\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Reader;\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "ASN1": {
                  "type": "assign"
                },
                "errors": {
                  "type": "assign"
                },
                "newInvalidAsn1Error": {
                  "type": "assign"
                },
                "Reader": {
                  "type": "assign"
                },
                "Buffer": {
                  "type": "reference"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  },
                  "./types": {
                    "where": "inline"
                  },
                  "./errors": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('__SYSTEM__/assert');\n\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\n\n\n///--- API\n\nfunction Reader(data) {\n  if (!data || !Buffer.isBuffer(data))\n    throw new TypeError('data must be a node Buffer');\n\n  this._buf = data;\n  this._size = data.length;\n\n  // These hold the \"current\" state\n  this._len = 0;\n  this._offset = 0;\n\n  var self = this;\n  this.__defineGetter__('length', function() { return self._len; });\n  this.__defineGetter__('offset', function() { return self._offset; });\n  this.__defineGetter__('remain', function() {\n    return self._size - self._offset;\n  });\n  this.__defineGetter__('buffer', function() {\n    return self._buf.slice(self._offset);\n  });\n}\n\n\n/**\n * Reads a single byte and advances offset; you can pass in `true` to make this\n * a \"peek\" operation (i.e., get the byte, but don't advance the offset).\n *\n * @param {Boolean} peek true means don't move offset.\n * @return {Number} the next byte, null if not enough data.\n */\nReader.prototype.readByte = function(peek) {\n  if (this._size - this._offset < 1)\n    return null;\n\n  var b = this._buf[this._offset] & 0xff;\n\n  if (!peek)\n    this._offset += 1;\n\n  return b;\n};\n\n\nReader.prototype.peek = function() {\n  return this.readByte(true);\n};\n\n\n/**\n * Reads a (potentially) variable length off the BER buffer.  This call is\n * not really meant to be called directly, as callers have to manipulate\n * the internal buffer afterwards.\n *\n * As a result of this call, you can call `Reader.length`, until the\n * next thing called that does a readLength.\n *\n * @return {Number} the amount of offset to advance the buffer.\n * @throws {InvalidAsn1Error} on bad ASN.1\n */\nReader.prototype.readLength = function(offset) {\n  if (offset === undefined)\n    offset = this._offset;\n\n  if (offset >= this._size)\n    return null;\n\n  var lenB = this._buf[offset++] & 0xff;\n  if (lenB === null)\n    return null;\n\n  if ((lenB & 0x80) == 0x80) {\n    lenB &= 0x7f;\n\n    if (lenB == 0)\n      throw newInvalidAsn1Error('Indefinite length not supported');\n\n    if (lenB > 4)\n      throw newInvalidAsn1Error('encoding too long');\n\n    if (this._size - offset < lenB)\n      return null;\n\n    this._len = 0;\n    for (var i = 0; i < lenB; i++)\n      this._len = (this._len << 8) + (this._buf[offset++] & 0xff);\n\n  } else {\n    // Wasn't a variable length\n    this._len = lenB;\n  }\n\n  return offset;\n};\n\n\n/**\n * Parses the next sequence in this BER buffer.\n *\n * To get the length of the sequence, call `Reader.length`.\n *\n * @return {Number} the sequence's tag.\n */\nReader.prototype.readSequence = function(tag) {\n  var seq = this.peek();\n  if (seq === null)\n    return null;\n  if (tag !== undefined && tag !== seq)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + seq.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  this._offset = o;\n  return seq;\n};\n\n\nReader.prototype.readInt = function() {\n  return this._readTag(ASN1.Integer);\n};\n\n\nReader.prototype.readBoolean = function() {\n  return (this._readTag(ASN1.Boolean) === 0 ? false : true);\n};\n\n\nReader.prototype.readEnumeration = function() {\n  return this._readTag(ASN1.Enumeration);\n};\n\n\nReader.prototype.readString = function(tag, retbuf) {\n  if (!tag)\n    tag = ASN1.OctetString;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  if (this.length === 0)\n    return '';\n\n  var str = this._buf.slice(this._offset, this._offset + this.length);\n  this._offset += this.length;\n\n  return retbuf ? str : str.toString('utf8');\n};\n\nReader.prototype.readOID = function(tag) {\n  if (!tag)\n    tag = ASN1.OID;\n\n  var b = this.peek();\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > this._size - o)\n    return null;\n\n  this._offset = o;\n\n  var values = [];\n  var value = 0;\n\n  for (var i = 0; i < this.length; i++) {\n    var byte = this._buf[this._offset++] & 0xff;\n\n    value <<= 7;\n    value += byte & 0x7f;\n    if ((byte & 0x80) == 0) {\n      values.push(value);\n      value = 0;\n    }\n  }\n\n  value = values.shift();\n  values.unshift(value % 40);\n  values.unshift((value / 40) >> 0);\n\n  return values.join('.');\n};\n\n\nReader.prototype._readTag = function(tag) {\n  assert.ok(tag !== undefined);\n\n  var b = this.peek();\n\n  if (b === null)\n    return null;\n\n  if (b !== tag)\n    throw newInvalidAsn1Error('Expected 0x' + tag.toString(16) +\n                              ': got 0x' + b.toString(16));\n\n  var o = this.readLength(this._offset + 1); // stored in `length`\n  if (o === null)\n    return null;\n\n  if (this.length > 4)\n    throw newInvalidAsn1Error('Integer too long: ' + this.length);\n\n  if (this.length > this._size - o)\n    return null;\n  this._offset = o;\n\n  var fb = this._buf[this._offset++];\n  var value = 0;\n\n  value = fb & 0x7F;\n  for (var i = 1; i < this.length; i++) {\n    value <<= 8;\n    value |= (this._buf[this._offset++] & 0xff);\n  }\n\n  if ((fb & 0x80) == 0x80)\n    value = -value;\n\n  return value;\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Reader;\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ASN1: (typeof ASN1 !== \"undefined\") ? ASN1 : null,\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    newInvalidAsn1Error: (typeof newInvalidAsn1Error !== \"undefined\") ? newInvalidAsn1Error : null,\n    Reader: (typeof Reader !== \"undefined\") ? Reader : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ASN1: (typeof ASN1 !== \"undefined\") ? ASN1 : null,\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    newInvalidAsn1Error: (typeof newInvalidAsn1Error !== \"undefined\") ? newInvalidAsn1Error : null,\n    Reader: (typeof Reader !== \"undefined\") ? Reader : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                },
                "./types": {
                  "where": "inline"
                },
                "./errors": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/writer.js": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/writer",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/ber/writer.js",
            "descriptor": {
              "filename": "writer.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber/writer.js",
              "mtime": 1325869054,
              "code": "// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('assert');\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\nvar DEFAULT_OPTS = {\n  size: 1024,\n  growthFactor: 8\n};\n\n\n///--- Helpers\n\nfunction merge(from, to) {\n  assert.ok(from);\n  assert.equal(typeof(from), 'object');\n  assert.ok(to);\n  assert.equal(typeof(to), 'object');\n\n  var keys = Object.getOwnPropertyNames(from);\n  keys.forEach(function(key) {\n    if (to[key])\n      return;\n\n    var value = Object.getOwnPropertyDescriptor(from, key);\n    Object.defineProperty(to, key, value);\n  });\n\n  return to;\n}\n\n\n\n///--- API\n\nfunction Writer(options) {\n  options = merge(DEFAULT_OPTS, options || {});\n\n  this._buf = new Buffer(options.size || 1024);\n  this._size = this._buf.length;\n  this._offset = 0;\n  this._options = options;\n\n  // A list of offsets in the buffer where we need to insert\n  // sequence tag/len pairs.\n  this._seq = [];\n\n  var self = this;\n  this.__defineGetter__('buffer', function() {\n    if (self._seq.length)\n      throw new InvalidAsn1Error(self._seq.length + ' unended sequence(s)');\n\n    return self._buf.slice(0, self._offset);\n  });\n}\n\n\nWriter.prototype.writeByte = function(b) {\n  if (typeof(b) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(1);\n  this._buf[this._offset++] = b;\n};\n\n\nWriter.prototype.writeInt = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Integer;\n\n  var sz = 4;\n\n  while ((((i & 0xff800000) === 0) || ((i & 0xff800000) === 0xff800000)) &&\n         (sz > 1)) {\n    sz--;\n    i <<= 8;\n  }\n\n  if (sz > 4)\n    throw new InvalidAsn1Error('BER ints cannot be > 0xffffffff');\n\n  this._ensure(2 + sz);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = sz;\n\n  while (sz-- > 0) {\n    this._buf[this._offset++] = ((i & 0xff000000) >> 24);\n    i <<= 8;\n  }\n\n};\n\n\nWriter.prototype.writeNull = function() {\n  this.writeByte(ASN1.Null);\n  this.writeByte(0x00);\n};\n\n\nWriter.prototype.writeEnumeration = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Enumeration;\n\n  return this.writeInt(i, tag);\n};\n\n\nWriter.prototype.writeBoolean = function(b, tag) {\n  if (typeof(b) !== 'boolean')\n    throw new TypeError('argument must be a Boolean');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Boolean;\n\n  this._ensure(3);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = 0x01;\n  this._buf[this._offset++] = b ? 0xff : 0x00;\n};\n\n\nWriter.prototype.writeString = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string (was: ' + typeof(s) + ')');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OctetString;\n\n  var len = Buffer.byteLength(s);\n  this.writeByte(tag);\n  this.writeLength(len);\n  if (len) {\n    this._ensure(len);\n    this._buf.write(s, this._offset);\n    this._offset += len;\n  }\n};\n\n\nWriter.prototype.writeBuffer = function(buf, tag) {\n  if (typeof(tag) !== 'number')\n    throw new TypeError('tag must be a number');\n  if (!Buffer.isBuffer(buf))\n    throw new TypeError('argument must be a buffer');\n\n  this.writeByte(tag);\n  this.writeLength(buf.length);\n  this._ensure(buf.length);\n  buf.copy(this._buf, this._offset, 0, buf.length);\n  this._offset += buf.length;\n};\n\n\nWriter.prototype.writeStringArray = function(strings) {\n  if ((!strings instanceof Array))\n    throw new TypeError('argument must be an Array[String]');\n\n  var self = this;\n  strings.forEach(function(s) {\n    self.writeString(s);\n  });\n};\n\n// This is really to solve DER cases, but whatever for now\nWriter.prototype.writeOID = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OID;\n\n  if (!/^([0-9]+\\.){3,}[0-9]+$/.test(s))\n    throw new Error('argument is not a valid OID string');\n\n  function encodeOctet(bytes, octet) {\n    if (octet < 128) {\n        bytes.push(octet);\n    } else if (octet < 16384) {\n        bytes.push((octet >>> 7) | 0x80);\n        bytes.push(octet & 0x7F);\n    } else if (octet < 2097152) {\n      bytes.push((octet >>> 14) | 0x80);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else if (octet < 268435456) {\n      bytes.push((octet >>> 21) | 0x80);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else {\n      bytes.push(((octet >>> 28) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 21) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    }\n  }\n\n  var tmp = s.split('.');\n  var bytes = [];\n  bytes.push(parseInt(tmp[0], 10) * 40 + parseInt(tmp[1], 10));\n  tmp.slice(2).forEach(function(b) {\n    encodeOctet(bytes, parseInt(b, 10));\n  });\n\n  var self = this;\n  this._ensure(2 + bytes.length);\n  this.writeByte(tag);\n  this.writeLength(bytes.length);\n  bytes.forEach(function(b) {\n    self.writeByte(b);\n  });\n};\n\n\nWriter.prototype.writeLength = function(len) {\n  if (typeof(len) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(4);\n\n  if (len <= 0x7f) {\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xff) {\n    this._buf[this._offset++] = 0x81;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffff) {\n    this._buf[this._offset++] = 0x82;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[this._offset++] = 0x83;\n    this._buf[this._offset++] = len >> 16;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else {\n    throw new InvalidAsn1ERror('Length too long (> 4 bytes)');\n  }\n};\n\nWriter.prototype.startSequence = function(tag) {\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Sequence | ASN1.Constructor;\n\n  this.writeByte(tag);\n  this._seq.push(this._offset);\n  this._ensure(3);\n  this._offset += 3;\n};\n\n\nWriter.prototype.endSequence = function() {\n  var seq = this._seq.pop();\n  var start = seq + 3;\n  var len = this._offset - start;\n\n  if (len <= 0x7f) {\n    this._shift(start, len, -2);\n    this._buf[seq] = len;\n  } else if (len <= 0xff) {\n    this._shift(start, len, -1);\n    this._buf[seq] = 0x81;\n    this._buf[seq + 1] = len;\n  } else if (len <= 0xffff) {\n    this._buf[seq] = 0x82;\n    this._buf[seq + 1] = len >> 8;\n    this._buf[seq + 2] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[seq] = 0x83;\n    this._buf[seq + 1] = len >> 16;\n    this._buf[seq + 2] = len >> 8;\n    this._buf[seq + 3] = len;\n  } else {\n    throw new InvalidAsn1Error('Sequence too long');\n  }\n};\n\n\nWriter.prototype._shift = function(start, len, shift) {\n  assert.ok(start !== undefined);\n  assert.ok(len !== undefined);\n  assert.ok(shift);\n\n  this._buf.copy(this._buf, start + shift, start, start + len);\n  this._offset += shift;\n};\n\nWriter.prototype._ensure = function(len) {\n  assert.ok(len);\n\n  if (this._size - this._offset < len) {\n    var sz = this._size * this._options.growthFactor;\n    if (sz - this._offset < len)\n      sz += len;\n\n    var buf = new Buffer(sz);\n\n    this._buf.copy(buf, 0, 0, this._offset);\n    this._buf = buf;\n    this._size = sz;\n  }\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Writer;\n",
              "globals": {
                "assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "ASN1": {
                  "type": "assign"
                },
                "errors": {
                  "type": "assign"
                },
                "newInvalidAsn1Error": {
                  "type": "assign"
                },
                "DEFAULT_OPTS": {
                  "type": "assign"
                },
                "merge": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "Writer": {
                  "type": "assign"
                },
                "Buffer": {
                  "type": "reference"
                },
                "parseInt": {
                  "type": "call"
                },
                "start": {
                  "type": "reference"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  },
                  "./types": {
                    "where": "inline"
                  },
                  "./errors": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/asn1/lib/ber';\n// Copyright 2011 Mark Cavage <mcavage@gmail.com> All rights reserved.\n\nvar assert = require('__SYSTEM__/assert');\nvar ASN1 = require('./types');\nvar errors = require('./errors');\n\n\n///--- Globals\n\nvar newInvalidAsn1Error = errors.newInvalidAsn1Error;\n\nvar DEFAULT_OPTS = {\n  size: 1024,\n  growthFactor: 8\n};\n\n\n///--- Helpers\n\nfunction merge(from, to) {\n  assert.ok(from);\n  assert.equal(typeof(from), 'object');\n  assert.ok(to);\n  assert.equal(typeof(to), 'object');\n\n  var keys = Object.getOwnPropertyNames(from);\n  keys.forEach(function(key) {\n    if (to[key])\n      return;\n\n    var value = Object.getOwnPropertyDescriptor(from, key);\n    Object.defineProperty(to, key, value);\n  });\n\n  return to;\n}\n\n\n\n///--- API\n\nfunction Writer(options) {\n  options = merge(DEFAULT_OPTS, options || {});\n\n  this._buf = new Buffer(options.size || 1024);\n  this._size = this._buf.length;\n  this._offset = 0;\n  this._options = options;\n\n  // A list of offsets in the buffer where we need to insert\n  // sequence tag/len pairs.\n  this._seq = [];\n\n  var self = this;\n  this.__defineGetter__('buffer', function() {\n    if (self._seq.length)\n      throw new InvalidAsn1Error(self._seq.length + ' unended sequence(s)');\n\n    return self._buf.slice(0, self._offset);\n  });\n}\n\n\nWriter.prototype.writeByte = function(b) {\n  if (typeof(b) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(1);\n  this._buf[this._offset++] = b;\n};\n\n\nWriter.prototype.writeInt = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Integer;\n\n  var sz = 4;\n\n  while ((((i & 0xff800000) === 0) || ((i & 0xff800000) === 0xff800000)) &&\n         (sz > 1)) {\n    sz--;\n    i <<= 8;\n  }\n\n  if (sz > 4)\n    throw new InvalidAsn1Error('BER ints cannot be > 0xffffffff');\n\n  this._ensure(2 + sz);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = sz;\n\n  while (sz-- > 0) {\n    this._buf[this._offset++] = ((i & 0xff000000) >> 24);\n    i <<= 8;\n  }\n\n};\n\n\nWriter.prototype.writeNull = function() {\n  this.writeByte(ASN1.Null);\n  this.writeByte(0x00);\n};\n\n\nWriter.prototype.writeEnumeration = function(i, tag) {\n  if (typeof(i) !== 'number')\n    throw new TypeError('argument must be a Number');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Enumeration;\n\n  return this.writeInt(i, tag);\n};\n\n\nWriter.prototype.writeBoolean = function(b, tag) {\n  if (typeof(b) !== 'boolean')\n    throw new TypeError('argument must be a Boolean');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Boolean;\n\n  this._ensure(3);\n  this._buf[this._offset++] = tag;\n  this._buf[this._offset++] = 0x01;\n  this._buf[this._offset++] = b ? 0xff : 0x00;\n};\n\n\nWriter.prototype.writeString = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string (was: ' + typeof(s) + ')');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OctetString;\n\n  var len = Buffer.byteLength(s);\n  this.writeByte(tag);\n  this.writeLength(len);\n  if (len) {\n    this._ensure(len);\n    this._buf.write(s, this._offset);\n    this._offset += len;\n  }\n};\n\n\nWriter.prototype.writeBuffer = function(buf, tag) {\n  if (typeof(tag) !== 'number')\n    throw new TypeError('tag must be a number');\n  if (!Buffer.isBuffer(buf))\n    throw new TypeError('argument must be a buffer');\n\n  this.writeByte(tag);\n  this.writeLength(buf.length);\n  this._ensure(buf.length);\n  buf.copy(this._buf, this._offset, 0, buf.length);\n  this._offset += buf.length;\n};\n\n\nWriter.prototype.writeStringArray = function(strings) {\n  if ((!strings instanceof Array))\n    throw new TypeError('argument must be an Array[String]');\n\n  var self = this;\n  strings.forEach(function(s) {\n    self.writeString(s);\n  });\n};\n\n// This is really to solve DER cases, but whatever for now\nWriter.prototype.writeOID = function(s, tag) {\n  if (typeof(s) !== 'string')\n    throw new TypeError('argument must be a string');\n  if (typeof(tag) !== 'number')\n    tag = ASN1.OID;\n\n  if (!/^([0-9]+\\.){3,}[0-9]+$/.test(s))\n    throw new Error('argument is not a valid OID string');\n\n  function encodeOctet(bytes, octet) {\n    if (octet < 128) {\n        bytes.push(octet);\n    } else if (octet < 16384) {\n        bytes.push((octet >>> 7) | 0x80);\n        bytes.push(octet & 0x7F);\n    } else if (octet < 2097152) {\n      bytes.push((octet >>> 14) | 0x80);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else if (octet < 268435456) {\n      bytes.push((octet >>> 21) | 0x80);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    } else {\n      bytes.push(((octet >>> 28) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 21) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 14) | 0x80) & 0xFF);\n      bytes.push(((octet >>> 7) | 0x80) & 0xFF);\n      bytes.push(octet & 0x7F);\n    }\n  }\n\n  var tmp = s.split('.');\n  var bytes = [];\n  bytes.push(parseInt(tmp[0], 10) * 40 + parseInt(tmp[1], 10));\n  tmp.slice(2).forEach(function(b) {\n    encodeOctet(bytes, parseInt(b, 10));\n  });\n\n  var self = this;\n  this._ensure(2 + bytes.length);\n  this.writeByte(tag);\n  this.writeLength(bytes.length);\n  bytes.forEach(function(b) {\n    self.writeByte(b);\n  });\n};\n\n\nWriter.prototype.writeLength = function(len) {\n  if (typeof(len) !== 'number')\n    throw new TypeError('argument must be a Number');\n\n  this._ensure(4);\n\n  if (len <= 0x7f) {\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xff) {\n    this._buf[this._offset++] = 0x81;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffff) {\n    this._buf[this._offset++] = 0x82;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[this._offset++] = 0x83;\n    this._buf[this._offset++] = len >> 16;\n    this._buf[this._offset++] = len >> 8;\n    this._buf[this._offset++] = len;\n  } else {\n    throw new InvalidAsn1ERror('Length too long (> 4 bytes)');\n  }\n};\n\nWriter.prototype.startSequence = function(tag) {\n  if (typeof(tag) !== 'number')\n    tag = ASN1.Sequence | ASN1.Constructor;\n\n  this.writeByte(tag);\n  this._seq.push(this._offset);\n  this._ensure(3);\n  this._offset += 3;\n};\n\n\nWriter.prototype.endSequence = function() {\n  var seq = this._seq.pop();\n  var start = seq + 3;\n  var len = this._offset - start;\n\n  if (len <= 0x7f) {\n    this._shift(start, len, -2);\n    this._buf[seq] = len;\n  } else if (len <= 0xff) {\n    this._shift(start, len, -1);\n    this._buf[seq] = 0x81;\n    this._buf[seq + 1] = len;\n  } else if (len <= 0xffff) {\n    this._buf[seq] = 0x82;\n    this._buf[seq + 1] = len >> 8;\n    this._buf[seq + 2] = len;\n  } else if (len <= 0xffffff) {\n    this._shift(start, len, 1);\n    this._buf[seq] = 0x83;\n    this._buf[seq + 1] = len >> 16;\n    this._buf[seq + 2] = len >> 8;\n    this._buf[seq + 3] = len;\n  } else {\n    throw new InvalidAsn1Error('Sequence too long');\n  }\n};\n\n\nWriter.prototype._shift = function(start, len, shift) {\n  assert.ok(start !== undefined);\n  assert.ok(len !== undefined);\n  assert.ok(shift);\n\n  this._buf.copy(this._buf, start + shift, start, start + len);\n  this._offset += shift;\n};\n\nWriter.prototype._ensure = function(len) {\n  assert.ok(len);\n\n  if (this._size - this._offset < len) {\n    var sz = this._size * this._options.growthFactor;\n    if (sz - this._offset < len)\n      sz += len;\n\n    var buf = new Buffer(sz);\n\n    this._buf.copy(buf, 0, 0, this._offset);\n    this._buf = buf;\n    this._size = sz;\n  }\n};\n\n\n\n///--- Exported API\n\nmodule.exports = Writer;\n\nreturn {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ASN1: (typeof ASN1 !== \"undefined\") ? ASN1 : null,\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    newInvalidAsn1Error: (typeof newInvalidAsn1Error !== \"undefined\") ? newInvalidAsn1Error : null,\n    DEFAULT_OPTS: (typeof DEFAULT_OPTS !== \"undefined\") ? DEFAULT_OPTS : null,\n    merge: (typeof merge !== \"undefined\") ? merge : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    Writer: (typeof Writer !== \"undefined\") ? Writer : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null,\n    start: (typeof start !== \"undefined\") ? start : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    assert: (typeof assert !== \"undefined\") ? assert : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    ASN1: (typeof ASN1 !== \"undefined\") ? ASN1 : null,\n    errors: (typeof errors !== \"undefined\") ? errors : null,\n    newInvalidAsn1Error: (typeof newInvalidAsn1Error !== \"undefined\") ? newInvalidAsn1Error : null,\n    DEFAULT_OPTS: (typeof DEFAULT_OPTS !== \"undefined\") ? DEFAULT_OPTS : null,\n    merge: (typeof merge !== \"undefined\") ? merge : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    Writer: (typeof Writer !== \"undefined\") ? Writer : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    parseInt: (typeof parseInt !== \"undefined\") ? parseInt : null,\n    start: (typeof start !== \"undefined\") ? start : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                },
                "./types": {
                  "where": "inline"
                },
                "./errors": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctype.js": {
            "requireId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctype.js",
            "memoizeId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctype.js",
            "descriptor": {
              "filename": "ctype.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/ctype/ctype.js",
              "mtime": 1349567501,
              "code": "/*\n * rm - Feb 2011\n * ctype.js\n *\n * This module provides a simple abstraction towards reading and writing\n * different types of binary data. It is designed to use ctio.js and provide a\n * richer and more expressive API on top of it.\n *\n * By default we support the following as built in basic types:\n *\tint8_t\n *\tint16_t\n *\tint32_t\n *\tuint8_t\n *\tuint16_t\n *\tuint32_t\n *\tuint64_t\n *\tfloat\n *\tdouble\n *\tchar\n *\tchar[]\n *\n * Each type is returned as a Number, with the exception of char and char[]\n * which are returned as Node Buffers. A char is considered a uint8_t.\n *\n * Requests to read and write data are specified as an array of JSON objects.\n * This is also the same way that one declares structs. Even if just a single\n * value is requested, it must be done as a struct. The array order determines\n * the order that we try and read values. Each entry has the following format\n * with values marked with a * being optional.\n *\n * { key: { type: /type/, value*: /value/, offset*: /offset/ }\n *\n * If offset is defined, we lseek(offset, SEEK_SET) before reading the next\n * value. Value is defined when we're writing out data, otherwise it's ignored.\n *\n */\n\nvar mod_ctf = require('./ctf.js');\nvar mod_ctio = require('./ctio.js');\nvar mod_assert = require('assert');\n\n/*\n * This is the set of basic types that we support.\n *\n *\tread\t\tThe function to call to read in a value from a buffer\n *\n *\twrite\t\tThe function to call to write a value to a buffer\n *\n */\nvar deftypes = {\n    'uint8_t':  { read: ctReadUint8, write: ctWriteUint8 },\n    'uint16_t': { read: ctReadUint16, write: ctWriteUint16 },\n    'uint32_t': { read: ctReadUint32, write: ctWriteUint32 },\n    'uint64_t': { read: ctReadUint64, write: ctWriteUint64 },\n    'int8_t': { read: ctReadSint8, write: ctWriteSint8 },\n    'int16_t': { read: ctReadSint16, write: ctWriteSint16 },\n    'int32_t': { read: ctReadSint32, write: ctWriteSint32 },\n    'int64_t': { read: ctReadSint64, write: ctWriteSint64 },\n    'float': { read: ctReadFloat, write: ctWriteFloat },\n    'double': { read: ctReadDouble, write: ctWriteDouble },\n    'char': { read: ctReadChar, write: ctWriteChar },\n    'char[]': { read: ctReadCharArray, write: ctWriteCharArray }\n};\n\n/*\n * The following are wrappers around the CType IO low level API. They encode\n * knowledge about the size and return something in the expected format.\n */\nfunction ctReadUint8(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint8(buffer, endian, offset);\n\treturn ({ value: val, size: 1 });\n}\n\nfunction ctReadUint16(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint16(buffer, endian, offset);\n\treturn ({ value: val, size: 2 });\n}\n\nfunction ctReadUint32(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint32(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadUint64(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint64(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\nfunction ctReadSint8(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint8(buffer, endian, offset);\n\treturn ({ value: val, size: 1 });\n}\n\nfunction ctReadSint16(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint16(buffer, endian, offset);\n\treturn ({ value: val, size: 2 });\n}\n\nfunction ctReadSint32(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint32(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadSint64(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint64(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\nfunction ctReadFloat(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rfloat(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadDouble(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rdouble(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\n/*\n * Reads a single character into a node buffer\n */\nfunction ctReadChar(endian, buffer, offset)\n{\n\tvar res = new Buffer(1);\n\tres[0] = mod_ctio.ruint8(buffer, endian, offset);\n\treturn ({ value: res, size: 1 });\n}\n\nfunction ctReadCharArray(length, endian, buffer, offset)\n{\n\tvar ii;\n\tvar res = new Buffer(length);\n\n\tfor (ii = 0; ii < length; ii++)\n\t\tres[ii] = mod_ctio.ruint8(buffer, endian, offset + ii);\n\n\treturn ({ value: res, size: length });\n}\n\nfunction ctWriteUint8(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint8(value, endian, buffer, offset);\n\treturn (1);\n}\n\nfunction ctWriteUint16(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint16(value, endian, buffer, offset);\n\treturn (2);\n}\n\nfunction ctWriteUint32(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint32(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteUint64(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint64(value, endian, buffer, offset);\n\treturn (8);\n}\n\nfunction ctWriteSint8(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint8(value, endian, buffer, offset);\n\treturn (1);\n}\n\nfunction ctWriteSint16(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint16(value, endian, buffer, offset);\n\treturn (2);\n}\n\nfunction ctWriteSint32(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint32(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteSint64(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint64(value, endian, buffer, offset);\n\treturn (8);\n}\n\nfunction ctWriteFloat(value, endian, buffer, offset)\n{\n\tmod_ctio.wfloat(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteDouble(value, endian, buffer, offset)\n{\n\tmod_ctio.wdouble(value, endian, buffer, offset);\n\treturn (8);\n}\n\n/*\n * Writes a single character into a node buffer\n */\nfunction ctWriteChar(value, endian, buffer, offset)\n{\n\tif (!(value instanceof Buffer))\n\t\tthrow (new Error('Input must be a buffer'));\n\n\tmod_ctio.ruint8(value[0], endian, buffer, offset);\n\treturn (1);\n}\n\n/*\n * We're going to write 0s into the buffer if the string is shorter than the\n * length of the array.\n */\nfunction ctWriteCharArray(value, length, endian, buffer, offset)\n{\n\tvar ii;\n\n\tif (!(value instanceof Buffer))\n\t\tthrow (new Error('Input must be a buffer'));\n\n\tif (value.length > length)\n\t\tthrow (new Error('value length greater than array length'));\n\n\tfor (ii = 0; ii < value.length && ii < length; ii++)\n\t\tmod_ctio.wuint8(value[ii], endian, buffer, offset + ii);\n\n\tfor (; ii < length; ii++)\n\t\tmod_ctio.wuint8(0, endian, offset + ii);\n\n\n\treturn (length);\n}\n\n/*\n * Each parser has their own set of types. We want to make sure that they each\n * get their own copy as they may need to modify it.\n */\nfunction ctGetBasicTypes()\n{\n\tvar ret = {};\n\tvar key;\n\tfor (key in deftypes)\n\t\tret[key] = deftypes[key];\n\n\treturn (ret);\n}\n\n/*\n * Given a string in the form of type[length] we want to split this into an\n * object that extracts that information. We want to note that we could possibly\n * have nested arrays so this should only check the furthest one. It may also be\n * the case that we have no [] pieces, in which case we just return the current\n * type.\n */\nfunction ctParseType(str)\n{\n\tvar begInd, endInd;\n\tvar type, len;\n\tif (typeof (str) != 'string')\n\t\tthrow (new Error('type must be a Javascript string'));\n\n\tendInd = str.lastIndexOf(']');\n\tif (endInd == -1) {\n\t\tif (str.lastIndexOf('[') != -1)\n\t\t\tthrow (new Error('found invalid type with \\'[\\' but ' +\n\t\t\t    'no corresponding \\']\\''));\n\n\t\treturn ({ type: str });\n\t}\n\n\tbegInd = str.lastIndexOf('[');\n\tif (begInd == -1)\n\t\tthrow (new Error('found invalid type with \\']\\' but ' +\n\t\t    'no corresponding \\'[\\''));\n\n\tif (begInd >= endInd)\n\t\tthrow (new Error('malformed type, \\']\\' appears before \\'[\\''));\n\n\ttype = str.substring(0, begInd);\n\tlen = str.substring(begInd + 1, endInd);\n\n\treturn ({ type: type, len: len });\n}\n\n/*\n * Given a request validate that all of the fields for it are valid and make\n * sense. This includes verifying the following notions:\n *  - Each type requested is present in types\n *  - Only allow a name for a field to be specified once\n *  - If an array is specified, validate that the requested field exists and\n *    comes before it.\n *  - If fields is defined, check that each entry has the occurrence of field\n */\nfunction ctCheckReq(def, types, fields)\n{\n\tvar ii, jj;\n\tvar req, keys, key;\n\tvar found = {};\n\n\tif (!(def instanceof Array))\n\t\tthrow (new Error('definition is not an array'));\n\n\tif (def.length === 0)\n\t\tthrow (new Error('definition must have at least one element'));\n\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\treq = def[ii];\n\t\tif (!(req instanceof Object))\n\t\t\tthrow (new Error('definition must be an array of' +\n\t\t\t    'objects'));\n\n\t\tkeys = Object.keys(req);\n\t\tif (keys.length != 1)\n\t\t\tthrow (new Error('definition entry must only have ' +\n\t\t\t    'one key'));\n\n\t\tif (keys[0] in found)\n\t\t\tthrow (new Error('Specified name already ' +\n\t\t\t    'specified: ' + keys[0]));\n\n\t\tif (!('type' in req[keys[0]]))\n\t\t\tthrow (new Error('missing required type definition'));\n\n\t\tkey = ctParseType(req[keys[0]]['type']);\n\n\t\t/*\n\t\t * We may have nested arrays, we need to check the validity of\n\t\t * the types until the len field is undefined in key. However,\n\t\t * each time len is defined we need to verify it is either an\n\t\t * integer or corresponds to an already seen key.\n\t\t */\n\t\twhile (key['len'] !== undefined) {\n\t\t\tif (isNaN(parseInt(key['len'], 10))) {\n\t\t\t\tif (!(key['len'] in found))\n\t\t\t\t\tthrow (new Error('Given an array ' +\n\t\t\t\t\t    'length without a matching type'));\n\n\t\t\t}\n\n\t\t\tkey = ctParseType(key['type']);\n\t\t}\n\n\t\t/* Now we can validate if the type is valid */\n\t\tif (!(key['type'] in types))\n\t\t\tthrow (new Error('type not found or typdefed: ' +\n\t\t\t    key['type']));\n\n\t\t/* Check for any required fields */\n\t\tif (fields !== undefined) {\n\t\t\tfor (jj = 0; jj < fields.length; jj++) {\n\t\t\t\tif (!(fields[jj] in req[keys[0]]))\n\t\t\t\t\tthrow (new Error('Missing required ' +\n\t\t\t\t\t    'field: ' + fields[jj]));\n\t\t\t}\n\t\t}\n\n\t\tfound[keys[0]] = true;\n\t}\n}\n\n\n/*\n * Create a new instance of the parser. Each parser has its own store of\n * typedefs and endianness. Conf is an object with the following required\n * values:\n *\n *\tendian\t\tEither 'big' or 'little' do determine the endianness we\n *\t\t\twant to read from or write to.\n *\n * And the following optional values:\n *\n * \tchar-type\tValid options here are uint8 and int8. If uint8 is\n * \t\t\tspecified this changes the default behavior of a single\n * \t\t\tchar from being a buffer of a single character to being\n * \t\t\ta uint8_t. If int8, it becomes an int8_t instead.\n */\nfunction CTypeParser(conf)\n{\n\tif (!conf) throw (new Error('missing required argument'));\n\n\tif (!('endian' in conf))\n\t\tthrow (new Error('missing required endian value'));\n\n\tif (conf['endian'] != 'big' && conf['endian'] != 'little')\n\t\tthrow (new Error('Invalid endian type'));\n\n\tif ('char-type' in conf && (conf['char-type'] != 'uint8' &&\n\t    conf['char-type'] != 'int8'))\n\t\tthrow (new Error('invalid option for char-type: ' +\n\t\t    conf['char-type']));\n\n\tthis.endian = conf['endian'];\n\tthis.types = ctGetBasicTypes();\n\n\t/*\n\t * There may be a more graceful way to do this, but this will have to\n\t * serve.\n\t */\n\tif ('char-type' in conf && conf['char-type'] == 'uint8')\n\t\tthis.types['char'] = this.types['uint8_t'];\n\n\tif ('char-type' in conf && conf['char-type'] == 'int8')\n\t\tthis.types['char'] = this.types['int8_t'];\n}\n\n/*\n * Sets the current endian value for the Parser. If the value is not valid,\n * throws an Error.\n *\n *\tendian\t\tEither 'big' or 'little' do determine the endianness we\n *\t\t\twant to read from or write to.\n *\n */\nCTypeParser.prototype.setEndian = function (endian)\n{\n\tif (endian != 'big' && endian != 'little')\n\t\tthrow (new Error('invalid endian type, must be big or ' +\n\t\t    'little'));\n\n\tthis.endian = endian;\n};\n\n/*\n * Returns the current value of the endian value for the parser.\n */\nCTypeParser.prototype.getEndian = function ()\n{\n\treturn (this.endian);\n};\n\n/*\n * A user has requested to add a type, let us honor their request. Yet, if their\n * request doth spurn us, send them unto the Hells which Dante describes.\n *\n * \tname\t\tThe string for the type definition we're adding\n *\n *\tvalue\t\tEither a string that is a type/array name or an object\n *\t\t\tthat describes a struct.\n */\nCTypeParser.prototype.typedef = function (name, value)\n{\n\tvar type;\n\n\tif (name === undefined)\n\t\tthrow (new (Error('missing required typedef argument: name')));\n\n\tif (value === undefined)\n\t\tthrow (new (Error('missing required typedef argument: value')));\n\n\tif (typeof (name) != 'string')\n\t\tthrow (new (Error('the name of a type must be a string')));\n\n\ttype = ctParseType(name);\n\n\tif (type['len'] !== undefined)\n\t\tthrow (new Error('Cannot have an array in the typedef name'));\n\n\tif (name in this.types)\n\t\tthrow (new Error('typedef name already present: ' + name));\n\n\tif (typeof (value) != 'string' && !(value instanceof Array))\n\t\tthrow (new Error('typedef value must either be a string or ' +\n\t\t    'struct'));\n\n\tif (typeof (value) == 'string') {\n\t\ttype = ctParseType(value);\n\t\tif (type['len'] !== undefined) {\n\t\t\tif (isNaN(parseInt(type['len'], 10)))\n\t\t\t\tthrow (new (Error('typedef value must use ' +\n\t\t\t\t    'fixed size array when outside of a ' +\n\t\t\t\t    'struct')));\n\t\t}\n\n\t\tthis.types[name] = value;\n\t} else {\n\t\t/* We have a struct, validate it */\n\t\tctCheckReq(value, this.types);\n\t\tthis.types[name] = value;\n\t}\n};\n\n/*\n * Include all of the typedefs, but none of the built in types. This should be\n * treated as read-only.\n */\nCTypeParser.prototype.lstypes = function ()\n{\n\tvar key;\n\tvar ret = {};\n\n\tfor (key in this.types) {\n\t\tif (key in deftypes)\n\t\t\tcontinue;\n\t\tret[key] = this.types[key];\n\t}\n\n\treturn (ret);\n};\n\n/*\n * Given a type string that may have array types that aren't numbers, try and\n * fill them in from the values object. The object should be of the format where\n * indexing into it should return a number for that type.\n *\n *\tstr\t\tThe type string\n *\n *\tvalues\t\tAn object that can be used to fulfill type information\n */\nfunction ctResolveArray(str, values)\n{\n\tvar ret = '';\n\tvar type = ctParseType(str);\n\n\twhile (type['len'] !== undefined) {\n\t\tif (isNaN(parseInt(type['len'], 10))) {\n\t\t\tif (typeof (values[type['len']]) != 'number')\n\t\t\t\tthrow (new Error('cannot sawp in non-number ' +\n\t\t\t\t    'for array value'));\n\t\t\tret = '[' + values[type['len']] + ']' + ret;\n\t\t} else {\n\t\t\tret = '[' + type['len'] + ']' + ret;\n\t\t}\n\t\ttype = ctParseType(type['type']);\n\t}\n\n\tret = type['type'] + ret;\n\n\treturn (ret);\n}\n\n/*\n * [private] Either the typedef resolves to another type string or to a struct.\n * If it resolves to a struct, we just pass it off to read struct. If not, we\n * can just pass it off to read entry.\n */\nCTypeParser.prototype.resolveTypedef = function (type, dispatch, buffer,\n    offset, value)\n{\n\tvar pt;\n\n\tmod_assert.ok(type in this.types);\n\tif (typeof (this.types[type]) == 'string') {\n\t\tpt = ctParseType(this.types[type]);\n\t\tif (dispatch == 'read')\n\t\t\treturn (this.readEntry(pt, buffer, offset));\n\t\telse if (dispatch == 'write')\n\t\t\treturn (this.writeEntry(value, pt, buffer, offset));\n\t\telse\n\t\t\tthrow (new Error('invalid dispatch type to ' +\n\t\t\t    'resolveTypedef'));\n\t} else {\n\t\tif (dispatch == 'read')\n\t\t\treturn (this.readStruct(this.types[type], buffer,\n\t\t\t    offset));\n\t\telse if (dispatch == 'write')\n\t\t\treturn (this.writeStruct(value, this.types[type],\n\t\t\t    buffer, offset));\n\t\telse\n\t\t\tthrow (new Error('invalid dispatch type to ' +\n\t\t\t    'resolveTypedef'));\n\t}\n\n};\n\n/*\n * [private] Try and read in the specific entry.\n */\nCTypeParser.prototype.readEntry = function (type, buffer, offset)\n{\n\tvar parse, len;\n\n\t/*\n\t * Because we want to special case char[]s this is unfortunately\n\t * a bit uglier than it really should be. We want to special\n\t * case char[]s so that we return a node buffer, thus they are a\n\t * first class type where as all other arrays just call into a\n\t * generic array routine which calls their data-specific routine\n\t * the specified number of times.\n\t *\n\t * The valid dispatch options we have are:\n\t *  - Array and char => char[] handler\n\t *  - Generic array handler\n\t *  - Generic typedef handler\n\t *  - Basic type handler\n\t */\n\tif (type['len'] !== undefined) {\n\t\tlen = parseInt(type['len'], 10);\n\t\tif (isNaN(len))\n\t\t\tthrow (new Error('somehow got a non-numeric length'));\n\n\t\tif (type['type'] == 'char')\n\t\t\tparse = this.types['char[]']['read'](len,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tparse = this.readArray(type['type'],\n\t\t\t    len, buffer, offset);\n\t} else {\n\t\tif (type['type'] in deftypes)\n\t\t\tparse = this.types[type['type']]['read'](this.endian,\n\t\t\t    buffer, offset);\n\t\telse\n\t\t\tparse = this.resolveTypedef(type['type'], 'read',\n\t\t\t    buffer, offset);\n\t}\n\n\treturn (parse);\n};\n\n/*\n * [private] Read an array of data\n */\nCTypeParser.prototype.readArray = function (type, length, buffer, offset)\n{\n\tvar ii, ent, pt;\n\tvar baseOffset = offset;\n\tvar ret = new Array(length);\n\tpt = ctParseType(type);\n\n\tfor (ii = 0; ii < length; ii++) {\n\t\tent = this.readEntry(pt, buffer, offset);\n\t\toffset += ent['size'];\n\t\tret[ii] = ent['value'];\n\t}\n\n\treturn ({ value: ret, size: offset - baseOffset });\n};\n\n/*\n * [private] Read a single struct in.\n */\nCTypeParser.prototype.readStruct = function (def, buffer, offset)\n{\n\tvar parse, ii, type, entry, key;\n\tvar baseOffset = offset;\n\tvar ret = {};\n\n\t/* Walk it and handle doing what's necessary */\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tentry = def[ii][key];\n\n\t\t/* Resolve all array values */\n\t\ttype = ctParseType(ctResolveArray(entry['type'], ret));\n\n\t\tif ('offset' in entry)\n\t\t\toffset = baseOffset + entry['offset'];\n\n\t\tparse = this.readEntry(type, buffer, offset);\n\n\t\toffset += parse['size'];\n\t\tret[key] = parse['value'];\n\t}\n\n\treturn ({ value: ret, size: (offset-baseOffset)});\n};\n\n/*\n * This is what we were born to do. We read the data from a buffer and return it\n * in an object whose keys match the values from the object.\n *\n *\tdef\t\tThe array definition of the data to read in\n *\n *\tbuffer\t\tThe buffer to read data from\n *\n *\toffset\t\tThe offset to start writing to\n *\n * Returns an object where each key corresponds to an entry in def and the value\n * is the read value.\n */\nCTypeParser.prototype.readData = function (def, buffer, offset)\n{\n\t/* Sanity check for arguments */\n\tif (def === undefined)\n\t\tthrow (new Error('missing definition for what we should be' +\n\t\t    'parsing'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer for what we should be ' +\n\t\t    'parsing'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset for what we should be ' +\n\t\t    'parsing'));\n\n\t/* Sanity check the object definition */\n\tctCheckReq(def, this.types);\n\n\treturn (this.readStruct(def, buffer, offset)['value']);\n};\n\n/*\n * [private] Write out an array of data\n */\nCTypeParser.prototype.writeArray = function (value, type, length, buffer,\n    offset)\n{\n\tvar ii, pt;\n\tvar baseOffset = offset;\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('asked to write an array, but value is not ' +\n\t\t    'an array'));\n\n\tif (value.length != length)\n\t\tthrow (new Error('asked to write array of length ' + length +\n\t\t    ' but that does not match value length: ' + value.length));\n\n\tpt = ctParseType(type);\n\tfor (ii = 0; ii < length; ii++)\n\t\toffset += this.writeEntry(value[ii], pt, buffer, offset);\n\n\treturn (offset - baseOffset);\n};\n\n/*\n * [private] Write the specific entry\n */\nCTypeParser.prototype.writeEntry = function (value, type, buffer, offset)\n{\n\tvar len, ret;\n\n\tif (type['len'] !== undefined) {\n\t\tlen = parseInt(type['len'], 10);\n\t\tif (isNaN(len))\n\t\t\tthrow (new Error('somehow got a non-numeric length'));\n\n\t\tif (type['type'] == 'char')\n\t\t\tret = this.types['char[]']['write'](value, len,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tret = this.writeArray(value, type['type'],\n\t\t\t    len, buffer, offset);\n\t} else {\n\t\tif (type['type'] in deftypes)\n\t\t\tret = this.types[type['type']]['write'](value,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tret = this.resolveTypedef(type['type'], 'write',\n\t\t\t    buffer, offset, value);\n\t}\n\n\treturn (ret);\n};\n\n/*\n * [private] Write a single struct out.\n */\nCTypeParser.prototype.writeStruct = function (value, def, buffer, offset)\n{\n\tvar ii, entry, type, key;\n\tvar baseOffset = offset;\n\tvar vals = {};\n\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tentry = def[ii][key];\n\n\t\ttype = ctParseType(ctResolveArray(entry['type'], vals));\n\n\t\tif ('offset' in entry)\n\t\t\toffset = baseOffset + entry['offset'];\n\n\t\toffset += this.writeEntry(value[ii], type, buffer, offset);\n\t\t/* Now that we've written it out, we can use it for arrays */\n\t\tvals[key] = value[ii];\n\t}\n\n\treturn (offset);\n};\n\n/*\n * Unfortunately, we're stuck with the sins of an initial poor design. Because\n * of that, we are going to have to support the old way of writing data via\n * writeData. There we insert the values that you want to write into the\n * definition. A little baroque. Internally, we use the new model. So we need to\n * just get those values out of there. But to maintain the principle of least\n * surprise, we're not going to modify the input data.\n */\nfunction getValues(def)\n{\n\tvar ii, out, key;\n\tout = [];\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tmod_assert.ok('value' in def[ii][key]);\n\t\tout.push(def[ii][key]['value']);\n\t}\n\n\treturn (out);\n}\n\n/*\n * This is the second half of what we were born to do, write out the data\n * itself. Historically this function required you to put your values in the\n * definition section. This was not the smartest thing to do and a bit of an\n * oversight to be honest. As such, this function now takes a values argument.\n * If values is non-null and non-undefined, it will be used to determine the\n * values. This means that the old method is still supported, but is no longer\n * acceptable.\n *\n *\tdef\t\tThe array definition of the data to write out with\n *\t\t\tvalues\n *\n *\tbuffer\t\tThe buffer to write to\n *\n *\toffset\t\tThe offset in the buffer to write to\n *\n *\tvalues\t\tAn array of values to write.\n */\nCTypeParser.prototype.writeData = function (def, buffer, offset, values)\n{\n\tvar hv;\n\n\tif (def === undefined)\n\t\tthrow (new Error('missing definition for what we should be' +\n\t\t    'parsing'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer for what we should be ' +\n\t\t    'parsing'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset for what we should be ' +\n\t\t    'parsing'));\n\n\thv = (values != null && values != undefined);\n\tif (hv) {\n\t\tif (!Array.isArray(values))\n\t\t\tthrow (new Error('missing values for writing'));\n\t\tctCheckReq(def, this.types);\n\t} else {\n\t\tctCheckReq(def, this.types, [ 'value' ]);\n\t}\n\n\tthis.writeStruct(hv ? values : getValues(def), def, buffer, offset);\n};\n\n/*\n * Functions to go to and from 64 bit numbers in a way that is compatible with\n * Javascript limitations. There are two sets. One where the user is okay with\n * an approximation and one where they are definitely not okay with an\n * approximation.\n */\n\n/*\n * Attempts to convert an array of two integers returned from rsint64 / ruint64\n * into an absolute 64 bit number. If however the value would exceed 2^52 this\n * will instead throw an error. The mantissa in a double is a 52 bit number and\n * rather than potentially give you a value that is an approximation this will\n * error. If you would rather an approximation, please see toApprox64.\n *\n *\tval\t\tAn array of two 32-bit integers\n */\nfunction toAbs64(val)\n{\n\tif (val === undefined)\n\t\tthrow (new Error('missing required arg: value'));\n\n\tif (!Array.isArray(val))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (val.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\t/* We have 20 bits worth of precision in this range */\n\tif (val[0] >= 0x100000)\n\t\tthrow (new Error('value would become approximated'));\n\n\treturn (val[0] * Math.pow(2, 32) + val[1]);\n}\n\n/*\n * Will return the 64 bit value as returned in an array from rsint64 / ruint64\n * to a value as close as it can. Note that Javascript stores all numbers as a\n * double and the mantissa only has 52 bits. Thus this version may approximate\n * the value.\n *\n *\tval\t\tAn array of two 32-bit integers\n */\nfunction toApprox64(val)\n{\n\tif (val === undefined)\n\t\tthrow (new Error('missing required arg: value'));\n\n\tif (!Array.isArray(val))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (val.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\treturn (Math.pow(2, 32) * val[0] + val[1]);\n}\n\nfunction parseCTF(json, conf)\n{\n\tvar ctype = new CTypeParser(conf);\n\tmod_ctf.ctfParseJson(json, ctype);\n\n\treturn (ctype);\n}\n\n/*\n * Export the few things we actually want to. Currently this is just the CType\n * Parser and ctio.\n */\nexports.Parser = CTypeParser;\nexports.toAbs64 = toAbs64;\nexports.toApprox64 = toApprox64;\n\nexports.parseCTF = parseCTF;\n\nexports.ruint8 = mod_ctio.ruint8;\nexports.ruint16 = mod_ctio.ruint16;\nexports.ruint32 = mod_ctio.ruint32;\nexports.ruint64 = mod_ctio.ruint64;\nexports.wuint8 = mod_ctio.wuint8;\nexports.wuint16 = mod_ctio.wuint16;\nexports.wuint32 = mod_ctio.wuint32;\nexports.wuint64 = mod_ctio.wuint64;\n\nexports.rsint8 = mod_ctio.rsint8;\nexports.rsint16 = mod_ctio.rsint16;\nexports.rsint32 = mod_ctio.rsint32;\nexports.rsint64 = mod_ctio.rsint64;\nexports.wsint8 = mod_ctio.wsint8;\nexports.wsint16 = mod_ctio.wsint16;\nexports.wsint32 = mod_ctio.wsint32;\nexports.wsint64 = mod_ctio.wsint64;\n\nexports.rfloat = mod_ctio.rfloat;\nexports.rdouble = mod_ctio.rdouble;\nexports.wfloat = mod_ctio.wfloat;\nexports.wdouble = mod_ctio.wdouble;\n",
              "globals": {
                "mod_ctf": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "mod_ctio": {
                  "type": "assign"
                },
                "mod_assert": {
                  "type": "assign"
                },
                "deftypes": {
                  "type": "assign"
                },
                "ctReadUint8": {
                  "type": "assign"
                },
                "ctReadUint16": {
                  "type": "assign"
                },
                "ctReadUint32": {
                  "type": "assign"
                },
                "ctReadUint64": {
                  "type": "assign"
                },
                "ctReadSint8": {
                  "type": "assign"
                },
                "ctReadSint16": {
                  "type": "assign"
                },
                "ctReadSint32": {
                  "type": "assign"
                },
                "ctReadSint64": {
                  "type": "assign"
                },
                "ctReadFloat": {
                  "type": "assign"
                },
                "ctReadDouble": {
                  "type": "assign"
                },
                "ctReadChar": {
                  "type": "assign"
                },
                "ctReadCharArray": {
                  "type": "assign"
                },
                "ctWriteUint8": {
                  "type": "assign"
                },
                "ctWriteUint16": {
                  "type": "assign"
                },
                "ctWriteUint32": {
                  "type": "assign"
                },
                "ctWriteUint64": {
                  "type": "assign"
                },
                "ctWriteSint8": {
                  "type": "assign"
                },
                "ctWriteSint16": {
                  "type": "assign"
                },
                "ctWriteSint32": {
                  "type": "assign"
                },
                "ctWriteSint64": {
                  "type": "assign"
                },
                "ctWriteFloat": {
                  "type": "assign"
                },
                "ctWriteDouble": {
                  "type": "assign"
                },
                "ctWriteChar": {
                  "type": "assign"
                },
                "ctWriteCharArray": {
                  "type": "assign"
                },
                "ctGetBasicTypes": {
                  "type": "assign"
                },
                "ctParseType": {
                  "type": "assign"
                },
                "ctCheckReq": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "isNaN": {
                  "type": "call"
                },
                "parseInt": {
                  "type": "call"
                },
                "CTypeParser": {
                  "type": "assign"
                },
                "ctResolveArray": {
                  "type": "assign"
                },
                "getValues": {
                  "type": "assign"
                },
                "Array": {
                  "type": "reference"
                },
                "toAbs64": {
                  "type": "assign"
                },
                "Math": {
                  "type": "reference"
                },
                "toApprox64": {
                  "type": "assign"
                },
                "parseCTF": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "./ctf.js": {
                    "where": "inline"
                  },
                  "./ctio.js": {
                    "where": "inline"
                  },
                  "assert": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';\n/*\n * rm - Feb 2011\n * ctype.js\n *\n * This module provides a simple abstraction towards reading and writing\n * different types of binary data. It is designed to use ctio.js and provide a\n * richer and more expressive API on top of it.\n *\n * By default we support the following as built in basic types:\n *\tint8_t\n *\tint16_t\n *\tint32_t\n *\tuint8_t\n *\tuint16_t\n *\tuint32_t\n *\tuint64_t\n *\tfloat\n *\tdouble\n *\tchar\n *\tchar[]\n *\n * Each type is returned as a Number, with the exception of char and char[]\n * which are returned as Node Buffers. A char is considered a uint8_t.\n *\n * Requests to read and write data are specified as an array of JSON objects.\n * This is also the same way that one declares structs. Even if just a single\n * value is requested, it must be done as a struct. The array order determines\n * the order that we try and read values. Each entry has the following format\n * with values marked with a * being optional.\n *\n * { key: { type: /type/, value*: /value/, offset*: /offset/ }\n *\n * If offset is defined, we lseek(offset, SEEK_SET) before reading the next\n * value. Value is defined when we're writing out data, otherwise it's ignored.\n *\n */\n\nvar mod_ctf = require('./ctf.js');\nvar mod_ctio = require('./ctio.js');\nvar mod_assert = require('__SYSTEM__/assert');\n\n/*\n * This is the set of basic types that we support.\n *\n *\tread\t\tThe function to call to read in a value from a buffer\n *\n *\twrite\t\tThe function to call to write a value to a buffer\n *\n */\nvar deftypes = {\n    'uint8_t':  { read: ctReadUint8, write: ctWriteUint8 },\n    'uint16_t': { read: ctReadUint16, write: ctWriteUint16 },\n    'uint32_t': { read: ctReadUint32, write: ctWriteUint32 },\n    'uint64_t': { read: ctReadUint64, write: ctWriteUint64 },\n    'int8_t': { read: ctReadSint8, write: ctWriteSint8 },\n    'int16_t': { read: ctReadSint16, write: ctWriteSint16 },\n    'int32_t': { read: ctReadSint32, write: ctWriteSint32 },\n    'int64_t': { read: ctReadSint64, write: ctWriteSint64 },\n    'float': { read: ctReadFloat, write: ctWriteFloat },\n    'double': { read: ctReadDouble, write: ctWriteDouble },\n    'char': { read: ctReadChar, write: ctWriteChar },\n    'char[]': { read: ctReadCharArray, write: ctWriteCharArray }\n};\n\n/*\n * The following are wrappers around the CType IO low level API. They encode\n * knowledge about the size and return something in the expected format.\n */\nfunction ctReadUint8(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint8(buffer, endian, offset);\n\treturn ({ value: val, size: 1 });\n}\n\nfunction ctReadUint16(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint16(buffer, endian, offset);\n\treturn ({ value: val, size: 2 });\n}\n\nfunction ctReadUint32(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint32(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadUint64(endian, buffer, offset)\n{\n\tvar val = mod_ctio.ruint64(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\nfunction ctReadSint8(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint8(buffer, endian, offset);\n\treturn ({ value: val, size: 1 });\n}\n\nfunction ctReadSint16(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint16(buffer, endian, offset);\n\treturn ({ value: val, size: 2 });\n}\n\nfunction ctReadSint32(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint32(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadSint64(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rsint64(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\nfunction ctReadFloat(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rfloat(buffer, endian, offset);\n\treturn ({ value: val, size: 4 });\n}\n\nfunction ctReadDouble(endian, buffer, offset)\n{\n\tvar val = mod_ctio.rdouble(buffer, endian, offset);\n\treturn ({ value: val, size: 8 });\n}\n\n/*\n * Reads a single character into a node buffer\n */\nfunction ctReadChar(endian, buffer, offset)\n{\n\tvar res = new Buffer(1);\n\tres[0] = mod_ctio.ruint8(buffer, endian, offset);\n\treturn ({ value: res, size: 1 });\n}\n\nfunction ctReadCharArray(length, endian, buffer, offset)\n{\n\tvar ii;\n\tvar res = new Buffer(length);\n\n\tfor (ii = 0; ii < length; ii++)\n\t\tres[ii] = mod_ctio.ruint8(buffer, endian, offset + ii);\n\n\treturn ({ value: res, size: length });\n}\n\nfunction ctWriteUint8(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint8(value, endian, buffer, offset);\n\treturn (1);\n}\n\nfunction ctWriteUint16(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint16(value, endian, buffer, offset);\n\treturn (2);\n}\n\nfunction ctWriteUint32(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint32(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteUint64(value, endian, buffer, offset)\n{\n\tmod_ctio.wuint64(value, endian, buffer, offset);\n\treturn (8);\n}\n\nfunction ctWriteSint8(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint8(value, endian, buffer, offset);\n\treturn (1);\n}\n\nfunction ctWriteSint16(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint16(value, endian, buffer, offset);\n\treturn (2);\n}\n\nfunction ctWriteSint32(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint32(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteSint64(value, endian, buffer, offset)\n{\n\tmod_ctio.wsint64(value, endian, buffer, offset);\n\treturn (8);\n}\n\nfunction ctWriteFloat(value, endian, buffer, offset)\n{\n\tmod_ctio.wfloat(value, endian, buffer, offset);\n\treturn (4);\n}\n\nfunction ctWriteDouble(value, endian, buffer, offset)\n{\n\tmod_ctio.wdouble(value, endian, buffer, offset);\n\treturn (8);\n}\n\n/*\n * Writes a single character into a node buffer\n */\nfunction ctWriteChar(value, endian, buffer, offset)\n{\n\tif (!(value instanceof Buffer))\n\t\tthrow (new Error('Input must be a buffer'));\n\n\tmod_ctio.ruint8(value[0], endian, buffer, offset);\n\treturn (1);\n}\n\n/*\n * We're going to write 0s into the buffer if the string is shorter than the\n * length of the array.\n */\nfunction ctWriteCharArray(value, length, endian, buffer, offset)\n{\n\tvar ii;\n\n\tif (!(value instanceof Buffer))\n\t\tthrow (new Error('Input must be a buffer'));\n\n\tif (value.length > length)\n\t\tthrow (new Error('value length greater than array length'));\n\n\tfor (ii = 0; ii < value.length && ii < length; ii++)\n\t\tmod_ctio.wuint8(value[ii], endian, buffer, offset + ii);\n\n\tfor (; ii < length; ii++)\n\t\tmod_ctio.wuint8(0, endian, offset + ii);\n\n\n\treturn (length);\n}\n\n/*\n * Each parser has their own set of types. We want to make sure that they each\n * get their own copy as they may need to modify it.\n */\nfunction ctGetBasicTypes()\n{\n\tvar ret = {};\n\tvar key;\n\tfor (key in deftypes)\n\t\tret[key] = deftypes[key];\n\n\treturn (ret);\n}\n\n/*\n * Given a string in the form of type[length] we want to split this into an\n * object that extracts that information. We want to note that we could possibly\n * have nested arrays so this should only check the furthest one. It may also be\n * the case that we have no [] pieces, in which case we just return the current\n * type.\n */\nfunction ctParseType(str)\n{\n\tvar begInd, endInd;\n\tvar type, len;\n\tif (typeof (str) != 'string')\n\t\tthrow (new Error('type must be a Javascript string'));\n\n\tendInd = str.lastIndexOf(']');\n\tif (endInd == -1) {\n\t\tif (str.lastIndexOf('[') != -1)\n\t\t\tthrow (new Error('found invalid type with \\'[\\' but ' +\n\t\t\t    'no corresponding \\']\\''));\n\n\t\treturn ({ type: str });\n\t}\n\n\tbegInd = str.lastIndexOf('[');\n\tif (begInd == -1)\n\t\tthrow (new Error('found invalid type with \\']\\' but ' +\n\t\t    'no corresponding \\'[\\''));\n\n\tif (begInd >= endInd)\n\t\tthrow (new Error('malformed type, \\']\\' appears before \\'[\\''));\n\n\ttype = str.substring(0, begInd);\n\tlen = str.substring(begInd + 1, endInd);\n\n\treturn ({ type: type, len: len });\n}\n\n/*\n * Given a request validate that all of the fields for it are valid and make\n * sense. This includes verifying the following notions:\n *  - Each type requested is present in types\n *  - Only allow a name for a field to be specified once\n *  - If an array is specified, validate that the requested field exists and\n *    comes before it.\n *  - If fields is defined, check that each entry has the occurrence of field\n */\nfunction ctCheckReq(def, types, fields)\n{\n\tvar ii, jj;\n\tvar req, keys, key;\n\tvar found = {};\n\n\tif (!(def instanceof Array))\n\t\tthrow (new Error('definition is not an array'));\n\n\tif (def.length === 0)\n\t\tthrow (new Error('definition must have at least one element'));\n\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\treq = def[ii];\n\t\tif (!(req instanceof Object))\n\t\t\tthrow (new Error('definition must be an array of' +\n\t\t\t    'objects'));\n\n\t\tkeys = Object.keys(req);\n\t\tif (keys.length != 1)\n\t\t\tthrow (new Error('definition entry must only have ' +\n\t\t\t    'one key'));\n\n\t\tif (keys[0] in found)\n\t\t\tthrow (new Error('Specified name already ' +\n\t\t\t    'specified: ' + keys[0]));\n\n\t\tif (!('type' in req[keys[0]]))\n\t\t\tthrow (new Error('missing required type definition'));\n\n\t\tkey = ctParseType(req[keys[0]]['type']);\n\n\t\t/*\n\t\t * We may have nested arrays, we need to check the validity of\n\t\t * the types until the len field is undefined in key. However,\n\t\t * each time len is defined we need to verify it is either an\n\t\t * integer or corresponds to an already seen key.\n\t\t */\n\t\twhile (key['len'] !== undefined) {\n\t\t\tif (isNaN(parseInt(key['len'], 10))) {\n\t\t\t\tif (!(key['len'] in found))\n\t\t\t\t\tthrow (new Error('Given an array ' +\n\t\t\t\t\t    'length without a matching type'));\n\n\t\t\t}\n\n\t\t\tkey = ctParseType(key['type']);\n\t\t}\n\n\t\t/* Now we can validate if the type is valid */\n\t\tif (!(key['type'] in types))\n\t\t\tthrow (new Error('type not found or typdefed: ' +\n\t\t\t    key['type']));\n\n\t\t/* Check for any required fields */\n\t\tif (fields !== undefined) {\n\t\t\tfor (jj = 0; jj < fields.length; jj++) {\n\t\t\t\tif (!(fields[jj] in req[keys[0]]))\n\t\t\t\t\tthrow (new Error('Missing required ' +\n\t\t\t\t\t    'field: ' + fields[jj]));\n\t\t\t}\n\t\t}\n\n\t\tfound[keys[0]] = true;\n\t}\n}\n\n\n/*\n * Create a new instance of the parser. Each parser has its own store of\n * typedefs and endianness. Conf is an object with the following required\n * values:\n *\n *\tendian\t\tEither 'big' or 'little' do determine the endianness we\n *\t\t\twant to read from or write to.\n *\n * And the following optional values:\n *\n * \tchar-type\tValid options here are uint8 and int8. If uint8 is\n * \t\t\tspecified this changes the default behavior of a single\n * \t\t\tchar from being a buffer of a single character to being\n * \t\t\ta uint8_t. If int8, it becomes an int8_t instead.\n */\nfunction CTypeParser(conf)\n{\n\tif (!conf) throw (new Error('missing required argument'));\n\n\tif (!('endian' in conf))\n\t\tthrow (new Error('missing required endian value'));\n\n\tif (conf['endian'] != 'big' && conf['endian'] != 'little')\n\t\tthrow (new Error('Invalid endian type'));\n\n\tif ('char-type' in conf && (conf['char-type'] != 'uint8' &&\n\t    conf['char-type'] != 'int8'))\n\t\tthrow (new Error('invalid option for char-type: ' +\n\t\t    conf['char-type']));\n\n\tthis.endian = conf['endian'];\n\tthis.types = ctGetBasicTypes();\n\n\t/*\n\t * There may be a more graceful way to do this, but this will have to\n\t * serve.\n\t */\n\tif ('char-type' in conf && conf['char-type'] == 'uint8')\n\t\tthis.types['char'] = this.types['uint8_t'];\n\n\tif ('char-type' in conf && conf['char-type'] == 'int8')\n\t\tthis.types['char'] = this.types['int8_t'];\n}\n\n/*\n * Sets the current endian value for the Parser. If the value is not valid,\n * throws an Error.\n *\n *\tendian\t\tEither 'big' or 'little' do determine the endianness we\n *\t\t\twant to read from or write to.\n *\n */\nCTypeParser.prototype.setEndian = function (endian)\n{\n\tif (endian != 'big' && endian != 'little')\n\t\tthrow (new Error('invalid endian type, must be big or ' +\n\t\t    'little'));\n\n\tthis.endian = endian;\n};\n\n/*\n * Returns the current value of the endian value for the parser.\n */\nCTypeParser.prototype.getEndian = function ()\n{\n\treturn (this.endian);\n};\n\n/*\n * A user has requested to add a type, let us honor their request. Yet, if their\n * request doth spurn us, send them unto the Hells which Dante describes.\n *\n * \tname\t\tThe string for the type definition we're adding\n *\n *\tvalue\t\tEither a string that is a type/array name or an object\n *\t\t\tthat describes a struct.\n */\nCTypeParser.prototype.typedef = function (name, value)\n{\n\tvar type;\n\n\tif (name === undefined)\n\t\tthrow (new (Error('missing required typedef argument: name')));\n\n\tif (value === undefined)\n\t\tthrow (new (Error('missing required typedef argument: value')));\n\n\tif (typeof (name) != 'string')\n\t\tthrow (new (Error('the name of a type must be a string')));\n\n\ttype = ctParseType(name);\n\n\tif (type['len'] !== undefined)\n\t\tthrow (new Error('Cannot have an array in the typedef name'));\n\n\tif (name in this.types)\n\t\tthrow (new Error('typedef name already present: ' + name));\n\n\tif (typeof (value) != 'string' && !(value instanceof Array))\n\t\tthrow (new Error('typedef value must either be a string or ' +\n\t\t    'struct'));\n\n\tif (typeof (value) == 'string') {\n\t\ttype = ctParseType(value);\n\t\tif (type['len'] !== undefined) {\n\t\t\tif (isNaN(parseInt(type['len'], 10)))\n\t\t\t\tthrow (new (Error('typedef value must use ' +\n\t\t\t\t    'fixed size array when outside of a ' +\n\t\t\t\t    'struct')));\n\t\t}\n\n\t\tthis.types[name] = value;\n\t} else {\n\t\t/* We have a struct, validate it */\n\t\tctCheckReq(value, this.types);\n\t\tthis.types[name] = value;\n\t}\n};\n\n/*\n * Include all of the typedefs, but none of the built in types. This should be\n * treated as read-only.\n */\nCTypeParser.prototype.lstypes = function ()\n{\n\tvar key;\n\tvar ret = {};\n\n\tfor (key in this.types) {\n\t\tif (key in deftypes)\n\t\t\tcontinue;\n\t\tret[key] = this.types[key];\n\t}\n\n\treturn (ret);\n};\n\n/*\n * Given a type string that may have array types that aren't numbers, try and\n * fill them in from the values object. The object should be of the format where\n * indexing into it should return a number for that type.\n *\n *\tstr\t\tThe type string\n *\n *\tvalues\t\tAn object that can be used to fulfill type information\n */\nfunction ctResolveArray(str, values)\n{\n\tvar ret = '';\n\tvar type = ctParseType(str);\n\n\twhile (type['len'] !== undefined) {\n\t\tif (isNaN(parseInt(type['len'], 10))) {\n\t\t\tif (typeof (values[type['len']]) != 'number')\n\t\t\t\tthrow (new Error('cannot sawp in non-number ' +\n\t\t\t\t    'for array value'));\n\t\t\tret = '[' + values[type['len']] + ']' + ret;\n\t\t} else {\n\t\t\tret = '[' + type['len'] + ']' + ret;\n\t\t}\n\t\ttype = ctParseType(type['type']);\n\t}\n\n\tret = type['type'] + ret;\n\n\treturn (ret);\n}\n\n/*\n * [private] Either the typedef resolves to another type string or to a struct.\n * If it resolves to a struct, we just pass it off to read struct. If not, we\n * can just pass it off to read entry.\n */\nCTypeParser.prototype.resolveTypedef = function (type, dispatch, buffer,\n    offset, value)\n{\n\tvar pt;\n\n\tmod_assert.ok(type in this.types);\n\tif (typeof (this.types[type]) == 'string') {\n\t\tpt = ctParseType(this.types[type]);\n\t\tif (dispatch == 'read')\n\t\t\treturn (this.readEntry(pt, buffer, offset));\n\t\telse if (dispatch == 'write')\n\t\t\treturn (this.writeEntry(value, pt, buffer, offset));\n\t\telse\n\t\t\tthrow (new Error('invalid dispatch type to ' +\n\t\t\t    'resolveTypedef'));\n\t} else {\n\t\tif (dispatch == 'read')\n\t\t\treturn (this.readStruct(this.types[type], buffer,\n\t\t\t    offset));\n\t\telse if (dispatch == 'write')\n\t\t\treturn (this.writeStruct(value, this.types[type],\n\t\t\t    buffer, offset));\n\t\telse\n\t\t\tthrow (new Error('invalid dispatch type to ' +\n\t\t\t    'resolveTypedef'));\n\t}\n\n};\n\n/*\n * [private] Try and read in the specific entry.\n */\nCTypeParser.prototype.readEntry = function (type, buffer, offset)\n{\n\tvar parse, len;\n\n\t/*\n\t * Because we want to special case char[]s this is unfortunately\n\t * a bit uglier than it really should be. We want to special\n\t * case char[]s so that we return a node buffer, thus they are a\n\t * first class type where as all other arrays just call into a\n\t * generic array routine which calls their data-specific routine\n\t * the specified number of times.\n\t *\n\t * The valid dispatch options we have are:\n\t *  - Array and char => char[] handler\n\t *  - Generic array handler\n\t *  - Generic typedef handler\n\t *  - Basic type handler\n\t */\n\tif (type['len'] !== undefined) {\n\t\tlen = parseInt(type['len'], 10);\n\t\tif (isNaN(len))\n\t\t\tthrow (new Error('somehow got a non-numeric length'));\n\n\t\tif (type['type'] == 'char')\n\t\t\tparse = this.types['char[]']['read'](len,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tparse = this.readArray(type['type'],\n\t\t\t    len, buffer, offset);\n\t} else {\n\t\tif (type['type'] in deftypes)\n\t\t\tparse = this.types[type['type']]['read'](this.endian,\n\t\t\t    buffer, offset);\n\t\telse\n\t\t\tparse = this.resolveTypedef(type['type'], 'read',\n\t\t\t    buffer, offset);\n\t}\n\n\treturn (parse);\n};\n\n/*\n * [private] Read an array of data\n */\nCTypeParser.prototype.readArray = function (type, length, buffer, offset)\n{\n\tvar ii, ent, pt;\n\tvar baseOffset = offset;\n\tvar ret = new Array(length);\n\tpt = ctParseType(type);\n\n\tfor (ii = 0; ii < length; ii++) {\n\t\tent = this.readEntry(pt, buffer, offset);\n\t\toffset += ent['size'];\n\t\tret[ii] = ent['value'];\n\t}\n\n\treturn ({ value: ret, size: offset - baseOffset });\n};\n\n/*\n * [private] Read a single struct in.\n */\nCTypeParser.prototype.readStruct = function (def, buffer, offset)\n{\n\tvar parse, ii, type, entry, key;\n\tvar baseOffset = offset;\n\tvar ret = {};\n\n\t/* Walk it and handle doing what's necessary */\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tentry = def[ii][key];\n\n\t\t/* Resolve all array values */\n\t\ttype = ctParseType(ctResolveArray(entry['type'], ret));\n\n\t\tif ('offset' in entry)\n\t\t\toffset = baseOffset + entry['offset'];\n\n\t\tparse = this.readEntry(type, buffer, offset);\n\n\t\toffset += parse['size'];\n\t\tret[key] = parse['value'];\n\t}\n\n\treturn ({ value: ret, size: (offset-baseOffset)});\n};\n\n/*\n * This is what we were born to do. We read the data from a buffer and return it\n * in an object whose keys match the values from the object.\n *\n *\tdef\t\tThe array definition of the data to read in\n *\n *\tbuffer\t\tThe buffer to read data from\n *\n *\toffset\t\tThe offset to start writing to\n *\n * Returns an object where each key corresponds to an entry in def and the value\n * is the read value.\n */\nCTypeParser.prototype.readData = function (def, buffer, offset)\n{\n\t/* Sanity check for arguments */\n\tif (def === undefined)\n\t\tthrow (new Error('missing definition for what we should be' +\n\t\t    'parsing'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer for what we should be ' +\n\t\t    'parsing'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset for what we should be ' +\n\t\t    'parsing'));\n\n\t/* Sanity check the object definition */\n\tctCheckReq(def, this.types);\n\n\treturn (this.readStruct(def, buffer, offset)['value']);\n};\n\n/*\n * [private] Write out an array of data\n */\nCTypeParser.prototype.writeArray = function (value, type, length, buffer,\n    offset)\n{\n\tvar ii, pt;\n\tvar baseOffset = offset;\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('asked to write an array, but value is not ' +\n\t\t    'an array'));\n\n\tif (value.length != length)\n\t\tthrow (new Error('asked to write array of length ' + length +\n\t\t    ' but that does not match value length: ' + value.length));\n\n\tpt = ctParseType(type);\n\tfor (ii = 0; ii < length; ii++)\n\t\toffset += this.writeEntry(value[ii], pt, buffer, offset);\n\n\treturn (offset - baseOffset);\n};\n\n/*\n * [private] Write the specific entry\n */\nCTypeParser.prototype.writeEntry = function (value, type, buffer, offset)\n{\n\tvar len, ret;\n\n\tif (type['len'] !== undefined) {\n\t\tlen = parseInt(type['len'], 10);\n\t\tif (isNaN(len))\n\t\t\tthrow (new Error('somehow got a non-numeric length'));\n\n\t\tif (type['type'] == 'char')\n\t\t\tret = this.types['char[]']['write'](value, len,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tret = this.writeArray(value, type['type'],\n\t\t\t    len, buffer, offset);\n\t} else {\n\t\tif (type['type'] in deftypes)\n\t\t\tret = this.types[type['type']]['write'](value,\n\t\t\t    this.endian, buffer, offset);\n\t\telse\n\t\t\tret = this.resolveTypedef(type['type'], 'write',\n\t\t\t    buffer, offset, value);\n\t}\n\n\treturn (ret);\n};\n\n/*\n * [private] Write a single struct out.\n */\nCTypeParser.prototype.writeStruct = function (value, def, buffer, offset)\n{\n\tvar ii, entry, type, key;\n\tvar baseOffset = offset;\n\tvar vals = {};\n\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tentry = def[ii][key];\n\n\t\ttype = ctParseType(ctResolveArray(entry['type'], vals));\n\n\t\tif ('offset' in entry)\n\t\t\toffset = baseOffset + entry['offset'];\n\n\t\toffset += this.writeEntry(value[ii], type, buffer, offset);\n\t\t/* Now that we've written it out, we can use it for arrays */\n\t\tvals[key] = value[ii];\n\t}\n\n\treturn (offset);\n};\n\n/*\n * Unfortunately, we're stuck with the sins of an initial poor design. Because\n * of that, we are going to have to support the old way of writing data via\n * writeData. There we insert the values that you want to write into the\n * definition. A little baroque. Internally, we use the new model. So we need to\n * just get those values out of there. But to maintain the principle of least\n * surprise, we're not going to modify the input data.\n */\nfunction getValues(def)\n{\n\tvar ii, out, key;\n\tout = [];\n\tfor (ii = 0; ii < def.length; ii++) {\n\t\tkey = Object.keys(def[ii])[0];\n\t\tmod_assert.ok('value' in def[ii][key]);\n\t\tout.push(def[ii][key]['value']);\n\t}\n\n\treturn (out);\n}\n\n/*\n * This is the second half of what we were born to do, write out the data\n * itself. Historically this function required you to put your values in the\n * definition section. This was not the smartest thing to do and a bit of an\n * oversight to be honest. As such, this function now takes a values argument.\n * If values is non-null and non-undefined, it will be used to determine the\n * values. This means that the old method is still supported, but is no longer\n * acceptable.\n *\n *\tdef\t\tThe array definition of the data to write out with\n *\t\t\tvalues\n *\n *\tbuffer\t\tThe buffer to write to\n *\n *\toffset\t\tThe offset in the buffer to write to\n *\n *\tvalues\t\tAn array of values to write.\n */\nCTypeParser.prototype.writeData = function (def, buffer, offset, values)\n{\n\tvar hv;\n\n\tif (def === undefined)\n\t\tthrow (new Error('missing definition for what we should be' +\n\t\t    'parsing'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer for what we should be ' +\n\t\t    'parsing'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset for what we should be ' +\n\t\t    'parsing'));\n\n\thv = (values != null && values != undefined);\n\tif (hv) {\n\t\tif (!Array.isArray(values))\n\t\t\tthrow (new Error('missing values for writing'));\n\t\tctCheckReq(def, this.types);\n\t} else {\n\t\tctCheckReq(def, this.types, [ 'value' ]);\n\t}\n\n\tthis.writeStruct(hv ? values : getValues(def), def, buffer, offset);\n};\n\n/*\n * Functions to go to and from 64 bit numbers in a way that is compatible with\n * Javascript limitations. There are two sets. One where the user is okay with\n * an approximation and one where they are definitely not okay with an\n * approximation.\n */\n\n/*\n * Attempts to convert an array of two integers returned from rsint64 / ruint64\n * into an absolute 64 bit number. If however the value would exceed 2^52 this\n * will instead throw an error. The mantissa in a double is a 52 bit number and\n * rather than potentially give you a value that is an approximation this will\n * error. If you would rather an approximation, please see toApprox64.\n *\n *\tval\t\tAn array of two 32-bit integers\n */\nfunction toAbs64(val)\n{\n\tif (val === undefined)\n\t\tthrow (new Error('missing required arg: value'));\n\n\tif (!Array.isArray(val))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (val.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\t/* We have 20 bits worth of precision in this range */\n\tif (val[0] >= 0x100000)\n\t\tthrow (new Error('value would become approximated'));\n\n\treturn (val[0] * Math.pow(2, 32) + val[1]);\n}\n\n/*\n * Will return the 64 bit value as returned in an array from rsint64 / ruint64\n * to a value as close as it can. Note that Javascript stores all numbers as a\n * double and the mantissa only has 52 bits. Thus this version may approximate\n * the value.\n *\n *\tval\t\tAn array of two 32-bit integers\n */\nfunction toApprox64(val)\n{\n\tif (val === undefined)\n\t\tthrow (new Error('missing required arg: value'));\n\n\tif (!Array.isArray(val))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (val.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\treturn (Math.pow(2, 32) * val[0] + val[1]);\n}\n\nfunction parseCTF(json, conf)\n{\n\tvar ctype = new CTypeParser(conf);\n\tmod_ctf.ctfParseJson(json, ctype);\n\n\treturn (ctype);\n}\n\n/*\n * Export the few things we actually want to. Currently this is just the CType\n * Parser and ctio.\n */\nexports.Parser = CTypeParser;\nexports.toAbs64 = toAbs64;\nexports.toApprox64 = toApprox64;\n\nexports.parseCTF = parseCTF;\n\nexports.ruint8 = mod_ctio.ruint8;\nexports.ruint16 = mod_ctio.ruint16;\nexports.ruint32 = mod_ctio.ruint32;\nexports.ruint64 = mod_ctio.ruint64;\nexports.wuint8 = mod_ctio.wuint8;\nexports.wuint16 = mod_ctio.wuint16;\nexports.wuint32 = mod_ctio.wuint32;\nexports.wuint64 = mod_ctio.wuint64;\n\nexports.rsint8 = mod_ctio.rsint8;\nexports.rsint16 = mod_ctio.rsint16;\nexports.rsint32 = mod_ctio.rsint32;\nexports.rsint64 = mod_ctio.rsint64;\nexports.wsint8 = mod_ctio.wsint8;\nexports.wsint16 = mod_ctio.wsint16;\nexports.wsint32 = mod_ctio.wsint32;\nexports.wsint64 = mod_ctio.wsint64;\n\nexports.rfloat = mod_ctio.rfloat;\nexports.rdouble = mod_ctio.rdouble;\nexports.wfloat = mod_ctio.wfloat;\nexports.wdouble = mod_ctio.wdouble;\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "./ctf.js": {
                  "where": "inline"
                },
                "./ctio.js": {
                  "where": "inline"
                },
                "assert": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctf.js": {
            "requireId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctf.js",
            "memoizeId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctf.js",
            "descriptor": {
              "filename": "ctf.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/ctype/ctf.js",
              "mtime": 1349069100,
              "code": "/*\n * ctf.js\n *\n * Understand and parse all of the different JSON formats of CTF data and\n * translate that into a series of node-ctype friendly pieces. The reason for\n * the abstraction is to handle different changes in the file format.\n *\n * We have to be careful here that we don't end up using a name that is already\n * a built in type.\n */\nvar mod_assert = require('assert');\nvar ASSERT = mod_assert.ok;\n\nvar ctf_versions = [ '1.0' ];\nvar ctf_entries = [ 'integer', 'float', 'typedef', 'struct' ];\nvar ctf_deftypes = [ 'int8_t', 'uint8_t', 'int16_t', 'uint16_t', 'int32_t',\n    'uint32_t', 'float', 'double' ];\n\nfunction ctfParseInteger(entry, ctype)\n{\n\tvar name, sign, len, type;\n\n\tname = entry['name'];\n\tif (!('signed' in entry['integer']))\n\t\tthrow (new Error('Malformed CTF JSON: integer missing ' +\n\t\t    'signed value'));\n\n\n\tif (!('length' in entry['integer']))\n\t\tthrow (new Error('Malformed CTF JSON: integer missing ' +\n\t\t    'length value'));\n\n\tsign = entry['integer']['signed'];\n\tlen = entry['integer']['length'];\n\ttype = null;\n\n\tif (sign && len == 1)\n\t\ttype = 'int8_t';\n\telse if (len == 1)\n\t\ttype = 'uint8_t';\n\telse if (sign && len == 2)\n\t\ttype = 'int16_t';\n\telse if (len == 2)\n\t\ttype = 'uint16_t';\n\telse if (sign && len == 4)\n\t\ttype = 'int32_t';\n\telse if (len == 4)\n\t\ttype = 'uint32_t';\n\telse if (sign && len == 8)\n\t\ttype = 'int64_t';\n\telse if (len == 8)\n\t\ttype = 'uint64_t';\n\n\tif (type === null)\n\t\tthrow (new Error('Malformed CTF JSON: integer has ' +\n\t\t    'unsupported length and sign - ' + len + '/' + sign));\n\n\t/*\n\t * This means that this is the same as one of our built in types. If\n\t * that's the case defining it would be an error. So instead of trying\n\t * to typedef it, we'll return here.\n\t */\n\tif (name == type)\n\t\treturn;\n\n\tif (name == 'char') {\n\t\tASSERT(type == 'int8_t');\n\t\treturn;\n\t}\n\n\tctype.typedef(name, type);\n}\n\nfunction ctfParseFloat(entry, ctype)\n{\n\tvar name, len;\n\n\tname = entry['name'];\n\tif (!('length' in entry['float']))\n\t\tthrow (new Error('Malformed CTF JSON: float missing ' +\n\t\t    'length value'));\n\n\tlen = entry['float']['length'];\n\tif (len != 4 && len != 8)\n\t\tthrow (new Error('Malformed CTF JSON: float has invalid ' +\n\t\t    'length value'));\n\n\tif (len == 4) {\n\t\tif (name == 'float')\n\t\t\treturn;\n\t\tctype.typedef(name, 'float');\n\t} else if (len == 8) {\n\t\tif (name == 'double')\n\t\t\treturn;\n\t\tctype.typedef(name, 'double');\n\t}\n}\n\nfunction ctfParseTypedef(entry, ctype)\n{\n\tvar name, type, ii;\n\n\tname = entry['name'];\n\tif (typeof (entry['typedef']) != 'string')\n\t\tthrow (new Error('Malformed CTF JSON: typedef value in not ' +\n\t\t    'a string'));\n\n\ttype = entry['typedef'];\n\n\t/*\n\t * We need to ensure that we're not looking at type that's one of our\n\t * built in types. Traditionally in C a uint32_t would be a typedef to\n\t * some kind of integer. However, those size types are built ins.\n\t */\n\tfor (ii = 0; ii < ctf_deftypes.length; ii++) {\n\t\tif (name == ctf_deftypes[ii])\n\t\t\treturn;\n\t}\n\n\tctype.typedef(name, type);\n}\n\nfunction ctfParseStruct(entry, ctype)\n{\n\tvar name, type, ii, val, index, member, push;\n\n\tmember = [];\n\tif (!Array.isArray(entry['struct']))\n\t\tthrow (new Error('Malformed CTF JSON: struct value is not ' +\n\t\t    'an array'));\n\n\tfor (ii = 0; ii < entry['struct'].length; ii++) {\n\t\tval = entry['struct'][ii];\n\t\tif (!('name' in val))\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'missing name'));\n\n\t\tif (!('type' in val))\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'missing type'));\n\n\t\tif (typeof (val['name']) != 'string')\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'name isn\\'t a string'));\n\n\t\tif (typeof (val['type']) != 'string')\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'type isn\\'t a string'));\n\n\t\t/*\n\t\t * CTF version 2 specifies array names as <type> [<num>] where\n\t\t * as node-ctype does this as <type>[<num>].\n\t\t */\n\t\tname = val['name'];\n\t\ttype = val['type'];\n\t\tindex = type.indexOf(' [');\n\t\tif (index != -1) {\n\t\t\ttype = type.substring(0, index) +\n\t\t\t    type.substring(index + 1, type.length);\n\t\t}\n\t\tpush = {};\n\t\tpush[name] = { 'type': type };\n\t\tmember.push(push);\n\t}\n\n\tname = entry['name'];\n\tctype.typedef(name, member);\n}\n\nfunction ctfParseEntry(entry, ctype)\n{\n\tvar ii, found;\n\n\tif (!('name' in entry))\n\t\tthrow (new Error('Malformed CTF JSON: entry missing \"name\" ' +\n\t\t    'section'));\n\n\tfor (ii = 0; ii < ctf_entries.length; ii++) {\n\t\tif (ctf_entries[ii] in entry)\n\t\t\tfound++;\n\t}\n\n\tif (found === 0)\n\t\tthrow (new Error('Malformed CTF JSON: found no entries'));\n\n\tif (found >= 2)\n\t\tthrow (new Error('Malformed CTF JSON: found more than one ' +\n\t\t    'entry'));\n\n\tif ('integer' in entry) {\n\t\tctfParseInteger(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('float' in entry) {\n\t\tctfParseFloat(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('typedef' in entry) {\n\t\tctfParseTypedef(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('struct' in entry) {\n\t\tctfParseStruct(entry, ctype);\n\t\treturn;\n\t}\n\n\tASSERT(false, 'shouldn\\'t reach here');\n}\n\nfunction ctfParseJson(json, ctype)\n{\n\tvar version, ii;\n\n\tASSERT(json);\n\tASSERT(ctype);\n\tif (!('metadata' in json))\n\t\tthrow (new Error('Invalid CTF JSON: missing metadata section'));\n\n\tif (!('ctf2json_version' in json['metadata']))\n\t\tthrow (new Error('Invalid CTF JSON: missing ctf2json_version'));\n\n\tversion = json['metadata']['ctf2json_version'];\n\tfor (ii = 0; ii < ctf_versions.length; ii++) {\n\t\tif (ctf_versions[ii] == version)\n\t\t\tbreak;\n\t}\n\n\tif (ii == ctf_versions.length)\n\t\tthrow (new Error('Unsuported ctf2json_version: ' + version));\n\n\tif (!('data' in json))\n\t\tthrow (new Error('Invalid CTF JSON: missing data section'));\n\n\tif (!Array.isArray(json['data']))\n\t\tthrow (new Error('Malformed CTF JSON: data section is not ' +\n\t\t    'an array'));\n\n\tfor (ii = 0; ii < json['data'].length; ii++)\n\t\tctfParseEntry(json['data'][ii], ctype);\n}\n\nexports.ctfParseJson = ctfParseJson;\n",
              "globals": {
                "mod_assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "ASSERT": {
                  "type": "assign"
                },
                "ctf_versions": {
                  "type": "assign"
                },
                "ctf_entries": {
                  "type": "assign"
                },
                "ctf_deftypes": {
                  "type": "assign"
                },
                "ctfParseInteger": {
                  "type": "assign"
                },
                "ctfParseFloat": {
                  "type": "assign"
                },
                "ctfParseTypedef": {
                  "type": "assign"
                },
                "ctfParseStruct": {
                  "type": "assign"
                },
                "Array": {
                  "type": "reference"
                },
                "ctfParseEntry": {
                  "type": "assign"
                },
                "ctfParseJson": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';\n/*\n * ctf.js\n *\n * Understand and parse all of the different JSON formats of CTF data and\n * translate that into a series of node-ctype friendly pieces. The reason for\n * the abstraction is to handle different changes in the file format.\n *\n * We have to be careful here that we don't end up using a name that is already\n * a built in type.\n */\nvar mod_assert = require('__SYSTEM__/assert');\nvar ASSERT = mod_assert.ok;\n\nvar ctf_versions = [ '1.0' ];\nvar ctf_entries = [ 'integer', 'float', 'typedef', 'struct' ];\nvar ctf_deftypes = [ 'int8_t', 'uint8_t', 'int16_t', 'uint16_t', 'int32_t',\n    'uint32_t', 'float', 'double' ];\n\nfunction ctfParseInteger(entry, ctype)\n{\n\tvar name, sign, len, type;\n\n\tname = entry['name'];\n\tif (!('signed' in entry['integer']))\n\t\tthrow (new Error('Malformed CTF JSON: integer missing ' +\n\t\t    'signed value'));\n\n\n\tif (!('length' in entry['integer']))\n\t\tthrow (new Error('Malformed CTF JSON: integer missing ' +\n\t\t    'length value'));\n\n\tsign = entry['integer']['signed'];\n\tlen = entry['integer']['length'];\n\ttype = null;\n\n\tif (sign && len == 1)\n\t\ttype = 'int8_t';\n\telse if (len == 1)\n\t\ttype = 'uint8_t';\n\telse if (sign && len == 2)\n\t\ttype = 'int16_t';\n\telse if (len == 2)\n\t\ttype = 'uint16_t';\n\telse if (sign && len == 4)\n\t\ttype = 'int32_t';\n\telse if (len == 4)\n\t\ttype = 'uint32_t';\n\telse if (sign && len == 8)\n\t\ttype = 'int64_t';\n\telse if (len == 8)\n\t\ttype = 'uint64_t';\n\n\tif (type === null)\n\t\tthrow (new Error('Malformed CTF JSON: integer has ' +\n\t\t    'unsupported length and sign - ' + len + '/' + sign));\n\n\t/*\n\t * This means that this is the same as one of our built in types. If\n\t * that's the case defining it would be an error. So instead of trying\n\t * to typedef it, we'll return here.\n\t */\n\tif (name == type)\n\t\treturn;\n\n\tif (name == 'char') {\n\t\tASSERT(type == 'int8_t');\n\t\treturn;\n\t}\n\n\tctype.typedef(name, type);\n}\n\nfunction ctfParseFloat(entry, ctype)\n{\n\tvar name, len;\n\n\tname = entry['name'];\n\tif (!('length' in entry['float']))\n\t\tthrow (new Error('Malformed CTF JSON: float missing ' +\n\t\t    'length value'));\n\n\tlen = entry['float']['length'];\n\tif (len != 4 && len != 8)\n\t\tthrow (new Error('Malformed CTF JSON: float has invalid ' +\n\t\t    'length value'));\n\n\tif (len == 4) {\n\t\tif (name == 'float')\n\t\t\treturn;\n\t\tctype.typedef(name, 'float');\n\t} else if (len == 8) {\n\t\tif (name == 'double')\n\t\t\treturn;\n\t\tctype.typedef(name, 'double');\n\t}\n}\n\nfunction ctfParseTypedef(entry, ctype)\n{\n\tvar name, type, ii;\n\n\tname = entry['name'];\n\tif (typeof (entry['typedef']) != 'string')\n\t\tthrow (new Error('Malformed CTF JSON: typedef value in not ' +\n\t\t    'a string'));\n\n\ttype = entry['typedef'];\n\n\t/*\n\t * We need to ensure that we're not looking at type that's one of our\n\t * built in types. Traditionally in C a uint32_t would be a typedef to\n\t * some kind of integer. However, those size types are built ins.\n\t */\n\tfor (ii = 0; ii < ctf_deftypes.length; ii++) {\n\t\tif (name == ctf_deftypes[ii])\n\t\t\treturn;\n\t}\n\n\tctype.typedef(name, type);\n}\n\nfunction ctfParseStruct(entry, ctype)\n{\n\tvar name, type, ii, val, index, member, push;\n\n\tmember = [];\n\tif (!Array.isArray(entry['struct']))\n\t\tthrow (new Error('Malformed CTF JSON: struct value is not ' +\n\t\t    'an array'));\n\n\tfor (ii = 0; ii < entry['struct'].length; ii++) {\n\t\tval = entry['struct'][ii];\n\t\tif (!('name' in val))\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'missing name'));\n\n\t\tif (!('type' in val))\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'missing type'));\n\n\t\tif (typeof (val['name']) != 'string')\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'name isn\\'t a string'));\n\n\t\tif (typeof (val['type']) != 'string')\n\t\t\tthrow (new Error('Malformed CTF JSON: struct member ' +\n\t\t\t    'type isn\\'t a string'));\n\n\t\t/*\n\t\t * CTF version 2 specifies array names as <type> [<num>] where\n\t\t * as node-ctype does this as <type>[<num>].\n\t\t */\n\t\tname = val['name'];\n\t\ttype = val['type'];\n\t\tindex = type.indexOf(' [');\n\t\tif (index != -1) {\n\t\t\ttype = type.substring(0, index) +\n\t\t\t    type.substring(index + 1, type.length);\n\t\t}\n\t\tpush = {};\n\t\tpush[name] = { 'type': type };\n\t\tmember.push(push);\n\t}\n\n\tname = entry['name'];\n\tctype.typedef(name, member);\n}\n\nfunction ctfParseEntry(entry, ctype)\n{\n\tvar ii, found;\n\n\tif (!('name' in entry))\n\t\tthrow (new Error('Malformed CTF JSON: entry missing \"name\" ' +\n\t\t    'section'));\n\n\tfor (ii = 0; ii < ctf_entries.length; ii++) {\n\t\tif (ctf_entries[ii] in entry)\n\t\t\tfound++;\n\t}\n\n\tif (found === 0)\n\t\tthrow (new Error('Malformed CTF JSON: found no entries'));\n\n\tif (found >= 2)\n\t\tthrow (new Error('Malformed CTF JSON: found more than one ' +\n\t\t    'entry'));\n\n\tif ('integer' in entry) {\n\t\tctfParseInteger(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('float' in entry) {\n\t\tctfParseFloat(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('typedef' in entry) {\n\t\tctfParseTypedef(entry, ctype);\n\t\treturn;\n\t}\n\n\tif ('struct' in entry) {\n\t\tctfParseStruct(entry, ctype);\n\t\treturn;\n\t}\n\n\tASSERT(false, 'shouldn\\'t reach here');\n}\n\nfunction ctfParseJson(json, ctype)\n{\n\tvar version, ii;\n\n\tASSERT(json);\n\tASSERT(ctype);\n\tif (!('metadata' in json))\n\t\tthrow (new Error('Invalid CTF JSON: missing metadata section'));\n\n\tif (!('ctf2json_version' in json['metadata']))\n\t\tthrow (new Error('Invalid CTF JSON: missing ctf2json_version'));\n\n\tversion = json['metadata']['ctf2json_version'];\n\tfor (ii = 0; ii < ctf_versions.length; ii++) {\n\t\tif (ctf_versions[ii] == version)\n\t\t\tbreak;\n\t}\n\n\tif (ii == ctf_versions.length)\n\t\tthrow (new Error('Unsuported ctf2json_version: ' + version));\n\n\tif (!('data' in json))\n\t\tthrow (new Error('Invalid CTF JSON: missing data section'));\n\n\tif (!Array.isArray(json['data']))\n\t\tthrow (new Error('Malformed CTF JSON: data section is not ' +\n\t\t    'an array'));\n\n\tfor (ii = 0; ii < json['data'].length; ii++)\n\t\tctfParseEntry(json['data'][ii], ctype);\n}\n\nexports.ctfParseJson = ctfParseJson;\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctio.js": {
            "requireId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctio.js",
            "memoizeId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctio.js",
            "descriptor": {
              "filename": "ctio.js",
              "filepath": "node_modules/request/node_modules/http-signature/node_modules/ctype/ctio.js",
              "mtime": 1349069100,
              "code": "/*\n * rm - Feb 2011\n * ctio.js:\n *\n * A simple way to read and write simple ctypes. Of course, as you'll find the\n * code isn't as simple as it might appear. The following types are currently\n * supported in big and little endian formats:\n *\n * \tuint8_t\t\t\tint8_t\n * \tuint16_t\t\tint16_t\n * \tuint32_t\t\tint32_t\n *\tfloat (single precision IEEE 754)\n *\tdouble (double precision IEEE 754)\n *\n * This is designed to work in Node and v8. It may in fact work in other\n * Javascript interpreters (that'd be pretty neat), but it hasn't been tested.\n * If you find that it does in fact work, that's pretty cool. Try and pass word\n * back to the original author.\n *\n * Note to the reader: If you're tabstop isn't set to 8, parts of this may look\n * weird.\n */\n\n/*\n * Numbers in Javascript have a secret: all numbers must be represented with an\n * IEEE-754 double. The double has a mantissa with a length of 52 bits with an\n * implicit one. Thus the range of integers that can be represented is limited\n * to the size of the mantissa, this makes reading and writing 64-bit integers\n * difficult, but far from impossible.\n *\n * Another side effect of this representation is what happens when you use the\n * bitwise operators, i.e. shift left, shift right, and, or, etc. In Javascript,\n * each operand and the result is cast to a signed 32-bit number. However, in\n * the case of >>> the values are cast to an unsigned number.\n */\n\n/*\n * A reminder on endian related issues:\n *\n * Big Endian: MSB -> First byte\n * Little Endian: MSB->Last byte\n */\nvar mod_assert = require('assert');\n\n/*\n * An 8 bit unsigned integer involves doing no significant work.\n */\nfunction ruint8(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (buffer[offset]);\n}\n\n/*\n * For 16 bit unsigned numbers we can do all the casting that we want to do.\n */\nfunction rgint16(buffer, endian, offset)\n{\n\tvar val = 0;\n\n\tif (endian == 'big') {\n\t\tval = buffer[offset] << 8;\n\t\tval |=  buffer[offset+1];\n\t} else {\n\t\tval = buffer[offset];\n\t\tval |= buffer[offset+1] << 8;\n\t}\n\n\treturn (val);\n\n}\n\nfunction ruint16(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint16(buffer, endian, offset));\n}\n\n/*\n * Because most bitshifting is done using signed numbers, if we would go into\n * the realm where we use that 32nd bit, we'll end up going into the negative\n * range. i.e.:\n * > 200 << 24\n * -939524096\n *\n * Not the value you'd expect. To work around this, we end up having to do some\n * abuse of the JavaScript standard. in this case, we know that a >>> shift is\n * defined to cast our value to an *unsigned* 32-bit number. Because of that, we\n * use that instead to save us some additional math, though it does feel a\n * little weird and it isn't obvious as to why you woul dwant to do this at\n * first.\n */\nfunction rgint32(buffer, endian, offset)\n{\n\tvar val = 0;\n\n\tif (endian == 'big') {\n\t\tval = buffer[offset+1] << 16;\n\t\tval |= buffer[offset+2] << 8;\n\t\tval |= buffer[offset+3];\n\t\tval = val + (buffer[offset] << 24 >>> 0);\n\t} else {\n\t\tval = buffer[offset+2] << 16;\n\t\tval |= buffer[offset+1] << 8;\n\t\tval |= buffer[offset];\n\t\tval = val + (buffer[offset + 3] << 24 >>> 0);\n\t}\n\n\treturn (val);\n}\n\nfunction ruint32(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint32(buffer, endian, offset));\n}\n\n/*\n * Reads a 64-bit unsigned number. The astue observer will note that this\n * doesn't quite work. Javascript has chosen to only have numbers that can be\n * represented by a double. A double only has 52 bits of mantissa with an\n * implicit 1, thus we have up to 53 bits to represent an integer. However, 2^53\n * doesn't quite give us what we want. Isn't 53 bits enough for anyone? What\n * could you have possibly wanted to represent that was larger than that? Oh,\n * maybe a size? You mean we bypassed the 4 GB limit on file sizes, when did\n * that happen?\n *\n * To get around this egregious language issue, we're going to instead construct\n * an array of two 32 bit unsigned integers. Where arr[0] << 32 + arr[1] would\n * give the actual number. However, note that the above code probably won't\n * produce the desired results because of the way Javascript numbers are\n * doubles.\n */\nfunction rgint64(buffer, endian, offset)\n{\n\tvar val = new Array(2);\n\n\tif (endian == 'big') {\n\t\tval[0] = ruint32(buffer, endian, offset);\n\t\tval[1] = ruint32(buffer, endian, offset+4);\n\t} else {\n\t\tval[0] = ruint32(buffer, endian, offset+4);\n\t\tval[1] = ruint32(buffer, endian, offset);\n\t}\n\n\treturn (val);\n}\n\nfunction ruint64(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint64(buffer, endian, offset));\n}\n\n\n/*\n * Signed integer types, yay team! A reminder on how two's complement actually\n * works. The first bit is the signed bit, i.e. tells us whether or not the\n * number should be positive or negative. If the two's complement value is\n * positive, then we're done, as it's equivalent to the unsigned representation.\n *\n * Now if the number is positive, you're pretty much done, you can just leverage\n * the unsigned translations and return those. Unfortunately, negative numbers\n * aren't quite that straightforward.\n *\n * At first glance, one might be inclined to use the traditional formula to\n * translate binary numbers between the positive and negative values in two's\n * complement. (Though it doesn't quite work for the most negative value)\n * Mainly:\n *  - invert all the bits\n *  - add one to the result\n *\n * Of course, this doesn't quite work in Javascript. Take for example the value\n * of -128. This could be represented in 16 bits (big-endian) as 0xff80. But of\n * course, Javascript will do the following:\n *\n * > ~0xff80\n * -65409\n *\n * Whoh there, Javascript, that's not quite right. But wait, according to\n * Javascript that's perfectly correct. When Javascript ends up seeing the\n * constant 0xff80, it has no notion that it is actually a signed number. It\n * assumes that we've input the unsigned value 0xff80. Thus, when it does the\n * binary negation, it casts it into a signed value, (positive 0xff80). Then\n * when you perform binary negation on that, it turns it into a negative number.\n *\n * Instead, we're going to have to use the following general formula, that works\n * in a rather Javascript friendly way. I'm glad we don't support this kind of\n * weird numbering scheme in the kernel.\n *\n * (BIT-MAX - (unsigned)val + 1) * -1\n *\n * The astute observer, may think that this doesn't make sense for 8-bit numbers\n * (really it isn't necessary for them). However, when you get 16-bit numbers,\n * you do. Let's go back to our prior example and see how this will look:\n *\n * (0xffff - 0xff80 + 1) * -1\n * (0x007f + 1) * -1\n * (0x0080) * -1\n *\n * Doing it this way ends up allowing us to treat it appropriately in\n * Javascript. Sigh, that's really quite ugly for what should just be a few bit\n * shifts, ~ and &.\n */\n\n/*\n * Endianness doesn't matter for 8-bit signed values. We could in fact optimize\n * this case because the more traditional methods work, but for consistency,\n * we'll keep doing this the same way.\n */\nfunction rsint8(buffer, endian, offset)\n{\n\tvar neg;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tneg = buffer[offset] & 0x80;\n\tif (!neg)\n\t\treturn (buffer[offset]);\n\n\treturn ((0xff - buffer[offset] + 1) * -1);\n}\n\n/*\n * The 16-bit version requires a bit more effort. In this case, we can leverage\n * our unsigned code to generate the value we want to return.\n */\nfunction rsint16(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint16(buffer, endian, offset);\n\tneg = val & 0x8000;\n\tif (!neg)\n\t\treturn (val);\n\n\treturn ((0xffff - val + 1) * -1);\n}\n\n/*\n * We really shouldn't leverage our 32-bit code here and instead utilize the\n * fact that we know that since these are signed numbers, we can do all the\n * shifting and binary anding to generate the 32-bit number. But, for\n * consistency we'll do the same. If we want to do otherwise, we should instead\n * make the 32 bit unsigned code do the optimization. But as long as there\n * aren't floats secretly under the hood for that, we /should/ be okay.\n */\nfunction rsint32(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint32(buffer, endian, offset);\n\tneg = val & 0x80000000;\n\tif (!neg)\n\t\treturn (val);\n\n\treturn ((0xffffffff - val + 1) * -1);\n}\n\n/*\n * The signed version of this code suffers from all of the same problems of the\n * other 64 bit version.\n */\nfunction rsint64(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint64(buffer, endian, offset);\n\tneg = val[0] & 0x80000000;\n\n\tif (!neg)\n\t\treturn (val);\n\n\tval[0] = (0xffffffff - val[0]) * -1;\n\tval[1] = (0xffffffff - val[1] + 1) * -1;\n\n\t/*\n\t * If we had the key 0x8000000000000000, that would leave the lower 32\n\t * bits as 0xffffffff, however, since we're goint to add one, that would\n\t * actually leave the lower 32-bits as 0x100000000, which would break\n\t * our ability to write back a value that we received. To work around\n\t * this, if we actually get that value, we're going to bump the upper\n\t * portion by 1 and set this to zero.\n\t */\n\tmod_assert.ok(val[1] <= 0x100000000);\n\tif (val[1] == -0x100000000) {\n\t\tval[1] = 0;\n\t\tval[0]--;\n\t}\n\n\treturn (val);\n}\n\n/*\n * We now move onto IEEE 754: The traditional form for floating point numbers\n * and what is secretly hiding at the heart of everything in this. I really hope\n * that someone is actually using this, as otherwise, this effort is probably\n * going to be more wasted.\n *\n * One might be tempted to use parseFloat here, but that wouldn't work at all\n * for several reasons. Mostly due to the way floats actually work, and\n * parseFloat only actually works in base 10. I don't see base 10 anywhere near\n * this file.\n *\n * In this case we'll implement the single and double precision versions. The\n * quadruple precision, while probably useful, wouldn't really be accepted by\n * Javascript, so let's not even waste our time.\n *\n * So let's review how this format looks like. A single precision value is 32\n * bits and has three parts:\n *   -  Sign bit\n *   -  Exponent (Using bias notation)\n *   -  Mantissa\n *\n * |s|eeeeeeee|mmmmmmmmmmmmmmmmmmmmmmmmm|\n * 31| 30-23  |  22    \t-       0       |\n *\n * The exponent is stored in a biased input. The bias in this case 127.\n * Therefore, our exponent is equal to the 8-bit value - 127.\n *\n * By default, a number is normalized in IEEE, that means that the mantissa has\n * an implicit one that we don't see. So really the value stored is 1.m.\n * However, if the exponent is all zeros, then instead we have to shift\n * everything to the right one and there is no more implicit one.\n *\n * Special values:\n *  - Positive Infinity:\n *\tSign:\t\t0\n *\tExponent: \tAll 1s\n *\tMantissa:\t0\n *  - Negative Infinity:\n *\tSign:\t\t1\n *\tExponent: \tAll 1s\n *\tMantissa:\t0\n *  - NaN:\n *\tSign:\t\t*\n *\tExponent: \tAll 1s\n *\tMantissa:\tnon-zero\n *  - Zero:\n *\tSign:\t\t*\n *\tExponent:\tAll 0s\n *\tMantissa:\t0\n *\n * In the case of zero, the sign bit determines whether we get a positive or\n * negative zero. However, since Javascript cannot determine the difference\n * between the two: i.e. -0 == 0, we just always return 0.\n *\n */\nfunction rfloat(buffer, endian, offset)\n{\n\tvar bytes = [];\n\tvar sign, exponent, mantissa, val;\n\tvar bias = 127;\n\tvar maxexp = 0xff;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/* Normalize the bytes to be in endian order */\n\tif (endian == 'big') {\n\t\tbytes[0] = buffer[offset];\n\t\tbytes[1] = buffer[offset+1];\n\t\tbytes[2] = buffer[offset+2];\n\t\tbytes[3] = buffer[offset+3];\n\t} else {\n\t\tbytes[3] = buffer[offset];\n\t\tbytes[2] = buffer[offset+1];\n\t\tbytes[1] = buffer[offset+2];\n\t\tbytes[0] = buffer[offset+3];\n\t}\n\n\tsign = bytes[0] & 0x80;\n\texponent = (bytes[0] & 0x7f) << 1;\n\texponent |= (bytes[1] & 0x80) >>> 7;\n\tmantissa = (bytes[1] & 0x7f) << 16;\n\tmantissa |= bytes[2] << 8;\n\tmantissa |= bytes[3];\n\n\t/* Check for special cases before we do general parsing */\n\tif (!sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.POSITIVE_INFINITY);\n\n\tif (sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.NEGATIVE_INFINITY);\n\n\tif (exponent == maxexp && mantissa !== 0)\n\t\treturn (Number.NaN);\n\n\t/*\n\t * Javascript really doesn't have support for positive or negative zero.\n\t * So we're not going to try and give it to you. That would be just\n\t * plain weird. Besides -0 == 0.\n\t */\n\tif (exponent === 0 && mantissa === 0)\n\t\treturn (0);\n\n\t/*\n\t * Now we can deal with the bias and the determine whether the mantissa\n\t * has the implicit one or not.\n\t */\n\texponent -= bias;\n\tif (exponent == -bias) {\n\t\texponent++;\n\t\tval = 0;\n\t} else {\n\t\tval = 1;\n\t}\n\n\tval = (val + mantissa * Math.pow(2, -23)) * Math.pow(2, exponent);\n\n\tif (sign)\n\t\tval *= -1;\n\n\treturn (val);\n}\n\n/*\n * Doubles in IEEE 754 are like their brothers except for a few changes and\n * increases in size:\n *   - The exponent is now 11 bits\n *   - The mantissa is now 52 bits\n *   - The bias is now 1023\n *\n * |s|eeeeeeeeeee|mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm|\n * 63| 62 - 52   | \t51\t\t-\t\t\t0     |\n * 63| 62 - 52   |      51              -                       0     |\n *\n * While the size has increased a fair amount, we're going to end up keeping the\n * same general formula for calculating the final value. As a reminder, this\n * formula is:\n *\n * (-1)^s * (n + m) * 2^(e-b)\n *\n * Where:\n *\ts\tis the sign bit\n *\tn\tis (exponent > 0) ? 1 : 0 -- Determines whether we're normalized\n *\t\t\t\t\t     or not\n *\tm\tis the mantissa\n *\te\tis the exponent specified\n *\tb\tis the bias for the exponent\n *\n */\nfunction rdouble(buffer, endian, offset)\n{\n\tvar bytes = [];\n\tvar sign, exponent, mantissa, val, lowmant;\n\tvar bias = 1023;\n\tvar maxexp = 0x7ff;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/* Normalize the bytes to be in endian order */\n\tif (endian == 'big') {\n\t\tbytes[0] = buffer[offset];\n\t\tbytes[1] = buffer[offset+1];\n\t\tbytes[2] = buffer[offset+2];\n\t\tbytes[3] = buffer[offset+3];\n\t\tbytes[4] = buffer[offset+4];\n\t\tbytes[5] = buffer[offset+5];\n\t\tbytes[6] = buffer[offset+6];\n\t\tbytes[7] = buffer[offset+7];\n\t} else {\n\t\tbytes[7] = buffer[offset];\n\t\tbytes[6] = buffer[offset+1];\n\t\tbytes[5] = buffer[offset+2];\n\t\tbytes[4] = buffer[offset+3];\n\t\tbytes[3] = buffer[offset+4];\n\t\tbytes[2] = buffer[offset+5];\n\t\tbytes[1] = buffer[offset+6];\n\t\tbytes[0] = buffer[offset+7];\n\t}\n\n\t/*\n\t * We can construct the exponent and mantissa the same way as we did in\n\t * the case of a float, just increase the range of the exponent.\n\t */\n\tsign = bytes[0] & 0x80;\n\texponent = (bytes[0] & 0x7f) << 4;\n\texponent |= (bytes[1] & 0xf0) >>> 4;\n\n\t/*\n\t * This is going to be ugly but then again, we're dealing with IEEE 754.\n\t * This could probably be done as a node add on in a few lines of C++,\n\t * but oh we'll, we've made it this far so let's be native the rest of\n\t * the way...\n\t *\n\t * What we're going to do is break the mantissa into two parts, the\n\t * lower 24 bits and the upper 28 bits. We'll multiply the upper 28 bits\n\t * by the appropriate power and then add in the lower 24-bits. Not\n\t * really that great. It's pretty much a giant kludge to deal with\n\t * Javascript eccentricities around numbers.\n\t */\n\tlowmant = bytes[7];\n\tlowmant |= bytes[6] << 8;\n\tlowmant |= bytes[5] << 16;\n\tmantissa = bytes[4];\n\tmantissa |= bytes[3] << 8;\n\tmantissa |= bytes[2] << 16;\n\tmantissa |= (bytes[1] & 0x0f) << 24;\n\tmantissa *= Math.pow(2, 24); /* Equivalent to << 24, but JS compat */\n\tmantissa += lowmant;\n\n\t/* Check for special cases before we do general parsing */\n\tif (!sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.POSITIVE_INFINITY);\n\n\tif (sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.NEGATIVE_INFINITY);\n\n\tif (exponent == maxexp && mantissa !== 0)\n\t\treturn (Number.NaN);\n\n\t/*\n\t * Javascript really doesn't have support for positive or negative zero.\n\t * So we're not going to try and give it to you. That would be just\n\t * plain weird. Besides -0 == 0.\n\t */\n\tif (exponent === 0 && mantissa === 0)\n\t\treturn (0);\n\n\t/*\n\t * Now we can deal with the bias and the determine whether the mantissa\n\t * has the implicit one or not.\n\t */\n\texponent -= bias;\n\tif (exponent == -bias) {\n\t\texponent++;\n\t\tval = 0;\n\t} else {\n\t\tval = 1;\n\t}\n\n\tval = (val + mantissa * Math.pow(2, -52)) * Math.pow(2, exponent);\n\n\tif (sign)\n\t\tval *= -1;\n\n\treturn (val);\n}\n\n/*\n * Now that we have gone through the pain of reading the individual types, we're\n * probably going to want some way to write these back. None of this is going to\n * be good. But since we have Javascript numbers this should certainly be more\n * interesting. Though we can constrain this end a little bit more in what is\n * valid. For now, let's go back to our friends the unsigned value.\n */\n\n/*\n * Unsigned numbers seem deceptively easy. Here are the general steps and rules\n * that we are going to take:\n *   -  If the number is negative, throw an Error\n *   -  Truncate any floating point portion\n *   -  Take the modulus of the number in our base\n *   -  Write it out to the buffer in the endian format requested at the offset\n */\n\n/*\n * We have to make sure that the value is a valid integer. This means that it is\n * non-negative. It has no fractional component and that it does not exceed the\n * maximum allowed value.\n *\n *\tvalue\t\tThe number to check for validity\n *\n *\tmax\t\tThe maximum value\n */\nfunction prepuint(value, max)\n{\n\tif (typeof (value) != 'number')\n\t\tthrow (new (Error('cannot write a non-number as a number')));\n\n\tif (value < 0)\n\t\tthrow (new Error('specified a negative value for writing an ' +\n\t\t    'unsigned value'));\n\n\tif (value > max)\n\t\tthrow (new Error('value is larger than maximum value for ' +\n\t\t    'type'));\n\n\tif (Math.floor(value) !== value)\n\t\tthrow (new Error('value has a fractional component'));\n\n\treturn (value);\n}\n\n/*\n * 8-bit version, classy. We can ignore endianness which is good.\n */\nfunction wuint8(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xff);\n\tbuffer[offset] = val;\n}\n\n/*\n * Pretty much the same as the 8-bit version, just this time we need to worry\n * about endian related issues.\n */\nfunction wgint16(val, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\tbuffer[offset] = (val & 0xff00) >>> 8;\n\t\tbuffer[offset+1] = val & 0x00ff;\n\t} else {\n\t\tbuffer[offset+1] = (val & 0xff00) >>> 8;\n\t\tbuffer[offset] = val & 0x00ff;\n\t}\n}\n\nfunction wuint16(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xffff);\n\twgint16(val, endian, buffer, offset);\n}\n\n/*\n * The 32-bit version is going to have to be a little different unfortunately.\n * We can't quite bitshift to get the largest byte, because that would end up\n * getting us caught by the signed values.\n *\n * And yes, we do want to subtract out the lower part by default. This means\n * that when we do the division, it will be treated as a bit shift and we won't\n * end up generating a floating point value. If we did generate a floating point\n * value we'd have to truncate it intelligently, this saves us that problem and\n * may even be somewhat faster under the hood.\n */\nfunction wgint32(val, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\tbuffer[offset] = (val - (val & 0x00ffffff)) / Math.pow(2, 24);\n\t\tbuffer[offset+1] = (val >>> 16) & 0xff;\n\t\tbuffer[offset+2] = (val >>> 8) & 0xff;\n\t\tbuffer[offset+3] = val & 0xff;\n\t} else {\n\t\tbuffer[offset+3] = (val - (val & 0x00ffffff)) /\n\t\t    Math.pow(2, 24);\n\t\tbuffer[offset+2] = (val >>> 16) & 0xff;\n\t\tbuffer[offset+1] = (val >>> 8) & 0xff;\n\t\tbuffer[offset] = val & 0xff;\n\t}\n}\n\nfunction wuint32(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xffffffff);\n\twgint32(val, endian, buffer, offset);\n}\n\n/*\n * Unlike the other versions, we expect the value to be in the form of two\n * arrays where value[0] << 32 + value[1] would result in the value that we\n * want.\n */\nfunction wgint64(value, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\twgint32(value[0], endian, buffer, offset);\n\t\twgint32(value[1], endian, buffer, offset+4);\n\t} else {\n\t\twgint32(value[0], endian, buffer, offset+4);\n\t\twgint32(value[1], endian, buffer, offset);\n\t}\n}\n\nfunction wuint64(value, endian, buffer, offset)\n{\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (value.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tprepuint(value[0], 0xffffffff);\n\tprepuint(value[1], 0xffffffff);\n\twgint64(value, endian, buffer, offset);\n}\n\n/*\n * We now move onto our friends in the signed number category. Unlike unsigned\n * numbers, we're going to have to worry a bit more about how we put values into\n * arrays. Since we are only worrying about signed 32-bit values, we're in\n * slightly better shape. Unfortunately, we really can't do our favorite binary\n * & in this system. It really seems to do the wrong thing. For example:\n *\n * > -32 & 0xff\n * 224\n *\n * What's happening above is really: 0xe0 & 0xff = 0xe0. However, the results of\n * this aren't treated as a signed number. Ultimately a bad thing.\n *\n * What we're going to want to do is basically create the unsigned equivalent of\n * our representation and pass that off to the wuint* functions. To do that\n * we're going to do the following:\n *\n *  - if the value is positive\n *\twe can pass it directly off to the equivalent wuint\n *  - if the value is negative\n *\twe do the following computation:\n *\tmb + val + 1, where\n *\tmb\tis the maximum unsigned value in that byte size\n *\tval\tis the Javascript negative integer\n *\n *\n * As a concrete value, take -128. In signed 16 bits this would be 0xff80. If\n * you do out the computations:\n *\n * 0xffff - 128 + 1\n * 0xffff - 127\n * 0xff80\n *\n * You can then encode this value as the signed version. This is really rather\n * hacky, but it should work and get the job done which is our goal here.\n *\n * Thus the overall flow is:\n *   -  Truncate the floating point part of the number\n *   -  We don't have to take the modulus, because the unsigned versions will\n *   \ttake care of that for us. And we don't have to worry about that\n *   \tpotentially causing bad things to happen because of sign extension\n *   -  Pass it off to the appropriate unsigned version, potentially modifying\n *\tthe negative portions as necessary.\n */\n\n/*\n * A series of checks to make sure we actually have a signed 32-bit number\n */\nfunction prepsint(value, max, min)\n{\n\tif (typeof (value) != 'number')\n\t\tthrow (new (Error('cannot write a non-number as a number')));\n\n\tif (value > max)\n\t\tthrow (new Error('value larger than maximum allowed value'));\n\n\tif (value < min)\n\t\tthrow (new Error('value smaller than minimum allowed value'));\n\n\tif (Math.floor(value) !== value)\n\t\tthrow (new Error('value has a fractional component'));\n\n\treturn (value);\n}\n\n/*\n * The 8-bit version of the signed value. Overall, fairly straightforward.\n */\nfunction wsint8(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7f, -0x80);\n\tif (val >= 0)\n\t\twuint8(val, endian, buffer, offset);\n\telse\n\t\twuint8(0xff + val + 1, endian, buffer, offset);\n}\n\n/*\n * The 16-bit version of the signed value. Also, fairly straightforward.\n */\nfunction wsint16(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7fff, -0x8000);\n\tif (val >= 0)\n\t\twgint16(val, endian, buffer, offset);\n\telse\n\t\twgint16(0xffff + val + 1, endian, buffer, offset);\n\n}\n\n/*\n * We can do this relatively easily by leveraging the code used for 32-bit\n * unsigned code.\n */\nfunction wsint32(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7fffffff, -0x80000000);\n\tif (val >= 0)\n\t\twgint32(val, endian, buffer, offset);\n\telse\n\t\twgint32(0xffffffff + val + 1, endian, buffer, offset);\n}\n\n/*\n * The signed 64 bit integer should by in the same format as when received.\n * Mainly it should ensure that the value is an array of two integers where\n * value[0] << 32 + value[1] is the desired number. Furthermore, the two values\n * need to be equal.\n */\nfunction wsint64(value, endian, buffer, offset)\n{\n\tvar vzpos, vopos;\n\tvar vals = new Array(2);\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (value.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/*\n\t * We need to make sure that we have the same sign on both values. The\n\t * hokiest way to to do this is to multiply the number by +inf. If we do\n\t * this, we'll get either +/-inf depending on the sign of the value.\n\t * Once we have this, we can compare it to +inf to see if the number is\n\t * positive or not.\n\t */\n\tvzpos = (value[0] * Number.POSITIVE_INFINITY) ==\n\t    Number.POSITIVE_INFINITY;\n\tvopos = (value[1] * Number.POSITIVE_INFINITY) ==\n\t    Number.POSITIVE_INFINITY;\n\n\t/*\n\t * If either of these is zero, then we don't actually need this check.\n\t */\n\tif (value[0] != 0 && value[1] != 0 && vzpos != vopos)\n\t\tthrow (new Error('Both entries in the array must have ' +\n\t\t    'the same sign'));\n\n\t/*\n\t * Doing verification for a signed 64-bit integer is actually a big\n\t * trickier than it appears. We can't quite use our standard techniques\n\t * because we need to compare both sets of values. The first value is\n\t * pretty straightforward. If the first value is beond the extremes than\n\t * we error out. However, the valid range of the second value varies\n\t * based on the first one. If the first value is negative, and *not* the\n\t * largest negative value, than it can be any integer within the range [\n\t * 0, 0xffffffff ]. If it is the largest negative number, it must be\n\t * zero.\n\t *\n\t * If the first number is positive, than it doesn't matter what the\n\t * value is. We just simply have to make sure we have a valid positive\n\t * integer.\n\t */\n\tif (vzpos) {\n\t\tprepuint(value[0], 0x7fffffff);\n\t\tprepuint(value[1], 0xffffffff);\n\t} else {\n\t\tprepsint(value[0], 0, -0x80000000);\n\t\tprepsint(value[1], 0, -0xffffffff);\n\t\tif (value[0] == -0x80000000 && value[1] != 0)\n\t\t\tthrow (new Error('value smaller than minimum ' +\n\t\t\t    'allowed value'));\n\t}\n\n\t/* Fix negative numbers */\n\tif (value[0] < 0 || value[1] < 0) {\n\t\tvals[0] = 0xffffffff - Math.abs(value[0]);\n\t\tvals[1] = 0x100000000 - Math.abs(value[1]);\n\t\tif (vals[1] == 0x100000000) {\n\t\t\tvals[1] = 0;\n\t\t\tvals[0]++;\n\t\t}\n\t} else {\n\t\tvals[0] = value[0];\n\t\tvals[1] = value[1];\n\t}\n\twgint64(vals, endian, buffer, offset);\n}\n\n/*\n * Now we are moving onto the weirder of these, the float and double. For this\n * we're going to just have to do something that's pretty weird. First off, we\n * have no way to get at the underlying float representation, at least not\n * easily. But that doesn't mean we can't figure it out, we just have to use our\n * heads.\n *\n * One might propose to use Number.toString(2). Of course, this is not really\n * that good, because the ECMAScript 262 v3 Standard says the following Section\n * 15.7.4.2-Number.prototype.toString (radix):\n *\n * If radix is an integer from 2 to 36, but not 10, the result is a string, the\n * choice of which is implementation-dependent.\n *\n * Well that doesn't really help us one bit now does it? We could use the\n * standard base 10 version of the string, but that's just going to create more\n * errors as we end up trying to convert it back to a binary value. So, really\n * this just means we have to be non-lazy and parse the structure intelligently.\n *\n * First off, we can do the basic checks: NaN, positive and negative infinity.\n *\n * Now that those are done we can work backwards to generate the mantissa and\n * exponent.\n *\n * The first thing we need to do is determine the sign bit, easy to do, check\n * whether the value is less than 0. And convert the number to its absolute\n * value representation. Next, we need to determine if the value is less than\n * one or greater than or equal to one and from there determine what power was\n * used to get there. What follows is now specific to floats, though the general\n * ideas behind this will hold for doubles as well, but the exact numbers\n * involved will change.\n *\n * Once we have that power we can determine the exponent and the mantissa. Call\n * the value that has the number of bits to reach the power ebits. In the\n * general case they have the following values:\n *\n *\texponent\t127 + ebits\n *\tmantissa\tvalue * 2^(23 - ebits) & 0x7fffff\n *\n * In the case where the value of ebits is <= -127 we are now in the case where\n * we no longer have normalized numbers. In this case the values take on the\n * following values:\n *\n * \texponent\t0\n *\tmantissa\tvalue * 2^149 & 0x7fffff\n *\n * Once we have the values for the sign, mantissa, and exponent. We reconstruct\n * the four bytes as follows:\n *\n *\tbyte0\t\tsign bit and seven most significant bits from the exp\n *\t\t\tsign << 7 | (exponent & 0xfe) >>> 1\n *\n *\tbyte1\t\tlsb from the exponent and 7 top bits from the mantissa\n *\t\t\t(exponent & 0x01) << 7 | (mantissa & 0x7f0000) >>> 16\n *\n *\tbyte2\t\tbits 8-15 (zero indexing) from mantissa\n *\t\t\tmantissa & 0xff00 >> 8\n *\n *\tbyte3\t\tbits 0-7 from mantissa\n *\t\t\tmantissa & 0xff\n *\n * Once we have this we have to assign them into the buffer in proper endian\n * order.\n */\n\n/*\n * Compute the log base 2 of the value. Now, someone who remembers basic\n * properties of logarithms will point out that we could use the change of base\n * formula for logs, and in fact that would be astute, because that's what we'll\n * do for now. It feels cleaner, albeit it may be less efficient than just\n * iterating and dividing by 2. We may want to come back and revisit that some\n * day.\n */\nfunction log2(value)\n{\n\treturn (Math.log(value) / Math.log(2));\n}\n\n/*\n * Helper to determine the exponent of the number we're looking at.\n */\nfunction intexp(value)\n{\n\treturn (Math.floor(log2(value)));\n}\n\n/*\n * Helper to determine the exponent of the fractional part of the value.\n */\nfunction fracexp(value)\n{\n\treturn (Math.floor(log2(value)));\n}\n\nfunction wfloat(value, endian, buffer, offset)\n{\n\tvar sign, exponent, mantissa, ebits;\n\tvar bytes = [];\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tif (isNaN(value)) {\n\t\tsign = 0;\n\t\texponent = 0xff;\n\t\tmantissa = 23;\n\t} else if (value == Number.POSITIVE_INFINITY) {\n\t\tsign = 0;\n\t\texponent = 0xff;\n\t\tmantissa = 0;\n\t} else if (value == Number.NEGATIVE_INFINITY) {\n\t\tsign = 1;\n\t\texponent = 0xff;\n\t\tmantissa = 0;\n\t} else {\n\t\t/* Well we have some work to do */\n\n\t\t/* Thankfully the sign bit is trivial */\n\t\tif (value < 0) {\n\t\t\tsign = 1;\n\t\t\tvalue = Math.abs(value);\n\t\t} else {\n\t\t\tsign = 0;\n\t\t}\n\n\t\t/* Use the correct function to determine number of bits */\n\t\tif (value < 1)\n\t\t\tebits = fracexp(value);\n\t\telse\n\t\t\tebits = intexp(value);\n\n\t\t/* Time to deal with the issues surrounding normalization */\n\t\tif (ebits <= -127) {\n\t\t\texponent = 0;\n\t\t\tmantissa = (value * Math.pow(2, 149)) & 0x7fffff;\n\t\t} else {\n\t\t\texponent = 127 + ebits;\n\t\t\tmantissa = value * Math.pow(2, 23 - ebits);\n\t\t\tmantissa &= 0x7fffff;\n\t\t}\n\t}\n\n\tbytes[0] = sign << 7 | (exponent & 0xfe) >>> 1;\n\tbytes[1] = (exponent & 0x01) << 7 | (mantissa & 0x7f0000) >>> 16;\n\tbytes[2] = (mantissa & 0x00ff00) >>> 8;\n\tbytes[3] = mantissa & 0x0000ff;\n\n\tif (endian == 'big') {\n\t\tbuffer[offset] = bytes[0];\n\t\tbuffer[offset+1] = bytes[1];\n\t\tbuffer[offset+2] = bytes[2];\n\t\tbuffer[offset+3] = bytes[3];\n\t} else {\n\t\tbuffer[offset] = bytes[3];\n\t\tbuffer[offset+1] = bytes[2];\n\t\tbuffer[offset+2] = bytes[1];\n\t\tbuffer[offset+3] = bytes[0];\n\t}\n}\n\n/*\n * Now we move onto doubles. Doubles are similar to floats in pretty much all\n * ways except that the processing isn't quite as straightforward because we\n * can't always use shifting, i.e. we have > 32 bit values.\n *\n * We're going to proceed in an identical fashion to floats and utilize the same\n * helper functions. All that really is changing are the specific values that we\n * use to do the calculations. Thus, to review we have to do the following.\n *\n * First get the sign bit and convert the value to its absolute value\n * representation. Next, we determine the number of bits that we used to get to\n * the value, branching whether the value is greater than or less than 1. Once\n * we have that value which we will again call ebits, we have to do the\n * following in the general case:\n *\n *\texponent\t1023 + ebits\n *\tmantissa\t[value * 2^(52 - ebits)] % 2^52\n *\n * In the case where the value of ebits <= -1023 we no longer use normalized\n * numbers, thus like with floats we have to do slightly different processing:\n *\n *\texponent\t0\n *\tmantissa\t[value * 2^1074] % 2^52\n *\n * Once we have determined the sign, exponent and mantissa we can construct the\n * bytes as follows:\n *\n *\tbyte0\t\tsign bit and seven most significant bits form the exp\n *\t\t\tsign << 7 | (exponent & 0x7f0) >>> 4\n *\n *\tbyte1\t\tRemaining 4 bits from the exponent and the four most\n *\t\t\tsignificant bits from the mantissa 48-51\n *\t\t\t(exponent & 0x00f) << 4 | mantissa >>> 48\n *\n *\tbyte2\t\tBits 40-47 from the mantissa\n *\t\t\t(mantissa >>> 40) & 0xff\n *\n *\tbyte3\t\tBits 32-39 from the mantissa\n *\t\t\t(mantissa >>> 32) & 0xff\n *\n *\tbyte4\t\tBits 24-31 from the mantissa\n *\t\t\t(mantissa >>> 24) & 0xff\n *\n *\tbyte5\t\tBits 16-23 from the Mantissa\n *\t\t\t(mantissa >>> 16) & 0xff\n *\n *\tbyte6\t\tBits 8-15 from the mantissa\n *\t\t\t(mantissa >>> 8) & 0xff\n *\n *\tbyte7\t\tBits 0-7 from the mantissa\n *\t\t\tmantissa & 0xff\n *\n * Now we can't quite do the right shifting that we want in bytes 1 - 3, because\n * we'll have extended too far and we'll lose those values when we try and do\n * the shift. Instead we have to use an alternate approach. To try and stay out\n * of floating point, what we'll do is say that mantissa -= bytes[4-7] and then\n * divide by 2^32. Once we've done that we can use binary arithmetic. Oof,\n * that's ugly, but it seems to avoid using floating point (just based on how v8\n * seems to be optimizing for base 2 arithmetic).\n */\nfunction wdouble(value, endian, buffer, offset)\n{\n\tvar sign, exponent, mantissa, ebits;\n\tvar bytes = [];\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tif (isNaN(value)) {\n\t\tsign = 0;\n\t\texponent = 0x7ff;\n\t\tmantissa = 23;\n\t} else if (value == Number.POSITIVE_INFINITY) {\n\t\tsign = 0;\n\t\texponent = 0x7ff;\n\t\tmantissa = 0;\n\t} else if (value == Number.NEGATIVE_INFINITY) {\n\t\tsign = 1;\n\t\texponent = 0x7ff;\n\t\tmantissa = 0;\n\t} else {\n\t\t/* Well we have some work to do */\n\n\t\t/* Thankfully the sign bit is trivial */\n\t\tif (value < 0) {\n\t\t\tsign = 1;\n\t\t\tvalue = Math.abs(value);\n\t\t} else {\n\t\t\tsign = 0;\n\t\t}\n\n\t\t/* Use the correct function to determine number of bits */\n\t\tif (value < 1)\n\t\t\tebits = fracexp(value);\n\t\telse\n\t\t\tebits = intexp(value);\n\n\t\t/*\n\t\t * This is a total hack to determine a denormalized value.\n\t\t * Unfortunately, we sometimes do not get a proper value for\n\t\t * ebits, i.e. we lose the values that would get rounded off.\n\t\t *\n\t\t *\n\t\t * The astute observer may wonder why we would be\n\t\t * multiplying by two Math.pows rather than just summing\n\t\t * them. Well, that's to get around a small bug in the\n\t\t * way v8 seems to implement the function. On occasion\n\t\t * doing:\n\t\t *\n\t\t * foo * Math.pow(2, 1023 + 51)\n\t\t *\n\t\t * Causes us to overflow to infinity, where as doing:\n\t\t *\n\t\t * foo * Math.pow(2, 1023) * Math.pow(2, 51)\n\t\t *\n\t\t * Does not cause us to overflow. Go figure.\n\t\t *\n\t\t */\n\t\tif (value <= 2.225073858507201e-308 || ebits <= -1023) {\n\t\t\texponent = 0;\n\t\t\tmantissa = value * Math.pow(2, 1023) * Math.pow(2, 51);\n\t\t\tmantissa %= Math.pow(2, 52);\n\t\t} else {\n\t\t\t/*\n\t\t\t * We might have gotten fucked by our floating point\n\t\t\t * logarithm magic. This is rather crappy, but that's\n\t\t\t * our luck. If we just had a log base 2 or access to\n\t\t\t * the stupid underlying representation this would have\n\t\t\t * been much easier and we wouldn't have such stupid\n\t\t\t * kludges or hacks.\n\t\t\t */\n\t\t\tif (ebits > 1023)\n\t\t\t\tebits = 1023;\n\t\t\texponent = 1023 + ebits;\n\t\t\tmantissa = value * Math.pow(2, -ebits);\n\t\t\tmantissa *= Math.pow(2, 52);\n\t\t\tmantissa %= Math.pow(2, 52);\n\t\t}\n\t}\n\n\t/* Fill the bytes in backwards to deal with the size issues */\n\tbytes[7] = mantissa & 0xff;\n\tbytes[6] = (mantissa >>> 8) & 0xff;\n\tbytes[5] = (mantissa >>> 16) & 0xff;\n\tmantissa = (mantissa - (mantissa & 0xffffff)) / Math.pow(2, 24);\n\tbytes[4] = mantissa & 0xff;\n\tbytes[3] = (mantissa >>> 8) & 0xff;\n\tbytes[2] = (mantissa >>> 16) & 0xff;\n\tbytes[1] = (exponent & 0x00f) << 4 | mantissa >>> 24;\n\tbytes[0] = (sign << 7) | (exponent & 0x7f0) >>> 4;\n\n\tif (endian == 'big') {\n\t\tbuffer[offset] = bytes[0];\n\t\tbuffer[offset+1] = bytes[1];\n\t\tbuffer[offset+2] = bytes[2];\n\t\tbuffer[offset+3] = bytes[3];\n\t\tbuffer[offset+4] = bytes[4];\n\t\tbuffer[offset+5] = bytes[5];\n\t\tbuffer[offset+6] = bytes[6];\n\t\tbuffer[offset+7] = bytes[7];\n\t} else {\n\t\tbuffer[offset+7] = bytes[0];\n\t\tbuffer[offset+6] = bytes[1];\n\t\tbuffer[offset+5] = bytes[2];\n\t\tbuffer[offset+4] = bytes[3];\n\t\tbuffer[offset+3] = bytes[4];\n\t\tbuffer[offset+2] = bytes[5];\n\t\tbuffer[offset+1] = bytes[6];\n\t\tbuffer[offset] = bytes[7];\n\t}\n}\n\n/*\n * Actually export our work above. One might argue that we shouldn't expose\n * these interfaces and just force people to use the higher level abstractions\n * around this work. However, unlike say other libraries we've come across, this\n * interface has several properties: it makes sense, it's simple, and it's\n * useful.\n */\nexports.ruint8 = ruint8;\nexports.ruint16 = ruint16;\nexports.ruint32 = ruint32;\nexports.ruint64 = ruint64;\nexports.wuint8 = wuint8;\nexports.wuint16 = wuint16;\nexports.wuint32 = wuint32;\nexports.wuint64 = wuint64;\n\nexports.rsint8 = rsint8;\nexports.rsint16 = rsint16;\nexports.rsint32 = rsint32;\nexports.rsint64 = rsint64;\nexports.wsint8 = wsint8;\nexports.wsint16 = wsint16;\nexports.wsint32 = wsint32;\nexports.wsint64 = wsint64;\n\nexports.rfloat = rfloat;\nexports.rdouble = rdouble;\nexports.wfloat = wfloat;\nexports.wdouble = wdouble;\n",
              "globals": {
                "mod_assert": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "ruint8": {
                  "type": "assign"
                },
                "rgint16": {
                  "type": "assign"
                },
                "ruint16": {
                  "type": "assign"
                },
                "rgint32": {
                  "type": "assign"
                },
                "ruint32": {
                  "type": "assign"
                },
                "rgint64": {
                  "type": "assign"
                },
                "ruint64": {
                  "type": "assign"
                },
                "rsint8": {
                  "type": "assign"
                },
                "rsint16": {
                  "type": "assign"
                },
                "rsint32": {
                  "type": "assign"
                },
                "rsint64": {
                  "type": "assign"
                },
                "rfloat": {
                  "type": "assign"
                },
                "Number": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "rdouble": {
                  "type": "assign"
                },
                "prepuint": {
                  "type": "assign"
                },
                "wuint8": {
                  "type": "assign"
                },
                "wgint16": {
                  "type": "assign"
                },
                "wuint16": {
                  "type": "assign"
                },
                "wgint32": {
                  "type": "assign"
                },
                "wuint32": {
                  "type": "assign"
                },
                "wgint64": {
                  "type": "assign"
                },
                "wuint64": {
                  "type": "assign"
                },
                "prepsint": {
                  "type": "assign"
                },
                "wsint8": {
                  "type": "assign"
                },
                "wsint16": {
                  "type": "assign"
                },
                "wsint32": {
                  "type": "assign"
                },
                "wsint64": {
                  "type": "assign"
                },
                "log2": {
                  "type": "assign"
                },
                "intexp": {
                  "type": "assign"
                },
                "fracexp": {
                  "type": "assign"
                },
                "wfloat": {
                  "type": "assign"
                },
                "isNaN": {
                  "type": "call"
                },
                "wdouble": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "assert": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/http-signature/node_modules/ctype';\n/*\n * rm - Feb 2011\n * ctio.js:\n *\n * A simple way to read and write simple ctypes. Of course, as you'll find the\n * code isn't as simple as it might appear. The following types are currently\n * supported in big and little endian formats:\n *\n * \tuint8_t\t\t\tint8_t\n * \tuint16_t\t\tint16_t\n * \tuint32_t\t\tint32_t\n *\tfloat (single precision IEEE 754)\n *\tdouble (double precision IEEE 754)\n *\n * This is designed to work in Node and v8. It may in fact work in other\n * Javascript interpreters (that'd be pretty neat), but it hasn't been tested.\n * If you find that it does in fact work, that's pretty cool. Try and pass word\n * back to the original author.\n *\n * Note to the reader: If you're tabstop isn't set to 8, parts of this may look\n * weird.\n */\n\n/*\n * Numbers in Javascript have a secret: all numbers must be represented with an\n * IEEE-754 double. The double has a mantissa with a length of 52 bits with an\n * implicit one. Thus the range of integers that can be represented is limited\n * to the size of the mantissa, this makes reading and writing 64-bit integers\n * difficult, but far from impossible.\n *\n * Another side effect of this representation is what happens when you use the\n * bitwise operators, i.e. shift left, shift right, and, or, etc. In Javascript,\n * each operand and the result is cast to a signed 32-bit number. However, in\n * the case of >>> the values are cast to an unsigned number.\n */\n\n/*\n * A reminder on endian related issues:\n *\n * Big Endian: MSB -> First byte\n * Little Endian: MSB->Last byte\n */\nvar mod_assert = require('__SYSTEM__/assert');\n\n/*\n * An 8 bit unsigned integer involves doing no significant work.\n */\nfunction ruint8(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (buffer[offset]);\n}\n\n/*\n * For 16 bit unsigned numbers we can do all the casting that we want to do.\n */\nfunction rgint16(buffer, endian, offset)\n{\n\tvar val = 0;\n\n\tif (endian == 'big') {\n\t\tval = buffer[offset] << 8;\n\t\tval |=  buffer[offset+1];\n\t} else {\n\t\tval = buffer[offset];\n\t\tval |= buffer[offset+1] << 8;\n\t}\n\n\treturn (val);\n\n}\n\nfunction ruint16(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint16(buffer, endian, offset));\n}\n\n/*\n * Because most bitshifting is done using signed numbers, if we would go into\n * the realm where we use that 32nd bit, we'll end up going into the negative\n * range. i.e.:\n * > 200 << 24\n * -939524096\n *\n * Not the value you'd expect. To work around this, we end up having to do some\n * abuse of the JavaScript standard. in this case, we know that a >>> shift is\n * defined to cast our value to an *unsigned* 32-bit number. Because of that, we\n * use that instead to save us some additional math, though it does feel a\n * little weird and it isn't obvious as to why you woul dwant to do this at\n * first.\n */\nfunction rgint32(buffer, endian, offset)\n{\n\tvar val = 0;\n\n\tif (endian == 'big') {\n\t\tval = buffer[offset+1] << 16;\n\t\tval |= buffer[offset+2] << 8;\n\t\tval |= buffer[offset+3];\n\t\tval = val + (buffer[offset] << 24 >>> 0);\n\t} else {\n\t\tval = buffer[offset+2] << 16;\n\t\tval |= buffer[offset+1] << 8;\n\t\tval |= buffer[offset];\n\t\tval = val + (buffer[offset + 3] << 24 >>> 0);\n\t}\n\n\treturn (val);\n}\n\nfunction ruint32(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint32(buffer, endian, offset));\n}\n\n/*\n * Reads a 64-bit unsigned number. The astue observer will note that this\n * doesn't quite work. Javascript has chosen to only have numbers that can be\n * represented by a double. A double only has 52 bits of mantissa with an\n * implicit 1, thus we have up to 53 bits to represent an integer. However, 2^53\n * doesn't quite give us what we want. Isn't 53 bits enough for anyone? What\n * could you have possibly wanted to represent that was larger than that? Oh,\n * maybe a size? You mean we bypassed the 4 GB limit on file sizes, when did\n * that happen?\n *\n * To get around this egregious language issue, we're going to instead construct\n * an array of two 32 bit unsigned integers. Where arr[0] << 32 + arr[1] would\n * give the actual number. However, note that the above code probably won't\n * produce the desired results because of the way Javascript numbers are\n * doubles.\n */\nfunction rgint64(buffer, endian, offset)\n{\n\tvar val = new Array(2);\n\n\tif (endian == 'big') {\n\t\tval[0] = ruint32(buffer, endian, offset);\n\t\tval[1] = ruint32(buffer, endian, offset+4);\n\t} else {\n\t\tval[0] = ruint32(buffer, endian, offset+4);\n\t\tval[1] = ruint32(buffer, endian, offset);\n\t}\n\n\treturn (val);\n}\n\nfunction ruint64(buffer, endian, offset)\n{\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\treturn (rgint64(buffer, endian, offset));\n}\n\n\n/*\n * Signed integer types, yay team! A reminder on how two's complement actually\n * works. The first bit is the signed bit, i.e. tells us whether or not the\n * number should be positive or negative. If the two's complement value is\n * positive, then we're done, as it's equivalent to the unsigned representation.\n *\n * Now if the number is positive, you're pretty much done, you can just leverage\n * the unsigned translations and return those. Unfortunately, negative numbers\n * aren't quite that straightforward.\n *\n * At first glance, one might be inclined to use the traditional formula to\n * translate binary numbers between the positive and negative values in two's\n * complement. (Though it doesn't quite work for the most negative value)\n * Mainly:\n *  - invert all the bits\n *  - add one to the result\n *\n * Of course, this doesn't quite work in Javascript. Take for example the value\n * of -128. This could be represented in 16 bits (big-endian) as 0xff80. But of\n * course, Javascript will do the following:\n *\n * > ~0xff80\n * -65409\n *\n * Whoh there, Javascript, that's not quite right. But wait, according to\n * Javascript that's perfectly correct. When Javascript ends up seeing the\n * constant 0xff80, it has no notion that it is actually a signed number. It\n * assumes that we've input the unsigned value 0xff80. Thus, when it does the\n * binary negation, it casts it into a signed value, (positive 0xff80). Then\n * when you perform binary negation on that, it turns it into a negative number.\n *\n * Instead, we're going to have to use the following general formula, that works\n * in a rather Javascript friendly way. I'm glad we don't support this kind of\n * weird numbering scheme in the kernel.\n *\n * (BIT-MAX - (unsigned)val + 1) * -1\n *\n * The astute observer, may think that this doesn't make sense for 8-bit numbers\n * (really it isn't necessary for them). However, when you get 16-bit numbers,\n * you do. Let's go back to our prior example and see how this will look:\n *\n * (0xffff - 0xff80 + 1) * -1\n * (0x007f + 1) * -1\n * (0x0080) * -1\n *\n * Doing it this way ends up allowing us to treat it appropriately in\n * Javascript. Sigh, that's really quite ugly for what should just be a few bit\n * shifts, ~ and &.\n */\n\n/*\n * Endianness doesn't matter for 8-bit signed values. We could in fact optimize\n * this case because the more traditional methods work, but for consistency,\n * we'll keep doing this the same way.\n */\nfunction rsint8(buffer, endian, offset)\n{\n\tvar neg;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tneg = buffer[offset] & 0x80;\n\tif (!neg)\n\t\treturn (buffer[offset]);\n\n\treturn ((0xff - buffer[offset] + 1) * -1);\n}\n\n/*\n * The 16-bit version requires a bit more effort. In this case, we can leverage\n * our unsigned code to generate the value we want to return.\n */\nfunction rsint16(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint16(buffer, endian, offset);\n\tneg = val & 0x8000;\n\tif (!neg)\n\t\treturn (val);\n\n\treturn ((0xffff - val + 1) * -1);\n}\n\n/*\n * We really shouldn't leverage our 32-bit code here and instead utilize the\n * fact that we know that since these are signed numbers, we can do all the\n * shifting and binary anding to generate the 32-bit number. But, for\n * consistency we'll do the same. If we want to do otherwise, we should instead\n * make the 32 bit unsigned code do the optimization. But as long as there\n * aren't floats secretly under the hood for that, we /should/ be okay.\n */\nfunction rsint32(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint32(buffer, endian, offset);\n\tneg = val & 0x80000000;\n\tif (!neg)\n\t\treturn (val);\n\n\treturn ((0xffffffff - val + 1) * -1);\n}\n\n/*\n * The signed version of this code suffers from all of the same problems of the\n * other 64 bit version.\n */\nfunction rsint64(buffer, endian, offset)\n{\n\tvar neg, val;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = rgint64(buffer, endian, offset);\n\tneg = val[0] & 0x80000000;\n\n\tif (!neg)\n\t\treturn (val);\n\n\tval[0] = (0xffffffff - val[0]) * -1;\n\tval[1] = (0xffffffff - val[1] + 1) * -1;\n\n\t/*\n\t * If we had the key 0x8000000000000000, that would leave the lower 32\n\t * bits as 0xffffffff, however, since we're goint to add one, that would\n\t * actually leave the lower 32-bits as 0x100000000, which would break\n\t * our ability to write back a value that we received. To work around\n\t * this, if we actually get that value, we're going to bump the upper\n\t * portion by 1 and set this to zero.\n\t */\n\tmod_assert.ok(val[1] <= 0x100000000);\n\tif (val[1] == -0x100000000) {\n\t\tval[1] = 0;\n\t\tval[0]--;\n\t}\n\n\treturn (val);\n}\n\n/*\n * We now move onto IEEE 754: The traditional form for floating point numbers\n * and what is secretly hiding at the heart of everything in this. I really hope\n * that someone is actually using this, as otherwise, this effort is probably\n * going to be more wasted.\n *\n * One might be tempted to use parseFloat here, but that wouldn't work at all\n * for several reasons. Mostly due to the way floats actually work, and\n * parseFloat only actually works in base 10. I don't see base 10 anywhere near\n * this file.\n *\n * In this case we'll implement the single and double precision versions. The\n * quadruple precision, while probably useful, wouldn't really be accepted by\n * Javascript, so let's not even waste our time.\n *\n * So let's review how this format looks like. A single precision value is 32\n * bits and has three parts:\n *   -  Sign bit\n *   -  Exponent (Using bias notation)\n *   -  Mantissa\n *\n * |s|eeeeeeee|mmmmmmmmmmmmmmmmmmmmmmmmm|\n * 31| 30-23  |  22    \t-       0       |\n *\n * The exponent is stored in a biased input. The bias in this case 127.\n * Therefore, our exponent is equal to the 8-bit value - 127.\n *\n * By default, a number is normalized in IEEE, that means that the mantissa has\n * an implicit one that we don't see. So really the value stored is 1.m.\n * However, if the exponent is all zeros, then instead we have to shift\n * everything to the right one and there is no more implicit one.\n *\n * Special values:\n *  - Positive Infinity:\n *\tSign:\t\t0\n *\tExponent: \tAll 1s\n *\tMantissa:\t0\n *  - Negative Infinity:\n *\tSign:\t\t1\n *\tExponent: \tAll 1s\n *\tMantissa:\t0\n *  - NaN:\n *\tSign:\t\t*\n *\tExponent: \tAll 1s\n *\tMantissa:\tnon-zero\n *  - Zero:\n *\tSign:\t\t*\n *\tExponent:\tAll 0s\n *\tMantissa:\t0\n *\n * In the case of zero, the sign bit determines whether we get a positive or\n * negative zero. However, since Javascript cannot determine the difference\n * between the two: i.e. -0 == 0, we just always return 0.\n *\n */\nfunction rfloat(buffer, endian, offset)\n{\n\tvar bytes = [];\n\tvar sign, exponent, mantissa, val;\n\tvar bias = 127;\n\tvar maxexp = 0xff;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/* Normalize the bytes to be in endian order */\n\tif (endian == 'big') {\n\t\tbytes[0] = buffer[offset];\n\t\tbytes[1] = buffer[offset+1];\n\t\tbytes[2] = buffer[offset+2];\n\t\tbytes[3] = buffer[offset+3];\n\t} else {\n\t\tbytes[3] = buffer[offset];\n\t\tbytes[2] = buffer[offset+1];\n\t\tbytes[1] = buffer[offset+2];\n\t\tbytes[0] = buffer[offset+3];\n\t}\n\n\tsign = bytes[0] & 0x80;\n\texponent = (bytes[0] & 0x7f) << 1;\n\texponent |= (bytes[1] & 0x80) >>> 7;\n\tmantissa = (bytes[1] & 0x7f) << 16;\n\tmantissa |= bytes[2] << 8;\n\tmantissa |= bytes[3];\n\n\t/* Check for special cases before we do general parsing */\n\tif (!sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.POSITIVE_INFINITY);\n\n\tif (sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.NEGATIVE_INFINITY);\n\n\tif (exponent == maxexp && mantissa !== 0)\n\t\treturn (Number.NaN);\n\n\t/*\n\t * Javascript really doesn't have support for positive or negative zero.\n\t * So we're not going to try and give it to you. That would be just\n\t * plain weird. Besides -0 == 0.\n\t */\n\tif (exponent === 0 && mantissa === 0)\n\t\treturn (0);\n\n\t/*\n\t * Now we can deal with the bias and the determine whether the mantissa\n\t * has the implicit one or not.\n\t */\n\texponent -= bias;\n\tif (exponent == -bias) {\n\t\texponent++;\n\t\tval = 0;\n\t} else {\n\t\tval = 1;\n\t}\n\n\tval = (val + mantissa * Math.pow(2, -23)) * Math.pow(2, exponent);\n\n\tif (sign)\n\t\tval *= -1;\n\n\treturn (val);\n}\n\n/*\n * Doubles in IEEE 754 are like their brothers except for a few changes and\n * increases in size:\n *   - The exponent is now 11 bits\n *   - The mantissa is now 52 bits\n *   - The bias is now 1023\n *\n * |s|eeeeeeeeeee|mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm|\n * 63| 62 - 52   | \t51\t\t-\t\t\t0     |\n * 63| 62 - 52   |      51              -                       0     |\n *\n * While the size has increased a fair amount, we're going to end up keeping the\n * same general formula for calculating the final value. As a reminder, this\n * formula is:\n *\n * (-1)^s * (n + m) * 2^(e-b)\n *\n * Where:\n *\ts\tis the sign bit\n *\tn\tis (exponent > 0) ? 1 : 0 -- Determines whether we're normalized\n *\t\t\t\t\t     or not\n *\tm\tis the mantissa\n *\te\tis the exponent specified\n *\tb\tis the bias for the exponent\n *\n */\nfunction rdouble(buffer, endian, offset)\n{\n\tvar bytes = [];\n\tvar sign, exponent, mantissa, val, lowmant;\n\tvar bias = 1023;\n\tvar maxexp = 0x7ff;\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/* Normalize the bytes to be in endian order */\n\tif (endian == 'big') {\n\t\tbytes[0] = buffer[offset];\n\t\tbytes[1] = buffer[offset+1];\n\t\tbytes[2] = buffer[offset+2];\n\t\tbytes[3] = buffer[offset+3];\n\t\tbytes[4] = buffer[offset+4];\n\t\tbytes[5] = buffer[offset+5];\n\t\tbytes[6] = buffer[offset+6];\n\t\tbytes[7] = buffer[offset+7];\n\t} else {\n\t\tbytes[7] = buffer[offset];\n\t\tbytes[6] = buffer[offset+1];\n\t\tbytes[5] = buffer[offset+2];\n\t\tbytes[4] = buffer[offset+3];\n\t\tbytes[3] = buffer[offset+4];\n\t\tbytes[2] = buffer[offset+5];\n\t\tbytes[1] = buffer[offset+6];\n\t\tbytes[0] = buffer[offset+7];\n\t}\n\n\t/*\n\t * We can construct the exponent and mantissa the same way as we did in\n\t * the case of a float, just increase the range of the exponent.\n\t */\n\tsign = bytes[0] & 0x80;\n\texponent = (bytes[0] & 0x7f) << 4;\n\texponent |= (bytes[1] & 0xf0) >>> 4;\n\n\t/*\n\t * This is going to be ugly but then again, we're dealing with IEEE 754.\n\t * This could probably be done as a node add on in a few lines of C++,\n\t * but oh we'll, we've made it this far so let's be native the rest of\n\t * the way...\n\t *\n\t * What we're going to do is break the mantissa into two parts, the\n\t * lower 24 bits and the upper 28 bits. We'll multiply the upper 28 bits\n\t * by the appropriate power and then add in the lower 24-bits. Not\n\t * really that great. It's pretty much a giant kludge to deal with\n\t * Javascript eccentricities around numbers.\n\t */\n\tlowmant = bytes[7];\n\tlowmant |= bytes[6] << 8;\n\tlowmant |= bytes[5] << 16;\n\tmantissa = bytes[4];\n\tmantissa |= bytes[3] << 8;\n\tmantissa |= bytes[2] << 16;\n\tmantissa |= (bytes[1] & 0x0f) << 24;\n\tmantissa *= Math.pow(2, 24); /* Equivalent to << 24, but JS compat */\n\tmantissa += lowmant;\n\n\t/* Check for special cases before we do general parsing */\n\tif (!sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.POSITIVE_INFINITY);\n\n\tif (sign && exponent == maxexp && mantissa === 0)\n\t\treturn (Number.NEGATIVE_INFINITY);\n\n\tif (exponent == maxexp && mantissa !== 0)\n\t\treturn (Number.NaN);\n\n\t/*\n\t * Javascript really doesn't have support for positive or negative zero.\n\t * So we're not going to try and give it to you. That would be just\n\t * plain weird. Besides -0 == 0.\n\t */\n\tif (exponent === 0 && mantissa === 0)\n\t\treturn (0);\n\n\t/*\n\t * Now we can deal with the bias and the determine whether the mantissa\n\t * has the implicit one or not.\n\t */\n\texponent -= bias;\n\tif (exponent == -bias) {\n\t\texponent++;\n\t\tval = 0;\n\t} else {\n\t\tval = 1;\n\t}\n\n\tval = (val + mantissa * Math.pow(2, -52)) * Math.pow(2, exponent);\n\n\tif (sign)\n\t\tval *= -1;\n\n\treturn (val);\n}\n\n/*\n * Now that we have gone through the pain of reading the individual types, we're\n * probably going to want some way to write these back. None of this is going to\n * be good. But since we have Javascript numbers this should certainly be more\n * interesting. Though we can constrain this end a little bit more in what is\n * valid. For now, let's go back to our friends the unsigned value.\n */\n\n/*\n * Unsigned numbers seem deceptively easy. Here are the general steps and rules\n * that we are going to take:\n *   -  If the number is negative, throw an Error\n *   -  Truncate any floating point portion\n *   -  Take the modulus of the number in our base\n *   -  Write it out to the buffer in the endian format requested at the offset\n */\n\n/*\n * We have to make sure that the value is a valid integer. This means that it is\n * non-negative. It has no fractional component and that it does not exceed the\n * maximum allowed value.\n *\n *\tvalue\t\tThe number to check for validity\n *\n *\tmax\t\tThe maximum value\n */\nfunction prepuint(value, max)\n{\n\tif (typeof (value) != 'number')\n\t\tthrow (new (Error('cannot write a non-number as a number')));\n\n\tif (value < 0)\n\t\tthrow (new Error('specified a negative value for writing an ' +\n\t\t    'unsigned value'));\n\n\tif (value > max)\n\t\tthrow (new Error('value is larger than maximum value for ' +\n\t\t    'type'));\n\n\tif (Math.floor(value) !== value)\n\t\tthrow (new Error('value has a fractional component'));\n\n\treturn (value);\n}\n\n/*\n * 8-bit version, classy. We can ignore endianness which is good.\n */\nfunction wuint8(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xff);\n\tbuffer[offset] = val;\n}\n\n/*\n * Pretty much the same as the 8-bit version, just this time we need to worry\n * about endian related issues.\n */\nfunction wgint16(val, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\tbuffer[offset] = (val & 0xff00) >>> 8;\n\t\tbuffer[offset+1] = val & 0x00ff;\n\t} else {\n\t\tbuffer[offset+1] = (val & 0xff00) >>> 8;\n\t\tbuffer[offset] = val & 0x00ff;\n\t}\n}\n\nfunction wuint16(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xffff);\n\twgint16(val, endian, buffer, offset);\n}\n\n/*\n * The 32-bit version is going to have to be a little different unfortunately.\n * We can't quite bitshift to get the largest byte, because that would end up\n * getting us caught by the signed values.\n *\n * And yes, we do want to subtract out the lower part by default. This means\n * that when we do the division, it will be treated as a bit shift and we won't\n * end up generating a floating point value. If we did generate a floating point\n * value we'd have to truncate it intelligently, this saves us that problem and\n * may even be somewhat faster under the hood.\n */\nfunction wgint32(val, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\tbuffer[offset] = (val - (val & 0x00ffffff)) / Math.pow(2, 24);\n\t\tbuffer[offset+1] = (val >>> 16) & 0xff;\n\t\tbuffer[offset+2] = (val >>> 8) & 0xff;\n\t\tbuffer[offset+3] = val & 0xff;\n\t} else {\n\t\tbuffer[offset+3] = (val - (val & 0x00ffffff)) /\n\t\t    Math.pow(2, 24);\n\t\tbuffer[offset+2] = (val >>> 16) & 0xff;\n\t\tbuffer[offset+1] = (val >>> 8) & 0xff;\n\t\tbuffer[offset] = val & 0xff;\n\t}\n}\n\nfunction wuint32(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepuint(value, 0xffffffff);\n\twgint32(val, endian, buffer, offset);\n}\n\n/*\n * Unlike the other versions, we expect the value to be in the form of two\n * arrays where value[0] << 32 + value[1] would result in the value that we\n * want.\n */\nfunction wgint64(value, endian, buffer, offset)\n{\n\tif (endian == 'big') {\n\t\twgint32(value[0], endian, buffer, offset);\n\t\twgint32(value[1], endian, buffer, offset+4);\n\t} else {\n\t\twgint32(value[0], endian, buffer, offset+4);\n\t\twgint32(value[1], endian, buffer, offset);\n\t}\n}\n\nfunction wuint64(value, endian, buffer, offset)\n{\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (value.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tprepuint(value[0], 0xffffffff);\n\tprepuint(value[1], 0xffffffff);\n\twgint64(value, endian, buffer, offset);\n}\n\n/*\n * We now move onto our friends in the signed number category. Unlike unsigned\n * numbers, we're going to have to worry a bit more about how we put values into\n * arrays. Since we are only worrying about signed 32-bit values, we're in\n * slightly better shape. Unfortunately, we really can't do our favorite binary\n * & in this system. It really seems to do the wrong thing. For example:\n *\n * > -32 & 0xff\n * 224\n *\n * What's happening above is really: 0xe0 & 0xff = 0xe0. However, the results of\n * this aren't treated as a signed number. Ultimately a bad thing.\n *\n * What we're going to want to do is basically create the unsigned equivalent of\n * our representation and pass that off to the wuint* functions. To do that\n * we're going to do the following:\n *\n *  - if the value is positive\n *\twe can pass it directly off to the equivalent wuint\n *  - if the value is negative\n *\twe do the following computation:\n *\tmb + val + 1, where\n *\tmb\tis the maximum unsigned value in that byte size\n *\tval\tis the Javascript negative integer\n *\n *\n * As a concrete value, take -128. In signed 16 bits this would be 0xff80. If\n * you do out the computations:\n *\n * 0xffff - 128 + 1\n * 0xffff - 127\n * 0xff80\n *\n * You can then encode this value as the signed version. This is really rather\n * hacky, but it should work and get the job done which is our goal here.\n *\n * Thus the overall flow is:\n *   -  Truncate the floating point part of the number\n *   -  We don't have to take the modulus, because the unsigned versions will\n *   \ttake care of that for us. And we don't have to worry about that\n *   \tpotentially causing bad things to happen because of sign extension\n *   -  Pass it off to the appropriate unsigned version, potentially modifying\n *\tthe negative portions as necessary.\n */\n\n/*\n * A series of checks to make sure we actually have a signed 32-bit number\n */\nfunction prepsint(value, max, min)\n{\n\tif (typeof (value) != 'number')\n\t\tthrow (new (Error('cannot write a non-number as a number')));\n\n\tif (value > max)\n\t\tthrow (new Error('value larger than maximum allowed value'));\n\n\tif (value < min)\n\t\tthrow (new Error('value smaller than minimum allowed value'));\n\n\tif (Math.floor(value) !== value)\n\t\tthrow (new Error('value has a fractional component'));\n\n\treturn (value);\n}\n\n/*\n * The 8-bit version of the signed value. Overall, fairly straightforward.\n */\nfunction wsint8(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7f, -0x80);\n\tif (val >= 0)\n\t\twuint8(val, endian, buffer, offset);\n\telse\n\t\twuint8(0xff + val + 1, endian, buffer, offset);\n}\n\n/*\n * The 16-bit version of the signed value. Also, fairly straightforward.\n */\nfunction wsint16(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 1 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7fff, -0x8000);\n\tif (val >= 0)\n\t\twgint16(val, endian, buffer, offset);\n\telse\n\t\twgint16(0xffff + val + 1, endian, buffer, offset);\n\n}\n\n/*\n * We can do this relatively easily by leveraging the code used for 32-bit\n * unsigned code.\n */\nfunction wsint32(value, endian, buffer, offset)\n{\n\tvar val;\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tval = prepsint(value, 0x7fffffff, -0x80000000);\n\tif (val >= 0)\n\t\twgint32(val, endian, buffer, offset);\n\telse\n\t\twgint32(0xffffffff + val + 1, endian, buffer, offset);\n}\n\n/*\n * The signed 64 bit integer should by in the same format as when received.\n * Mainly it should ensure that the value is an array of two integers where\n * value[0] << 32 + value[1] is the desired number. Furthermore, the two values\n * need to be equal.\n */\nfunction wsint64(value, endian, buffer, offset)\n{\n\tvar vzpos, vopos;\n\tvar vals = new Array(2);\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (!(value instanceof Array))\n\t\tthrow (new Error('value must be an array'));\n\n\tif (value.length != 2)\n\t\tthrow (new Error('value must be an array of length 2'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\t/*\n\t * We need to make sure that we have the same sign on both values. The\n\t * hokiest way to to do this is to multiply the number by +inf. If we do\n\t * this, we'll get either +/-inf depending on the sign of the value.\n\t * Once we have this, we can compare it to +inf to see if the number is\n\t * positive or not.\n\t */\n\tvzpos = (value[0] * Number.POSITIVE_INFINITY) ==\n\t    Number.POSITIVE_INFINITY;\n\tvopos = (value[1] * Number.POSITIVE_INFINITY) ==\n\t    Number.POSITIVE_INFINITY;\n\n\t/*\n\t * If either of these is zero, then we don't actually need this check.\n\t */\n\tif (value[0] != 0 && value[1] != 0 && vzpos != vopos)\n\t\tthrow (new Error('Both entries in the array must have ' +\n\t\t    'the same sign'));\n\n\t/*\n\t * Doing verification for a signed 64-bit integer is actually a big\n\t * trickier than it appears. We can't quite use our standard techniques\n\t * because we need to compare both sets of values. The first value is\n\t * pretty straightforward. If the first value is beond the extremes than\n\t * we error out. However, the valid range of the second value varies\n\t * based on the first one. If the first value is negative, and *not* the\n\t * largest negative value, than it can be any integer within the range [\n\t * 0, 0xffffffff ]. If it is the largest negative number, it must be\n\t * zero.\n\t *\n\t * If the first number is positive, than it doesn't matter what the\n\t * value is. We just simply have to make sure we have a valid positive\n\t * integer.\n\t */\n\tif (vzpos) {\n\t\tprepuint(value[0], 0x7fffffff);\n\t\tprepuint(value[1], 0xffffffff);\n\t} else {\n\t\tprepsint(value[0], 0, -0x80000000);\n\t\tprepsint(value[1], 0, -0xffffffff);\n\t\tif (value[0] == -0x80000000 && value[1] != 0)\n\t\t\tthrow (new Error('value smaller than minimum ' +\n\t\t\t    'allowed value'));\n\t}\n\n\t/* Fix negative numbers */\n\tif (value[0] < 0 || value[1] < 0) {\n\t\tvals[0] = 0xffffffff - Math.abs(value[0]);\n\t\tvals[1] = 0x100000000 - Math.abs(value[1]);\n\t\tif (vals[1] == 0x100000000) {\n\t\t\tvals[1] = 0;\n\t\t\tvals[0]++;\n\t\t}\n\t} else {\n\t\tvals[0] = value[0];\n\t\tvals[1] = value[1];\n\t}\n\twgint64(vals, endian, buffer, offset);\n}\n\n/*\n * Now we are moving onto the weirder of these, the float and double. For this\n * we're going to just have to do something that's pretty weird. First off, we\n * have no way to get at the underlying float representation, at least not\n * easily. But that doesn't mean we can't figure it out, we just have to use our\n * heads.\n *\n * One might propose to use Number.toString(2). Of course, this is not really\n * that good, because the ECMAScript 262 v3 Standard says the following Section\n * 15.7.4.2-Number.prototype.toString (radix):\n *\n * If radix is an integer from 2 to 36, but not 10, the result is a string, the\n * choice of which is implementation-dependent.\n *\n * Well that doesn't really help us one bit now does it? We could use the\n * standard base 10 version of the string, but that's just going to create more\n * errors as we end up trying to convert it back to a binary value. So, really\n * this just means we have to be non-lazy and parse the structure intelligently.\n *\n * First off, we can do the basic checks: NaN, positive and negative infinity.\n *\n * Now that those are done we can work backwards to generate the mantissa and\n * exponent.\n *\n * The first thing we need to do is determine the sign bit, easy to do, check\n * whether the value is less than 0. And convert the number to its absolute\n * value representation. Next, we need to determine if the value is less than\n * one or greater than or equal to one and from there determine what power was\n * used to get there. What follows is now specific to floats, though the general\n * ideas behind this will hold for doubles as well, but the exact numbers\n * involved will change.\n *\n * Once we have that power we can determine the exponent and the mantissa. Call\n * the value that has the number of bits to reach the power ebits. In the\n * general case they have the following values:\n *\n *\texponent\t127 + ebits\n *\tmantissa\tvalue * 2^(23 - ebits) & 0x7fffff\n *\n * In the case where the value of ebits is <= -127 we are now in the case where\n * we no longer have normalized numbers. In this case the values take on the\n * following values:\n *\n * \texponent\t0\n *\tmantissa\tvalue * 2^149 & 0x7fffff\n *\n * Once we have the values for the sign, mantissa, and exponent. We reconstruct\n * the four bytes as follows:\n *\n *\tbyte0\t\tsign bit and seven most significant bits from the exp\n *\t\t\tsign << 7 | (exponent & 0xfe) >>> 1\n *\n *\tbyte1\t\tlsb from the exponent and 7 top bits from the mantissa\n *\t\t\t(exponent & 0x01) << 7 | (mantissa & 0x7f0000) >>> 16\n *\n *\tbyte2\t\tbits 8-15 (zero indexing) from mantissa\n *\t\t\tmantissa & 0xff00 >> 8\n *\n *\tbyte3\t\tbits 0-7 from mantissa\n *\t\t\tmantissa & 0xff\n *\n * Once we have this we have to assign them into the buffer in proper endian\n * order.\n */\n\n/*\n * Compute the log base 2 of the value. Now, someone who remembers basic\n * properties of logarithms will point out that we could use the change of base\n * formula for logs, and in fact that would be astute, because that's what we'll\n * do for now. It feels cleaner, albeit it may be less efficient than just\n * iterating and dividing by 2. We may want to come back and revisit that some\n * day.\n */\nfunction log2(value)\n{\n\treturn (Math.log(value) / Math.log(2));\n}\n\n/*\n * Helper to determine the exponent of the number we're looking at.\n */\nfunction intexp(value)\n{\n\treturn (Math.floor(log2(value)));\n}\n\n/*\n * Helper to determine the exponent of the fractional part of the value.\n */\nfunction fracexp(value)\n{\n\treturn (Math.floor(log2(value)));\n}\n\nfunction wfloat(value, endian, buffer, offset)\n{\n\tvar sign, exponent, mantissa, ebits;\n\tvar bytes = [];\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\n\tif (offset + 3 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tif (isNaN(value)) {\n\t\tsign = 0;\n\t\texponent = 0xff;\n\t\tmantissa = 23;\n\t} else if (value == Number.POSITIVE_INFINITY) {\n\t\tsign = 0;\n\t\texponent = 0xff;\n\t\tmantissa = 0;\n\t} else if (value == Number.NEGATIVE_INFINITY) {\n\t\tsign = 1;\n\t\texponent = 0xff;\n\t\tmantissa = 0;\n\t} else {\n\t\t/* Well we have some work to do */\n\n\t\t/* Thankfully the sign bit is trivial */\n\t\tif (value < 0) {\n\t\t\tsign = 1;\n\t\t\tvalue = Math.abs(value);\n\t\t} else {\n\t\t\tsign = 0;\n\t\t}\n\n\t\t/* Use the correct function to determine number of bits */\n\t\tif (value < 1)\n\t\t\tebits = fracexp(value);\n\t\telse\n\t\t\tebits = intexp(value);\n\n\t\t/* Time to deal with the issues surrounding normalization */\n\t\tif (ebits <= -127) {\n\t\t\texponent = 0;\n\t\t\tmantissa = (value * Math.pow(2, 149)) & 0x7fffff;\n\t\t} else {\n\t\t\texponent = 127 + ebits;\n\t\t\tmantissa = value * Math.pow(2, 23 - ebits);\n\t\t\tmantissa &= 0x7fffff;\n\t\t}\n\t}\n\n\tbytes[0] = sign << 7 | (exponent & 0xfe) >>> 1;\n\tbytes[1] = (exponent & 0x01) << 7 | (mantissa & 0x7f0000) >>> 16;\n\tbytes[2] = (mantissa & 0x00ff00) >>> 8;\n\tbytes[3] = mantissa & 0x0000ff;\n\n\tif (endian == 'big') {\n\t\tbuffer[offset] = bytes[0];\n\t\tbuffer[offset+1] = bytes[1];\n\t\tbuffer[offset+2] = bytes[2];\n\t\tbuffer[offset+3] = bytes[3];\n\t} else {\n\t\tbuffer[offset] = bytes[3];\n\t\tbuffer[offset+1] = bytes[2];\n\t\tbuffer[offset+2] = bytes[1];\n\t\tbuffer[offset+3] = bytes[0];\n\t}\n}\n\n/*\n * Now we move onto doubles. Doubles are similar to floats in pretty much all\n * ways except that the processing isn't quite as straightforward because we\n * can't always use shifting, i.e. we have > 32 bit values.\n *\n * We're going to proceed in an identical fashion to floats and utilize the same\n * helper functions. All that really is changing are the specific values that we\n * use to do the calculations. Thus, to review we have to do the following.\n *\n * First get the sign bit and convert the value to its absolute value\n * representation. Next, we determine the number of bits that we used to get to\n * the value, branching whether the value is greater than or less than 1. Once\n * we have that value which we will again call ebits, we have to do the\n * following in the general case:\n *\n *\texponent\t1023 + ebits\n *\tmantissa\t[value * 2^(52 - ebits)] % 2^52\n *\n * In the case where the value of ebits <= -1023 we no longer use normalized\n * numbers, thus like with floats we have to do slightly different processing:\n *\n *\texponent\t0\n *\tmantissa\t[value * 2^1074] % 2^52\n *\n * Once we have determined the sign, exponent and mantissa we can construct the\n * bytes as follows:\n *\n *\tbyte0\t\tsign bit and seven most significant bits form the exp\n *\t\t\tsign << 7 | (exponent & 0x7f0) >>> 4\n *\n *\tbyte1\t\tRemaining 4 bits from the exponent and the four most\n *\t\t\tsignificant bits from the mantissa 48-51\n *\t\t\t(exponent & 0x00f) << 4 | mantissa >>> 48\n *\n *\tbyte2\t\tBits 40-47 from the mantissa\n *\t\t\t(mantissa >>> 40) & 0xff\n *\n *\tbyte3\t\tBits 32-39 from the mantissa\n *\t\t\t(mantissa >>> 32) & 0xff\n *\n *\tbyte4\t\tBits 24-31 from the mantissa\n *\t\t\t(mantissa >>> 24) & 0xff\n *\n *\tbyte5\t\tBits 16-23 from the Mantissa\n *\t\t\t(mantissa >>> 16) & 0xff\n *\n *\tbyte6\t\tBits 8-15 from the mantissa\n *\t\t\t(mantissa >>> 8) & 0xff\n *\n *\tbyte7\t\tBits 0-7 from the mantissa\n *\t\t\tmantissa & 0xff\n *\n * Now we can't quite do the right shifting that we want in bytes 1 - 3, because\n * we'll have extended too far and we'll lose those values when we try and do\n * the shift. Instead we have to use an alternate approach. To try and stay out\n * of floating point, what we'll do is say that mantissa -= bytes[4-7] and then\n * divide by 2^32. Once we've done that we can use binary arithmetic. Oof,\n * that's ugly, but it seems to avoid using floating point (just based on how v8\n * seems to be optimizing for base 2 arithmetic).\n */\nfunction wdouble(value, endian, buffer, offset)\n{\n\tvar sign, exponent, mantissa, ebits;\n\tvar bytes = [];\n\n\tif (value === undefined)\n\t\tthrow (new Error('missing value'));\n\n\tif (endian === undefined)\n\t\tthrow (new Error('missing endian'));\n\n\tif (buffer === undefined)\n\t\tthrow (new Error('missing buffer'));\n\n\tif (offset === undefined)\n\t\tthrow (new Error('missing offset'));\n\n\n\tif (offset + 7 >= buffer.length)\n\t\tthrow (new Error('Trying to read beyond buffer length'));\n\n\tif (isNaN(value)) {\n\t\tsign = 0;\n\t\texponent = 0x7ff;\n\t\tmantissa = 23;\n\t} else if (value == Number.POSITIVE_INFINITY) {\n\t\tsign = 0;\n\t\texponent = 0x7ff;\n\t\tmantissa = 0;\n\t} else if (value == Number.NEGATIVE_INFINITY) {\n\t\tsign = 1;\n\t\texponent = 0x7ff;\n\t\tmantissa = 0;\n\t} else {\n\t\t/* Well we have some work to do */\n\n\t\t/* Thankfully the sign bit is trivial */\n\t\tif (value < 0) {\n\t\t\tsign = 1;\n\t\t\tvalue = Math.abs(value);\n\t\t} else {\n\t\t\tsign = 0;\n\t\t}\n\n\t\t/* Use the correct function to determine number of bits */\n\t\tif (value < 1)\n\t\t\tebits = fracexp(value);\n\t\telse\n\t\t\tebits = intexp(value);\n\n\t\t/*\n\t\t * This is a total hack to determine a denormalized value.\n\t\t * Unfortunately, we sometimes do not get a proper value for\n\t\t * ebits, i.e. we lose the values that would get rounded off.\n\t\t *\n\t\t *\n\t\t * The astute observer may wonder why we would be\n\t\t * multiplying by two Math.pows rather than just summing\n\t\t * them. Well, that's to get around a small bug in the\n\t\t * way v8 seems to implement the function. On occasion\n\t\t * doing:\n\t\t *\n\t\t * foo * Math.pow(2, 1023 + 51)\n\t\t *\n\t\t * Causes us to overflow to infinity, where as doing:\n\t\t *\n\t\t * foo * Math.pow(2, 1023) * Math.pow(2, 51)\n\t\t *\n\t\t * Does not cause us to overflow. Go figure.\n\t\t *\n\t\t */\n\t\tif (value <= 2.225073858507201e-308 || ebits <= -1023) {\n\t\t\texponent = 0;\n\t\t\tmantissa = value * Math.pow(2, 1023) * Math.pow(2, 51);\n\t\t\tmantissa %= Math.pow(2, 52);\n\t\t} else {\n\t\t\t/*\n\t\t\t * We might have gotten fucked by our floating point\n\t\t\t * logarithm magic. This is rather crappy, but that's\n\t\t\t * our luck. If we just had a log base 2 or access to\n\t\t\t * the stupid underlying representation this would have\n\t\t\t * been much easier and we wouldn't have such stupid\n\t\t\t * kludges or hacks.\n\t\t\t */\n\t\t\tif (ebits > 1023)\n\t\t\t\tebits = 1023;\n\t\t\texponent = 1023 + ebits;\n\t\t\tmantissa = value * Math.pow(2, -ebits);\n\t\t\tmantissa *= Math.pow(2, 52);\n\t\t\tmantissa %= Math.pow(2, 52);\n\t\t}\n\t}\n\n\t/* Fill the bytes in backwards to deal with the size issues */\n\tbytes[7] = mantissa & 0xff;\n\tbytes[6] = (mantissa >>> 8) & 0xff;\n\tbytes[5] = (mantissa >>> 16) & 0xff;\n\tmantissa = (mantissa - (mantissa & 0xffffff)) / Math.pow(2, 24);\n\tbytes[4] = mantissa & 0xff;\n\tbytes[3] = (mantissa >>> 8) & 0xff;\n\tbytes[2] = (mantissa >>> 16) & 0xff;\n\tbytes[1] = (exponent & 0x00f) << 4 | mantissa >>> 24;\n\tbytes[0] = (sign << 7) | (exponent & 0x7f0) >>> 4;\n\n\tif (endian == 'big') {\n\t\tbuffer[offset] = bytes[0];\n\t\tbuffer[offset+1] = bytes[1];\n\t\tbuffer[offset+2] = bytes[2];\n\t\tbuffer[offset+3] = bytes[3];\n\t\tbuffer[offset+4] = bytes[4];\n\t\tbuffer[offset+5] = bytes[5];\n\t\tbuffer[offset+6] = bytes[6];\n\t\tbuffer[offset+7] = bytes[7];\n\t} else {\n\t\tbuffer[offset+7] = bytes[0];\n\t\tbuffer[offset+6] = bytes[1];\n\t\tbuffer[offset+5] = bytes[2];\n\t\tbuffer[offset+4] = bytes[3];\n\t\tbuffer[offset+3] = bytes[4];\n\t\tbuffer[offset+2] = bytes[5];\n\t\tbuffer[offset+1] = bytes[6];\n\t\tbuffer[offset] = bytes[7];\n\t}\n}\n\n/*\n * Actually export our work above. One might argue that we shouldn't expose\n * these interfaces and just force people to use the higher level abstractions\n * around this work. However, unlike say other libraries we've come across, this\n * interface has several properties: it makes sense, it's simple, and it's\n * useful.\n */\nexports.ruint8 = ruint8;\nexports.ruint16 = ruint16;\nexports.ruint32 = ruint32;\nexports.ruint64 = ruint64;\nexports.wuint8 = wuint8;\nexports.wuint16 = wuint16;\nexports.wuint32 = wuint32;\nexports.wuint64 = wuint64;\n\nexports.rsint8 = rsint8;\nexports.rsint16 = rsint16;\nexports.rsint32 = rsint32;\nexports.rsint64 = rsint64;\nexports.wsint8 = wsint8;\nexports.wsint16 = wsint16;\nexports.wsint32 = wsint32;\nexports.wsint64 = wsint64;\n\nexports.rfloat = rfloat;\nexports.rdouble = rdouble;\nexports.wfloat = wfloat;\nexports.wdouble = wdouble;\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "assert": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/uuid.js": {
            "requireId": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/uuid.js",
            "memoizeId": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/uuid.js",
            "descriptor": {
              "filename": "uuid.js",
              "filepath": "node_modules/request/node_modules/node-uuid/uuid.js",
              "mtime": 1350567957,
              "code": "//     uuid.js\n//\n//     (c) 2010-2012 Robert Kieffer\n//     MIT License\n//     https://github.com/broofa/node-uuid\n(function() {\n  var _global = this;\n\n  // Unique ID creation requires a high quality random # generator.  We feature\n  // detect to determine the best RNG source, normalizing to a function that\n  // returns 128-bits of randomness, since that's what's usually required\n  var _rng;\n\n  // Node.js crypto-based RNG - http://nodejs.org/docs/v0.6.2/api/crypto.html\n  //\n  // Moderately fast, high quality\n  if (typeof(require) == 'function') {\n    try {\n      var _rb = require('crypto').randomBytes;\n      _rng = _rb && function() {return _rb(16);};\n    } catch(e) {}\n  }\n\n  if (!_rng && _global.crypto && crypto.getRandomValues) {\n    // WHATWG crypto-based RNG - http://wiki.whatwg.org/wiki/Crypto\n    //\n    // Moderately fast, high quality\n    var _rnds8 = new Uint8Array(16);\n    _rng = function whatwgRNG() {\n      crypto.getRandomValues(_rnds8);\n      return _rnds8;\n    };\n  }\n\n  if (!_rng) {\n    // Math.random()-based (RNG)\n    //\n    // If all else fails, use Math.random().  It's fast, but is of unspecified\n    // quality.\n    var  _rnds = new Array(16);\n    _rng = function() {\n      for (var i = 0, r; i < 16; i++) {\n        if ((i & 0x03) === 0) r = Math.random() * 0x100000000;\n        _rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;\n      }\n\n      return _rnds;\n    };\n  }\n\n  // Buffer class to use\n  var BufferClass = typeof(Buffer) == 'function' ? Buffer : Array;\n\n  // Maps for number <-> hex string conversion\n  var _byteToHex = [];\n  var _hexToByte = {};\n  for (var i = 0; i < 256; i++) {\n    _byteToHex[i] = (i + 0x100).toString(16).substr(1);\n    _hexToByte[_byteToHex[i]] = i;\n  }\n\n  // **`parse()` - Parse a UUID into it's component bytes**\n  function parse(s, buf, offset) {\n    var i = (buf && offset) || 0, ii = 0;\n\n    buf = buf || [];\n    s.toLowerCase().replace(/[0-9a-f]{2}/g, function(oct) {\n      if (ii < 16) { // Don't overflow!\n        buf[i + ii++] = _hexToByte[oct];\n      }\n    });\n\n    // Zero out remaining bytes if string was short\n    while (ii < 16) {\n      buf[i + ii++] = 0;\n    }\n\n    return buf;\n  }\n\n  // **`unparse()` - Convert UUID byte array (ala parse()) into a string**\n  function unparse(buf, offset) {\n    var i = offset || 0, bth = _byteToHex;\n    return  bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]];\n  }\n\n  // **`v1()` - Generate time-based UUID**\n  //\n  // Inspired by https://github.com/LiosK/UUID.js\n  // and http://docs.python.org/library/uuid.html\n\n  // random #'s we need to init node and clockseq\n  var _seedBytes = _rng();\n\n  // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n  var _nodeId = [\n    _seedBytes[0] | 0x01,\n    _seedBytes[1], _seedBytes[2], _seedBytes[3], _seedBytes[4], _seedBytes[5]\n  ];\n\n  // Per 4.2.2, randomize (14 bit) clockseq\n  var _clockseq = (_seedBytes[6] << 8 | _seedBytes[7]) & 0x3fff;\n\n  // Previous uuid creation time\n  var _lastMSecs = 0, _lastNSecs = 0;\n\n  // See https://github.com/broofa/node-uuid for API details\n  function v1(options, buf, offset) {\n    var i = buf && offset || 0;\n    var b = buf || [];\n\n    options = options || {};\n\n    var clockseq = options.clockseq != null ? options.clockseq : _clockseq;\n\n    // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n    // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n    // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n    // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n    var msecs = options.msecs != null ? options.msecs : new Date().getTime();\n\n    // Per 4.2.1.2, use count of uuid's generated during the current clock\n    // cycle to simulate higher resolution clock\n    var nsecs = options.nsecs != null ? options.nsecs : _lastNSecs + 1;\n\n    // Time since last uuid creation (in msecs)\n    var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n    // Per 4.2.1.2, Bump clockseq on clock regression\n    if (dt < 0 && options.clockseq == null) {\n      clockseq = clockseq + 1 & 0x3fff;\n    }\n\n    // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n    // time interval\n    if ((dt < 0 || msecs > _lastMSecs) && options.nsecs == null) {\n      nsecs = 0;\n    }\n\n    // Per 4.2.1.2 Throw error if too many uuids are requested\n    if (nsecs >= 10000) {\n      throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n    }\n\n    _lastMSecs = msecs;\n    _lastNSecs = nsecs;\n    _clockseq = clockseq;\n\n    // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n    msecs += 12219292800000;\n\n    // `time_low`\n    var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n    b[i++] = tl >>> 24 & 0xff;\n    b[i++] = tl >>> 16 & 0xff;\n    b[i++] = tl >>> 8 & 0xff;\n    b[i++] = tl & 0xff;\n\n    // `time_mid`\n    var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n    b[i++] = tmh >>> 8 & 0xff;\n    b[i++] = tmh & 0xff;\n\n    // `time_high_and_version`\n    b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n    b[i++] = tmh >>> 16 & 0xff;\n\n    // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n    b[i++] = clockseq >>> 8 | 0x80;\n\n    // `clock_seq_low`\n    b[i++] = clockseq & 0xff;\n\n    // `node`\n    var node = options.node || _nodeId;\n    for (var n = 0; n < 6; n++) {\n      b[i + n] = node[n];\n    }\n\n    return buf ? buf : unparse(b);\n  }\n\n  // **`v4()` - Generate random UUID**\n\n  // See https://github.com/broofa/node-uuid for API details\n  function v4(options, buf, offset) {\n    // Deprecated - 'format' argument, as supported in v1.2\n    var i = buf && offset || 0;\n\n    if (typeof(options) == 'string') {\n      buf = options == 'binary' ? new BufferClass(16) : null;\n      options = null;\n    }\n    options = options || {};\n\n    var rnds = options.random || (options.rng || _rng)();\n\n    // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n    rnds[6] = (rnds[6] & 0x0f) | 0x40;\n    rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n    // Copy bytes to buffer, if provided\n    if (buf) {\n      for (var ii = 0; ii < 16; ii++) {\n        buf[i + ii] = rnds[ii];\n      }\n    }\n\n    return buf || unparse(rnds);\n  }\n\n  // Export public API\n  var uuid = v4;\n  uuid.v1 = v1;\n  uuid.v4 = v4;\n  uuid.parse = parse;\n  uuid.unparse = unparse;\n  uuid.BufferClass = BufferClass;\n\n  if (_global.define && define.amd) {\n    // Publish as AMD module\n    define(function() {return uuid;});\n  } else if (typeof(module) != 'undefined' && module.exports) {\n    // Publish as node.js module\n    module.exports = uuid;\n  } else {\n    // Publish as global (in browsers)\n    var _previousRoot = _global.uuid;\n\n    // **`noConflict()` - (browser only) to reset global 'uuid' var**\n    uuid.noConflict = function() {\n      _global.uuid = _previousRoot;\n      return uuid;\n    };\n\n    _global.uuid = uuid;\n  }\n}());\n",
              "globals": {
                "require": {
                  "type": "typeof"
                },
                "crypto": {
                  "type": "reference"
                },
                "r": {
                  "type": "assign"
                },
                "Math": {
                  "type": "reference"
                },
                "Buffer": {
                  "type": "typeof"
                },
                "define": {
                  "type": "reference"
                },
                "module": {
                  "type": "typeof"
                }
              },
              "syntax": "javascript",
              "format": "amd-ish",
              "undefine": [
                "module"
              ],
              "uses": {},
              "dependencies": {
                "static": {
                  "crypto": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "amd-ish",
              "top": "wrapAMD(function(require, define) {",
              "code": "wrapAMD(function(require, define) {\n//     uuid.js\n//\n//     (c) 2010-2012 Robert Kieffer\n//     MIT License\n//     https://github.com/broofa/node-uuid\n(function() {\n  var _global = this;\n\n  // Unique ID creation requires a high quality random # generator.  We feature\n  // detect to determine the best RNG source, normalizing to a function that\n  // returns 128-bits of randomness, since that's what's usually required\n  var _rng;\n\n  // Node.js crypto-based RNG - http://nodejs.org/docs/v0.6.2/api/crypto.html\n  //\n  // Moderately fast, high quality\n  if (typeof(require) == 'function') {\n    try {\n      var _rb = require('__SYSTEM__/crypto').randomBytes;\n      _rng = _rb && function() {return _rb(16);};\n    } catch(e) {}\n  }\n\n  if (!_rng && _global.crypto && crypto.getRandomValues) {\n    // WHATWG crypto-based RNG - http://wiki.whatwg.org/wiki/Crypto\n    //\n    // Moderately fast, high quality\n    var _rnds8 = new Uint8Array(16);\n    _rng = function whatwgRNG() {\n      crypto.getRandomValues(_rnds8);\n      return _rnds8;\n    };\n  }\n\n  if (!_rng) {\n    // Math.random()-based (RNG)\n    //\n    // If all else fails, use Math.random().  It's fast, but is of unspecified\n    // quality.\n    var  _rnds = new Array(16);\n    _rng = function() {\n      for (var i = 0, r; i < 16; i++) {\n        if ((i & 0x03) === 0) r = Math.random() * 0x100000000;\n        _rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;\n      }\n\n      return _rnds;\n    };\n  }\n\n  // Buffer class to use\n  var BufferClass = typeof(Buffer) == 'function' ? Buffer : Array;\n\n  // Maps for number <-> hex string conversion\n  var _byteToHex = [];\n  var _hexToByte = {};\n  for (var i = 0; i < 256; i++) {\n    _byteToHex[i] = (i + 0x100).toString(16).substr(1);\n    _hexToByte[_byteToHex[i]] = i;\n  }\n\n  // **`parse()` - Parse a UUID into it's component bytes**\n  function parse(s, buf, offset) {\n    var i = (buf && offset) || 0, ii = 0;\n\n    buf = buf || [];\n    s.toLowerCase().replace(/[0-9a-f]{2}/g, function(oct) {\n      if (ii < 16) { // Don't overflow!\n        buf[i + ii++] = _hexToByte[oct];\n      }\n    });\n\n    // Zero out remaining bytes if string was short\n    while (ii < 16) {\n      buf[i + ii++] = 0;\n    }\n\n    return buf;\n  }\n\n  // **`unparse()` - Convert UUID byte array (ala parse()) into a string**\n  function unparse(buf, offset) {\n    var i = offset || 0, bth = _byteToHex;\n    return  bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] + '-' +\n            bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]] +\n            bth[buf[i++]] + bth[buf[i++]];\n  }\n\n  // **`v1()` - Generate time-based UUID**\n  //\n  // Inspired by https://github.com/LiosK/UUID.js\n  // and http://docs.python.org/library/uuid.html\n\n  // random #'s we need to init node and clockseq\n  var _seedBytes = _rng();\n\n  // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n  var _nodeId = [\n    _seedBytes[0] | 0x01,\n    _seedBytes[1], _seedBytes[2], _seedBytes[3], _seedBytes[4], _seedBytes[5]\n  ];\n\n  // Per 4.2.2, randomize (14 bit) clockseq\n  var _clockseq = (_seedBytes[6] << 8 | _seedBytes[7]) & 0x3fff;\n\n  // Previous uuid creation time\n  var _lastMSecs = 0, _lastNSecs = 0;\n\n  // See https://github.com/broofa/node-uuid for API details\n  function v1(options, buf, offset) {\n    var i = buf && offset || 0;\n    var b = buf || [];\n\n    options = options || {};\n\n    var clockseq = options.clockseq != null ? options.clockseq : _clockseq;\n\n    // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n    // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n    // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n    // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n    var msecs = options.msecs != null ? options.msecs : new Date().getTime();\n\n    // Per 4.2.1.2, use count of uuid's generated during the current clock\n    // cycle to simulate higher resolution clock\n    var nsecs = options.nsecs != null ? options.nsecs : _lastNSecs + 1;\n\n    // Time since last uuid creation (in msecs)\n    var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n    // Per 4.2.1.2, Bump clockseq on clock regression\n    if (dt < 0 && options.clockseq == null) {\n      clockseq = clockseq + 1 & 0x3fff;\n    }\n\n    // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n    // time interval\n    if ((dt < 0 || msecs > _lastMSecs) && options.nsecs == null) {\n      nsecs = 0;\n    }\n\n    // Per 4.2.1.2 Throw error if too many uuids are requested\n    if (nsecs >= 10000) {\n      throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n    }\n\n    _lastMSecs = msecs;\n    _lastNSecs = nsecs;\n    _clockseq = clockseq;\n\n    // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n    msecs += 12219292800000;\n\n    // `time_low`\n    var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n    b[i++] = tl >>> 24 & 0xff;\n    b[i++] = tl >>> 16 & 0xff;\n    b[i++] = tl >>> 8 & 0xff;\n    b[i++] = tl & 0xff;\n\n    // `time_mid`\n    var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n    b[i++] = tmh >>> 8 & 0xff;\n    b[i++] = tmh & 0xff;\n\n    // `time_high_and_version`\n    b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n    b[i++] = tmh >>> 16 & 0xff;\n\n    // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n    b[i++] = clockseq >>> 8 | 0x80;\n\n    // `clock_seq_low`\n    b[i++] = clockseq & 0xff;\n\n    // `node`\n    var node = options.node || _nodeId;\n    for (var n = 0; n < 6; n++) {\n      b[i + n] = node[n];\n    }\n\n    return buf ? buf : unparse(b);\n  }\n\n  // **`v4()` - Generate random UUID**\n\n  // See https://github.com/broofa/node-uuid for API details\n  function v4(options, buf, offset) {\n    // Deprecated - 'format' argument, as supported in v1.2\n    var i = buf && offset || 0;\n\n    if (typeof(options) == 'string') {\n      buf = options == 'binary' ? new BufferClass(16) : null;\n      options = null;\n    }\n    options = options || {};\n\n    var rnds = options.random || (options.rng || _rng)();\n\n    // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n    rnds[6] = (rnds[6] & 0x0f) | 0x40;\n    rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n    // Copy bytes to buffer, if provided\n    if (buf) {\n      for (var ii = 0; ii < 16; ii++) {\n        buf[i + ii] = rnds[ii];\n      }\n    }\n\n    return buf || unparse(rnds);\n  }\n\n  // Export public API\n  var uuid = v4;\n  uuid.v1 = v1;\n  uuid.v4 = v4;\n  uuid.parse = parse;\n  uuid.unparse = unparse;\n  uuid.BufferClass = BufferClass;\n\n  if (_global.define && define.amd) {\n    // Publish as AMD module\n    define(function() {return uuid;});\n  } else if (typeof(module) != 'undefined' && module.exports) {\n    // Publish as node.js module\n    module.exports = uuid;\n  } else {\n    // Publish as global (in browsers)\n    var _previousRoot = _global.uuid;\n\n    // **`noConflict()` - (browser only) to reset global 'uuid' var**\n    uuid.noConflict = function() {\n      _global.uuid = _previousRoot;\n      return uuid;\n    };\n\n    _global.uuid = uuid;\n  }\n}());\n\n})",
              "bottom": "})"
            },
            "dependencies": {
              "static": {
                "crypto": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/mime.js": {
            "requireId": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/mime.js",
            "memoizeId": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/mime.js",
            "descriptor": {
              "filename": "mime.js",
              "filepath": "node_modules/request/node_modules/mime/mime.js",
              "mtime": 1363819327,
              "code": "var path = require('path');\nvar fs = require('fs');\n\nfunction Mime() {\n  // Map of extension -> mime type\n  this.types = Object.create(null);\n\n  // Map of mime type -> extension\n  this.extensions = Object.create(null);\n}\n\n/**\n * Define mimetype -> extension mappings.  Each key is a mime-type that maps\n * to an array of extensions associated with the type.  The first extension is\n * used as the default extension for the type.\n *\n * e.g. mime.define({'audio/ogg', ['oga', 'ogg', 'spx']});\n *\n * @param map (Object) type definitions\n */\nMime.prototype.define = function (map) {\n  for (var type in map) {\n    var exts = map[type];\n\n    for (var i = 0; i < exts.length; i++) {\n      if (process.env.DEBUG_MIME && this.types[exts]) {\n        console.warn(this._loading.replace(/.*\\//, ''), 'changes \"' + exts[i] + '\" extension type from ' +\n          this.types[exts] + ' to ' + type);\n      }\n\n      this.types[exts[i]] = type;\n    }\n\n    // Default extension is the first one we encounter\n    if (!this.extensions[type]) {\n      this.extensions[type] = exts[0];\n    }\n  }\n};\n\n/**\n * Load an Apache2-style \".types\" file\n *\n * This may be called multiple times (it's expected).  Where files declare\n * overlapping types/extensions, the last file wins.\n *\n * @param file (String) path of file to load.\n */\nMime.prototype.load = function(file) {\n\n  this._loading = file;\n  // Read file and split into lines\n  var map = {},\n      content = fs.readFileSync(file, 'ascii'),\n      lines = content.split(/[\\r\\n]+/);\n\n  lines.forEach(function(line) {\n    // Clean up whitespace/comments, and split into fields\n    var fields = line.replace(/\\s*#.*|^\\s*|\\s*$/g, '').split(/\\s+/);\n    map[fields.shift()] = fields;\n  });\n\n  this.define(map);\n\n  this._loading = null;\n};\n\n/**\n * Lookup a mime type based on extension\n */\nMime.prototype.lookup = function(path, fallback) {\n  var ext = path.replace(/.*[\\.\\/]/, '').toLowerCase();\n\n  return this.types[ext] || fallback || this.default_type;\n};\n\n/**\n * Return file extension associated with a mime type\n */\nMime.prototype.extension = function(mimeType) {\n  var type = mimeType.match(/^\\s*([^;\\s]*)(?:;|\\s|$)/)[1].toLowerCase();\n  return this.extensions[type];\n};\n\n// Default instance\nvar mime = new Mime();\n\n// Load local copy of\n// http://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types\nmime.load(path.join(__dirname, 'types/mime.types'));\n\n// Load additional types from node.js community\nmime.load(path.join(__dirname, 'types/node.types'));\n\n// Default type\nmime.default_type = mime.lookup('bin');\n\n//\n// Additional API specific to the default instance\n//\n\nmime.Mime = Mime;\n\n/**\n * Lookup a charset based on mime type.\n */\nmime.charsets = {\n  lookup: function(mimeType, fallback) {\n    // Assume text types are utf8\n    return (/^text\\//).test(mimeType) ? 'UTF-8' : fallback;\n  }\n};\n\nmodule.exports = mime;\n",
              "globals": {
                "path": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "fs": {
                  "type": "assign"
                },
                "Mime": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                },
                "mime": {
                  "type": "assign"
                },
                "__dirname": {
                  "type": "reference"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "path": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/mime';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/mime';\nvar path = require('__SYSTEM__/path');\nvar fs = require('__SYSTEM__/fs');\n\nfunction Mime() {\n  // Map of extension -> mime type\n  this.types = Object.create(null);\n\n  // Map of mime type -> extension\n  this.extensions = Object.create(null);\n}\n\n/**\n * Define mimetype -> extension mappings.  Each key is a mime-type that maps\n * to an array of extensions associated with the type.  The first extension is\n * used as the default extension for the type.\n *\n * e.g. mime.define({'audio/ogg', ['oga', 'ogg', 'spx']});\n *\n * @param map (Object) type definitions\n */\nMime.prototype.define = function (map) {\n  for (var type in map) {\n    var exts = map[type];\n\n    for (var i = 0; i < exts.length; i++) {\n      if (process.env.DEBUG_MIME && this.types[exts]) {\n        console.warn(this._loading.replace(/.*\\//, ''), 'changes \"' + exts[i] + '\" extension type from ' +\n          this.types[exts] + ' to ' + type);\n      }\n\n      this.types[exts[i]] = type;\n    }\n\n    // Default extension is the first one we encounter\n    if (!this.extensions[type]) {\n      this.extensions[type] = exts[0];\n    }\n  }\n};\n\n/**\n * Load an Apache2-style \".types\" file\n *\n * This may be called multiple times (it's expected).  Where files declare\n * overlapping types/extensions, the last file wins.\n *\n * @param file (String) path of file to load.\n */\nMime.prototype.load = function(file) {\n\n  this._loading = file;\n  // Read file and split into lines\n  var map = {},\n      content = fs.readFileSync(file, 'ascii'),\n      lines = content.split(/[\\r\\n]+/);\n\n  lines.forEach(function(line) {\n    // Clean up whitespace/comments, and split into fields\n    var fields = line.replace(/\\s*#.*|^\\s*|\\s*$/g, '').split(/\\s+/);\n    map[fields.shift()] = fields;\n  });\n\n  this.define(map);\n\n  this._loading = null;\n};\n\n/**\n * Lookup a mime type based on extension\n */\nMime.prototype.lookup = function(path, fallback) {\n  var ext = path.replace(/.*[\\.\\/]/, '').toLowerCase();\n\n  return this.types[ext] || fallback || this.default_type;\n};\n\n/**\n * Return file extension associated with a mime type\n */\nMime.prototype.extension = function(mimeType) {\n  var type = mimeType.match(/^\\s*([^;\\s]*)(?:;|\\s|$)/)[1].toLowerCase();\n  return this.extensions[type];\n};\n\n// Default instance\nvar mime = new Mime();\n\n// Load local copy of\n// http://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types\nmime.load(path.join(__dirname, 'types/mime.types'));\n\n// Load additional types from node.js community\nmime.load(path.join(__dirname, 'types/node.types'));\n\n// Default type\nmime.default_type = mime.lookup('bin');\n\n//\n// Additional API specific to the default instance\n//\n\nmime.Mime = Mime;\n\n/**\n * Lookup a charset based on mime type.\n */\nmime.charsets = {\n  lookup: function(mimeType, fallback) {\n    // Assume text types are utf8\n    return (/^text\\//).test(mimeType) ? 'UTF-8' : fallback;\n  }\n};\n\nmodule.exports = mime;\n\nreturn {\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    Mime: (typeof Mime !== \"undefined\") ? Mime : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    __dirname: (typeof __dirname !== \"undefined\") ? __dirname : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}",
              "bottom": "return {\n    path: (typeof path !== \"undefined\") ? path : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    Mime: (typeof Mime !== \"undefined\") ? Mime : null,\n    Object: (typeof Object !== \"undefined\") ? Object : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    console: (typeof console !== \"undefined\") ? console : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    __dirname: (typeof __dirname !== \"undefined\") ? __dirname : null,\n    module: (typeof module !== \"undefined\") ? module : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "path": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/index.js": {
            "requireId": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/index.js",
            "memoizeId": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/tunnel-agent/index.js",
              "mtime": 1362170392,
              "code": "'use strict'\n\nvar net = require('net')\n  , tls = require('tls')\n  , http = require('http')\n  , https = require('https')\n  , events = require('events')\n  , assert = require('assert')\n  , util = require('util')\n  ;\n\nexports.httpOverHttp = httpOverHttp\nexports.httpsOverHttp = httpsOverHttp\nexports.httpOverHttps = httpOverHttps\nexports.httpsOverHttps = httpsOverHttps\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  return agent\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  agent.createSocket = createSecureSocket\n  return agent\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  return agent\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  agent.createSocket = createSecureSocket\n  return agent\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.proxyOptions = self.options.proxy || {}\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets\n  self.requests = []\n  self.sockets = []\n\n  self.on('free', function onFree(socket, host, port) {\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i]\n      if (pending.host === host && pending.port === port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1)\n        pending.request.onSocket(socket)\n        return\n      }\n    }\n    socket.destroy()\n    self.removeSocket(socket)\n  })\n}\nutil.inherits(TunnelingAgent, events.EventEmitter)\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port) {\n  var self = this\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push({host: host, port: port, request: req})\n    return\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket({host: host, port: port, request: req}, function(socket) {\n    socket.on('free', onFree)\n    socket.on('close', onCloseOrRemove)\n    socket.on('agentRemove', onCloseOrRemove)\n    req.onSocket(socket)\n\n    function onFree() {\n      self.emit('free', socket, host, port)\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket()\n      socket.removeListener('free', onFree)\n      socket.removeListener('close', onCloseOrRemove)\n      socket.removeListener('agentRemove', onCloseOrRemove)\n    }\n  })\n}\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this\n  var placeholder = {}\n  self.sockets.push(placeholder)\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, \n    { method: 'CONNECT'\n    , path: options.host + ':' + options.port\n    , agent: false\n    }\n  )\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {}\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64')\n  }\n\n  debug('making CONNECT request')\n  var connectReq = self.request(connectOptions)\n  connectReq.useChunkedEncodingByDefault = false // for v0.6\n  connectReq.once('response', onResponse) // for v0.6\n  connectReq.once('upgrade', onUpgrade)   // for v0.6\n  connectReq.once('connect', onConnect)   // for v0.7 or later\n  connectReq.once('error', onError)\n  connectReq.end()\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head)\n    })\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners()\n    socket.removeAllListeners()\n\n    if (res.statusCode === 200) {\n      assert.equal(head.length, 0)\n      debug('tunneling connection has established')\n      self.sockets[self.sockets.indexOf(placeholder)] = socket\n      cb(socket)\n    } else {\n      debug('tunneling socket could not be established, statusCode=%d', res.statusCode)\n      var error = new Error('tunneling socket could not be established, ' + 'statusCode=' + res.statusCode)\n      error.code = 'ECONNRESET'\n      options.request.emit('error', error)\n      self.removeSocket(placeholder)\n    }\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners()\n\n    debug('tunneling socket could not be established, cause=%s\\n', cause.message, cause.stack)\n    var error = new Error('tunneling socket could not be established, ' + 'cause=' + cause.message)\n    error.code = 'ECONNRESET'\n    options.request.emit('error', error)\n    self.removeSocket(placeholder)\n  }\n}\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) return\n  \n  this.sockets.splice(pos, 1)\n\n  var pending = this.requests.shift()\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket)\n    })\n  }\n}\n\nfunction createSecureSocket(options, cb) {\n  var self = this\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, mergeOptions({}, self.options, \n      { servername: options.host\n      , socket: socket\n      }\n    ))\n    cb(secureSocket)\n  })\n}\n\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i]\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides)\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j]\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k]\n        }\n      }\n    }\n  }\n  return target\n}\n\n\nvar debug\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments)\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0]\n    } else {\n      args.unshift('TUNNEL:')\n    }\n    console.error.apply(console, args)\n  }\n} else {\n  debug = function() {}\n}\nexports.debug = debug // for test\n",
              "globals": {
                "net": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "tls": {
                  "type": "assign"
                },
                "http": {
                  "type": "assign"
                },
                "https": {
                  "type": "assign"
                },
                "events": {
                  "type": "assign"
                },
                "assert": {
                  "type": "assign"
                },
                "util": {
                  "type": "assign"
                },
                "exports": {
                  "type": "reference"
                },
                "httpOverHttp": {
                  "type": "assign"
                },
                "httpsOverHttp": {
                  "type": "assign"
                },
                "httpOverHttps": {
                  "type": "assign"
                },
                "httpsOverHttps": {
                  "type": "assign"
                },
                "TunnelingAgent": {
                  "type": "assign"
                },
                "i": {
                  "type": "reference"
                },
                "mergeOptions": {
                  "type": "call"
                },
                "debug": {
                  "type": "call"
                },
                "process": {
                  "type": "reference"
                },
                "createSecureSocket": {
                  "type": "assign"
                },
                "Object": {
                  "type": "reference"
                },
                "Array": {
                  "type": "reference"
                },
                "console": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "net": {
                    "where": "inline"
                  },
                  "tls": {
                    "where": "inline"
                  },
                  "http": {
                    "where": "inline"
                  },
                  "https": {
                    "where": "inline"
                  },
                  "events": {
                    "where": "inline"
                  },
                  "assert": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/tunnel-agent';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/tunnel-agent';\n'use strict'\n\nvar net = require('__SYSTEM__/net')\n  , tls = require('__SYSTEM__/tls')\n  , http = require('__SYSTEM__/http')\n  , https = require('__SYSTEM__/https')\n  , events = require('__SYSTEM__/events')\n  , assert = require('__SYSTEM__/assert')\n  , util = require('__SYSTEM__/util')\n  ;\n\nexports.httpOverHttp = httpOverHttp\nexports.httpsOverHttp = httpsOverHttp\nexports.httpOverHttps = httpOverHttps\nexports.httpsOverHttps = httpsOverHttps\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  return agent\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = http.request\n  agent.createSocket = createSecureSocket\n  return agent\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  return agent\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options)\n  agent.request = https.request\n  agent.createSocket = createSecureSocket\n  return agent\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.proxyOptions = self.options.proxy || {}\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets\n  self.requests = []\n  self.sockets = []\n\n  self.on('free', function onFree(socket, host, port) {\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i]\n      if (pending.host === host && pending.port === port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1)\n        pending.request.onSocket(socket)\n        return\n      }\n    }\n    socket.destroy()\n    self.removeSocket(socket)\n  })\n}\nutil.inherits(TunnelingAgent, events.EventEmitter)\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port) {\n  var self = this\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push({host: host, port: port, request: req})\n    return\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket({host: host, port: port, request: req}, function(socket) {\n    socket.on('free', onFree)\n    socket.on('close', onCloseOrRemove)\n    socket.on('agentRemove', onCloseOrRemove)\n    req.onSocket(socket)\n\n    function onFree() {\n      self.emit('free', socket, host, port)\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket()\n      socket.removeListener('free', onFree)\n      socket.removeListener('close', onCloseOrRemove)\n      socket.removeListener('agentRemove', onCloseOrRemove)\n    }\n  })\n}\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this\n  var placeholder = {}\n  self.sockets.push(placeholder)\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, \n    { method: 'CONNECT'\n    , path: options.host + ':' + options.port\n    , agent: false\n    }\n  )\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {}\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64')\n  }\n\n  debug('making CONNECT request')\n  var connectReq = self.request(connectOptions)\n  connectReq.useChunkedEncodingByDefault = false // for v0.6\n  connectReq.once('response', onResponse) // for v0.6\n  connectReq.once('upgrade', onUpgrade)   // for v0.6\n  connectReq.once('connect', onConnect)   // for v0.7 or later\n  connectReq.once('error', onError)\n  connectReq.end()\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head)\n    })\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners()\n    socket.removeAllListeners()\n\n    if (res.statusCode === 200) {\n      assert.equal(head.length, 0)\n      debug('tunneling connection has established')\n      self.sockets[self.sockets.indexOf(placeholder)] = socket\n      cb(socket)\n    } else {\n      debug('tunneling socket could not be established, statusCode=%d', res.statusCode)\n      var error = new Error('tunneling socket could not be established, ' + 'statusCode=' + res.statusCode)\n      error.code = 'ECONNRESET'\n      options.request.emit('error', error)\n      self.removeSocket(placeholder)\n    }\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners()\n\n    debug('tunneling socket could not be established, cause=%s\\n', cause.message, cause.stack)\n    var error = new Error('tunneling socket could not be established, ' + 'cause=' + cause.message)\n    error.code = 'ECONNRESET'\n    options.request.emit('error', error)\n    self.removeSocket(placeholder)\n  }\n}\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) return\n  \n  this.sockets.splice(pos, 1)\n\n  var pending = this.requests.shift()\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket)\n    })\n  }\n}\n\nfunction createSecureSocket(options, cb) {\n  var self = this\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, mergeOptions({}, self.options, \n      { servername: options.host\n      , socket: socket\n      }\n    ))\n    cb(secureSocket)\n  })\n}\n\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i]\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides)\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j]\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k]\n        }\n      }\n    }\n  }\n  return target\n}\n\n\nvar debug\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments)\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0]\n    } else {\n      args.unshift('TUNNEL:')\n    }\n    console.error.apply(console, args)\n  }\n} else {\n  debug = function() {}\n}\nexports.debug = debug // for test\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "net": {
                  "where": "inline"
                },
                "tls": {
                  "where": "inline"
                },
                "http": {
                  "where": "inline"
                },
                "https": {
                  "where": "inline"
                },
                "events": {
                  "where": "inline"
                },
                "assert": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/stringify.js": {
            "requireId": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/stringify.js",
            "memoizeId": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/stringify.js",
            "descriptor": {
              "filename": "stringify.js",
              "filepath": "node_modules/request/node_modules/json-stringify-safe/stringify.js",
              "mtime": 1363154454,
              "code": "module.exports = stringify;\n\nfunction getSerialize (fn, decycle) {\n  var seen = [];\n  decycle = decycle || function(key, value) {\n    return '[Circular]';\n  };\n  return function(key, value) {\n    var ret = value;\n    if (typeof value === 'object' && value) {\n      if (seen.indexOf(value) !== -1)\n        ret = decycle(key, value);\n      else\n        seen.push(value);\n    }\n    if (fn) ret = fn(key, ret);\n    return ret;\n  }\n}\n\nfunction stringify(obj, fn, spaces, decycle) {\n  return JSON.stringify(obj, getSerialize(fn, decycle), spaces);\n}\n\nstringify.getSerialize = getSerialize;\n",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "getSerialize": {
                  "type": "assign"
                },
                "stringify": {
                  "type": "assign"
                },
                "JSON": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/json-stringify-safe';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/json-stringify-safe';\nmodule.exports = stringify;\n\nfunction getSerialize (fn, decycle) {\n  var seen = [];\n  decycle = decycle || function(key, value) {\n    return '[Circular]';\n  };\n  return function(key, value) {\n    var ret = value;\n    if (typeof value === 'object' && value) {\n      if (seen.indexOf(value) !== -1)\n        ret = decycle(key, value);\n      else\n        seen.push(value);\n    }\n    if (fn) ret = fn(key, ret);\n    return ret;\n  }\n}\n\nfunction stringify(obj, fn, spaces, decycle) {\n  return JSON.stringify(obj, getSerialize(fn, decycle), spaces);\n}\n\nstringify.getSerialize = getSerialize;\n\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    getSerialize: (typeof getSerialize !== \"undefined\") ? getSerialize : null,\n    stringify: (typeof stringify !== \"undefined\") ? stringify : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    getSerialize: (typeof getSerialize !== \"undefined\") ? getSerialize : null,\n    stringify: (typeof stringify !== \"undefined\") ? stringify : null,\n    JSON: (typeof JSON !== \"undefined\") ? JSON : null\n};\n}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/index.js": {
            "requireId": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/index.js",
            "memoizeId": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/forever-agent/index.js",
              "mtime": 1366064761,
              "code": "module.exports = ForeverAgent\nForeverAgent.SSL = ForeverAgentSSL\n\nvar util = require('util')\n  , Agent = require('http').Agent\n  , net = require('net')\n  , tls = require('tls')\n  , AgentSSL = require('https').Agent\n\nfunction ForeverAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.requests = {}\n  self.sockets = {}\n  self.freeSockets = {}\n  self.maxSockets = self.options.maxSockets || Agent.defaultMaxSockets\n  self.minSockets = self.options.minSockets || ForeverAgent.defaultMinSockets\n  self.on('free', function(socket, host, port) {\n    var name = host + ':' + port\n    if (self.requests[name] && self.requests[name].length) {\n      self.requests[name].shift().onSocket(socket)\n    } else if (self.sockets[name].length < self.minSockets) {\n      if (!self.freeSockets[name]) self.freeSockets[name] = []\n      self.freeSockets[name].push(socket)\n      \n      // if an error happens while we don't use the socket anyway, meh, throw the socket away\n      function onIdleError() {\n        socket.destroy()\n      }\n      socket._onIdleError = onIdleError\n      socket.on('error', onIdleError)\n    } else {\n      // If there are no pending requests just destroy the\n      // socket and it will get removed from the pool. This\n      // gets us out of timeout issues and allows us to\n      // default to Connection:keep-alive.\n      socket.destroy()\n    }\n  })\n\n}\nutil.inherits(ForeverAgent, Agent)\n\nForeverAgent.defaultMinSockets = 5\n\n\nForeverAgent.prototype.createConnection = net.createConnection\nForeverAgent.prototype.addRequestNoreuse = Agent.prototype.addRequest\nForeverAgent.prototype.addRequest = function(req, host, port) {\n  var name = host + ':' + port\n  if (this.freeSockets[name] && this.freeSockets[name].length > 0 && !req.useChunkedEncodingByDefault) {\n    var idleSocket = this.freeSockets[name].pop()\n    idleSocket.removeListener('error', idleSocket._onIdleError)\n    delete idleSocket._onIdleError\n    req._reusedSocket = true\n    req.onSocket(idleSocket)\n  } else {\n    this.addRequestNoreuse(req, host, port)\n  }\n}\n\nForeverAgent.prototype.removeSocket = function(s, name, host, port) {\n  if (this.sockets[name]) {\n    var index = this.sockets[name].indexOf(s)\n    if (index !== -1) {\n      this.sockets[name].splice(index, 1)\n    }\n  } else if (this.sockets[name] && this.sockets[name].length === 0) {\n    // don't leak\n    delete this.sockets[name]\n    delete this.requests[name]\n  }\n  \n  if (this.freeSockets[name]) {\n    var index = this.freeSockets[name].indexOf(s)\n    if (index !== -1) {\n      this.freeSockets[name].splice(index, 1)\n      if (this.freeSockets[name].length === 0) {\n        delete this.freeSockets[name]\n      }\n    }\n  }\n\n  if (this.requests[name] && this.requests[name].length) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(name, host, port).emit('free')\n  }\n}\n\nfunction ForeverAgentSSL (options) {\n  ForeverAgent.call(this, options)\n}\nutil.inherits(ForeverAgentSSL, ForeverAgent)\n\nForeverAgentSSL.prototype.createConnection = createConnectionSSL\nForeverAgentSSL.prototype.addRequestNoreuse = AgentSSL.prototype.addRequest\n\nfunction createConnectionSSL (port, host, options) {\n  if (typeof port === 'object') {\n    options = port;\n  } else if (typeof host === 'object') {\n    options = host;\n  } else if (typeof options === 'object') {\n    options = options;\n  } else {\n    options = {};\n  }\n\n  if (typeof port === 'number') {\n    options.port = port;\n  }\n\n  if (typeof host === 'string') {\n    options.host = host;\n  }\n\n  return tls.connect(options);\n}\n",
              "globals": {
                "module": {
                  "type": "reference"
                },
                "ForeverAgent": {
                  "type": "reference"
                },
                "util": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Agent": {
                  "type": "assign"
                },
                "net": {
                  "type": "assign"
                },
                "tls": {
                  "type": "assign"
                },
                "AgentSSL": {
                  "type": "assign"
                },
                "ForeverAgentSSL": {
                  "type": "assign"
                },
                "createConnectionSSL": {
                  "type": "assign"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "util": {
                    "where": "inline"
                  },
                  "http": {
                    "where": "inline"
                  },
                  "net": {
                    "where": "inline"
                  },
                  "tls": {
                    "where": "inline"
                  },
                  "https": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/forever-agent';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/forever-agent';\nmodule.exports = ForeverAgent\nForeverAgent.SSL = ForeverAgentSSL\n\nvar util = require('__SYSTEM__/util')\n  , Agent = require('__SYSTEM__/http').Agent\n  , net = require('__SYSTEM__/net')\n  , tls = require('__SYSTEM__/tls')\n  , AgentSSL = require('__SYSTEM__/https').Agent\n\nfunction ForeverAgent(options) {\n  var self = this\n  self.options = options || {}\n  self.requests = {}\n  self.sockets = {}\n  self.freeSockets = {}\n  self.maxSockets = self.options.maxSockets || Agent.defaultMaxSockets\n  self.minSockets = self.options.minSockets || ForeverAgent.defaultMinSockets\n  self.on('free', function(socket, host, port) {\n    var name = host + ':' + port\n    if (self.requests[name] && self.requests[name].length) {\n      self.requests[name].shift().onSocket(socket)\n    } else if (self.sockets[name].length < self.minSockets) {\n      if (!self.freeSockets[name]) self.freeSockets[name] = []\n      self.freeSockets[name].push(socket)\n      \n      // if an error happens while we don't use the socket anyway, meh, throw the socket away\n      function onIdleError() {\n        socket.destroy()\n      }\n      socket._onIdleError = onIdleError\n      socket.on('error', onIdleError)\n    } else {\n      // If there are no pending requests just destroy the\n      // socket and it will get removed from the pool. This\n      // gets us out of timeout issues and allows us to\n      // default to Connection:keep-alive.\n      socket.destroy()\n    }\n  })\n\n}\nutil.inherits(ForeverAgent, Agent)\n\nForeverAgent.defaultMinSockets = 5\n\n\nForeverAgent.prototype.createConnection = net.createConnection\nForeverAgent.prototype.addRequestNoreuse = Agent.prototype.addRequest\nForeverAgent.prototype.addRequest = function(req, host, port) {\n  var name = host + ':' + port\n  if (this.freeSockets[name] && this.freeSockets[name].length > 0 && !req.useChunkedEncodingByDefault) {\n    var idleSocket = this.freeSockets[name].pop()\n    idleSocket.removeListener('error', idleSocket._onIdleError)\n    delete idleSocket._onIdleError\n    req._reusedSocket = true\n    req.onSocket(idleSocket)\n  } else {\n    this.addRequestNoreuse(req, host, port)\n  }\n}\n\nForeverAgent.prototype.removeSocket = function(s, name, host, port) {\n  if (this.sockets[name]) {\n    var index = this.sockets[name].indexOf(s)\n    if (index !== -1) {\n      this.sockets[name].splice(index, 1)\n    }\n  } else if (this.sockets[name] && this.sockets[name].length === 0) {\n    // don't leak\n    delete this.sockets[name]\n    delete this.requests[name]\n  }\n  \n  if (this.freeSockets[name]) {\n    var index = this.freeSockets[name].indexOf(s)\n    if (index !== -1) {\n      this.freeSockets[name].splice(index, 1)\n      if (this.freeSockets[name].length === 0) {\n        delete this.freeSockets[name]\n      }\n    }\n  }\n\n  if (this.requests[name] && this.requests[name].length) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(name, host, port).emit('free')\n  }\n}\n\nfunction ForeverAgentSSL (options) {\n  ForeverAgent.call(this, options)\n}\nutil.inherits(ForeverAgentSSL, ForeverAgent)\n\nForeverAgentSSL.prototype.createConnection = createConnectionSSL\nForeverAgentSSL.prototype.addRequestNoreuse = AgentSSL.prototype.addRequest\n\nfunction createConnectionSSL (port, host, options) {\n  if (typeof port === 'object') {\n    options = port;\n  } else if (typeof host === 'object') {\n    options = host;\n  } else if (typeof options === 'object') {\n    options = options;\n  } else {\n    options = {};\n  }\n\n  if (typeof port === 'number') {\n    options.port = port;\n  }\n\n  if (typeof host === 'string') {\n    options.host = host;\n  }\n\n  return tls.connect(options);\n}\n\nreturn {\n    module: (typeof module !== \"undefined\") ? module : null,\n    ForeverAgent: (typeof ForeverAgent !== \"undefined\") ? ForeverAgent : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Agent: (typeof Agent !== \"undefined\") ? Agent : null,\n    net: (typeof net !== \"undefined\") ? net : null,\n    tls: (typeof tls !== \"undefined\") ? tls : null,\n    AgentSSL: (typeof AgentSSL !== \"undefined\") ? AgentSSL : null,\n    ForeverAgentSSL: (typeof ForeverAgentSSL !== \"undefined\") ? ForeverAgentSSL : null,\n    createConnectionSSL: (typeof createConnectionSSL !== \"undefined\") ? createConnectionSSL : null\n};\n}",
              "bottom": "return {\n    module: (typeof module !== \"undefined\") ? module : null,\n    ForeverAgent: (typeof ForeverAgent !== \"undefined\") ? ForeverAgent : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Agent: (typeof Agent !== \"undefined\") ? Agent : null,\n    net: (typeof net !== \"undefined\") ? net : null,\n    tls: (typeof tls !== \"undefined\") ? tls : null,\n    AgentSSL: (typeof AgentSSL !== \"undefined\") ? AgentSSL : null,\n    ForeverAgentSSL: (typeof ForeverAgentSSL !== \"undefined\") ? ForeverAgentSSL : null,\n    createConnectionSSL: (typeof createConnectionSSL !== \"undefined\") ? createConnectionSSL : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "util": {
                  "where": "inline"
                },
                "http": {
                  "where": "inline"
                },
                "net": {
                  "where": "inline"
                },
                "tls": {
                  "where": "inline"
                },
                "https": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/lib/form_data.js": {
            "requireId": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/lib/form_data.js",
            "memoizeId": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/lib/form_data.js",
            "descriptor": {
              "filename": "form_data.js",
              "filepath": "node_modules/request/node_modules/form-data/lib/form_data.js",
              "mtime": 1366517895,
              "code": "var CombinedStream = require('combined-stream');\nvar util = require('util');\nvar path = require('path');\nvar http = require('http');\nvar https = require('https');\nvar parseUrl = require('url').parse;\nvar fs = require('fs');\nvar mime = require('mime');\nvar async = require('async');\n\nmodule.exports = FormData;\nfunction FormData() {\n  this._overheadLength = 0;\n  this._valueLength = 0;\n  this._lengthRetrievers = [];\n\n  CombinedStream.call(this);\n}\nutil.inherits(FormData, CombinedStream);\n\nFormData.LINE_BREAK = '\\r\\n';\n\nFormData.prototype.append = function(field, value, options) {\n  options = options || {};\n\n  var append = CombinedStream.prototype.append.bind(this);\n\n  // all that streamy business can't handle numbers\n  if (typeof value == 'number') value = ''+value;\n\n  var header = this._multiPartHeader(field, value, options);\n  var footer = this._multiPartFooter(field, value, options);\n\n  append(header);\n  append(value);\n  append(footer);\n\n  // pass along options.knownLength\n  this._trackLength(header, value, options);\n};\n\nFormData.prototype._trackLength = function(header, value, options) {\n  var valueLength = 0;\n\n  // used w/ trackLengthSync(), when length is known.\n  // e.g. for streaming directly from a remote server,\n  // w/ a known file a size, and not wanting to wait for\n  // incoming file to finish to get its size.\n  if (options.knownLength != null) {\n    valueLength += +options.knownLength;\n  } else if (Buffer.isBuffer(value)) {\n    valueLength = value.length;\n  } else if (typeof value === 'string') {\n    valueLength = Buffer.byteLength(value);\n  }\n\n  this._valueLength += valueLength;\n\n  // @check why add CRLF? does this account for custom/multiple CRLFs?\n  this._overheadLength +=\n    Buffer.byteLength(header) +\n    + FormData.LINE_BREAK.length;\n\n  // empty or either doesn't have path or not an http response\n  if (!value || ( !value.path && !(value.readable && value.hasOwnProperty('httpVersion')) )) {\n    return;\n  }\n\n  this._lengthRetrievers.push(function(next) {\n\n    // do we already know the size?\n    // 0 additional leaves value from getSyncLength()\n    if (options.knownLength != null) {\n      next(null, 0);\n\n    // check if it's local file\n    } else if (value.hasOwnProperty('fd')) {\n      fs.stat(value.path, function(err, stat) {\n        if (err) {\n          next(err);\n          return;\n        }\n\n        next(null, stat.size);\n      });\n\n    // or http response\n    } else if (value.hasOwnProperty('httpVersion')) {\n      next(null, +value.headers['content-length']);\n\n    // or request stream http://github.com/mikeal/request\n    } else if (value.hasOwnProperty('httpModule')) {\n      // wait till response come back\n      value.on('response', function(response) {\n        value.pause();\n        next(null, +response.headers['content-length']);\n      });\n      value.resume();\n\n    // something else\n    } else {\n      next('Unknown stream');\n    }\n  });\n};\n\nFormData.prototype._multiPartHeader = function(field, value, options) {\n  var boundary = this.getBoundary();\n  var header = '';\n\n  // custom header specified (as string)?\n  // it becomes responsible for boundary\n  // (e.g. to handle extra CRLFs on .NET servers)\n  if (options.header != null) {\n    header = options.header;\n  } else {\n    header += '--' + boundary + FormData.LINE_BREAK +\n      'Content-Disposition: form-data; name=\"' + field + '\"';\n\n    // fs- and request- streams have path property\n    // or use custom filename and/or contentType\n    // TODO: Use request's response mime-type\n    if (options.filename || value.path) {\n      header +=\n        '; filename=\"' + path.basename(options.filename || value.path) + '\"' + FormData.LINE_BREAK +\n        'Content-Type: ' +  (options.contentType || mime.lookup(options.filename || value.path));\n\n    // http response has not\n    } else if (value.readable && value.hasOwnProperty('httpVersion')) {\n      header +=\n        '; filename=\"' + path.basename(value.client._httpMessage.path) + '\"' + FormData.LINE_BREAK +\n        'Content-Type: ' + value.headers['content-type'];\n    }\n\n    header += FormData.LINE_BREAK + FormData.LINE_BREAK;\n  }\n\n  return header;\n};\n\nFormData.prototype._multiPartFooter = function(field, value, options) {\n  return function(next) {\n    var footer = FormData.LINE_BREAK;\n\n    var lastPart = (this._streams.length === 0);\n    if (lastPart) {\n      footer += this._lastBoundary();\n    }\n\n    next(footer);\n  }.bind(this);\n};\n\nFormData.prototype._lastBoundary = function() {\n  return '--' + this.getBoundary() + '--';\n};\n\nFormData.prototype.getHeaders = function(userHeaders) {\n  var formHeaders = {\n    'content-type': 'multipart/form-data; boundary=' + this.getBoundary()\n  };\n\n  for (var header in userHeaders) {\n    formHeaders[header.toLowerCase()] = userHeaders[header];\n  }\n\n  return formHeaders;\n}\n\nFormData.prototype.getCustomHeaders = function(contentType) {\n    contentType = contentType ? contentType : 'multipart/form-data';\n\n    var formHeaders = {\n        'content-type': contentType + '; boundary=' + this.getBoundary(),\n        'content-length': this.getLengthSync()\n    };\n\n    return formHeaders;\n}\n\nFormData.prototype.getBoundary = function() {\n  if (!this._boundary) {\n    this._generateBoundary();\n  }\n\n  return this._boundary;\n};\n\nFormData.prototype._generateBoundary = function() {\n  // This generates a 50 character boundary similar to those used by Firefox.\n  // They are optimized for boyer-moore parsing.\n  var boundary = '--------------------------';\n  for (var i = 0; i < 24; i++) {\n    boundary += Math.floor(Math.random() * 10).toString(16);\n  }\n\n  this._boundary = boundary;\n};\n\nFormData.prototype.getLengthSync = function() {\n    var knownLength = this._overheadLength + this._valueLength;\n\n    if (this._streams.length) {\n        knownLength += this._lastBoundary().length;\n    }\n\n    return knownLength;\n};\n\nFormData.prototype.getLength = function(cb) {\n  var knownLength = this._overheadLength + this._valueLength;\n\n  if (this._streams.length) {\n    knownLength += this._lastBoundary().length;\n  }\n\n  if (!this._lengthRetrievers.length) {\n    process.nextTick(cb.bind(this, null, knownLength));\n    return;\n  }\n\n  async.parallel(this._lengthRetrievers, function(err, values) {\n    if (err) {\n      cb(err);\n      return;\n    }\n\n    values.forEach(function(length) {\n      knownLength += length;\n    });\n\n    cb(null, knownLength);\n  });\n};\n\nFormData.prototype.submit = function(params, cb) {\n  this.getLength(function(err, length) {\n\n    var request\n      , options\n      , defaults = {\n          method : 'post',\n          port   : 80,\n          headers: this.getHeaders({'Content-Length': length})\n      };\n\n    // parse provided url if it's string\n    // or treat it as options object\n    if (typeof params == 'string') {\n      params = parseUrl(params);\n\n      options = populate({\n        port: params.port,\n        path: params.pathname,\n        host: params.hostname\n      }, defaults);\n    }\n    else // use custom params\n    {\n      options = populate(params, defaults);\n    }\n\n    // https if specified, fallback to http in any other case\n    if (params.protocol == 'https:') {\n      // override default port\n      if (!params.port) options.port = 443;\n      request = https.request(options);\n    } else {\n      request = http.request(options);\n    }\n\n    this.pipe(request);\n    if (cb) {\n      request.on('error', cb);\n      request.on('response', cb.bind(this, null));\n    }\n\n    return request;\n  }.bind(this));\n};\n\n/*\n * Santa's little helpers\n */\n\n// populates missing values\nfunction populate(dst, src) {\n  for (var prop in src) {\n    if (!dst[prop]) dst[prop] = src[prop];\n  }\n  return dst;\n}\n",
              "globals": {
                "CombinedStream": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "util": {
                  "type": "assign"
                },
                "path": {
                  "type": "assign"
                },
                "http": {
                  "type": "assign"
                },
                "https": {
                  "type": "assign"
                },
                "parseUrl": {
                  "type": "assign"
                },
                "fs": {
                  "type": "assign"
                },
                "mime": {
                  "type": "assign"
                },
                "async": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "FormData": {
                  "type": "assign"
                },
                "Buffer": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "process": {
                  "type": "reference"
                },
                "populate": {
                  "type": "call"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "combined-stream": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  },
                  "path": {
                    "where": "inline"
                  },
                  "http": {
                    "where": "inline"
                  },
                  "https": {
                    "where": "inline"
                  },
                  "url": {
                    "where": "inline"
                  },
                  "fs": {
                    "where": "inline"
                  },
                  "mime": {
                    "where": "inline"
                  },
                  "async": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/lib';\nvar CombinedStream = require('combined-stream');\nvar util = require('__SYSTEM__/util');\nvar path = require('__SYSTEM__/path');\nvar http = require('__SYSTEM__/http');\nvar https = require('__SYSTEM__/https');\nvar parseUrl = require('__SYSTEM__/url').parse;\nvar fs = require('__SYSTEM__/fs');\nvar mime = require('mime');\nvar async = require('async');\n\nmodule.exports = FormData;\nfunction FormData() {\n  this._overheadLength = 0;\n  this._valueLength = 0;\n  this._lengthRetrievers = [];\n\n  CombinedStream.call(this);\n}\nutil.inherits(FormData, CombinedStream);\n\nFormData.LINE_BREAK = '\\r\\n';\n\nFormData.prototype.append = function(field, value, options) {\n  options = options || {};\n\n  var append = CombinedStream.prototype.append.bind(this);\n\n  // all that streamy business can't handle numbers\n  if (typeof value == 'number') value = ''+value;\n\n  var header = this._multiPartHeader(field, value, options);\n  var footer = this._multiPartFooter(field, value, options);\n\n  append(header);\n  append(value);\n  append(footer);\n\n  // pass along options.knownLength\n  this._trackLength(header, value, options);\n};\n\nFormData.prototype._trackLength = function(header, value, options) {\n  var valueLength = 0;\n\n  // used w/ trackLengthSync(), when length is known.\n  // e.g. for streaming directly from a remote server,\n  // w/ a known file a size, and not wanting to wait for\n  // incoming file to finish to get its size.\n  if (options.knownLength != null) {\n    valueLength += +options.knownLength;\n  } else if (Buffer.isBuffer(value)) {\n    valueLength = value.length;\n  } else if (typeof value === 'string') {\n    valueLength = Buffer.byteLength(value);\n  }\n\n  this._valueLength += valueLength;\n\n  // @check why add CRLF? does this account for custom/multiple CRLFs?\n  this._overheadLength +=\n    Buffer.byteLength(header) +\n    + FormData.LINE_BREAK.length;\n\n  // empty or either doesn't have path or not an http response\n  if (!value || ( !value.path && !(value.readable && value.hasOwnProperty('httpVersion')) )) {\n    return;\n  }\n\n  this._lengthRetrievers.push(function(next) {\n\n    // do we already know the size?\n    // 0 additional leaves value from getSyncLength()\n    if (options.knownLength != null) {\n      next(null, 0);\n\n    // check if it's local file\n    } else if (value.hasOwnProperty('fd')) {\n      fs.stat(value.path, function(err, stat) {\n        if (err) {\n          next(err);\n          return;\n        }\n\n        next(null, stat.size);\n      });\n\n    // or http response\n    } else if (value.hasOwnProperty('httpVersion')) {\n      next(null, +value.headers['content-length']);\n\n    // or request stream http://github.com/mikeal/request\n    } else if (value.hasOwnProperty('httpModule')) {\n      // wait till response come back\n      value.on('response', function(response) {\n        value.pause();\n        next(null, +response.headers['content-length']);\n      });\n      value.resume();\n\n    // something else\n    } else {\n      next('Unknown stream');\n    }\n  });\n};\n\nFormData.prototype._multiPartHeader = function(field, value, options) {\n  var boundary = this.getBoundary();\n  var header = '';\n\n  // custom header specified (as string)?\n  // it becomes responsible for boundary\n  // (e.g. to handle extra CRLFs on .NET servers)\n  if (options.header != null) {\n    header = options.header;\n  } else {\n    header += '--' + boundary + FormData.LINE_BREAK +\n      'Content-Disposition: form-data; name=\"' + field + '\"';\n\n    // fs- and request- streams have path property\n    // or use custom filename and/or contentType\n    // TODO: Use request's response mime-type\n    if (options.filename || value.path) {\n      header +=\n        '; filename=\"' + path.basename(options.filename || value.path) + '\"' + FormData.LINE_BREAK +\n        'Content-Type: ' +  (options.contentType || mime.lookup(options.filename || value.path));\n\n    // http response has not\n    } else if (value.readable && value.hasOwnProperty('httpVersion')) {\n      header +=\n        '; filename=\"' + path.basename(value.client._httpMessage.path) + '\"' + FormData.LINE_BREAK +\n        'Content-Type: ' + value.headers['content-type'];\n    }\n\n    header += FormData.LINE_BREAK + FormData.LINE_BREAK;\n  }\n\n  return header;\n};\n\nFormData.prototype._multiPartFooter = function(field, value, options) {\n  return function(next) {\n    var footer = FormData.LINE_BREAK;\n\n    var lastPart = (this._streams.length === 0);\n    if (lastPart) {\n      footer += this._lastBoundary();\n    }\n\n    next(footer);\n  }.bind(this);\n};\n\nFormData.prototype._lastBoundary = function() {\n  return '--' + this.getBoundary() + '--';\n};\n\nFormData.prototype.getHeaders = function(userHeaders) {\n  var formHeaders = {\n    'content-type': 'multipart/form-data; boundary=' + this.getBoundary()\n  };\n\n  for (var header in userHeaders) {\n    formHeaders[header.toLowerCase()] = userHeaders[header];\n  }\n\n  return formHeaders;\n}\n\nFormData.prototype.getCustomHeaders = function(contentType) {\n    contentType = contentType ? contentType : 'multipart/form-data';\n\n    var formHeaders = {\n        'content-type': contentType + '; boundary=' + this.getBoundary(),\n        'content-length': this.getLengthSync()\n    };\n\n    return formHeaders;\n}\n\nFormData.prototype.getBoundary = function() {\n  if (!this._boundary) {\n    this._generateBoundary();\n  }\n\n  return this._boundary;\n};\n\nFormData.prototype._generateBoundary = function() {\n  // This generates a 50 character boundary similar to those used by Firefox.\n  // They are optimized for boyer-moore parsing.\n  var boundary = '--------------------------';\n  for (var i = 0; i < 24; i++) {\n    boundary += Math.floor(Math.random() * 10).toString(16);\n  }\n\n  this._boundary = boundary;\n};\n\nFormData.prototype.getLengthSync = function() {\n    var knownLength = this._overheadLength + this._valueLength;\n\n    if (this._streams.length) {\n        knownLength += this._lastBoundary().length;\n    }\n\n    return knownLength;\n};\n\nFormData.prototype.getLength = function(cb) {\n  var knownLength = this._overheadLength + this._valueLength;\n\n  if (this._streams.length) {\n    knownLength += this._lastBoundary().length;\n  }\n\n  if (!this._lengthRetrievers.length) {\n    process.nextTick(cb.bind(this, null, knownLength));\n    return;\n  }\n\n  async.parallel(this._lengthRetrievers, function(err, values) {\n    if (err) {\n      cb(err);\n      return;\n    }\n\n    values.forEach(function(length) {\n      knownLength += length;\n    });\n\n    cb(null, knownLength);\n  });\n};\n\nFormData.prototype.submit = function(params, cb) {\n  this.getLength(function(err, length) {\n\n    var request\n      , options\n      , defaults = {\n          method : 'post',\n          port   : 80,\n          headers: this.getHeaders({'Content-Length': length})\n      };\n\n    // parse provided url if it's string\n    // or treat it as options object\n    if (typeof params == 'string') {\n      params = parseUrl(params);\n\n      options = populate({\n        port: params.port,\n        path: params.pathname,\n        host: params.hostname\n      }, defaults);\n    }\n    else // use custom params\n    {\n      options = populate(params, defaults);\n    }\n\n    // https if specified, fallback to http in any other case\n    if (params.protocol == 'https:') {\n      // override default port\n      if (!params.port) options.port = 443;\n      request = https.request(options);\n    } else {\n      request = http.request(options);\n    }\n\n    this.pipe(request);\n    if (cb) {\n      request.on('error', cb);\n      request.on('response', cb.bind(this, null));\n    }\n\n    return request;\n  }.bind(this));\n};\n\n/*\n * Santa's little helpers\n */\n\n// populates missing values\nfunction populate(dst, src) {\n  for (var prop in src) {\n    if (!dst[prop]) dst[prop] = src[prop];\n  }\n  return dst;\n}\n\nreturn {\n    CombinedStream: (typeof CombinedStream !== \"undefined\") ? CombinedStream : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    http: (typeof http !== \"undefined\") ? http : null,\n    https: (typeof https !== \"undefined\") ? https : null,\n    parseUrl: (typeof parseUrl !== \"undefined\") ? parseUrl : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    async: (typeof async !== \"undefined\") ? async : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    FormData: (typeof FormData !== \"undefined\") ? FormData : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    populate: (typeof populate !== \"undefined\") ? populate : null\n};\n}",
              "bottom": "return {\n    CombinedStream: (typeof CombinedStream !== \"undefined\") ? CombinedStream : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    path: (typeof path !== \"undefined\") ? path : null,\n    http: (typeof http !== \"undefined\") ? http : null,\n    https: (typeof https !== \"undefined\") ? https : null,\n    parseUrl: (typeof parseUrl !== \"undefined\") ? parseUrl : null,\n    fs: (typeof fs !== \"undefined\") ? fs : null,\n    mime: (typeof mime !== \"undefined\") ? mime : null,\n    async: (typeof async !== \"undefined\") ? async : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    FormData: (typeof FormData !== \"undefined\") ? FormData : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null,\n    Math: (typeof Math !== \"undefined\") ? Math : null,\n    process: (typeof process !== \"undefined\") ? process : null,\n    populate: (typeof populate !== \"undefined\") ? populate : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "combined-stream": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                },
                "path": {
                  "where": "inline"
                },
                "http": {
                  "where": "inline"
                },
                "https": {
                  "where": "inline"
                },
                "url": {
                  "where": "inline"
                },
                "fs": {
                  "where": "inline"
                },
                "mime": {
                  "where": "inline"
                },
                "async": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/lib/combined_stream.js": {
            "requireId": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/lib/combined_stream.js",
            "memoizeId": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/lib/combined_stream.js",
            "descriptor": {
              "filename": "combined_stream.js",
              "filepath": "node_modules/request/node_modules/form-data/node_modules/combined-stream/lib/combined_stream.js",
              "mtime": 1359829774,
              "code": "var util = require('util');\nvar Stream = require('stream').Stream;\nvar DelayedStream = require('delayed-stream');\n\nmodule.exports = CombinedStream;\nfunction CombinedStream() {\n  this.writable = false;\n  this.readable = true;\n  this.dataSize = 0;\n  this.maxDataSize = 2 * 1024 * 1024;\n  this.pauseStreams = true;\n\n  this._released = false;\n  this._streams = [];\n  this._currentStream = null;\n}\nutil.inherits(CombinedStream, Stream);\n\nCombinedStream.create = function(options) {\n  var combinedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    combinedStream[option] = options[option];\n  }\n\n  return combinedStream;\n};\n\nCombinedStream.isStreamLike = function(stream) {\n  return (typeof stream !== 'function')\n    && (typeof stream !== 'string')\n    && (typeof stream !== 'boolean')    \n    && (typeof stream !== 'number')\n    && (!Buffer.isBuffer(stream));\n};\n\nCombinedStream.prototype.append = function(stream) {\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n\n  if (isStreamLike) {\n    if (!(stream instanceof DelayedStream)) {\n      stream.on('data', this._checkDataSize.bind(this));\n\n      stream = DelayedStream.create(stream, {\n        maxDataSize: Infinity,\n        pauseStream: this.pauseStreams,\n      });\n    }\n\n    this._handleErrors(stream);\n\n    if (this.pauseStreams) {\n      stream.pause();\n    }\n  }\n\n  this._streams.push(stream);\n  return this;\n};\n\nCombinedStream.prototype.pipe = function(dest, options) {\n  Stream.prototype.pipe.call(this, dest, options);\n  this.resume();\n};\n\nCombinedStream.prototype._getNext = function() {\n  this._currentStream = null;\n  var stream = this._streams.shift();\n\n\n  if (typeof stream == 'undefined') {\n    this.end();\n    return;\n  }\n\n  if (typeof stream !== 'function') {\n    this._pipeNext(stream);\n    return;\n  }\n\n  var getStream = stream;\n  getStream(function(stream) {\n    var isStreamLike = CombinedStream.isStreamLike(stream);\n    if (isStreamLike) {\n      stream.on('data', this._checkDataSize.bind(this));\n      this._handleErrors(stream);\n    }\n\n    this._pipeNext(stream);\n  }.bind(this));\n};\n\nCombinedStream.prototype._pipeNext = function(stream) {\n  this._currentStream = stream;\n\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n  if (isStreamLike) {\n    stream.on('end', this._getNext.bind(this))\n    stream.pipe(this, {end: false});\n    return;\n  }\n\n  var value = stream;\n  this.write(value);\n  this._getNext();\n};\n\nCombinedStream.prototype._handleErrors = function(stream) {\n  var self = this;\n  stream.on('error', function(err) {\n    self._emitError(err);\n  });\n};\n\nCombinedStream.prototype.write = function(data) {\n  this.emit('data', data);\n};\n\nCombinedStream.prototype.pause = function() {\n  if (!this.pauseStreams) {\n    return;\n  }\n\n  this.emit('pause');\n};\n\nCombinedStream.prototype.resume = function() {\n  if (!this._released) {\n    this._released = true;\n    this.writable = true;\n    this._getNext();\n  }\n\n  this.emit('resume');\n};\n\nCombinedStream.prototype.end = function() {\n  this._reset();\n  this.emit('end');\n};\n\nCombinedStream.prototype.destroy = function() {\n  this._reset();\n  this.emit('close');\n};\n\nCombinedStream.prototype._reset = function() {\n  this.writable = false;\n  this._streams = [];\n  this._currentStream = null;\n};\n\nCombinedStream.prototype._checkDataSize = function() {\n  this._updateDataSize();\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.'\n  this._emitError(new Error(message));\n};\n\nCombinedStream.prototype._updateDataSize = function() {\n  this.dataSize = 0;\n\n  var self = this;\n  this._streams.forEach(function(stream) {\n    if (!stream.dataSize) {\n      return;\n    }\n\n    self.dataSize += stream.dataSize;\n  });\n\n  if (this._currentStream && this._currentStream.dataSize) {\n    this.dataSize += this._currentStream.dataSize;\n  }\n};\n\nCombinedStream.prototype._emitError = function(err) {\n  this._reset();\n  this.emit('error', err);\n};\n",
              "globals": {
                "util": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Stream": {
                  "type": "assign"
                },
                "DelayedStream": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "CombinedStream": {
                  "type": "assign"
                },
                "Buffer": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "util": {
                    "where": "inline"
                  },
                  "stream": {
                    "where": "inline"
                  },
                  "delayed-stream": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/node_modules/combined-stream/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/node_modules/combined-stream/lib';\nvar util = require('__SYSTEM__/util');\nvar Stream = require('__SYSTEM__/stream').Stream;\nvar DelayedStream = require('delayed-stream');\n\nmodule.exports = CombinedStream;\nfunction CombinedStream() {\n  this.writable = false;\n  this.readable = true;\n  this.dataSize = 0;\n  this.maxDataSize = 2 * 1024 * 1024;\n  this.pauseStreams = true;\n\n  this._released = false;\n  this._streams = [];\n  this._currentStream = null;\n}\nutil.inherits(CombinedStream, Stream);\n\nCombinedStream.create = function(options) {\n  var combinedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    combinedStream[option] = options[option];\n  }\n\n  return combinedStream;\n};\n\nCombinedStream.isStreamLike = function(stream) {\n  return (typeof stream !== 'function')\n    && (typeof stream !== 'string')\n    && (typeof stream !== 'boolean')    \n    && (typeof stream !== 'number')\n    && (!Buffer.isBuffer(stream));\n};\n\nCombinedStream.prototype.append = function(stream) {\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n\n  if (isStreamLike) {\n    if (!(stream instanceof DelayedStream)) {\n      stream.on('data', this._checkDataSize.bind(this));\n\n      stream = DelayedStream.create(stream, {\n        maxDataSize: Infinity,\n        pauseStream: this.pauseStreams,\n      });\n    }\n\n    this._handleErrors(stream);\n\n    if (this.pauseStreams) {\n      stream.pause();\n    }\n  }\n\n  this._streams.push(stream);\n  return this;\n};\n\nCombinedStream.prototype.pipe = function(dest, options) {\n  Stream.prototype.pipe.call(this, dest, options);\n  this.resume();\n};\n\nCombinedStream.prototype._getNext = function() {\n  this._currentStream = null;\n  var stream = this._streams.shift();\n\n\n  if (typeof stream == 'undefined') {\n    this.end();\n    return;\n  }\n\n  if (typeof stream !== 'function') {\n    this._pipeNext(stream);\n    return;\n  }\n\n  var getStream = stream;\n  getStream(function(stream) {\n    var isStreamLike = CombinedStream.isStreamLike(stream);\n    if (isStreamLike) {\n      stream.on('data', this._checkDataSize.bind(this));\n      this._handleErrors(stream);\n    }\n\n    this._pipeNext(stream);\n  }.bind(this));\n};\n\nCombinedStream.prototype._pipeNext = function(stream) {\n  this._currentStream = stream;\n\n  var isStreamLike = CombinedStream.isStreamLike(stream);\n  if (isStreamLike) {\n    stream.on('end', this._getNext.bind(this))\n    stream.pipe(this, {end: false});\n    return;\n  }\n\n  var value = stream;\n  this.write(value);\n  this._getNext();\n};\n\nCombinedStream.prototype._handleErrors = function(stream) {\n  var self = this;\n  stream.on('error', function(err) {\n    self._emitError(err);\n  });\n};\n\nCombinedStream.prototype.write = function(data) {\n  this.emit('data', data);\n};\n\nCombinedStream.prototype.pause = function() {\n  if (!this.pauseStreams) {\n    return;\n  }\n\n  this.emit('pause');\n};\n\nCombinedStream.prototype.resume = function() {\n  if (!this._released) {\n    this._released = true;\n    this.writable = true;\n    this._getNext();\n  }\n\n  this.emit('resume');\n};\n\nCombinedStream.prototype.end = function() {\n  this._reset();\n  this.emit('end');\n};\n\nCombinedStream.prototype.destroy = function() {\n  this._reset();\n  this.emit('close');\n};\n\nCombinedStream.prototype._reset = function() {\n  this.writable = false;\n  this._streams = [];\n  this._currentStream = null;\n};\n\nCombinedStream.prototype._checkDataSize = function() {\n  this._updateDataSize();\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.'\n  this._emitError(new Error(message));\n};\n\nCombinedStream.prototype._updateDataSize = function() {\n  this.dataSize = 0;\n\n  var self = this;\n  this._streams.forEach(function(stream) {\n    if (!stream.dataSize) {\n      return;\n    }\n\n    self.dataSize += stream.dataSize;\n  });\n\n  if (this._currentStream && this._currentStream.dataSize) {\n    this.dataSize += this._currentStream.dataSize;\n  }\n};\n\nCombinedStream.prototype._emitError = function(err) {\n  this._reset();\n  this.emit('error', err);\n};\n\nreturn {\n    util: (typeof util !== \"undefined\") ? util : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    DelayedStream: (typeof DelayedStream !== \"undefined\") ? DelayedStream : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    CombinedStream: (typeof CombinedStream !== \"undefined\") ? CombinedStream : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null\n};\n}",
              "bottom": "return {\n    util: (typeof util !== \"undefined\") ? util : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    DelayedStream: (typeof DelayedStream !== \"undefined\") ? DelayedStream : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    CombinedStream: (typeof CombinedStream !== \"undefined\") ? CombinedStream : null,\n    Buffer: (typeof Buffer !== \"undefined\") ? Buffer : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "util": {
                  "where": "inline"
                },
                "stream": {
                  "where": "inline"
                },
                "delayed-stream": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/lib/delayed_stream.js": {
            "requireId": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/lib/delayed_stream.js",
            "memoizeId": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/lib/delayed_stream.js",
            "descriptor": {
              "filename": "delayed_stream.js",
              "filepath": "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/lib/delayed_stream.js",
              "mtime": 1306224584,
              "code": "var Stream = require('stream').Stream;\nvar util = require('util');\n\nmodule.exports = DelayedStream;\nfunction DelayedStream() {\n  this.source = null;\n  this.dataSize = 0;\n  this.maxDataSize = 1024 * 1024;\n  this.pauseStream = true;\n\n  this._maxDataSizeExceeded = false;\n  this._released = false;\n  this._bufferedEvents = [];\n}\nutil.inherits(DelayedStream, Stream);\n\nDelayedStream.create = function(source, options) {\n  var delayedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    delayedStream[option] = options[option];\n  }\n\n  delayedStream.source = source;\n\n  var realEmit = source.emit;\n  source.emit = function() {\n    delayedStream._handleEmit(arguments);\n    return realEmit.apply(source, arguments);\n  };\n\n  source.on('error', function() {});\n  if (delayedStream.pauseStream) {\n    source.pause();\n  }\n\n  return delayedStream;\n};\n\nDelayedStream.prototype.__defineGetter__('readable', function() {\n  return this.source.readable;\n});\n\nDelayedStream.prototype.resume = function() {\n  if (!this._released) {\n    this.release();\n  }\n\n  this.source.resume();\n};\n\nDelayedStream.prototype.pause = function() {\n  this.source.pause();\n};\n\nDelayedStream.prototype.release = function() {\n  this._released = true;\n\n  this._bufferedEvents.forEach(function(args) {\n    this.emit.apply(this, args);\n  }.bind(this));\n  this._bufferedEvents = [];\n};\n\nDelayedStream.prototype.pipe = function() {\n  var r = Stream.prototype.pipe.apply(this, arguments);\n  this.resume();\n  return r;\n};\n\nDelayedStream.prototype._handleEmit = function(args) {\n  if (this._released) {\n    this.emit.apply(this, args);\n    return;\n  }\n\n  if (args[0] === 'data') {\n    this.dataSize += args[1].length;\n    this._checkIfMaxDataSizeExceeded();\n  }\n\n  this._bufferedEvents.push(args);\n};\n\nDelayedStream.prototype._checkIfMaxDataSizeExceeded = function() {\n  if (this._maxDataSizeExceeded) {\n    return;\n  }\n\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  this._maxDataSizeExceeded = true;\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.'\n  this.emit('error', new Error(message));\n};\n",
              "globals": {
                "Stream": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "util": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                },
                "DelayedStream": {
                  "type": "assign"
                }
              },
              "syntax": "javascript",
              "format": "leaky",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "stream": {
                    "where": "inline"
                  },
                  "util": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs/leaky",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/lib';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/lib';\nvar Stream = require('__SYSTEM__/stream').Stream;\nvar util = require('__SYSTEM__/util');\n\nmodule.exports = DelayedStream;\nfunction DelayedStream() {\n  this.source = null;\n  this.dataSize = 0;\n  this.maxDataSize = 1024 * 1024;\n  this.pauseStream = true;\n\n  this._maxDataSizeExceeded = false;\n  this._released = false;\n  this._bufferedEvents = [];\n}\nutil.inherits(DelayedStream, Stream);\n\nDelayedStream.create = function(source, options) {\n  var delayedStream = new this();\n\n  options = options || {};\n  for (var option in options) {\n    delayedStream[option] = options[option];\n  }\n\n  delayedStream.source = source;\n\n  var realEmit = source.emit;\n  source.emit = function() {\n    delayedStream._handleEmit(arguments);\n    return realEmit.apply(source, arguments);\n  };\n\n  source.on('error', function() {});\n  if (delayedStream.pauseStream) {\n    source.pause();\n  }\n\n  return delayedStream;\n};\n\nDelayedStream.prototype.__defineGetter__('readable', function() {\n  return this.source.readable;\n});\n\nDelayedStream.prototype.resume = function() {\n  if (!this._released) {\n    this.release();\n  }\n\n  this.source.resume();\n};\n\nDelayedStream.prototype.pause = function() {\n  this.source.pause();\n};\n\nDelayedStream.prototype.release = function() {\n  this._released = true;\n\n  this._bufferedEvents.forEach(function(args) {\n    this.emit.apply(this, args);\n  }.bind(this));\n  this._bufferedEvents = [];\n};\n\nDelayedStream.prototype.pipe = function() {\n  var r = Stream.prototype.pipe.apply(this, arguments);\n  this.resume();\n  return r;\n};\n\nDelayedStream.prototype._handleEmit = function(args) {\n  if (this._released) {\n    this.emit.apply(this, args);\n    return;\n  }\n\n  if (args[0] === 'data') {\n    this.dataSize += args[1].length;\n    this._checkIfMaxDataSizeExceeded();\n  }\n\n  this._bufferedEvents.push(args);\n};\n\nDelayedStream.prototype._checkIfMaxDataSizeExceeded = function() {\n  if (this._maxDataSizeExceeded) {\n    return;\n  }\n\n  if (this.dataSize <= this.maxDataSize) {\n    return;\n  }\n\n  this._maxDataSizeExceeded = true;\n  var message =\n    'DelayedStream#maxDataSize of ' + this.maxDataSize + ' bytes exceeded.'\n  this.emit('error', new Error(message));\n};\n\nreturn {\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    DelayedStream: (typeof DelayedStream !== \"undefined\") ? DelayedStream : null\n};\n}",
              "bottom": "return {\n    Stream: (typeof Stream !== \"undefined\") ? Stream : null,\n    require: (typeof require !== \"undefined\") ? require : null,\n    util: (typeof util !== \"undefined\") ? util : null,\n    module: (typeof module !== \"undefined\") ? module : null,\n    DelayedStream: (typeof DelayedStream !== \"undefined\") ? DelayedStream : null\n};\n}"
            },
            "dependencies": {
              "static": {
                "stream": {
                  "where": "inline"
                },
                "util": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "257a70b6290719603e5079400727f3d2d2d1b03a-async/lib/async.js": {
            "requireId": "257a70b6290719603e5079400727f3d2d2d1b03a-async/lib/async.js",
            "memoizeId": "257a70b6290719603e5079400727f3d2d2d1b03a-async/lib/async.js",
            "descriptor": {
              "filename": "async.js",
              "filepath": "node_modules/request/node_modules/form-data/node_modules/async/lib/async.js",
              "mtime": 1369727354,
              "code": "/*global setImmediate: false, setTimeout: false, console: false */\n(function () {\n\n    var async = {};\n\n    // global on the server, window in the browser\n    var root, previous_async;\n\n    root = this;\n    if (root != null) {\n      previous_async = root.async;\n    }\n\n    async.noConflict = function () {\n        root.async = previous_async;\n        return async;\n    };\n\n    function only_once(fn) {\n        var called = false;\n        return function() {\n            if (called) throw new Error(\"Callback was already called.\");\n            called = true;\n            fn.apply(root, arguments);\n        }\n    }\n\n    //// cross-browser compatiblity functions ////\n\n    var _each = function (arr, iterator) {\n        if (arr.forEach) {\n            return arr.forEach(iterator);\n        }\n        for (var i = 0; i < arr.length; i += 1) {\n            iterator(arr[i], i, arr);\n        }\n    };\n\n    var _map = function (arr, iterator) {\n        if (arr.map) {\n            return arr.map(iterator);\n        }\n        var results = [];\n        _each(arr, function (x, i, a) {\n            results.push(iterator(x, i, a));\n        });\n        return results;\n    };\n\n    var _reduce = function (arr, iterator, memo) {\n        if (arr.reduce) {\n            return arr.reduce(iterator, memo);\n        }\n        _each(arr, function (x, i, a) {\n            memo = iterator(memo, x, i, a);\n        });\n        return memo;\n    };\n\n    var _keys = function (obj) {\n        if (Object.keys) {\n            return Object.keys(obj);\n        }\n        var keys = [];\n        for (var k in obj) {\n            if (obj.hasOwnProperty(k)) {\n                keys.push(k);\n            }\n        }\n        return keys;\n    };\n\n    //// exported async module functions ////\n\n    //// nextTick implementation with browser-compatible fallback ////\n    if (typeof process === 'undefined' || !(process.nextTick)) {\n        if (typeof setImmediate === 'function') {\n            async.nextTick = function (fn) {\n                // not a direct alias for IE10 compatibility\n                setImmediate(fn);\n            };\n            async.setImmediate = async.nextTick;\n        }\n        else {\n            async.nextTick = function (fn) {\n                setTimeout(fn, 0);\n            };\n            async.setImmediate = async.nextTick;\n        }\n    }\n    else {\n        async.nextTick = process.nextTick;\n        if (typeof setImmediate !== 'undefined') {\n            async.setImmediate = setImmediate;\n        }\n        else {\n            async.setImmediate = async.nextTick;\n        }\n    }\n\n    async.each = function (arr, iterator, callback) {\n        callback = callback || function () {};\n        if (!arr.length) {\n            return callback();\n        }\n        var completed = 0;\n        _each(arr, function (x) {\n            iterator(x, only_once(function (err) {\n                if (err) {\n                    callback(err);\n                    callback = function () {};\n                }\n                else {\n                    completed += 1;\n                    if (completed >= arr.length) {\n                        callback(null);\n                    }\n                }\n            }));\n        });\n    };\n    async.forEach = async.each;\n\n    async.eachSeries = function (arr, iterator, callback) {\n        callback = callback || function () {};\n        if (!arr.length) {\n            return callback();\n        }\n        var completed = 0;\n        var iterate = function () {\n            iterator(arr[completed], function (err) {\n                if (err) {\n                    callback(err);\n                    callback = function () {};\n                }\n                else {\n                    completed += 1;\n                    if (completed >= arr.length) {\n                        callback(null);\n                    }\n                    else {\n                        iterate();\n                    }\n                }\n            });\n        };\n        iterate();\n    };\n    async.forEachSeries = async.eachSeries;\n\n    async.eachLimit = function (arr, limit, iterator, callback) {\n        var fn = _eachLimit(limit);\n        fn.apply(null, [arr, iterator, callback]);\n    };\n    async.forEachLimit = async.eachLimit;\n\n    var _eachLimit = function (limit) {\n\n        return function (arr, iterator, callback) {\n            callback = callback || function () {};\n            if (!arr.length || limit <= 0) {\n                return callback();\n            }\n            var completed = 0;\n            var started = 0;\n            var running = 0;\n\n            (function replenish () {\n                if (completed >= arr.length) {\n                    return callback();\n                }\n\n                while (running < limit && started < arr.length) {\n                    started += 1;\n                    running += 1;\n                    iterator(arr[started - 1], function (err) {\n                        if (err) {\n                            callback(err);\n                            callback = function () {};\n                        }\n                        else {\n                            completed += 1;\n                            running -= 1;\n                            if (completed >= arr.length) {\n                                callback();\n                            }\n                            else {\n                                replenish();\n                            }\n                        }\n                    });\n                }\n            })();\n        };\n    };\n\n\n    var doParallel = function (fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [async.each].concat(args));\n        };\n    };\n    var doParallelLimit = function(limit, fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [_eachLimit(limit)].concat(args));\n        };\n    };\n    var doSeries = function (fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [async.eachSeries].concat(args));\n        };\n    };\n\n\n    var _asyncMap = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (err, v) {\n                results[x.index] = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, results);\n        });\n    };\n    async.map = doParallel(_asyncMap);\n    async.mapSeries = doSeries(_asyncMap);\n    async.mapLimit = function (arr, limit, iterator, callback) {\n        return _mapLimit(limit)(arr, iterator, callback);\n    };\n\n    var _mapLimit = function(limit) {\n        return doParallelLimit(limit, _asyncMap);\n    };\n\n    // reduce only has a series version, as doing reduce in parallel won't\n    // work in many situations.\n    async.reduce = function (arr, memo, iterator, callback) {\n        async.eachSeries(arr, function (x, callback) {\n            iterator(memo, x, function (err, v) {\n                memo = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, memo);\n        });\n    };\n    // inject alias\n    async.inject = async.reduce;\n    // foldl alias\n    async.foldl = async.reduce;\n\n    async.reduceRight = function (arr, memo, iterator, callback) {\n        var reversed = _map(arr, function (x) {\n            return x;\n        }).reverse();\n        async.reduce(reversed, memo, iterator, callback);\n    };\n    // foldr alias\n    async.foldr = async.reduceRight;\n\n    var _filter = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (v) {\n                if (v) {\n                    results.push(x);\n                }\n                callback();\n            });\n        }, function (err) {\n            callback(_map(results.sort(function (a, b) {\n                return a.index - b.index;\n            }), function (x) {\n                return x.value;\n            }));\n        });\n    };\n    async.filter = doParallel(_filter);\n    async.filterSeries = doSeries(_filter);\n    // select alias\n    async.select = async.filter;\n    async.selectSeries = async.filterSeries;\n\n    var _reject = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (v) {\n                if (!v) {\n                    results.push(x);\n                }\n                callback();\n            });\n        }, function (err) {\n            callback(_map(results.sort(function (a, b) {\n                return a.index - b.index;\n            }), function (x) {\n                return x.value;\n            }));\n        });\n    };\n    async.reject = doParallel(_reject);\n    async.rejectSeries = doSeries(_reject);\n\n    var _detect = function (eachfn, arr, iterator, main_callback) {\n        eachfn(arr, function (x, callback) {\n            iterator(x, function (result) {\n                if (result) {\n                    main_callback(x);\n                    main_callback = function () {};\n                }\n                else {\n                    callback();\n                }\n            });\n        }, function (err) {\n            main_callback();\n        });\n    };\n    async.detect = doParallel(_detect);\n    async.detectSeries = doSeries(_detect);\n\n    async.some = function (arr, iterator, main_callback) {\n        async.each(arr, function (x, callback) {\n            iterator(x, function (v) {\n                if (v) {\n                    main_callback(true);\n                    main_callback = function () {};\n                }\n                callback();\n            });\n        }, function (err) {\n            main_callback(false);\n        });\n    };\n    // any alias\n    async.any = async.some;\n\n    async.every = function (arr, iterator, main_callback) {\n        async.each(arr, function (x, callback) {\n            iterator(x, function (v) {\n                if (!v) {\n                    main_callback(false);\n                    main_callback = function () {};\n                }\n                callback();\n            });\n        }, function (err) {\n            main_callback(true);\n        });\n    };\n    // all alias\n    async.all = async.every;\n\n    async.sortBy = function (arr, iterator, callback) {\n        async.map(arr, function (x, callback) {\n            iterator(x, function (err, criteria) {\n                if (err) {\n                    callback(err);\n                }\n                else {\n                    callback(null, {value: x, criteria: criteria});\n                }\n            });\n        }, function (err, results) {\n            if (err) {\n                return callback(err);\n            }\n            else {\n                var fn = function (left, right) {\n                    var a = left.criteria, b = right.criteria;\n                    return a < b ? -1 : a > b ? 1 : 0;\n                };\n                callback(null, _map(results.sort(fn), function (x) {\n                    return x.value;\n                }));\n            }\n        });\n    };\n\n    async.auto = function (tasks, callback) {\n        callback = callback || function () {};\n        var keys = _keys(tasks);\n        if (!keys.length) {\n            return callback(null);\n        }\n\n        var results = {};\n\n        var listeners = [];\n        var addListener = function (fn) {\n            listeners.unshift(fn);\n        };\n        var removeListener = function (fn) {\n            for (var i = 0; i < listeners.length; i += 1) {\n                if (listeners[i] === fn) {\n                    listeners.splice(i, 1);\n                    return;\n                }\n            }\n        };\n        var taskComplete = function () {\n            _each(listeners.slice(0), function (fn) {\n                fn();\n            });\n        };\n\n        addListener(function () {\n            if (_keys(results).length === keys.length) {\n                callback(null, results);\n                callback = function () {};\n            }\n        });\n\n        _each(keys, function (k) {\n            var task = (tasks[k] instanceof Function) ? [tasks[k]]: tasks[k];\n            var taskCallback = function (err) {\n                var args = Array.prototype.slice.call(arguments, 1);\n                if (args.length <= 1) {\n                    args = args[0];\n                }\n                if (err) {\n                    var safeResults = {};\n                    _each(_keys(results), function(rkey) {\n                        safeResults[rkey] = results[rkey];\n                    });\n                    safeResults[k] = args;\n                    callback(err, safeResults);\n                    // stop subsequent errors hitting callback multiple times\n                    callback = function () {};\n                }\n                else {\n                    results[k] = args;\n                    async.setImmediate(taskComplete);\n                }\n            };\n            var requires = task.slice(0, Math.abs(task.length - 1)) || [];\n            var ready = function () {\n                return _reduce(requires, function (a, x) {\n                    return (a && results.hasOwnProperty(x));\n                }, true) && !results.hasOwnProperty(k);\n            };\n            if (ready()) {\n                task[task.length - 1](taskCallback, results);\n            }\n            else {\n                var listener = function () {\n                    if (ready()) {\n                        removeListener(listener);\n                        task[task.length - 1](taskCallback, results);\n                    }\n                };\n                addListener(listener);\n            }\n        });\n    };\n\n    async.waterfall = function (tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor !== Array) {\n          var err = new Error('First argument to waterfall must be an array of functions');\n          return callback(err);\n        }\n        if (!tasks.length) {\n            return callback();\n        }\n        var wrapIterator = function (iterator) {\n            return function (err) {\n                if (err) {\n                    callback.apply(null, arguments);\n                    callback = function () {};\n                }\n                else {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    var next = iterator.next();\n                    if (next) {\n                        args.push(wrapIterator(next));\n                    }\n                    else {\n                        args.push(callback);\n                    }\n                    async.setImmediate(function () {\n                        iterator.apply(null, args);\n                    });\n                }\n            };\n        };\n        wrapIterator(async.iterator(tasks))();\n    };\n\n    var _parallel = function(eachfn, tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor === Array) {\n            eachfn.map(tasks, function (fn, callback) {\n                if (fn) {\n                    fn(function (err) {\n                        var args = Array.prototype.slice.call(arguments, 1);\n                        if (args.length <= 1) {\n                            args = args[0];\n                        }\n                        callback.call(null, err, args);\n                    });\n                }\n            }, callback);\n        }\n        else {\n            var results = {};\n            eachfn.each(_keys(tasks), function (k, callback) {\n                tasks[k](function (err) {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    if (args.length <= 1) {\n                        args = args[0];\n                    }\n                    results[k] = args;\n                    callback(err);\n                });\n            }, function (err) {\n                callback(err, results);\n            });\n        }\n    };\n\n    async.parallel = function (tasks, callback) {\n        _parallel({ map: async.map, each: async.each }, tasks, callback);\n    };\n\n    async.parallelLimit = function(tasks, limit, callback) {\n        _parallel({ map: _mapLimit(limit), each: _eachLimit(limit) }, tasks, callback);\n    };\n\n    async.series = function (tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor === Array) {\n            async.mapSeries(tasks, function (fn, callback) {\n                if (fn) {\n                    fn(function (err) {\n                        var args = Array.prototype.slice.call(arguments, 1);\n                        if (args.length <= 1) {\n                            args = args[0];\n                        }\n                        callback.call(null, err, args);\n                    });\n                }\n            }, callback);\n        }\n        else {\n            var results = {};\n            async.eachSeries(_keys(tasks), function (k, callback) {\n                tasks[k](function (err) {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    if (args.length <= 1) {\n                        args = args[0];\n                    }\n                    results[k] = args;\n                    callback(err);\n                });\n            }, function (err) {\n                callback(err, results);\n            });\n        }\n    };\n\n    async.iterator = function (tasks) {\n        var makeCallback = function (index) {\n            var fn = function () {\n                if (tasks.length) {\n                    tasks[index].apply(null, arguments);\n                }\n                return fn.next();\n            };\n            fn.next = function () {\n                return (index < tasks.length - 1) ? makeCallback(index + 1): null;\n            };\n            return fn;\n        };\n        return makeCallback(0);\n    };\n\n    async.apply = function (fn) {\n        var args = Array.prototype.slice.call(arguments, 1);\n        return function () {\n            return fn.apply(\n                null, args.concat(Array.prototype.slice.call(arguments))\n            );\n        };\n    };\n\n    var _concat = function (eachfn, arr, fn, callback) {\n        var r = [];\n        eachfn(arr, function (x, cb) {\n            fn(x, function (err, y) {\n                r = r.concat(y || []);\n                cb(err);\n            });\n        }, function (err) {\n            callback(err, r);\n        });\n    };\n    async.concat = doParallel(_concat);\n    async.concatSeries = doSeries(_concat);\n\n    async.whilst = function (test, iterator, callback) {\n        if (test()) {\n            iterator(function (err) {\n                if (err) {\n                    return callback(err);\n                }\n                async.whilst(test, iterator, callback);\n            });\n        }\n        else {\n            callback();\n        }\n    };\n\n    async.doWhilst = function (iterator, test, callback) {\n        iterator(function (err) {\n            if (err) {\n                return callback(err);\n            }\n            if (test()) {\n                async.doWhilst(iterator, test, callback);\n            }\n            else {\n                callback();\n            }\n        });\n    };\n\n    async.until = function (test, iterator, callback) {\n        if (!test()) {\n            iterator(function (err) {\n                if (err) {\n                    return callback(err);\n                }\n                async.until(test, iterator, callback);\n            });\n        }\n        else {\n            callback();\n        }\n    };\n\n    async.doUntil = function (iterator, test, callback) {\n        iterator(function (err) {\n            if (err) {\n                return callback(err);\n            }\n            if (!test()) {\n                async.doUntil(iterator, test, callback);\n            }\n            else {\n                callback();\n            }\n        });\n    };\n\n    async.queue = function (worker, concurrency) {\n        if (concurrency === undefined) {\n            concurrency = 1;\n        }\n        function _insert(q, data, pos, callback) {\n          if(data.constructor !== Array) {\n              data = [data];\n          }\n          _each(data, function(task) {\n              var item = {\n                  data: task,\n                  callback: typeof callback === 'function' ? callback : null\n              };\n\n              if (pos) {\n                q.tasks.unshift(item);\n              } else {\n                q.tasks.push(item);\n              }\n\n              if (q.saturated && q.tasks.length === concurrency) {\n                  q.saturated();\n              }\n              async.setImmediate(q.process);\n          });\n        }\n\n        var workers = 0;\n        var q = {\n            tasks: [],\n            concurrency: concurrency,\n            saturated: null,\n            empty: null,\n            drain: null,\n            push: function (data, callback) {\n              _insert(q, data, false, callback);\n            },\n            unshift: function (data, callback) {\n              _insert(q, data, true, callback);\n            },\n            process: function () {\n                if (workers < q.concurrency && q.tasks.length) {\n                    var task = q.tasks.shift();\n                    if (q.empty && q.tasks.length === 0) {\n                        q.empty();\n                    }\n                    workers += 1;\n                    var next = function () {\n                        workers -= 1;\n                        if (task.callback) {\n                            task.callback.apply(task, arguments);\n                        }\n                        if (q.drain && q.tasks.length + workers === 0) {\n                            q.drain();\n                        }\n                        q.process();\n                    };\n                    var cb = only_once(next);\n                    worker(task.data, cb);\n                }\n            },\n            length: function () {\n                return q.tasks.length;\n            },\n            running: function () {\n                return workers;\n            }\n        };\n        return q;\n    };\n\n    async.cargo = function (worker, payload) {\n        var working     = false,\n            tasks       = [];\n\n        var cargo = {\n            tasks: tasks,\n            payload: payload,\n            saturated: null,\n            empty: null,\n            drain: null,\n            push: function (data, callback) {\n                if(data.constructor !== Array) {\n                    data = [data];\n                }\n                _each(data, function(task) {\n                    tasks.push({\n                        data: task,\n                        callback: typeof callback === 'function' ? callback : null\n                    });\n                    if (cargo.saturated && tasks.length === payload) {\n                        cargo.saturated();\n                    }\n                });\n                async.setImmediate(cargo.process);\n            },\n            process: function process() {\n                if (working) return;\n                if (tasks.length === 0) {\n                    if(cargo.drain) cargo.drain();\n                    return;\n                }\n\n                var ts = typeof payload === 'number'\n                            ? tasks.splice(0, payload)\n                            : tasks.splice(0);\n\n                var ds = _map(ts, function (task) {\n                    return task.data;\n                });\n\n                if(cargo.empty) cargo.empty();\n                working = true;\n                worker(ds, function () {\n                    working = false;\n\n                    var args = arguments;\n                    _each(ts, function (data) {\n                        if (data.callback) {\n                            data.callback.apply(null, args);\n                        }\n                    });\n\n                    process();\n                });\n            },\n            length: function () {\n                return tasks.length;\n            },\n            running: function () {\n                return working;\n            }\n        };\n        return cargo;\n    };\n\n    var _console_fn = function (name) {\n        return function (fn) {\n            var args = Array.prototype.slice.call(arguments, 1);\n            fn.apply(null, args.concat([function (err) {\n                var args = Array.prototype.slice.call(arguments, 1);\n                if (typeof console !== 'undefined') {\n                    if (err) {\n                        if (console.error) {\n                            console.error(err);\n                        }\n                    }\n                    else if (console[name]) {\n                        _each(args, function (x) {\n                            console[name](x);\n                        });\n                    }\n                }\n            }]));\n        };\n    };\n    async.log = _console_fn('log');\n    async.dir = _console_fn('dir');\n    /*async.info = _console_fn('info');\n    async.warn = _console_fn('warn');\n    async.error = _console_fn('error');*/\n\n    async.memoize = function (fn, hasher) {\n        var memo = {};\n        var queues = {};\n        hasher = hasher || function (x) {\n            return x;\n        };\n        var memoized = function () {\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            var key = hasher.apply(null, args);\n            if (key in memo) {\n                callback.apply(null, memo[key]);\n            }\n            else if (key in queues) {\n                queues[key].push(callback);\n            }\n            else {\n                queues[key] = [callback];\n                fn.apply(null, args.concat([function () {\n                    memo[key] = arguments;\n                    var q = queues[key];\n                    delete queues[key];\n                    for (var i = 0, l = q.length; i < l; i++) {\n                      q[i].apply(null, arguments);\n                    }\n                }]));\n            }\n        };\n        memoized.memo = memo;\n        memoized.unmemoized = fn;\n        return memoized;\n    };\n\n    async.unmemoize = function (fn) {\n      return function () {\n        return (fn.unmemoized || fn).apply(null, arguments);\n      };\n    };\n\n    async.times = function (count, iterator, callback) {\n        var counter = [];\n        for (var i = 0; i < count; i++) {\n            counter.push(i);\n        }\n        return async.map(counter, iterator, callback);\n    };\n\n    async.timesSeries = function (count, iterator, callback) {\n        var counter = [];\n        for (var i = 0; i < count; i++) {\n            counter.push(i);\n        }\n        return async.mapSeries(counter, iterator, callback);\n    };\n\n    async.compose = function (/* functions... */) {\n        var fns = Array.prototype.reverse.call(arguments);\n        return function () {\n            var that = this;\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            async.reduce(fns, args, function (newargs, fn, cb) {\n                fn.apply(that, newargs.concat([function () {\n                    var err = arguments[0];\n                    var nextargs = Array.prototype.slice.call(arguments, 1);\n                    cb(err, nextargs);\n                }]))\n            },\n            function (err, results) {\n                callback.apply(that, [err].concat(results));\n            });\n        };\n    };\n\n    var _applyEach = function (eachfn, fns /*args...*/) {\n        var go = function () {\n            var that = this;\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            return eachfn(fns, function (fn, cb) {\n                fn.apply(that, args.concat([cb]));\n            },\n            callback);\n        };\n        if (arguments.length > 2) {\n            var args = Array.prototype.slice.call(arguments, 2);\n            return go.apply(this, args);\n        }\n        else {\n            return go;\n        }\n    };\n    async.applyEach = doParallel(_applyEach);\n    async.applyEachSeries = doSeries(_applyEach);\n\n    async.forever = function (fn, callback) {\n        function next(err) {\n            if (err) {\n                if (callback) {\n                    return callback(err);\n                }\n                throw err;\n            }\n            fn(next);\n        }\n        next();\n    };\n\n    // AMD / RequireJS\n    if (typeof define !== 'undefined' && define.amd) {\n        define([], function () {\n            return async;\n        });\n    }\n    // Node.js\n    else if (typeof module !== 'undefined' && module.exports) {\n        module.exports = async;\n    }\n    // included directly via <script> tag\n    else {\n        root.async = async;\n    }\n\n}());\n",
              "globals": {
                "i": {
                  "type": "reference"
                },
                "Object": {
                  "type": "reference"
                },
                "process": {
                  "type": "typeof"
                },
                "setImmediate": {
                  "type": "typeof"
                },
                "setTimeout": {
                  "type": "call"
                },
                "Array": {
                  "type": "reference"
                },
                "Math": {
                  "type": "reference"
                },
                "console": {
                  "type": "typeof"
                },
                "define": {
                  "type": "typeof"
                },
                "module": {
                  "type": "typeof"
                }
              },
              "syntax": "javascript",
              "format": "amd-ish",
              "undefine": [
                "module"
              ],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "amd-ish",
              "top": "wrapAMD(function(require, define) {",
              "code": "wrapAMD(function(require, define) {\n/*global setImmediate: false, setTimeout: false, console: false */\n(function () {\n\n    var async = {};\n\n    // global on the server, window in the browser\n    var root, previous_async;\n\n    root = this;\n    if (root != null) {\n      previous_async = root.async;\n    }\n\n    async.noConflict = function () {\n        root.async = previous_async;\n        return async;\n    };\n\n    function only_once(fn) {\n        var called = false;\n        return function() {\n            if (called) throw new Error(\"Callback was already called.\");\n            called = true;\n            fn.apply(root, arguments);\n        }\n    }\n\n    //// cross-browser compatiblity functions ////\n\n    var _each = function (arr, iterator) {\n        if (arr.forEach) {\n            return arr.forEach(iterator);\n        }\n        for (var i = 0; i < arr.length; i += 1) {\n            iterator(arr[i], i, arr);\n        }\n    };\n\n    var _map = function (arr, iterator) {\n        if (arr.map) {\n            return arr.map(iterator);\n        }\n        var results = [];\n        _each(arr, function (x, i, a) {\n            results.push(iterator(x, i, a));\n        });\n        return results;\n    };\n\n    var _reduce = function (arr, iterator, memo) {\n        if (arr.reduce) {\n            return arr.reduce(iterator, memo);\n        }\n        _each(arr, function (x, i, a) {\n            memo = iterator(memo, x, i, a);\n        });\n        return memo;\n    };\n\n    var _keys = function (obj) {\n        if (Object.keys) {\n            return Object.keys(obj);\n        }\n        var keys = [];\n        for (var k in obj) {\n            if (obj.hasOwnProperty(k)) {\n                keys.push(k);\n            }\n        }\n        return keys;\n    };\n\n    //// exported async module functions ////\n\n    //// nextTick implementation with browser-compatible fallback ////\n    if (typeof process === 'undefined' || !(process.nextTick)) {\n        if (typeof setImmediate === 'function') {\n            async.nextTick = function (fn) {\n                // not a direct alias for IE10 compatibility\n                setImmediate(fn);\n            };\n            async.setImmediate = async.nextTick;\n        }\n        else {\n            async.nextTick = function (fn) {\n                setTimeout(fn, 0);\n            };\n            async.setImmediate = async.nextTick;\n        }\n    }\n    else {\n        async.nextTick = process.nextTick;\n        if (typeof setImmediate !== 'undefined') {\n            async.setImmediate = setImmediate;\n        }\n        else {\n            async.setImmediate = async.nextTick;\n        }\n    }\n\n    async.each = function (arr, iterator, callback) {\n        callback = callback || function () {};\n        if (!arr.length) {\n            return callback();\n        }\n        var completed = 0;\n        _each(arr, function (x) {\n            iterator(x, only_once(function (err) {\n                if (err) {\n                    callback(err);\n                    callback = function () {};\n                }\n                else {\n                    completed += 1;\n                    if (completed >= arr.length) {\n                        callback(null);\n                    }\n                }\n            }));\n        });\n    };\n    async.forEach = async.each;\n\n    async.eachSeries = function (arr, iterator, callback) {\n        callback = callback || function () {};\n        if (!arr.length) {\n            return callback();\n        }\n        var completed = 0;\n        var iterate = function () {\n            iterator(arr[completed], function (err) {\n                if (err) {\n                    callback(err);\n                    callback = function () {};\n                }\n                else {\n                    completed += 1;\n                    if (completed >= arr.length) {\n                        callback(null);\n                    }\n                    else {\n                        iterate();\n                    }\n                }\n            });\n        };\n        iterate();\n    };\n    async.forEachSeries = async.eachSeries;\n\n    async.eachLimit = function (arr, limit, iterator, callback) {\n        var fn = _eachLimit(limit);\n        fn.apply(null, [arr, iterator, callback]);\n    };\n    async.forEachLimit = async.eachLimit;\n\n    var _eachLimit = function (limit) {\n\n        return function (arr, iterator, callback) {\n            callback = callback || function () {};\n            if (!arr.length || limit <= 0) {\n                return callback();\n            }\n            var completed = 0;\n            var started = 0;\n            var running = 0;\n\n            (function replenish () {\n                if (completed >= arr.length) {\n                    return callback();\n                }\n\n                while (running < limit && started < arr.length) {\n                    started += 1;\n                    running += 1;\n                    iterator(arr[started - 1], function (err) {\n                        if (err) {\n                            callback(err);\n                            callback = function () {};\n                        }\n                        else {\n                            completed += 1;\n                            running -= 1;\n                            if (completed >= arr.length) {\n                                callback();\n                            }\n                            else {\n                                replenish();\n                            }\n                        }\n                    });\n                }\n            })();\n        };\n    };\n\n\n    var doParallel = function (fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [async.each].concat(args));\n        };\n    };\n    var doParallelLimit = function(limit, fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [_eachLimit(limit)].concat(args));\n        };\n    };\n    var doSeries = function (fn) {\n        return function () {\n            var args = Array.prototype.slice.call(arguments);\n            return fn.apply(null, [async.eachSeries].concat(args));\n        };\n    };\n\n\n    var _asyncMap = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (err, v) {\n                results[x.index] = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, results);\n        });\n    };\n    async.map = doParallel(_asyncMap);\n    async.mapSeries = doSeries(_asyncMap);\n    async.mapLimit = function (arr, limit, iterator, callback) {\n        return _mapLimit(limit)(arr, iterator, callback);\n    };\n\n    var _mapLimit = function(limit) {\n        return doParallelLimit(limit, _asyncMap);\n    };\n\n    // reduce only has a series version, as doing reduce in parallel won't\n    // work in many situations.\n    async.reduce = function (arr, memo, iterator, callback) {\n        async.eachSeries(arr, function (x, callback) {\n            iterator(memo, x, function (err, v) {\n                memo = v;\n                callback(err);\n            });\n        }, function (err) {\n            callback(err, memo);\n        });\n    };\n    // inject alias\n    async.inject = async.reduce;\n    // foldl alias\n    async.foldl = async.reduce;\n\n    async.reduceRight = function (arr, memo, iterator, callback) {\n        var reversed = _map(arr, function (x) {\n            return x;\n        }).reverse();\n        async.reduce(reversed, memo, iterator, callback);\n    };\n    // foldr alias\n    async.foldr = async.reduceRight;\n\n    var _filter = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (v) {\n                if (v) {\n                    results.push(x);\n                }\n                callback();\n            });\n        }, function (err) {\n            callback(_map(results.sort(function (a, b) {\n                return a.index - b.index;\n            }), function (x) {\n                return x.value;\n            }));\n        });\n    };\n    async.filter = doParallel(_filter);\n    async.filterSeries = doSeries(_filter);\n    // select alias\n    async.select = async.filter;\n    async.selectSeries = async.filterSeries;\n\n    var _reject = function (eachfn, arr, iterator, callback) {\n        var results = [];\n        arr = _map(arr, function (x, i) {\n            return {index: i, value: x};\n        });\n        eachfn(arr, function (x, callback) {\n            iterator(x.value, function (v) {\n                if (!v) {\n                    results.push(x);\n                }\n                callback();\n            });\n        }, function (err) {\n            callback(_map(results.sort(function (a, b) {\n                return a.index - b.index;\n            }), function (x) {\n                return x.value;\n            }));\n        });\n    };\n    async.reject = doParallel(_reject);\n    async.rejectSeries = doSeries(_reject);\n\n    var _detect = function (eachfn, arr, iterator, main_callback) {\n        eachfn(arr, function (x, callback) {\n            iterator(x, function (result) {\n                if (result) {\n                    main_callback(x);\n                    main_callback = function () {};\n                }\n                else {\n                    callback();\n                }\n            });\n        }, function (err) {\n            main_callback();\n        });\n    };\n    async.detect = doParallel(_detect);\n    async.detectSeries = doSeries(_detect);\n\n    async.some = function (arr, iterator, main_callback) {\n        async.each(arr, function (x, callback) {\n            iterator(x, function (v) {\n                if (v) {\n                    main_callback(true);\n                    main_callback = function () {};\n                }\n                callback();\n            });\n        }, function (err) {\n            main_callback(false);\n        });\n    };\n    // any alias\n    async.any = async.some;\n\n    async.every = function (arr, iterator, main_callback) {\n        async.each(arr, function (x, callback) {\n            iterator(x, function (v) {\n                if (!v) {\n                    main_callback(false);\n                    main_callback = function () {};\n                }\n                callback();\n            });\n        }, function (err) {\n            main_callback(true);\n        });\n    };\n    // all alias\n    async.all = async.every;\n\n    async.sortBy = function (arr, iterator, callback) {\n        async.map(arr, function (x, callback) {\n            iterator(x, function (err, criteria) {\n                if (err) {\n                    callback(err);\n                }\n                else {\n                    callback(null, {value: x, criteria: criteria});\n                }\n            });\n        }, function (err, results) {\n            if (err) {\n                return callback(err);\n            }\n            else {\n                var fn = function (left, right) {\n                    var a = left.criteria, b = right.criteria;\n                    return a < b ? -1 : a > b ? 1 : 0;\n                };\n                callback(null, _map(results.sort(fn), function (x) {\n                    return x.value;\n                }));\n            }\n        });\n    };\n\n    async.auto = function (tasks, callback) {\n        callback = callback || function () {};\n        var keys = _keys(tasks);\n        if (!keys.length) {\n            return callback(null);\n        }\n\n        var results = {};\n\n        var listeners = [];\n        var addListener = function (fn) {\n            listeners.unshift(fn);\n        };\n        var removeListener = function (fn) {\n            for (var i = 0; i < listeners.length; i += 1) {\n                if (listeners[i] === fn) {\n                    listeners.splice(i, 1);\n                    return;\n                }\n            }\n        };\n        var taskComplete = function () {\n            _each(listeners.slice(0), function (fn) {\n                fn();\n            });\n        };\n\n        addListener(function () {\n            if (_keys(results).length === keys.length) {\n                callback(null, results);\n                callback = function () {};\n            }\n        });\n\n        _each(keys, function (k) {\n            var task = (tasks[k] instanceof Function) ? [tasks[k]]: tasks[k];\n            var taskCallback = function (err) {\n                var args = Array.prototype.slice.call(arguments, 1);\n                if (args.length <= 1) {\n                    args = args[0];\n                }\n                if (err) {\n                    var safeResults = {};\n                    _each(_keys(results), function(rkey) {\n                        safeResults[rkey] = results[rkey];\n                    });\n                    safeResults[k] = args;\n                    callback(err, safeResults);\n                    // stop subsequent errors hitting callback multiple times\n                    callback = function () {};\n                }\n                else {\n                    results[k] = args;\n                    async.setImmediate(taskComplete);\n                }\n            };\n            var requires = task.slice(0, Math.abs(task.length - 1)) || [];\n            var ready = function () {\n                return _reduce(requires, function (a, x) {\n                    return (a && results.hasOwnProperty(x));\n                }, true) && !results.hasOwnProperty(k);\n            };\n            if (ready()) {\n                task[task.length - 1](taskCallback, results);\n            }\n            else {\n                var listener = function () {\n                    if (ready()) {\n                        removeListener(listener);\n                        task[task.length - 1](taskCallback, results);\n                    }\n                };\n                addListener(listener);\n            }\n        });\n    };\n\n    async.waterfall = function (tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor !== Array) {\n          var err = new Error('First argument to waterfall must be an array of functions');\n          return callback(err);\n        }\n        if (!tasks.length) {\n            return callback();\n        }\n        var wrapIterator = function (iterator) {\n            return function (err) {\n                if (err) {\n                    callback.apply(null, arguments);\n                    callback = function () {};\n                }\n                else {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    var next = iterator.next();\n                    if (next) {\n                        args.push(wrapIterator(next));\n                    }\n                    else {\n                        args.push(callback);\n                    }\n                    async.setImmediate(function () {\n                        iterator.apply(null, args);\n                    });\n                }\n            };\n        };\n        wrapIterator(async.iterator(tasks))();\n    };\n\n    var _parallel = function(eachfn, tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor === Array) {\n            eachfn.map(tasks, function (fn, callback) {\n                if (fn) {\n                    fn(function (err) {\n                        var args = Array.prototype.slice.call(arguments, 1);\n                        if (args.length <= 1) {\n                            args = args[0];\n                        }\n                        callback.call(null, err, args);\n                    });\n                }\n            }, callback);\n        }\n        else {\n            var results = {};\n            eachfn.each(_keys(tasks), function (k, callback) {\n                tasks[k](function (err) {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    if (args.length <= 1) {\n                        args = args[0];\n                    }\n                    results[k] = args;\n                    callback(err);\n                });\n            }, function (err) {\n                callback(err, results);\n            });\n        }\n    };\n\n    async.parallel = function (tasks, callback) {\n        _parallel({ map: async.map, each: async.each }, tasks, callback);\n    };\n\n    async.parallelLimit = function(tasks, limit, callback) {\n        _parallel({ map: _mapLimit(limit), each: _eachLimit(limit) }, tasks, callback);\n    };\n\n    async.series = function (tasks, callback) {\n        callback = callback || function () {};\n        if (tasks.constructor === Array) {\n            async.mapSeries(tasks, function (fn, callback) {\n                if (fn) {\n                    fn(function (err) {\n                        var args = Array.prototype.slice.call(arguments, 1);\n                        if (args.length <= 1) {\n                            args = args[0];\n                        }\n                        callback.call(null, err, args);\n                    });\n                }\n            }, callback);\n        }\n        else {\n            var results = {};\n            async.eachSeries(_keys(tasks), function (k, callback) {\n                tasks[k](function (err) {\n                    var args = Array.prototype.slice.call(arguments, 1);\n                    if (args.length <= 1) {\n                        args = args[0];\n                    }\n                    results[k] = args;\n                    callback(err);\n                });\n            }, function (err) {\n                callback(err, results);\n            });\n        }\n    };\n\n    async.iterator = function (tasks) {\n        var makeCallback = function (index) {\n            var fn = function () {\n                if (tasks.length) {\n                    tasks[index].apply(null, arguments);\n                }\n                return fn.next();\n            };\n            fn.next = function () {\n                return (index < tasks.length - 1) ? makeCallback(index + 1): null;\n            };\n            return fn;\n        };\n        return makeCallback(0);\n    };\n\n    async.apply = function (fn) {\n        var args = Array.prototype.slice.call(arguments, 1);\n        return function () {\n            return fn.apply(\n                null, args.concat(Array.prototype.slice.call(arguments))\n            );\n        };\n    };\n\n    var _concat = function (eachfn, arr, fn, callback) {\n        var r = [];\n        eachfn(arr, function (x, cb) {\n            fn(x, function (err, y) {\n                r = r.concat(y || []);\n                cb(err);\n            });\n        }, function (err) {\n            callback(err, r);\n        });\n    };\n    async.concat = doParallel(_concat);\n    async.concatSeries = doSeries(_concat);\n\n    async.whilst = function (test, iterator, callback) {\n        if (test()) {\n            iterator(function (err) {\n                if (err) {\n                    return callback(err);\n                }\n                async.whilst(test, iterator, callback);\n            });\n        }\n        else {\n            callback();\n        }\n    };\n\n    async.doWhilst = function (iterator, test, callback) {\n        iterator(function (err) {\n            if (err) {\n                return callback(err);\n            }\n            if (test()) {\n                async.doWhilst(iterator, test, callback);\n            }\n            else {\n                callback();\n            }\n        });\n    };\n\n    async.until = function (test, iterator, callback) {\n        if (!test()) {\n            iterator(function (err) {\n                if (err) {\n                    return callback(err);\n                }\n                async.until(test, iterator, callback);\n            });\n        }\n        else {\n            callback();\n        }\n    };\n\n    async.doUntil = function (iterator, test, callback) {\n        iterator(function (err) {\n            if (err) {\n                return callback(err);\n            }\n            if (!test()) {\n                async.doUntil(iterator, test, callback);\n            }\n            else {\n                callback();\n            }\n        });\n    };\n\n    async.queue = function (worker, concurrency) {\n        if (concurrency === undefined) {\n            concurrency = 1;\n        }\n        function _insert(q, data, pos, callback) {\n          if(data.constructor !== Array) {\n              data = [data];\n          }\n          _each(data, function(task) {\n              var item = {\n                  data: task,\n                  callback: typeof callback === 'function' ? callback : null\n              };\n\n              if (pos) {\n                q.tasks.unshift(item);\n              } else {\n                q.tasks.push(item);\n              }\n\n              if (q.saturated && q.tasks.length === concurrency) {\n                  q.saturated();\n              }\n              async.setImmediate(q.process);\n          });\n        }\n\n        var workers = 0;\n        var q = {\n            tasks: [],\n            concurrency: concurrency,\n            saturated: null,\n            empty: null,\n            drain: null,\n            push: function (data, callback) {\n              _insert(q, data, false, callback);\n            },\n            unshift: function (data, callback) {\n              _insert(q, data, true, callback);\n            },\n            process: function () {\n                if (workers < q.concurrency && q.tasks.length) {\n                    var task = q.tasks.shift();\n                    if (q.empty && q.tasks.length === 0) {\n                        q.empty();\n                    }\n                    workers += 1;\n                    var next = function () {\n                        workers -= 1;\n                        if (task.callback) {\n                            task.callback.apply(task, arguments);\n                        }\n                        if (q.drain && q.tasks.length + workers === 0) {\n                            q.drain();\n                        }\n                        q.process();\n                    };\n                    var cb = only_once(next);\n                    worker(task.data, cb);\n                }\n            },\n            length: function () {\n                return q.tasks.length;\n            },\n            running: function () {\n                return workers;\n            }\n        };\n        return q;\n    };\n\n    async.cargo = function (worker, payload) {\n        var working     = false,\n            tasks       = [];\n\n        var cargo = {\n            tasks: tasks,\n            payload: payload,\n            saturated: null,\n            empty: null,\n            drain: null,\n            push: function (data, callback) {\n                if(data.constructor !== Array) {\n                    data = [data];\n                }\n                _each(data, function(task) {\n                    tasks.push({\n                        data: task,\n                        callback: typeof callback === 'function' ? callback : null\n                    });\n                    if (cargo.saturated && tasks.length === payload) {\n                        cargo.saturated();\n                    }\n                });\n                async.setImmediate(cargo.process);\n            },\n            process: function process() {\n                if (working) return;\n                if (tasks.length === 0) {\n                    if(cargo.drain) cargo.drain();\n                    return;\n                }\n\n                var ts = typeof payload === 'number'\n                            ? tasks.splice(0, payload)\n                            : tasks.splice(0);\n\n                var ds = _map(ts, function (task) {\n                    return task.data;\n                });\n\n                if(cargo.empty) cargo.empty();\n                working = true;\n                worker(ds, function () {\n                    working = false;\n\n                    var args = arguments;\n                    _each(ts, function (data) {\n                        if (data.callback) {\n                            data.callback.apply(null, args);\n                        }\n                    });\n\n                    process();\n                });\n            },\n            length: function () {\n                return tasks.length;\n            },\n            running: function () {\n                return working;\n            }\n        };\n        return cargo;\n    };\n\n    var _console_fn = function (name) {\n        return function (fn) {\n            var args = Array.prototype.slice.call(arguments, 1);\n            fn.apply(null, args.concat([function (err) {\n                var args = Array.prototype.slice.call(arguments, 1);\n                if (typeof console !== 'undefined') {\n                    if (err) {\n                        if (console.error) {\n                            console.error(err);\n                        }\n                    }\n                    else if (console[name]) {\n                        _each(args, function (x) {\n                            console[name](x);\n                        });\n                    }\n                }\n            }]));\n        };\n    };\n    async.log = _console_fn('log');\n    async.dir = _console_fn('dir');\n    /*async.info = _console_fn('info');\n    async.warn = _console_fn('warn');\n    async.error = _console_fn('error');*/\n\n    async.memoize = function (fn, hasher) {\n        var memo = {};\n        var queues = {};\n        hasher = hasher || function (x) {\n            return x;\n        };\n        var memoized = function () {\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            var key = hasher.apply(null, args);\n            if (key in memo) {\n                callback.apply(null, memo[key]);\n            }\n            else if (key in queues) {\n                queues[key].push(callback);\n            }\n            else {\n                queues[key] = [callback];\n                fn.apply(null, args.concat([function () {\n                    memo[key] = arguments;\n                    var q = queues[key];\n                    delete queues[key];\n                    for (var i = 0, l = q.length; i < l; i++) {\n                      q[i].apply(null, arguments);\n                    }\n                }]));\n            }\n        };\n        memoized.memo = memo;\n        memoized.unmemoized = fn;\n        return memoized;\n    };\n\n    async.unmemoize = function (fn) {\n      return function () {\n        return (fn.unmemoized || fn).apply(null, arguments);\n      };\n    };\n\n    async.times = function (count, iterator, callback) {\n        var counter = [];\n        for (var i = 0; i < count; i++) {\n            counter.push(i);\n        }\n        return async.map(counter, iterator, callback);\n    };\n\n    async.timesSeries = function (count, iterator, callback) {\n        var counter = [];\n        for (var i = 0; i < count; i++) {\n            counter.push(i);\n        }\n        return async.mapSeries(counter, iterator, callback);\n    };\n\n    async.compose = function (/* functions... */) {\n        var fns = Array.prototype.reverse.call(arguments);\n        return function () {\n            var that = this;\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            async.reduce(fns, args, function (newargs, fn, cb) {\n                fn.apply(that, newargs.concat([function () {\n                    var err = arguments[0];\n                    var nextargs = Array.prototype.slice.call(arguments, 1);\n                    cb(err, nextargs);\n                }]))\n            },\n            function (err, results) {\n                callback.apply(that, [err].concat(results));\n            });\n        };\n    };\n\n    var _applyEach = function (eachfn, fns /*args...*/) {\n        var go = function () {\n            var that = this;\n            var args = Array.prototype.slice.call(arguments);\n            var callback = args.pop();\n            return eachfn(fns, function (fn, cb) {\n                fn.apply(that, args.concat([cb]));\n            },\n            callback);\n        };\n        if (arguments.length > 2) {\n            var args = Array.prototype.slice.call(arguments, 2);\n            return go.apply(this, args);\n        }\n        else {\n            return go;\n        }\n    };\n    async.applyEach = doParallel(_applyEach);\n    async.applyEachSeries = doSeries(_applyEach);\n\n    async.forever = function (fn, callback) {\n        function next(err) {\n            if (err) {\n                if (callback) {\n                    return callback(err);\n                }\n                throw err;\n            }\n            fn(next);\n        }\n        next();\n    };\n\n    // AMD / RequireJS\n    if (typeof define !== 'undefined' && define.amd) {\n        define([], function () {\n            return async;\n        });\n    }\n    // Node.js\n    else if (typeof module !== 'undefined' && module.exports) {\n        module.exports = async;\n    }\n    // included directly via <script> tag\n    else {\n        root.async = async;\n    }\n\n}());\n\n})",
              "bottom": "})"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/index.js": {
            "requireId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/index.js",
            "memoizeId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/index.js",
            "descriptor": {
              "filename": "index.js",
              "filepath": "node_modules/request/node_modules/cookie-jar/index.js",
              "mtime": 1362167190,
              "code": "/*!\n * Tobi - Cookie\n * Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n */\n\nvar url = require('url');\n\n/**\n * Initialize a new `Cookie` with the given cookie `str` and `req`.\n *\n * @param {String} str\n * @param {IncomingRequest} req\n * @api private\n */\n\nvar Cookie = exports = module.exports = function Cookie(str, req) {\n  this.str = str;\n\n  // Map the key/val pairs\n  str.split(/ *; */).reduce(function(obj, pair){\n   var p = pair.indexOf('=');\n   var key = p > 0 ? pair.substring(0, p).trim() : pair.trim();\n   var lowerCasedKey = key.toLowerCase();\n   var value = p > 0 ? pair.substring(p + 1).trim() : true;\n\n   if (!obj.name) {\n    // First key is the name\n    obj.name = key;\n    obj.value = value;\n   }\n   else if (lowerCasedKey === 'httponly') {\n    obj.httpOnly = value;\n   }\n   else {\n    obj[lowerCasedKey] = value;\n   }\n   return obj;\n  }, this);\n\n  // Expires\n  this.expires = this.expires\n    ? new Date(this.expires)\n    : Infinity;\n\n  // Default or trim path\n  this.path = this.path\n    ? this.path.trim(): req \n    ? url.parse(req.url).pathname: '/';\n};\n\n/**\n * Return the original cookie string.\n *\n * @return {String}\n * @api public\n */\n\nCookie.prototype.toString = function(){\n  return this.str;\n};\n\nmodule.exports.Jar = require('./jar')",
              "globals": {
                "url": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "Cookie": {
                  "type": "assign"
                },
                "exports": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "url": {
                    "where": "inline"
                  },
                  "./jar": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/cookie-jar';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/cookie-jar';\n/*!\n * Tobi - Cookie\n * Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n * MIT Licensed\n */\n\n/**\n * Module dependencies.\n */\n\nvar url = require('__SYSTEM__/url');\n\n/**\n * Initialize a new `Cookie` with the given cookie `str` and `req`.\n *\n * @param {String} str\n * @param {IncomingRequest} req\n * @api private\n */\n\nvar Cookie = exports = module.exports = function Cookie(str, req) {\n  this.str = str;\n\n  // Map the key/val pairs\n  str.split(/ *; */).reduce(function(obj, pair){\n   var p = pair.indexOf('=');\n   var key = p > 0 ? pair.substring(0, p).trim() : pair.trim();\n   var lowerCasedKey = key.toLowerCase();\n   var value = p > 0 ? pair.substring(p + 1).trim() : true;\n\n   if (!obj.name) {\n    // First key is the name\n    obj.name = key;\n    obj.value = value;\n   }\n   else if (lowerCasedKey === 'httponly') {\n    obj.httpOnly = value;\n   }\n   else {\n    obj[lowerCasedKey] = value;\n   }\n   return obj;\n  }, this);\n\n  // Expires\n  this.expires = this.expires\n    ? new Date(this.expires)\n    : Infinity;\n\n  // Default or trim path\n  this.path = this.path\n    ? this.path.trim(): req \n    ? url.parse(req.url).pathname: '/';\n};\n\n/**\n * Return the original cookie string.\n *\n * @return {String}\n * @api public\n */\n\nCookie.prototype.toString = function(){\n  return this.str;\n};\n\nmodule.exports.Jar = require('./jar')\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "url": {
                  "where": "inline"
                },
                "./jar": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/jar.js": {
            "requireId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/jar",
            "memoizeId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/jar.js",
            "descriptor": {
              "filename": "jar.js",
              "filepath": "node_modules/request/node_modules/cookie-jar/jar.js",
              "mtime": 1362166690,
              "code": "/*!\n* Tobi - CookieJar\n* Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n* MIT Licensed\n*/\n\n/**\n* Module dependencies.\n*/\n\nvar url = require('url');\n\n/**\n* Initialize a new `CookieJar`.\n*\n* @api private\n*/\n\nvar CookieJar = exports = module.exports = function CookieJar() {\n  this.cookies = [];\n};\n\n/**\n* Add the given `cookie` to the jar.\n*\n* @param {Cookie} cookie\n* @api private\n*/\n\nCookieJar.prototype.add = function(cookie){\n  this.cookies = this.cookies.filter(function(c){\n    // Avoid duplication (same path, same name)\n    return !(c.name == cookie.name && c.path == cookie.path);\n  });\n  this.cookies.push(cookie);\n};\n\n/**\n* Get cookies for the given `req`.\n*\n* @param {IncomingRequest} req\n* @return {Array}\n* @api private\n*/\n\nCookieJar.prototype.get = function(req){\n  var path = url.parse(req.url).pathname\n    , now = new Date\n    , specificity = {};\n  return this.cookies.filter(function(cookie){\n    if (0 == path.indexOf(cookie.path) && now < cookie.expires\n      && cookie.path.length > (specificity[cookie.name] || 0))\n      return specificity[cookie.name] = cookie.path.length;\n  });\n};\n\n/**\n* Return Cookie string for the given `req`.\n*\n* @param {IncomingRequest} req\n* @return {String}\n* @api private\n*/\n\nCookieJar.prototype.cookieString = function(req){\n  var cookies = this.get(req);\n  if (cookies.length) {\n    return cookies.map(function(cookie){\n      return cookie.name + '=' + cookie.value;\n    }).join('; ');\n  }\n};\n",
              "globals": {
                "url": {
                  "type": "assign"
                },
                "require": {
                  "type": "call"
                },
                "CookieJar": {
                  "type": "assign"
                },
                "exports": {
                  "type": "assign"
                },
                "module": {
                  "type": "reference"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {
                  "url": {
                    "where": "inline"
                  }
                },
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/cookie-jar';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/request/node_modules/cookie-jar';\n/*!\n* Tobi - CookieJar\n* Copyright(c) 2010 LearnBoost <dev@learnboost.com>\n* MIT Licensed\n*/\n\n/**\n* Module dependencies.\n*/\n\nvar url = require('__SYSTEM__/url');\n\n/**\n* Initialize a new `CookieJar`.\n*\n* @api private\n*/\n\nvar CookieJar = exports = module.exports = function CookieJar() {\n  this.cookies = [];\n};\n\n/**\n* Add the given `cookie` to the jar.\n*\n* @param {Cookie} cookie\n* @api private\n*/\n\nCookieJar.prototype.add = function(cookie){\n  this.cookies = this.cookies.filter(function(c){\n    // Avoid duplication (same path, same name)\n    return !(c.name == cookie.name && c.path == cookie.path);\n  });\n  this.cookies.push(cookie);\n};\n\n/**\n* Get cookies for the given `req`.\n*\n* @param {IncomingRequest} req\n* @return {Array}\n* @api private\n*/\n\nCookieJar.prototype.get = function(req){\n  var path = url.parse(req.url).pathname\n    , now = new Date\n    , specificity = {};\n  return this.cookies.filter(function(cookie){\n    if (0 == path.indexOf(cookie.path) && now < cookie.expires\n      && cookie.path.length > (specificity[cookie.name] || 0))\n      return specificity[cookie.name] = cookie.path.length;\n  });\n};\n\n/**\n* Return Cookie string for the given `req`.\n*\n* @param {IncomingRequest} req\n* @return {String}\n* @api private\n*/\n\nCookieJar.prototype.cookieString = function(req){\n  var cookies = this.get(req);\n  if (cookies.length) {\n    return cookies.map(function(cookie){\n      return cookie.name + '=' + cookie.value;\n    }).join('; ');\n  }\n};\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {
                "url": {
                  "where": "inline"
                }
              },
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/./loader.js": {
            "requireId": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/./loader",
            "memoizeId": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/./loader.js",
            "descriptor": {
              "filename": "loader.js",
              "filepath": "node_modules/pinf-loader-js/loader.js",
              "mtime": 1381607720,
              "code": "/**\n * Author: Christoph Dorn <christoph@christophdorn.com>\n * [UNLICENSE](http://unlicense.org/)\n */\n\n// NOTE: Remove lines marked /*DEBUG*/ when compiling loader for 'min' release!\n\n// Combat pollution when used via <script> tag.\n// Don't touch any globals except for `exports` and `PINF`.\n;(function (global) {\n\n\t// If `PINF` gloabl already exists, don't do anything to change it.\n\tif (typeof global.PINF !== \"undefined\") {\n\t\treturn;\n\t}\n\n\tvar loadedBundles = [],\n\t\t// @see https://github.com/unscriptable/curl/blob/62caf808a8fd358ec782693399670be6806f1845/src/curl.js#L69\n\t\treadyStates = { 'loaded': 1, 'interactive': 1, 'complete': 1 },\n\t\tlastModule = null;\n\n\t// For older browsers that don't have `Object.keys()` (Firefox 3.6)\n\tfunction keys(obj) {\n\t\tvar keys = [];\n\t\tfor (var key in obj) {\n\t\t\tkeys.push(key);\n\t\t}\n\t\treturn keys;\n\t}\n\n\tfunction normalizeSandboxArguments(implementation) {\n\t\treturn function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\t/*DEBUG*/ if (typeof options === \"function\" && typeof loadedCallback === \"object\") {\n\t\t\t/*DEBUG*/     throw new Error(\"Callback before options for `require.sandbox(programIdentifier, options, loadedCallback)`\");\n\t\t\t/*DEBUG*/ }\n\t\t\tif (typeof options === \"function\" && !loadedCallback && !errorCallback) {\n\t\t\t\tloadedCallback = options;\n\t\t\t\toptions = {};\n\t\t\t} else\n\t\t\tif (typeof options === \"function\" && typeof loadedCallback === \"function\" && !errorCallback) {\n\t\t\t\terrorCallback = loadedCallback;\n\t\t\t\tloadedCallback = options;\n\t\t\t\toptions = {};\n\t\t\t} else {\n\t\t\t\toptions = options || {};\n\t\t\t}\n\t\t\timplementation(programIdentifier, options, loadedCallback, errorCallback);\n\t\t};\n\t}\n\n\t// A set of modules working together.\n\tvar Sandbox = function(sandboxIdentifier, sandboxOptions, loadedCallback) {\n\n\t\tvar moduleInitializers = {},\n\t\t\tinitializedModules = {},\n\t\t\t/*DEBUG*/ bundleIdentifiers = {},\n\t\t\tpackages = {},\n\t\t\theadTag,\n\t\t\tloadingBundles = {};\n\n\t\tvar sandbox = {\n\t\t\t\tid: sandboxIdentifier\n\t\t\t};\n\n\t\t/*DEBUG*/ function logDebug() {\n\t\t/*DEBUG*/ \tif (sandboxOptions.debug !== true) return;\n\t\t/*DEBUG*/ \t// NOTRE: This does not work in google chrome.\n\t\t/*DEBUG*/ \t//console.log.apply(null, arguments);\n\t\t/*DEBUG*/ \tif (arguments.length === 1) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 2) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 3) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1], arguments[2]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 4) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1], arguments[2], arguments[3]);\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ }\n\n\t\t// @credit https://github.com/unscriptable/curl/blob/62caf808a8fd358ec782693399670be6806f1845/src/curl.js#L319-360\n\t\tfunction loadInBrowser(uri, loadedCallback) {\n\t\t\ttry {\n\t\t\t\t/*DEBUG*/ logDebug(\"[pinf-loader]\", 'loadInBrowser(\"' + uri + '\")\"');\n\t\t\t    // See if we are in a web worker.\n\t\t\t    if (typeof importScripts !== \"undefined\") {\n\t\t\t        importScripts(uri.replace(/^\\/?\\{host\\}/, \"\"));\n\t\t\t        return loadedCallback(null);\n\t\t\t    }\n\t\t\t    var document = global.document;\n\t\t\t    var location = document.location;\n\t            if (/^\\/?\\{host\\}\\//.test(uri)) {\n\t                uri = location.protocol + \"//\" + location.host + uri.replace(/^\\/?\\{host\\}/, \"\");\n\t            } else\n\t            if (/^\\/\\//.test(uri)) {\n\t                uri = location.protocol + \"/\" + uri;\n\t            }\n\t\t\t\tif (!headTag) {\n\t\t\t\t\theadTag = document.getElementsByTagName(\"head\")[0];\n\t\t\t\t}\n\t\t\t\tvar element = document.createElement(\"script\");\n\t\t\t\telement.type = \"text/javascript\";\n\t\t\t\telement.onload = element.onreadystatechange = function(ev) {\n\t\t\t\t\tev = ev || global.event;\n\t\t\t\t\tif (ev.type === \"load\" || readyStates[this.readyState]) {\n\t\t\t\t\t\tthis.onload = this.onreadystatechange = this.onerror = null;\n\t\t\t\t\t\tloadedCallback(null, function() {\n\t\t\t\t\t\t\telement.parentNode.removeChild(element);\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telement.onerror = function(err) {\n\t\t\t\t\t/*DEBUG*/ console.error(err);\n\t\t\t\t\treturn loadedCallback(new Error(\"Error loading '\" + uri + \"'\"));\n\t\t\t\t}\n\t\t\t\telement.charset = \"utf-8\";\n\t\t\t\telement.async = true;\n\t\t\t\telement.src = uri;\n\t\t\t\telement = headTag.insertBefore(element, headTag.firstChild);\n\t\t\t} catch(err) {\n\t\t\t\tloadedCallback(err);\n\t\t\t}\n\t\t}\n\n\t\tfunction load(bundleIdentifier, packageIdentifier, bundleSubPath, loadedCallback) {\n\t\t\ttry {\n\t            if (packageIdentifier !== \"\") {\n\t                bundleIdentifier = (\"/\" + packageIdentifier + \"/\" + bundleIdentifier).replace(/\\/+/g, \"/\");\n\t            }\n\t\t\t\tif (initializedModules[bundleIdentifier]) {\n\t\t\t\t\t// Module is already loaded and initialized.\n\t\t\t\t\tloadedCallback(null, sandbox);\n\t\t\t\t} else {\n\t\t\t\t\t// Module is not initialized.\n\t\t\t\t\tif (loadingBundles[bundleIdentifier]) {\n\t\t\t\t\t\t// Module is already loading.\n\t\t\t\t\t\tloadingBundles[bundleIdentifier].push(loadedCallback);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Module is not already loading.\n\t\t\t\t\t\tloadingBundles[bundleIdentifier] = [];\n\t\t\t\t\t\tbundleIdentifier = sandboxIdentifier + bundleSubPath + bundleIdentifier;\n\t\t\t\t\t\t// Default to our script-injection browser loader.\n\t\t\t\t\t\t(sandboxOptions.rootBundleLoader || sandboxOptions.load || loadInBrowser)(bundleIdentifier, function(err, cleanupCallback) {\n\t\t\t\t\t\t\tif (err) return loadedCallback(err);\n\t\t\t\t\t\t    // The rootBundleLoader is only applicable for the first load.\n\t                        delete sandboxOptions.rootBundleLoader;\n\t\t\t\t\t\t\tfinalizeLoad(bundleIdentifier);\n\t\t\t\t\t\t\tloadedCallback(null, sandbox);\n\t\t\t\t\t\t\tif (cleanupCallback) {\n\t\t\t\t\t\t\t\tcleanupCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch(err) {\n\t\t\t\tloadedCallback(err);\n\t\t\t}\n\t\t}\n\n\t\t// Called after a bundle has been loaded. Takes the top bundle off the *loading* stack\n\t\t// and makes the new modules available to the sandbox.\n\t\tfunction finalizeLoad(bundleIdentifier)\n\t\t{\n\t\t\t// Assume a consistent statically linked set of modules has been memoized.\n\t\t\t/*DEBUG*/ bundleIdentifiers[bundleIdentifier] = loadedBundles[0][0];\n\t\t\tvar key;\n\t\t\tfor (key in loadedBundles[0][1]) {\n\t\t\t\t// If we have a package descriptor add it or merge it on top.\n\t\t\t\tif (/^[^\\/]*\\/package.json$/.test(key)) {\n\t\t\t\t\t// NOTE: Not quite sure if we should allow agumenting package descriptors.\n\t\t\t\t\t//       When doing nested requires using same package we can either add all\n\t\t\t\t\t//\t\t mappings (included mappings not needed until further down the tree) to\n\t\t\t\t\t//       the first encounter of the package descriptor or add more mappings as\n\t\t\t\t\t//       needed down the road. We currently support both.\n\t\t\t\t\tif (moduleInitializers[key]) {\n\t\t\t\t\t\t// TODO: Keep array of bundle identifiers instead of overwriting existing one?\n\t\t\t\t\t\t//\t\t Overwriting may change subsequent bundeling behaviour?\n\t\t\t\t\t\tmoduleInitializers[key][0] = bundleIdentifier;\n\t\t\t\t\t\t// Only augment (instead of replace existing values).\n\t\t\t\t\t\tif (typeof moduleInitializers[key][1].main === \"undefined\") {\n\t\t\t\t\t\t\tmoduleInitializers[key][1].main = loadedBundles[0][1][key][0].main;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (loadedBundles[0][1][key][0].mappings) {\n\t\t\t\t\t\t\tif (!moduleInitializers[key][1].mappings) {\n\t\t\t\t\t\t\t\tmoduleInitializers[key][1].mappings = {};\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfor (var alias in loadedBundles[0][1][key][0].mappings) {\n\t\t\t\t\t\t\t\tif (typeof moduleInitializers[key][1].mappings[alias] === \"undefined\") {\n\t\t\t\t\t\t\t\t\tmoduleInitializers[key][1].mappings[alias] = loadedBundles[0][1][key][0].mappings[alias];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmoduleInitializers[key] = [bundleIdentifier, loadedBundles[0][1][key][0], loadedBundles[0][1][key][1]];\n\t\t\t\t\t}\n\t\t\t\t\t// Now that we have a [updated] package descriptor, re-initialize it if we have it already in cache.\n\t\t\t\t\tvar packageIdentifier = key.split(\"/\").shift();\n\t\t\t\t\tif (packages[packageIdentifier]) {\n\t\t\t\t\t\tpackages[packageIdentifier].init();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Only add modules that don't already exist!\n\t\t\t\t// TODO: Log warning in debug mode if module already exists.\n\t\t\t\tif (typeof moduleInitializers[key] === \"undefined\") {\n\t\t\t\t\tmoduleInitializers[key] = [bundleIdentifier, loadedBundles[0][1][key][0], loadedBundles[0][1][key][1]];\n\t\t\t\t}\n\t\t\t}\n\t\t\tloadedBundles.shift();\n\t\t}\n\n\t\tvar Package = function(packageIdentifier) {\n\t\t\tif (packages[packageIdentifier]) {\n\t\t\t\treturn packages[packageIdentifier];\n\t\t\t}\n\n\t\t\tvar pkg = {\n\t\t\t\tid: packageIdentifier,\n\t\t\t\tdescriptor: {},\n\t\t\t\tmain: \"/main.js\",\n\t\t\t\tmappings: {},\n\t\t\t\tdirectories: {},\n\t\t\t\tlibPath: \"\"\n\t\t\t};\n\n\t\t\tvar parentModule = lastModule;\n\n\t\t\tpkg.init = function() {\n\t\t\t\tvar descriptor = (moduleInitializers[packageIdentifier + \"/package.json\"] && moduleInitializers[packageIdentifier + \"/package.json\"][1]) || {};\n\t\t\t\tif (descriptor) {\n\t\t\t\t\tpkg.descriptor = descriptor;\n\t\t\t\t\tif (typeof descriptor.main === \"string\") {\n\t\t\t\t\t\tpkg.main = descriptor.main;\n\t\t\t\t\t}\n\t\t\t\t\tpkg.mappings = descriptor.mappings || pkg.mappings;\n\t\t\t\t\tpkg.directories = descriptor.directories || pkg.directories;\n\t\t\t\t\t// NOTE: We need `lib` directory support so that the source directory structure can be mapped\n\t\t\t\t\t//       into the bundle structure without modification. If this is not done, a module doing a relative require\n\t\t\t\t\t//       for a resource outside of the lib directory will not find the file.\n\t\t\t\t\tpkg.libPath = (typeof pkg.directories.lib !== \"undefined\" && pkg.directories.lib != \"\") ? pkg.directories.lib + \"/\" : pkg.libPath;\n\t\t\t\t}\n\t\t\t}\n\t\t\tpkg.init();\n\n\t\t\tfunction normalizeIdentifier(identifier) {\n\t\t\t    // If we have a period (\".\") in the basename we want an absolute path from\n\t\t\t    // the root of the package. Otherwise a relative path to the \"lib\" directory.\n\t\t\t    if (identifier.split(\"/\").pop().indexOf(\".\") === -1) {\n\t\t\t        // We have a module relative to the \"lib\" directory of the package.\n\t\t\t        identifier = identifier + \".js\";\n\t\t\t    } else\n\t\t\t    if (!/^\\//.test(identifier)) {\n\t\t\t        // We want an absolute path for the module from the root of the package.\n\t\t\t        identifier = \"/\" + identifier;\n\t\t\t    }\n                return identifier;\n\t\t\t}\n\n\t\t\tvar Module = function(moduleIdentifier, parentModule) {\n\n\t\t\t\tvar moduleIdentifierSegment = moduleIdentifier.replace(/\\/[^\\/]*$/, \"\").split(\"/\"),\n\t\t\t\t\tmodule = {\n\t\t\t\t\t\tid: moduleIdentifier,\n\t\t\t\t\t\texports: {},\n\t\t\t\t\t\tparentModule: parentModule,\n\t\t\t\t\t\tbundle: null,\n\t\t\t\t\t\tpkg: packageIdentifier\n\t\t\t\t\t};\n\n\t\t\t\tfunction resolveIdentifier(identifier) {\n\t\t\t\t\tlastModule = module;\n\t\t\t\t\t// Check for relative module path to module within same package.\n\t\t\t\t\tif (/^\\./.test(identifier)) {\n\t\t\t\t\t\tvar segments = identifier.replace(/^\\.\\//, \"\").split(\"../\");\n\t\t\t\t\t\tidentifier = \"/\" + moduleIdentifierSegment.slice(1, moduleIdentifierSegment.length-segments.length+1).concat(segments[segments.length-1]).join(\"/\");\n\t\t\t\t\t\tif (identifier === \"/.\") {\n\t\t\t\t\t\t\treturn [pkg, \"\"];\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn [pkg, normalizeIdentifier(identifier.replace(/\\/\\.$/, \"/\"))];\n\t\t\t\t\t}\n\t\t\t\t\tvar splitIdentifier = identifier.split(\"/\");\n\t\t\t\t\t// Check for mapped module path to module within mapped package.\n\t\t\t\t\tif (typeof pkg.mappings[splitIdentifier[0]] !== \"undefined\") {\n\t\t\t\t\t\treturn [Package(pkg.mappings[splitIdentifier[0]]), (splitIdentifier.length > 1)?normalizeIdentifier(splitIdentifier.slice(1).join(\"/\")):\"\"];\n\t\t\t\t\t}\n\t\t\t\t\t/*DEBUG*/ if (!moduleInitializers[\"/\" + normalizeIdentifier(identifier)]) {\n\t\t\t\t\t/*DEBUG*/     throw new Error(\"Descriptor for package '\" + pkg.id + \"' in sandbox '\" + sandbox.id + \"' does not declare 'mappings[\\\"\" + splitIdentifier[0] + \"\\\"]' property nor does sandbox have module memoized at '\" + \"/\" + normalizeIdentifier(identifier) + \"' needed to satisfy module path '\" + identifier + \"' in module '\" + moduleIdentifier + \"'!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\treturn [Package(\"\"), \"/\" + normalizeIdentifier(identifier)];\n\t\t\t\t}\n\n\t\t\t\t// Statically link a module and its dependencies\n\t\t\t\tmodule.require = function(identifier) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\treturn identifier[0].require(identifier[1]).exports;\n\t\t\t\t};\n\n\t\t\t\tmodule.require.supports = [\n\t\t            \"ucjs-pinf-0\"\n\t\t        ];\n\n\t\t\t\tmodule.require.id = function(identifier) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\treturn identifier[0].require.id(identifier[1]);\n\t\t\t\t};\n\n\t\t\t\tmodule.require.async = function(identifier, loadedCallback, errorCallback) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\tidentifier[0].load(identifier[1], moduleInitializers[moduleIdentifier][0], function(err, moduleAPI) {\n\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\tif (errorCallback) return errorCallback(err);\n\t\t\t\t\t\t\tthrow err;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tloadedCallback(moduleAPI);\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\t\tmodule.require.sandbox = normalizeSandboxArguments(function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\t\t\toptions.load = options.load || sandboxOptions.load;\n\t                // If the `programIdentifier` is relative it is resolved against the URI of the owning sandbox (not the owning page).\n\t\t\t\t\tif (/^\\./.test(programIdentifier))\n\t\t\t\t\t{\n\t\t\t\t\t    programIdentifier = sandboxIdentifier + \"/\" + programIdentifier;\n\t\t\t\t\t    // HACK: Temporary hack as zombie (https://github.com/assaf/zombie) does not normalize path before sending to server.\n\t\t\t\t\t    programIdentifier = programIdentifier.replace(/\\/\\.\\//g, \"/\");\n\t\t\t\t\t}\n\t\t\t\t\treturn PINF.sandbox(programIdentifier, options, loadedCallback, errorCallback);\n\t\t\t\t});\n\t\t\t\tmodule.require.sandbox.id = sandboxIdentifier;\n\n\t\t\t\tmodule.load = function() {\n\t\t\t\t\tmodule.bundle = moduleInitializers[moduleIdentifier][0];\n\t\t\t\t\tif (typeof moduleInitializers[moduleIdentifier][1] === \"function\") {\n\n\t\t\t\t\t\tvar moduleInterface = {\n\t\t\t\t\t\t\tid: module.id,\n\t\t\t\t\t\t\tfilename: \n\t\t\t\t\t\t\t\t// The `filename` from the meta info attached to the module.\n\t\t\t\t\t\t\t\t// This is typically where the module was originally found on the filesystem.\n\t\t\t\t\t\t\t\tmoduleInitializers[moduleIdentifier][2].filename ||\n\t\t\t\t\t\t\t\t// Fall back to the virtual path of the module in the bundle.\n\t\t\t\t\t\t\t\t// TODO: Insert a delimiter between bundle and module id.\n\t\t\t\t\t\t\t\t(module.bundle.replace(/\\.js$/, \"\") + \"/\" + module.id).replace(/\\/+/g, \"/\"),\n\t\t\t\t\t\t\texports: {}\n\t\t\t\t\t\t}\n\n\t\t\t\t        if (packageIdentifier === \"\" && pkg.main === moduleIdentifier) {\n\t\t\t\t        \tmodule.require.main = moduleInterface;\n\t\t\t\t        }\n\n\t\t\t\t\t\tif (sandboxOptions.onInitModule) {\n\t\t\t\t\t\t\tsandboxOptions.onInitModule(moduleInterface, module, pkg, sandbox, {\n\t\t\t\t\t\t\t\tnormalizeIdentifier: normalizeIdentifier,\n\t\t\t\t\t\t\t\tresolveIdentifier: resolveIdentifier,\n\t\t\t\t\t\t\t\tfinalizeLoad: finalizeLoad,\n\t\t\t\t\t\t\t\tmoduleInitializers: moduleInitializers,\n\t\t\t\t\t\t\t\tinitializedModules: initializedModules\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar exports = moduleInitializers[moduleIdentifier][1](module.require, module.exports, moduleInterface);\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof moduleInterface.exports !== \"undefined\" &&\n\t\t\t\t\t\t\t(\n\t\t\t\t\t\t\t\ttypeof moduleInterface.exports !== \"object\" ||\n\t\t\t\t\t\t\t\tkeys(moduleInterface.exports).length !== 0\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tmodule.exports = moduleInterface.exports;\n\t\t\t\t\t\t} else\n\t\t\t\t\t\tif (typeof exports !== \"undefined\") {\n\t\t\t\t\t\t\tmodule.exports = exports;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\tif (typeof moduleInitializers[moduleIdentifier][1] === \"string\") {\n\t\t\t\t\t\t// TODO: Use more optimal string encoding algorythm to reduce payload size?\n\t\t\t\t\t\tmodule.exports = decodeURIComponent(moduleInitializers[moduleIdentifier][1]);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmodule.exports = moduleInitializers[moduleIdentifier][1];\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\t\t/*DEBUG*/ module.getReport = function() {\n\t\t\t\t/*DEBUG*/ \tvar exportsCount = 0,\n\t\t\t\t/*DEBUG*/ \t\tkey;\n\t\t\t\t/*DEBUG*/ \tfor (key in module.exports) {\n\t\t\t\t/*DEBUG*/ \t\texportsCount++;\n\t\t\t\t/*DEBUG*/ \t}\n\t\t\t\t/*DEBUG*/ \treturn {\n\t\t\t\t/*DEBUG*/ \t\texports: exportsCount\n\t\t\t\t/*DEBUG*/ \t};\n\t\t\t\t/*DEBUG*/ };\n\n\t\t\t\treturn module;\n\t\t\t};\n\n\t\t\tpkg.load = function(moduleIdentifier, bundleIdentifier, loadedCallback) {\n\t\t\t\t// If module/bundle to be loaded asynchronously is already memoized we skip the load.\n\t\t\t\tif (moduleInitializers[moduleIdentifier]) {\n\t\t\t\t\treturn loadedCallback(null, pkg.require(moduleIdentifier).exports);\n\t\t\t\t}\n\t\t\t\tvar bundleSubPath = bundleIdentifier.substring(sandboxIdentifier.length);\n                load(\n                \t((!/^\\//.test(moduleIdentifier))?\"/\"+pkg.libPath:\"\") + moduleIdentifier,\n                \tpackageIdentifier,\n                \tbundleSubPath.replace(/\\.js$/g, \"\"),\n                \tfunction(err) {\n\t                \tif (err) return loadedCallback(err);\n\t                    loadedCallback(null, pkg.require(moduleIdentifier).exports);\n\t                }\n\t            );\n\t\t\t}\n\n\t\t\tpkg.require = function(moduleIdentifier) {\n\n\t\t\t\tif (moduleIdentifier) {\n\t                if (!/^\\//.test(moduleIdentifier)) {\n\t                    moduleIdentifier = \"/\" + ((moduleIdentifier.substring(0, pkg.libPath.length)===pkg.libPath)?\"\":pkg.libPath) + moduleIdentifier;\n\t                }\n\t\t\t\t\tmoduleIdentifier = packageIdentifier + moduleIdentifier;\n\t\t\t\t} else {\n\t\t\t\t\tmoduleIdentifier = pkg.main;\n\t\t\t\t}\n\n\t\t\t\tif (!initializedModules[moduleIdentifier]) {\n\t\t\t\t\t/*DEBUG*/ if (!moduleInitializers[moduleIdentifier]) {\n\t\t\t\t\t/*DEBUG*/ \tconsole.error(\"[pinf-loader-js]\", \"moduleInitializers\", moduleInitializers);\n\t\t\t\t\t/*DEBUG*/ \tthrow new Error(\"Module '\" + moduleIdentifier + \"' not found in sandbox '\" + sandbox.id + \"'!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\t(initializedModules[moduleIdentifier] = Module(moduleIdentifier, lastModule)).load();\n\t\t\t\t}\n\n\t\t\t\tvar loadingBundlesCallbacks;\n\t\t\t\tif (loadingBundles[moduleIdentifier]) {\n\t\t\t\t\tloadingBundlesCallbacks = loadingBundles[moduleIdentifier];\n\t\t\t\t\tdelete loadingBundles[moduleIdentifier];\n\t\t\t\t\tfor (var i=0 ; i<loadingBundlesCallbacks.length ; i++) {\n\t\t\t\t\t\tloadingBundlesCallbacks[i](null, sandbox);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn initializedModules[moduleIdentifier];\n\t\t\t}\n\n            pkg.require.id = function(moduleIdentifier) {\n                if (!/^\\//.test(moduleIdentifier)) {\n                    moduleIdentifier = \"/\" + pkg.libPath + moduleIdentifier;\n                }\n                return (((packageIdentifier !== \"\")?\"/\"+packageIdentifier+\"/\":\"\") + moduleIdentifier).replace(/\\/+/g, \"/\");\n            }\n\n\t\t\t/*DEBUG*/ pkg.getReport = function() {\n\t\t\t/*DEBUG*/ \treturn {\n\t\t\t/*DEBUG*/ \t\tmain: pkg.main,\n\t\t\t/*DEBUG*/ \t\tmappings: pkg.mappings,\n\t\t\t/*DEBUG*/ \t\tdirectories: pkg.directories,\n\t\t\t/*DEBUG*/ \t\tlibPath: pkg.libPath\n\t\t\t/*DEBUG*/ \t};\n\t\t\t/*DEBUG*/ }\n\n\t\t\tif (sandboxOptions.onInitPackage) {\n\t\t\t\tsandboxOptions.onInitPackage(pkg, sandbox, {\n\t\t\t\t\tnormalizeIdentifier: normalizeIdentifier,\n\t\t\t\t\tfinalizeLoad: finalizeLoad,\n\t\t\t\t\tmoduleInitializers: moduleInitializers,\n\t\t\t\t\tinitializedModules: initializedModules\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tpackages[packageIdentifier] = pkg;\n\n\t\t\treturn pkg;\n\t\t}\n\n\t\t// Get a module and initialize it (statically link its dependencies) if it is not already so\n\t\tsandbox.require = function(moduleIdentifier) {\n\t\t\treturn Package(\"\").require(moduleIdentifier).exports;\n\t\t}\n\n\t\t// Call the 'main' module of the program\n\t\tsandbox.boot = function() {\n\t\t\t/*DEBUG*/ if (typeof Package(\"\").main !== \"string\") {\n\t\t\t/*DEBUG*/ \tthrow new Error(\"No 'main' property declared in '/package.json' in sandbox '\" + sandbox.id + \"'!\");\n\t\t\t/*DEBUG*/ }\n\t\t\treturn sandbox.require(Package(\"\").main);\n\t\t};\n\n\t\t// Call the 'main' exported function of the main' module of the program\n\t\tsandbox.main = function() {\n\t\t\tvar exports = sandbox.boot();\n\t\t\treturn ((exports.main)?exports.main.apply(null, arguments):exports);\n\t\t};\n\n\t\t/*DEBUG*/ sandbox.getReport = function() {\n\t\t/*DEBUG*/ \tvar report = {\n\t\t/*DEBUG*/ \t\t\tbundles: {},\n\t\t/*DEBUG*/ \t\t\tpackages: {},\n\t\t/*DEBUG*/ \t\t\tmodules: {}\n\t\t/*DEBUG*/ \t\t},\n\t\t/*DEBUG*/ \t\tkey;\n\t\t/*DEBUG*/ \tfor (key in bundleIdentifiers) {\n\t\t/*DEBUG*/ \t\treport.bundles[key] = bundleIdentifiers[key];\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tfor (key in packages) {\n\t\t/*DEBUG*/ \t\treport.packages[key] = packages[key].getReport();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tfor (key in moduleInitializers) {\n\t\t/*DEBUG*/ \t\tif (initializedModules[key]) {\n\t\t/*DEBUG*/ \t\t\treport.modules[key] = initializedModules[key].getReport();\n\t\t/*DEBUG*/ \t\t} else {\n\t\t/*DEBUG*/ \t\t\treport.modules[key] = {};\n\t\t/*DEBUG*/ \t\t}\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \treturn report;\n\t\t/*DEBUG*/ }\n\t\t/*DEBUG*/ sandbox.reset = function() {\n\t\t/*DEBUG*/   moduleInitializers = {};\n\t\t/*DEBUG*/   initializedModules = {};\n\t\t/*DEBUG*/   bundleIdentifiers = {};\n\t\t/*DEBUG*/   packages = {};\n\t\t/*DEBUG*/   loadingBundles = {};\n\t\t/*DEBUG*/ }\n\n\t\tload(\".js\", \"\", \"\", loadedCallback);\n\n\t\treturn sandbox;\n\t};\n\n\n\t// The global `require` for the 'external' (to the loader) environment.\n\tvar Loader = function() {\n\n\t\tvar \n\t\t\t/*DEBUG*/ bundleIdentifiers = {},\n\t\t\tsandboxes = {};\n\n\t\tvar Require = function(bundle) {\n\n\t\t\t\t// Address a specific sandbox or currently loading sandbox if initial load.\n\t\t\t\tthis.bundle = function(uid, callback) {\n\t\t\t\t\t/*DEBUG*/ if (uid && bundleIdentifiers[uid]) {\n\t\t\t\t\t/*DEBUG*/ \tthrow new Error(\"You cannot split require.bundle(UID) calls where UID is constant!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\t/*DEBUG*/ bundleIdentifiers[uid] = true;\n\t\t\t\t\tvar moduleInitializers = {},\n\t\t\t\t\t\treq = new Require(uid);\n\t\t\t\t\tdelete req.bundle;\n\t\t\t\t\t// Store raw module in loading bundle\n\t\t\t\t\treq.memoize = function(moduleIdentifier, moduleInitializer, moduleMeta) {\n\t\t\t\t\t\tmoduleInitializers[moduleIdentifier] = [moduleInitializer, moduleMeta || {}];\n\t\t\t\t\t}\n\t\t\t\t\tcallback(req);\n\t\t\t\t\tloadedBundles.push([uid, moduleInitializers]);\n\t\t\t\t}\n\t\t\t};\n\n\t\tvar require = new Require();\n\n\t\t// TODO: @see URL_TO_SPEC\n\t\trequire.supports = [\n\t\t\t\"ucjs-pinf-0\"\n\t\t];\n\n\t\t// Create a new environment to memoize modules to.\n\t\t// If relative, the `programIdentifier` is resolved against the URI of the owning page (this is only for the global require).\n\t\trequire.sandbox = normalizeSandboxArguments(function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\tvar sandboxIdentifier = programIdentifier.replace(/\\.js$/, \"\");\n\t\t\treturn sandboxes[sandboxIdentifier] = Sandbox(sandboxIdentifier, options, function(err, sandbox) {\n\t\t\t\tif (err) {\n\t\t\t\t\tif (errorCallback) return errorCallback(err);\n\t\t\t\t\tthrow err;\n\t\t\t\t}\n\t\t\t\tloadedCallback(sandbox);\n\t\t\t});\n\t\t});\n\t\t\n\t\t/*DEBUG*/ require.getReport = function() {\n\t\t/*DEBUG*/ \tvar report = {\n\t\t/*DEBUG*/ \t\t\tsandboxes: {}\n\t\t/*DEBUG*/ \t\t},\n\t\t/*DEBUG*/ \t\tkey;\n\t\t/*DEBUG*/ \tfor (key in sandboxes) {\n\t\t/*DEBUG*/ \t\treport.sandboxes[key] = sandboxes[key].getReport();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \treturn report;\n\t\t/*DEBUG*/ }\n\t\t/*DEBUG*/ require.reset = function() {\n\t\t/*DEBUG*/ \tfor (key in sandboxes) {\n\t\t/*DEBUG*/ \t\tsandboxes[key].reset();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tsandboxes = {};\n\t\t/*DEBUG*/ \tbundleIdentifiers = {};\n\t\t/*DEBUG*/ \tloadedBundles = [];\n\t\t/*DEBUG*/ }\n\n\t\treturn require;\n\t}\n\n\t// Set `PINF` gloabl.\n\tglobal.PINF = PINF = Loader();\n\n\t// Export `require` for CommonJS if `module` and `exports` globals exists.\n\tif (typeof module === \"object\" && typeof exports === \"object\") {\n\t\tmodule.exports = PINF;\n\t}\n\n}(this));\n",
              "globals": {
                "console": {
                  "type": "reference"
                },
                "importScripts": {
                  "type": "typeof"
                },
                "PINF": {
                  "type": "reference"
                },
                "decodeURIComponent": {
                  "type": "call"
                },
                "module": {
                  "type": "typeof"
                },
                "exports": {
                  "type": "typeof"
                }
              },
              "syntax": "javascript",
              "format": "commonjs",
              "undefine": [],
              "uses": {},
              "dependencies": {
                "static": {},
                "dynamic": {},
                "computed": false
              }
            },
            "wrapper": {
              "type": "commonjs",
              "top": "function(require, exports, module) {var __dirname = 'node_modules/pinf-loader-js';",
              "code": "function(require, exports, module) {var __dirname = 'node_modules/pinf-loader-js';\n/**\n * Author: Christoph Dorn <christoph@christophdorn.com>\n * [UNLICENSE](http://unlicense.org/)\n */\n\n// NOTE: Remove lines marked /*DEBUG*/ when compiling loader for 'min' release!\n\n// Combat pollution when used via <script> tag.\n// Don't touch any globals except for `exports` and `PINF`.\n;(function (global) {\n\n\t// If `PINF` gloabl already exists, don't do anything to change it.\n\tif (typeof global.PINF !== \"undefined\") {\n\t\treturn;\n\t}\n\n\tvar loadedBundles = [],\n\t\t// @see https://github.com/unscriptable/curl/blob/62caf808a8fd358ec782693399670be6806f1845/src/curl.js#L69\n\t\treadyStates = { 'loaded': 1, 'interactive': 1, 'complete': 1 },\n\t\tlastModule = null;\n\n\t// For older browsers that don't have `Object.keys()` (Firefox 3.6)\n\tfunction keys(obj) {\n\t\tvar keys = [];\n\t\tfor (var key in obj) {\n\t\t\tkeys.push(key);\n\t\t}\n\t\treturn keys;\n\t}\n\n\tfunction normalizeSandboxArguments(implementation) {\n\t\treturn function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\t/*DEBUG*/ if (typeof options === \"function\" && typeof loadedCallback === \"object\") {\n\t\t\t/*DEBUG*/     throw new Error(\"Callback before options for `require.sandbox(programIdentifier, options, loadedCallback)`\");\n\t\t\t/*DEBUG*/ }\n\t\t\tif (typeof options === \"function\" && !loadedCallback && !errorCallback) {\n\t\t\t\tloadedCallback = options;\n\t\t\t\toptions = {};\n\t\t\t} else\n\t\t\tif (typeof options === \"function\" && typeof loadedCallback === \"function\" && !errorCallback) {\n\t\t\t\terrorCallback = loadedCallback;\n\t\t\t\tloadedCallback = options;\n\t\t\t\toptions = {};\n\t\t\t} else {\n\t\t\t\toptions = options || {};\n\t\t\t}\n\t\t\timplementation(programIdentifier, options, loadedCallback, errorCallback);\n\t\t};\n\t}\n\n\t// A set of modules working together.\n\tvar Sandbox = function(sandboxIdentifier, sandboxOptions, loadedCallback) {\n\n\t\tvar moduleInitializers = {},\n\t\t\tinitializedModules = {},\n\t\t\t/*DEBUG*/ bundleIdentifiers = {},\n\t\t\tpackages = {},\n\t\t\theadTag,\n\t\t\tloadingBundles = {};\n\n\t\tvar sandbox = {\n\t\t\t\tid: sandboxIdentifier\n\t\t\t};\n\n\t\t/*DEBUG*/ function logDebug() {\n\t\t/*DEBUG*/ \tif (sandboxOptions.debug !== true) return;\n\t\t/*DEBUG*/ \t// NOTRE: This does not work in google chrome.\n\t\t/*DEBUG*/ \t//console.log.apply(null, arguments);\n\t\t/*DEBUG*/ \tif (arguments.length === 1) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 2) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 3) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1], arguments[2]);\n\t\t/*DEBUG*/ \t} else\n\t\t/*DEBUG*/ \tif (arguments.length === 4) {\n\t\t/*DEBUG*/ \t\tconsole.log(arguments[0], arguments[1], arguments[2], arguments[3]);\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ }\n\n\t\t// @credit https://github.com/unscriptable/curl/blob/62caf808a8fd358ec782693399670be6806f1845/src/curl.js#L319-360\n\t\tfunction loadInBrowser(uri, loadedCallback) {\n\t\t\ttry {\n\t\t\t\t/*DEBUG*/ logDebug(\"[pinf-loader]\", 'loadInBrowser(\"' + uri + '\")\"');\n\t\t\t    // See if we are in a web worker.\n\t\t\t    if (typeof importScripts !== \"undefined\") {\n\t\t\t        importScripts(uri.replace(/^\\/?\\{host\\}/, \"\"));\n\t\t\t        return loadedCallback(null);\n\t\t\t    }\n\t\t\t    var document = global.document;\n\t\t\t    var location = document.location;\n\t            if (/^\\/?\\{host\\}\\//.test(uri)) {\n\t                uri = location.protocol + \"//\" + location.host + uri.replace(/^\\/?\\{host\\}/, \"\");\n\t            } else\n\t            if (/^\\/\\//.test(uri)) {\n\t                uri = location.protocol + \"/\" + uri;\n\t            }\n\t\t\t\tif (!headTag) {\n\t\t\t\t\theadTag = document.getElementsByTagName(\"head\")[0];\n\t\t\t\t}\n\t\t\t\tvar element = document.createElement(\"script\");\n\t\t\t\telement.type = \"text/javascript\";\n\t\t\t\telement.onload = element.onreadystatechange = function(ev) {\n\t\t\t\t\tev = ev || global.event;\n\t\t\t\t\tif (ev.type === \"load\" || readyStates[this.readyState]) {\n\t\t\t\t\t\tthis.onload = this.onreadystatechange = this.onerror = null;\n\t\t\t\t\t\tloadedCallback(null, function() {\n\t\t\t\t\t\t\telement.parentNode.removeChild(element);\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telement.onerror = function(err) {\n\t\t\t\t\t/*DEBUG*/ console.error(err);\n\t\t\t\t\treturn loadedCallback(new Error(\"Error loading '\" + uri + \"'\"));\n\t\t\t\t}\n\t\t\t\telement.charset = \"utf-8\";\n\t\t\t\telement.async = true;\n\t\t\t\telement.src = uri;\n\t\t\t\telement = headTag.insertBefore(element, headTag.firstChild);\n\t\t\t} catch(err) {\n\t\t\t\tloadedCallback(err);\n\t\t\t}\n\t\t}\n\n\t\tfunction load(bundleIdentifier, packageIdentifier, bundleSubPath, loadedCallback) {\n\t\t\ttry {\n\t            if (packageIdentifier !== \"\") {\n\t                bundleIdentifier = (\"/\" + packageIdentifier + \"/\" + bundleIdentifier).replace(/\\/+/g, \"/\");\n\t            }\n\t\t\t\tif (initializedModules[bundleIdentifier]) {\n\t\t\t\t\t// Module is already loaded and initialized.\n\t\t\t\t\tloadedCallback(null, sandbox);\n\t\t\t\t} else {\n\t\t\t\t\t// Module is not initialized.\n\t\t\t\t\tif (loadingBundles[bundleIdentifier]) {\n\t\t\t\t\t\t// Module is already loading.\n\t\t\t\t\t\tloadingBundles[bundleIdentifier].push(loadedCallback);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Module is not already loading.\n\t\t\t\t\t\tloadingBundles[bundleIdentifier] = [];\n\t\t\t\t\t\tbundleIdentifier = sandboxIdentifier + bundleSubPath + bundleIdentifier;\n\t\t\t\t\t\t// Default to our script-injection browser loader.\n\t\t\t\t\t\t(sandboxOptions.rootBundleLoader || sandboxOptions.load || loadInBrowser)(bundleIdentifier, function(err, cleanupCallback) {\n\t\t\t\t\t\t\tif (err) return loadedCallback(err);\n\t\t\t\t\t\t    // The rootBundleLoader is only applicable for the first load.\n\t                        delete sandboxOptions.rootBundleLoader;\n\t\t\t\t\t\t\tfinalizeLoad(bundleIdentifier);\n\t\t\t\t\t\t\tloadedCallback(null, sandbox);\n\t\t\t\t\t\t\tif (cleanupCallback) {\n\t\t\t\t\t\t\t\tcleanupCallback();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch(err) {\n\t\t\t\tloadedCallback(err);\n\t\t\t}\n\t\t}\n\n\t\t// Called after a bundle has been loaded. Takes the top bundle off the *loading* stack\n\t\t// and makes the new modules available to the sandbox.\n\t\tfunction finalizeLoad(bundleIdentifier)\n\t\t{\n\t\t\t// Assume a consistent statically linked set of modules has been memoized.\n\t\t\t/*DEBUG*/ bundleIdentifiers[bundleIdentifier] = loadedBundles[0][0];\n\t\t\tvar key;\n\t\t\tfor (key in loadedBundles[0][1]) {\n\t\t\t\t// If we have a package descriptor add it or merge it on top.\n\t\t\t\tif (/^[^\\/]*\\/package.json$/.test(key)) {\n\t\t\t\t\t// NOTE: Not quite sure if we should allow agumenting package descriptors.\n\t\t\t\t\t//       When doing nested requires using same package we can either add all\n\t\t\t\t\t//\t\t mappings (included mappings not needed until further down the tree) to\n\t\t\t\t\t//       the first encounter of the package descriptor or add more mappings as\n\t\t\t\t\t//       needed down the road. We currently support both.\n\t\t\t\t\tif (moduleInitializers[key]) {\n\t\t\t\t\t\t// TODO: Keep array of bundle identifiers instead of overwriting existing one?\n\t\t\t\t\t\t//\t\t Overwriting may change subsequent bundeling behaviour?\n\t\t\t\t\t\tmoduleInitializers[key][0] = bundleIdentifier;\n\t\t\t\t\t\t// Only augment (instead of replace existing values).\n\t\t\t\t\t\tif (typeof moduleInitializers[key][1].main === \"undefined\") {\n\t\t\t\t\t\t\tmoduleInitializers[key][1].main = loadedBundles[0][1][key][0].main;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (loadedBundles[0][1][key][0].mappings) {\n\t\t\t\t\t\t\tif (!moduleInitializers[key][1].mappings) {\n\t\t\t\t\t\t\t\tmoduleInitializers[key][1].mappings = {};\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tfor (var alias in loadedBundles[0][1][key][0].mappings) {\n\t\t\t\t\t\t\t\tif (typeof moduleInitializers[key][1].mappings[alias] === \"undefined\") {\n\t\t\t\t\t\t\t\t\tmoduleInitializers[key][1].mappings[alias] = loadedBundles[0][1][key][0].mappings[alias];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmoduleInitializers[key] = [bundleIdentifier, loadedBundles[0][1][key][0], loadedBundles[0][1][key][1]];\n\t\t\t\t\t}\n\t\t\t\t\t// Now that we have a [updated] package descriptor, re-initialize it if we have it already in cache.\n\t\t\t\t\tvar packageIdentifier = key.split(\"/\").shift();\n\t\t\t\t\tif (packages[packageIdentifier]) {\n\t\t\t\t\t\tpackages[packageIdentifier].init();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Only add modules that don't already exist!\n\t\t\t\t// TODO: Log warning in debug mode if module already exists.\n\t\t\t\tif (typeof moduleInitializers[key] === \"undefined\") {\n\t\t\t\t\tmoduleInitializers[key] = [bundleIdentifier, loadedBundles[0][1][key][0], loadedBundles[0][1][key][1]];\n\t\t\t\t}\n\t\t\t}\n\t\t\tloadedBundles.shift();\n\t\t}\n\n\t\tvar Package = function(packageIdentifier) {\n\t\t\tif (packages[packageIdentifier]) {\n\t\t\t\treturn packages[packageIdentifier];\n\t\t\t}\n\n\t\t\tvar pkg = {\n\t\t\t\tid: packageIdentifier,\n\t\t\t\tdescriptor: {},\n\t\t\t\tmain: \"/main.js\",\n\t\t\t\tmappings: {},\n\t\t\t\tdirectories: {},\n\t\t\t\tlibPath: \"\"\n\t\t\t};\n\n\t\t\tvar parentModule = lastModule;\n\n\t\t\tpkg.init = function() {\n\t\t\t\tvar descriptor = (moduleInitializers[packageIdentifier + \"/package.json\"] && moduleInitializers[packageIdentifier + \"/package.json\"][1]) || {};\n\t\t\t\tif (descriptor) {\n\t\t\t\t\tpkg.descriptor = descriptor;\n\t\t\t\t\tif (typeof descriptor.main === \"string\") {\n\t\t\t\t\t\tpkg.main = descriptor.main;\n\t\t\t\t\t}\n\t\t\t\t\tpkg.mappings = descriptor.mappings || pkg.mappings;\n\t\t\t\t\tpkg.directories = descriptor.directories || pkg.directories;\n\t\t\t\t\t// NOTE: We need `lib` directory support so that the source directory structure can be mapped\n\t\t\t\t\t//       into the bundle structure without modification. If this is not done, a module doing a relative require\n\t\t\t\t\t//       for a resource outside of the lib directory will not find the file.\n\t\t\t\t\tpkg.libPath = (typeof pkg.directories.lib !== \"undefined\" && pkg.directories.lib != \"\") ? pkg.directories.lib + \"/\" : pkg.libPath;\n\t\t\t\t}\n\t\t\t}\n\t\t\tpkg.init();\n\n\t\t\tfunction normalizeIdentifier(identifier) {\n\t\t\t    // If we have a period (\".\") in the basename we want an absolute path from\n\t\t\t    // the root of the package. Otherwise a relative path to the \"lib\" directory.\n\t\t\t    if (identifier.split(\"/\").pop().indexOf(\".\") === -1) {\n\t\t\t        // We have a module relative to the \"lib\" directory of the package.\n\t\t\t        identifier = identifier + \".js\";\n\t\t\t    } else\n\t\t\t    if (!/^\\//.test(identifier)) {\n\t\t\t        // We want an absolute path for the module from the root of the package.\n\t\t\t        identifier = \"/\" + identifier;\n\t\t\t    }\n                return identifier;\n\t\t\t}\n\n\t\t\tvar Module = function(moduleIdentifier, parentModule) {\n\n\t\t\t\tvar moduleIdentifierSegment = moduleIdentifier.replace(/\\/[^\\/]*$/, \"\").split(\"/\"),\n\t\t\t\t\tmodule = {\n\t\t\t\t\t\tid: moduleIdentifier,\n\t\t\t\t\t\texports: {},\n\t\t\t\t\t\tparentModule: parentModule,\n\t\t\t\t\t\tbundle: null,\n\t\t\t\t\t\tpkg: packageIdentifier\n\t\t\t\t\t};\n\n\t\t\t\tfunction resolveIdentifier(identifier) {\n\t\t\t\t\tlastModule = module;\n\t\t\t\t\t// Check for relative module path to module within same package.\n\t\t\t\t\tif (/^\\./.test(identifier)) {\n\t\t\t\t\t\tvar segments = identifier.replace(/^\\.\\//, \"\").split(\"../\");\n\t\t\t\t\t\tidentifier = \"/\" + moduleIdentifierSegment.slice(1, moduleIdentifierSegment.length-segments.length+1).concat(segments[segments.length-1]).join(\"/\");\n\t\t\t\t\t\tif (identifier === \"/.\") {\n\t\t\t\t\t\t\treturn [pkg, \"\"];\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn [pkg, normalizeIdentifier(identifier.replace(/\\/\\.$/, \"/\"))];\n\t\t\t\t\t}\n\t\t\t\t\tvar splitIdentifier = identifier.split(\"/\");\n\t\t\t\t\t// Check for mapped module path to module within mapped package.\n\t\t\t\t\tif (typeof pkg.mappings[splitIdentifier[0]] !== \"undefined\") {\n\t\t\t\t\t\treturn [Package(pkg.mappings[splitIdentifier[0]]), (splitIdentifier.length > 1)?normalizeIdentifier(splitIdentifier.slice(1).join(\"/\")):\"\"];\n\t\t\t\t\t}\n\t\t\t\t\t/*DEBUG*/ if (!moduleInitializers[\"/\" + normalizeIdentifier(identifier)]) {\n\t\t\t\t\t/*DEBUG*/     throw new Error(\"Descriptor for package '\" + pkg.id + \"' in sandbox '\" + sandbox.id + \"' does not declare 'mappings[\\\"\" + splitIdentifier[0] + \"\\\"]' property nor does sandbox have module memoized at '\" + \"/\" + normalizeIdentifier(identifier) + \"' needed to satisfy module path '\" + identifier + \"' in module '\" + moduleIdentifier + \"'!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\treturn [Package(\"\"), \"/\" + normalizeIdentifier(identifier)];\n\t\t\t\t}\n\n\t\t\t\t// Statically link a module and its dependencies\n\t\t\t\tmodule.require = function(identifier) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\treturn identifier[0].require(identifier[1]).exports;\n\t\t\t\t};\n\n\t\t\t\tmodule.require.supports = [\n\t\t            \"ucjs-pinf-0\"\n\t\t        ];\n\n\t\t\t\tmodule.require.id = function(identifier) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\treturn identifier[0].require.id(identifier[1]);\n\t\t\t\t};\n\n\t\t\t\tmodule.require.async = function(identifier, loadedCallback, errorCallback) {\n\t\t\t\t\tidentifier = resolveIdentifier(identifier);\n\t\t\t\t\tidentifier[0].load(identifier[1], moduleInitializers[moduleIdentifier][0], function(err, moduleAPI) {\n\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\tif (errorCallback) return errorCallback(err);\n\t\t\t\t\t\t\tthrow err;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tloadedCallback(moduleAPI);\n\t\t\t\t\t});\n\t\t\t\t};\n\n\t\t\t\tmodule.require.sandbox = normalizeSandboxArguments(function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\t\t\toptions.load = options.load || sandboxOptions.load;\n\t                // If the `programIdentifier` is relative it is resolved against the URI of the owning sandbox (not the owning page).\n\t\t\t\t\tif (/^\\./.test(programIdentifier))\n\t\t\t\t\t{\n\t\t\t\t\t    programIdentifier = sandboxIdentifier + \"/\" + programIdentifier;\n\t\t\t\t\t    // HACK: Temporary hack as zombie (https://github.com/assaf/zombie) does not normalize path before sending to server.\n\t\t\t\t\t    programIdentifier = programIdentifier.replace(/\\/\\.\\//g, \"/\");\n\t\t\t\t\t}\n\t\t\t\t\treturn PINF.sandbox(programIdentifier, options, loadedCallback, errorCallback);\n\t\t\t\t});\n\t\t\t\tmodule.require.sandbox.id = sandboxIdentifier;\n\n\t\t\t\tmodule.load = function() {\n\t\t\t\t\tmodule.bundle = moduleInitializers[moduleIdentifier][0];\n\t\t\t\t\tif (typeof moduleInitializers[moduleIdentifier][1] === \"function\") {\n\n\t\t\t\t\t\tvar moduleInterface = {\n\t\t\t\t\t\t\tid: module.id,\n\t\t\t\t\t\t\tfilename: \n\t\t\t\t\t\t\t\t// The `filename` from the meta info attached to the module.\n\t\t\t\t\t\t\t\t// This is typically where the module was originally found on the filesystem.\n\t\t\t\t\t\t\t\tmoduleInitializers[moduleIdentifier][2].filename ||\n\t\t\t\t\t\t\t\t// Fall back to the virtual path of the module in the bundle.\n\t\t\t\t\t\t\t\t// TODO: Insert a delimiter between bundle and module id.\n\t\t\t\t\t\t\t\t(module.bundle.replace(/\\.js$/, \"\") + \"/\" + module.id).replace(/\\/+/g, \"/\"),\n\t\t\t\t\t\t\texports: {}\n\t\t\t\t\t\t}\n\n\t\t\t\t        if (packageIdentifier === \"\" && pkg.main === moduleIdentifier) {\n\t\t\t\t        \tmodule.require.main = moduleInterface;\n\t\t\t\t        }\n\n\t\t\t\t\t\tif (sandboxOptions.onInitModule) {\n\t\t\t\t\t\t\tsandboxOptions.onInitModule(moduleInterface, module, pkg, sandbox, {\n\t\t\t\t\t\t\t\tnormalizeIdentifier: normalizeIdentifier,\n\t\t\t\t\t\t\t\tresolveIdentifier: resolveIdentifier,\n\t\t\t\t\t\t\t\tfinalizeLoad: finalizeLoad,\n\t\t\t\t\t\t\t\tmoduleInitializers: moduleInitializers,\n\t\t\t\t\t\t\t\tinitializedModules: initializedModules\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar exports = moduleInitializers[moduleIdentifier][1](module.require, module.exports, moduleInterface);\n\t\t\t\t\t\tif (\n\t\t\t\t\t\t\ttypeof moduleInterface.exports !== \"undefined\" &&\n\t\t\t\t\t\t\t(\n\t\t\t\t\t\t\t\ttypeof moduleInterface.exports !== \"object\" ||\n\t\t\t\t\t\t\t\tkeys(moduleInterface.exports).length !== 0\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t) {\n\t\t\t\t\t\t\tmodule.exports = moduleInterface.exports;\n\t\t\t\t\t\t} else\n\t\t\t\t\t\tif (typeof exports !== \"undefined\") {\n\t\t\t\t\t\t\tmodule.exports = exports;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else\n\t\t\t\t\tif (typeof moduleInitializers[moduleIdentifier][1] === \"string\") {\n\t\t\t\t\t\t// TODO: Use more optimal string encoding algorythm to reduce payload size?\n\t\t\t\t\t\tmodule.exports = decodeURIComponent(moduleInitializers[moduleIdentifier][1]);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmodule.exports = moduleInitializers[moduleIdentifier][1];\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\t\t/*DEBUG*/ module.getReport = function() {\n\t\t\t\t/*DEBUG*/ \tvar exportsCount = 0,\n\t\t\t\t/*DEBUG*/ \t\tkey;\n\t\t\t\t/*DEBUG*/ \tfor (key in module.exports) {\n\t\t\t\t/*DEBUG*/ \t\texportsCount++;\n\t\t\t\t/*DEBUG*/ \t}\n\t\t\t\t/*DEBUG*/ \treturn {\n\t\t\t\t/*DEBUG*/ \t\texports: exportsCount\n\t\t\t\t/*DEBUG*/ \t};\n\t\t\t\t/*DEBUG*/ };\n\n\t\t\t\treturn module;\n\t\t\t};\n\n\t\t\tpkg.load = function(moduleIdentifier, bundleIdentifier, loadedCallback) {\n\t\t\t\t// If module/bundle to be loaded asynchronously is already memoized we skip the load.\n\t\t\t\tif (moduleInitializers[moduleIdentifier]) {\n\t\t\t\t\treturn loadedCallback(null, pkg.require(moduleIdentifier).exports);\n\t\t\t\t}\n\t\t\t\tvar bundleSubPath = bundleIdentifier.substring(sandboxIdentifier.length);\n                load(\n                \t((!/^\\//.test(moduleIdentifier))?\"/\"+pkg.libPath:\"\") + moduleIdentifier,\n                \tpackageIdentifier,\n                \tbundleSubPath.replace(/\\.js$/g, \"\"),\n                \tfunction(err) {\n\t                \tif (err) return loadedCallback(err);\n\t                    loadedCallback(null, pkg.require(moduleIdentifier).exports);\n\t                }\n\t            );\n\t\t\t}\n\n\t\t\tpkg.require = function(moduleIdentifier) {\n\n\t\t\t\tif (moduleIdentifier) {\n\t                if (!/^\\//.test(moduleIdentifier)) {\n\t                    moduleIdentifier = \"/\" + ((moduleIdentifier.substring(0, pkg.libPath.length)===pkg.libPath)?\"\":pkg.libPath) + moduleIdentifier;\n\t                }\n\t\t\t\t\tmoduleIdentifier = packageIdentifier + moduleIdentifier;\n\t\t\t\t} else {\n\t\t\t\t\tmoduleIdentifier = pkg.main;\n\t\t\t\t}\n\n\t\t\t\tif (!initializedModules[moduleIdentifier]) {\n\t\t\t\t\t/*DEBUG*/ if (!moduleInitializers[moduleIdentifier]) {\n\t\t\t\t\t/*DEBUG*/ \tconsole.error(\"[pinf-loader-js]\", \"moduleInitializers\", moduleInitializers);\n\t\t\t\t\t/*DEBUG*/ \tthrow new Error(\"Module '\" + moduleIdentifier + \"' not found in sandbox '\" + sandbox.id + \"'!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\t(initializedModules[moduleIdentifier] = Module(moduleIdentifier, lastModule)).load();\n\t\t\t\t}\n\n\t\t\t\tvar loadingBundlesCallbacks;\n\t\t\t\tif (loadingBundles[moduleIdentifier]) {\n\t\t\t\t\tloadingBundlesCallbacks = loadingBundles[moduleIdentifier];\n\t\t\t\t\tdelete loadingBundles[moduleIdentifier];\n\t\t\t\t\tfor (var i=0 ; i<loadingBundlesCallbacks.length ; i++) {\n\t\t\t\t\t\tloadingBundlesCallbacks[i](null, sandbox);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn initializedModules[moduleIdentifier];\n\t\t\t}\n\n            pkg.require.id = function(moduleIdentifier) {\n                if (!/^\\//.test(moduleIdentifier)) {\n                    moduleIdentifier = \"/\" + pkg.libPath + moduleIdentifier;\n                }\n                return (((packageIdentifier !== \"\")?\"/\"+packageIdentifier+\"/\":\"\") + moduleIdentifier).replace(/\\/+/g, \"/\");\n            }\n\n\t\t\t/*DEBUG*/ pkg.getReport = function() {\n\t\t\t/*DEBUG*/ \treturn {\n\t\t\t/*DEBUG*/ \t\tmain: pkg.main,\n\t\t\t/*DEBUG*/ \t\tmappings: pkg.mappings,\n\t\t\t/*DEBUG*/ \t\tdirectories: pkg.directories,\n\t\t\t/*DEBUG*/ \t\tlibPath: pkg.libPath\n\t\t\t/*DEBUG*/ \t};\n\t\t\t/*DEBUG*/ }\n\n\t\t\tif (sandboxOptions.onInitPackage) {\n\t\t\t\tsandboxOptions.onInitPackage(pkg, sandbox, {\n\t\t\t\t\tnormalizeIdentifier: normalizeIdentifier,\n\t\t\t\t\tfinalizeLoad: finalizeLoad,\n\t\t\t\t\tmoduleInitializers: moduleInitializers,\n\t\t\t\t\tinitializedModules: initializedModules\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tpackages[packageIdentifier] = pkg;\n\n\t\t\treturn pkg;\n\t\t}\n\n\t\t// Get a module and initialize it (statically link its dependencies) if it is not already so\n\t\tsandbox.require = function(moduleIdentifier) {\n\t\t\treturn Package(\"\").require(moduleIdentifier).exports;\n\t\t}\n\n\t\t// Call the 'main' module of the program\n\t\tsandbox.boot = function() {\n\t\t\t/*DEBUG*/ if (typeof Package(\"\").main !== \"string\") {\n\t\t\t/*DEBUG*/ \tthrow new Error(\"No 'main' property declared in '/package.json' in sandbox '\" + sandbox.id + \"'!\");\n\t\t\t/*DEBUG*/ }\n\t\t\treturn sandbox.require(Package(\"\").main);\n\t\t};\n\n\t\t// Call the 'main' exported function of the main' module of the program\n\t\tsandbox.main = function() {\n\t\t\tvar exports = sandbox.boot();\n\t\t\treturn ((exports.main)?exports.main.apply(null, arguments):exports);\n\t\t};\n\n\t\t/*DEBUG*/ sandbox.getReport = function() {\n\t\t/*DEBUG*/ \tvar report = {\n\t\t/*DEBUG*/ \t\t\tbundles: {},\n\t\t/*DEBUG*/ \t\t\tpackages: {},\n\t\t/*DEBUG*/ \t\t\tmodules: {}\n\t\t/*DEBUG*/ \t\t},\n\t\t/*DEBUG*/ \t\tkey;\n\t\t/*DEBUG*/ \tfor (key in bundleIdentifiers) {\n\t\t/*DEBUG*/ \t\treport.bundles[key] = bundleIdentifiers[key];\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tfor (key in packages) {\n\t\t/*DEBUG*/ \t\treport.packages[key] = packages[key].getReport();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tfor (key in moduleInitializers) {\n\t\t/*DEBUG*/ \t\tif (initializedModules[key]) {\n\t\t/*DEBUG*/ \t\t\treport.modules[key] = initializedModules[key].getReport();\n\t\t/*DEBUG*/ \t\t} else {\n\t\t/*DEBUG*/ \t\t\treport.modules[key] = {};\n\t\t/*DEBUG*/ \t\t}\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \treturn report;\n\t\t/*DEBUG*/ }\n\t\t/*DEBUG*/ sandbox.reset = function() {\n\t\t/*DEBUG*/   moduleInitializers = {};\n\t\t/*DEBUG*/   initializedModules = {};\n\t\t/*DEBUG*/   bundleIdentifiers = {};\n\t\t/*DEBUG*/   packages = {};\n\t\t/*DEBUG*/   loadingBundles = {};\n\t\t/*DEBUG*/ }\n\n\t\tload(\".js\", \"\", \"\", loadedCallback);\n\n\t\treturn sandbox;\n\t};\n\n\n\t// The global `require` for the 'external' (to the loader) environment.\n\tvar Loader = function() {\n\n\t\tvar \n\t\t\t/*DEBUG*/ bundleIdentifiers = {},\n\t\t\tsandboxes = {};\n\n\t\tvar Require = function(bundle) {\n\n\t\t\t\t// Address a specific sandbox or currently loading sandbox if initial load.\n\t\t\t\tthis.bundle = function(uid, callback) {\n\t\t\t\t\t/*DEBUG*/ if (uid && bundleIdentifiers[uid]) {\n\t\t\t\t\t/*DEBUG*/ \tthrow new Error(\"You cannot split require.bundle(UID) calls where UID is constant!\");\n\t\t\t\t\t/*DEBUG*/ }\n\t\t\t\t\t/*DEBUG*/ bundleIdentifiers[uid] = true;\n\t\t\t\t\tvar moduleInitializers = {},\n\t\t\t\t\t\treq = new Require(uid);\n\t\t\t\t\tdelete req.bundle;\n\t\t\t\t\t// Store raw module in loading bundle\n\t\t\t\t\treq.memoize = function(moduleIdentifier, moduleInitializer, moduleMeta) {\n\t\t\t\t\t\tmoduleInitializers[moduleIdentifier] = [moduleInitializer, moduleMeta || {}];\n\t\t\t\t\t}\n\t\t\t\t\tcallback(req);\n\t\t\t\t\tloadedBundles.push([uid, moduleInitializers]);\n\t\t\t\t}\n\t\t\t};\n\n\t\tvar require = new Require();\n\n\t\t// TODO: @see URL_TO_SPEC\n\t\trequire.supports = [\n\t\t\t\"ucjs-pinf-0\"\n\t\t];\n\n\t\t// Create a new environment to memoize modules to.\n\t\t// If relative, the `programIdentifier` is resolved against the URI of the owning page (this is only for the global require).\n\t\trequire.sandbox = normalizeSandboxArguments(function(programIdentifier, options, loadedCallback, errorCallback) {\n\t\t\tvar sandboxIdentifier = programIdentifier.replace(/\\.js$/, \"\");\n\t\t\treturn sandboxes[sandboxIdentifier] = Sandbox(sandboxIdentifier, options, function(err, sandbox) {\n\t\t\t\tif (err) {\n\t\t\t\t\tif (errorCallback) return errorCallback(err);\n\t\t\t\t\tthrow err;\n\t\t\t\t}\n\t\t\t\tloadedCallback(sandbox);\n\t\t\t});\n\t\t});\n\t\t\n\t\t/*DEBUG*/ require.getReport = function() {\n\t\t/*DEBUG*/ \tvar report = {\n\t\t/*DEBUG*/ \t\t\tsandboxes: {}\n\t\t/*DEBUG*/ \t\t},\n\t\t/*DEBUG*/ \t\tkey;\n\t\t/*DEBUG*/ \tfor (key in sandboxes) {\n\t\t/*DEBUG*/ \t\treport.sandboxes[key] = sandboxes[key].getReport();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \treturn report;\n\t\t/*DEBUG*/ }\n\t\t/*DEBUG*/ require.reset = function() {\n\t\t/*DEBUG*/ \tfor (key in sandboxes) {\n\t\t/*DEBUG*/ \t\tsandboxes[key].reset();\n\t\t/*DEBUG*/ \t}\n\t\t/*DEBUG*/ \tsandboxes = {};\n\t\t/*DEBUG*/ \tbundleIdentifiers = {};\n\t\t/*DEBUG*/ \tloadedBundles = [];\n\t\t/*DEBUG*/ }\n\n\t\treturn require;\n\t}\n\n\t// Set `PINF` gloabl.\n\tglobal.PINF = PINF = Loader();\n\n\t// Export `require` for CommonJS if `module` and `exports` globals exists.\n\tif (typeof module === \"object\" && typeof exports === \"object\") {\n\t\tmodule.exports = PINF;\n\t}\n\n}(this));\n\n}",
              "bottom": "}"
            },
            "dependencies": {
              "static": {},
              "dynamic": {},
              "computed": false
            },
            "warnings": [],
            "errors": []
          },
          "/package.json": {
            "requireId": "/package.json",
            "memoizeId": "/package.json",
            "descriptor": {
              "dirpath": ".",
              "dirrealpath": "",
              "id": "",
              "lookupPaths": [
                "package.json",
                ".package.json"
              ],
              "descriptorPaths": [
                "package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "pinf-for-nodejs",
                  "version": "0.1.3",
                  "pm": "npm",
                  "publish": true,
                  "main": "lib/pinf.js",
                  "bin": {
                    "pinf": "./bin/pinf"
                  },
                  "dependencies": {
                    "fs-extra": "~0.6.4",
                    "pinf-loader-js": "~0.4.5",
                    "request": "~2.21.0",
                    "waitfor": "~0.1.3",
                    "deepmerge": "~0.2.7",
                    "commander": "~2.0.0",
                    "colors": "~0.6.1",
                    "pinf-primitives-js": "~0.1.0",
                    "pinf-it-package-insight": "~0.1.3",
                    "pinf-it-program-insight": "~0.1.0",
                    "deepcopy": "~0.3.1",
                    "require.async": "~0.1.1",
                    "send": "~0.1.4",
                    "pinf-it-bundler": "github.com/pinf-it/pinf-it-bundler/~0.1.1"
                  },
                  "devDependencies": {
                    "mocha": "~1.9.0",
                    "grunt": "~0.4.1",
                    "grunt-mocha": "~0.3.1",
                    "q": "~0.9.3",
                    "pinf-loader-js": "github.com/pinf/pinf-loader-js/~0.4.5"
                  },
                  "mappings": {
                    "pinf-it-bundler": "github.com/pinf-it/pinf-it-bundler/~0.1.1"
                  },
                  "devMappings": {
                    "pinf-loader-js": "github.com/pinf/pinf-loader-js/~0.4.5"
                  },
                  "require.async": {
                    "./lib/main.js": "./context"
                  },
                  "scripts": {
                    "test": "node_modules/.bin/mocha --reporter list test/*.js",
                    "build": "./bin/pinf bundle"
                  },
                  "exports": {
                    "bundles": {
                      "lib/pinf.js": "./lib/pinf.js",
                      "lib/main.js": "./lib/main.js",
                      "lib/loader.js": "./lib/loader.js"
                    }
                  },
                  "overrides": {
                    "./node_modules/request/node_modules/hawk/node_modules/boom": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/form-data": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    }
                  }
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "colors": "./node_modules/colors",
                      "commander": "./node_modules/commander",
                      "deepcopy": "./node_modules/deepcopy",
                      "deepmerge": "./node_modules/deepmerge",
                      "fs-extra": "./node_modules/fs-extra",
                      "grunt": "./node_modules/grunt",
                      "grunt-mocha": "./node_modules/grunt-mocha",
                      "mocha": "./node_modules/mocha",
                      "pinf-it-bundler": "./node_modules/pinf-it-bundler",
                      "pinf-it-package-insight": "./node_modules/pinf-it-package-insight",
                      "pinf-it-program-insight": "./node_modules/pinf-it-program-insight",
                      "pinf-loader-js": "./node_modules/pinf-loader-js",
                      "pinf-primitives-js": "./node_modules/pinf-primitives-js",
                      "q": "./node_modules/q",
                      "request": "./node_modules/request",
                      "require.async": "./node_modules/require.async",
                      "send": "./node_modules/send",
                      "waitfor": "./node_modules/waitfor"
                    }
                  },
                  "mappings": {
                    ".bin": "2ff3dd234eb25191da421162f8efcfb215189cf1-.bin",
                    "colors": "cea8853e485c16de5615a7a50d031a5dd03bc673-colors",
                    "commander": "a0c51c78acfea78e63228ffabdef2ea71bfd6eb0-commander",
                    "deepcopy": "11124220cd02b820fdc3ab7d0acdcfd08a720fbe-deepcopy",
                    "deepmerge": "1e29e18e148032301f32032281a983e3f4419e8a-deepmerge",
                    "fs-extra": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra",
                    "grunt": "4a0439821c09963702d3becb7bc455af3bede4cd-grunt",
                    "grunt-mocha": "94d3ae3548194d31bebe5729416cbbceef383a9a-grunt-mocha",
                    "mocha": "cc0e4bdb970b4c51a2be73182b12639aea627660-mocha",
                    "pinf-it-bundler": "d410d765c4a91b52828ad9d1eba8d92a9eb81b63-pinf-it-bundler",
                    "pinf-it-package-insight": "79c3886f38d246eca26d997a4cde1dc621d53b56-pinf-it-package-insight",
                    "pinf-it-program-insight": "4cbfcf3a6f76b102c8abe5ac9f4f68bc773ef413-pinf-it-program-insight",
                    "pinf-loader-js": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js",
                    "pinf-primitives-js": "cf11d4f040476e26b811c17d7a25673b6a6f6e86-pinf-primitives-js",
                    "q": "289ab28d99ade60eb35e118aa9a775aee509f57c-q",
                    "request": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request",
                    "require.async": "437ef8aee826325a41c701ca21e78f84f35ff9f1-require.async",
                    "send": "578e39eb720000db89052482057dd13216c8d2bf-send",
                    "waitfor": "416bf2c65cd8db6a197939f8a9c5b953245a0d2f-waitfor"
                  }
                },
                "package.json": {
                  "name": "pinf-for-nodejs",
                  "version": "0.1.3",
                  "pm": {
                    "install": "npm"
                  },
                  "dependencies": {
                    "required": {
                      "fs-extra": "~0.6.4",
                      "pinf-loader-js": "~0.4.5",
                      "request": "~2.21.0",
                      "waitfor": "~0.1.3",
                      "deepmerge": "~0.2.7",
                      "commander": "~2.0.0",
                      "colors": "~0.6.1",
                      "pinf-primitives-js": "~0.1.0",
                      "pinf-it-package-insight": "~0.1.3",
                      "pinf-it-program-insight": "~0.1.0",
                      "deepcopy": "~0.3.1",
                      "require.async": "~0.1.1",
                      "send": "~0.1.4",
                      "pinf-it-bundler": "github.com/pinf-it/pinf-it-bundler/~0.1.1"
                    },
                    "development": {
                      "mocha": "~1.9.0",
                      "grunt": "~0.4.1",
                      "grunt-mocha": "~0.3.1",
                      "q": "~0.9.3",
                      "pinf-loader-js": "github.com/pinf/pinf-loader-js/~0.4.5"
                    },
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "colors": "./node_modules/colors",
                      "commander": "./node_modules/commander",
                      "deepcopy": "./node_modules/deepcopy",
                      "deepmerge": "./node_modules/deepmerge",
                      "fs-extra": "./node_modules/fs-extra",
                      "grunt": "./node_modules/grunt",
                      "grunt-mocha": "./node_modules/grunt-mocha",
                      "mocha": "./node_modules/mocha",
                      "pinf-it-bundler": "./node_modules/pinf-it-bundler",
                      "pinf-it-package-insight": "./node_modules/pinf-it-package-insight",
                      "pinf-it-program-insight": "./node_modules/pinf-it-program-insight",
                      "pinf-loader-js": "./node_modules/pinf-loader-js",
                      "pinf-primitives-js": "./node_modules/pinf-primitives-js",
                      "q": "./node_modules/q",
                      "request": "./node_modules/request",
                      "require.async": "./node_modules/require.async",
                      "send": "./node_modules/send",
                      "waitfor": "./node_modules/waitfor"
                    }
                  },
                  "exports": {
                    "bin": {
                      "pinf": "./bin/pinf"
                    },
                    "scripts": {
                      "test": "node_modules/.bin/mocha --reporter list test/*.js",
                      "build": "./bin/pinf bundle"
                    },
                    "main": "./lib/pinf.js"
                  },
                  "overrides": {
                    "./node_modules/request/node_modules/hawk/node_modules/boom": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/form-data": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    }
                  },
                  "events": {
                    "publish": true
                  },
                  "require.async": {
                    "./lib/main.js": "./context"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    ".bin": "2ff3dd234eb25191da421162f8efcfb215189cf1-.bin",
                    "colors": "cea8853e485c16de5615a7a50d031a5dd03bc673-colors",
                    "commander": "a0c51c78acfea78e63228ffabdef2ea71bfd6eb0-commander",
                    "deepcopy": "11124220cd02b820fdc3ab7d0acdcfd08a720fbe-deepcopy",
                    "deepmerge": "1e29e18e148032301f32032281a983e3f4419e8a-deepmerge",
                    "fs-extra": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra",
                    "grunt": "4a0439821c09963702d3becb7bc455af3bede4cd-grunt",
                    "grunt-mocha": "94d3ae3548194d31bebe5729416cbbceef383a9a-grunt-mocha",
                    "mocha": "cc0e4bdb970b4c51a2be73182b12639aea627660-mocha",
                    "pinf-it-bundler": "d410d765c4a91b52828ad9d1eba8d92a9eb81b63-pinf-it-bundler",
                    "pinf-it-package-insight": "79c3886f38d246eca26d997a4cde1dc621d53b56-pinf-it-package-insight",
                    "pinf-it-program-insight": "4cbfcf3a6f76b102c8abe5ac9f4f68bc773ef413-pinf-it-program-insight",
                    "pinf-loader-js": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js",
                    "pinf-primitives-js": "cf11d4f040476e26b811c17d7a25673b6a6f6e86-pinf-primitives-js",
                    "q": "289ab28d99ade60eb35e118aa9a775aee509f57c-q",
                    "request": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request",
                    "require.async": "437ef8aee826325a41c701ca21e78f84f35ff9f1-require.async",
                    "send": "578e39eb720000db89052482057dd13216c8d2bf-send",
                    "waitfor": "416bf2c65cd8db6a197939f8a9c5b953245a0d2f-waitfor"
                  }
                }
              },
              "combined": {
                "name": "pinf-for-nodejs",
                "version": "0.1.3",
                "pm": {
                  "install": "npm"
                },
                "dependencies": {
                  "required": {
                    "fs-extra": "~0.6.4",
                    "pinf-loader-js": "~0.4.5",
                    "request": "~2.21.0",
                    "waitfor": "~0.1.3",
                    "deepmerge": "~0.2.7",
                    "commander": "~2.0.0",
                    "colors": "~0.6.1",
                    "pinf-primitives-js": "~0.1.0",
                    "pinf-it-package-insight": "~0.1.3",
                    "pinf-it-program-insight": "~0.1.0",
                    "deepcopy": "~0.3.1",
                    "require.async": "~0.1.1",
                    "send": "~0.1.4",
                    "pinf-it-bundler": "github.com/pinf-it/pinf-it-bundler/~0.1.1"
                  },
                  "development": {
                    "mocha": "~1.9.0",
                    "grunt": "~0.4.1",
                    "grunt-mocha": "~0.3.1",
                    "q": "~0.9.3",
                    "pinf-loader-js": "github.com/pinf/pinf-loader-js/~0.4.5"
                  },
                  "bundled": {
                    ".bin": "./node_modules/.bin",
                    "colors": "./node_modules/colors",
                    "commander": "./node_modules/commander",
                    "deepcopy": "./node_modules/deepcopy",
                    "deepmerge": "./node_modules/deepmerge",
                    "fs-extra": "./node_modules/fs-extra",
                    "grunt": "./node_modules/grunt",
                    "grunt-mocha": "./node_modules/grunt-mocha",
                    "mocha": "./node_modules/mocha",
                    "pinf-it-bundler": "./node_modules/pinf-it-bundler",
                    "pinf-it-package-insight": "./node_modules/pinf-it-package-insight",
                    "pinf-it-program-insight": "./node_modules/pinf-it-program-insight",
                    "pinf-loader-js": "./node_modules/pinf-loader-js",
                    "pinf-primitives-js": "./node_modules/pinf-primitives-js",
                    "q": "./node_modules/q",
                    "request": "./node_modules/request",
                    "require.async": "./node_modules/require.async",
                    "send": "./node_modules/send",
                    "waitfor": "./node_modules/waitfor"
                  }
                },
                "exports": {
                  "bin": {
                    "pinf": "./bin/pinf"
                  },
                  "scripts": {
                    "test": "node_modules/.bin/mocha --reporter list test/*.js",
                    "build": "./bin/pinf bundle"
                  },
                  "main": "./lib/pinf.js"
                },
                "overrides": {
                  "./node_modules/request/node_modules/hawk/node_modules/boom": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/form-data": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  }
                },
                "events": {
                  "publish": true
                },
                "require.async": {
                  "./lib/main.js": "./context"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  ".bin": "2ff3dd234eb25191da421162f8efcfb215189cf1-.bin",
                  "colors": "cea8853e485c16de5615a7a50d031a5dd03bc673-colors",
                  "commander": "a0c51c78acfea78e63228ffabdef2ea71bfd6eb0-commander",
                  "deepcopy": "11124220cd02b820fdc3ab7d0acdcfd08a720fbe-deepcopy",
                  "deepmerge": "1e29e18e148032301f32032281a983e3f4419e8a-deepmerge",
                  "fs-extra": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra",
                  "grunt": "4a0439821c09963702d3becb7bc455af3bede4cd-grunt",
                  "grunt-mocha": "94d3ae3548194d31bebe5729416cbbceef383a9a-grunt-mocha",
                  "mocha": "cc0e4bdb970b4c51a2be73182b12639aea627660-mocha",
                  "pinf-it-bundler": "d410d765c4a91b52828ad9d1eba8d92a9eb81b63-pinf-it-bundler",
                  "pinf-it-package-insight": "79c3886f38d246eca26d997a4cde1dc621d53b56-pinf-it-package-insight",
                  "pinf-it-program-insight": "4cbfcf3a6f76b102c8abe5ac9f4f68bc773ef413-pinf-it-program-insight",
                  "pinf-loader-js": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js",
                  "pinf-primitives-js": "cf11d4f040476e26b811c17d7a25673b6a6f6e86-pinf-primitives-js",
                  "q": "289ab28d99ade60eb35e118aa9a775aee509f57c-q",
                  "request": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request",
                  "require.async": "437ef8aee826325a41c701ca21e78f84f35ff9f1-require.async",
                  "send": "578e39eb720000db89052482057dd13216c8d2bf-send",
                  "waitfor": "416bf2c65cd8db6a197939f8a9c5b953245a0d2f-waitfor"
                }
              },
              "warnings": [
                [
                  "normalize",
                  "Property 'exports' was ignored",
                  "descriptor",
                  "package.json"
                ]
              ],
              "errors": [],
              "memoized": {
                "main": "/lib/pinf.js",
                "mappings": {
                  "fs-extra": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra",
                  "request": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request",
                  "pinf-loader-js": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js"
                },
                "dirpath": "."
              }
            },
            "wrapper": "json"
          },
          "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/package.json": {
            "requireId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/package.json",
            "memoizeId": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra",
              "dirrealpath": "node_modules/fs-extra",
              "id": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra",
              "lookupPaths": [
                "node_modules/fs-extra/package.json",
                "node_modules/fs-extra/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "fs-extra",
                  "version": "0.6.4",
                  "description": "fs-extra contains methods that aren't included in the vanilla Node.js fs package. Such as mkdir -p, cp -r, and rm -rf.",
                  "homepage": "https://github.com/jprichardson/node-fs-extra",
                  "repository": {
                    "type": "git",
                    "url": "https://github.com/jprichardson/node-fs-extra"
                  },
                  "keywords": [
                    "fs",
                    "file",
                    "file system",
                    "copy",
                    "directory",
                    "extra",
                    "mkdirp",
                    "mkdir",
                    "mkdirs",
                    "recursive",
                    "json",
                    "read",
                    "write",
                    "extra",
                    "delete",
                    "remove",
                    "touch",
                    "create",
                    "text",
                    "output"
                  ],
                  "author": {
                    "name": "JP Richardson",
                    "email": "jprichardson@gmail.com"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": "http://github.com/jprichardson/node-fs-extra/raw/master/LICENSE"
                    }
                  ],
                  "dependencies": {
                    "ncp": "~0.4.2",
                    "mkdirp": "0.3.x",
                    "jsonfile": "~1.0.1",
                    "rimraf": "~2.2.0"
                  },
                  "devDependencies": {
                    "mocha": "*",
                    "path-extra": "0.0.x",
                    "testutil": "~0.5.0"
                  },
                  "main": "./lib/index",
                  "scripts": {
                    "test": "mocha test"
                  },
                  "readme": "\nNode.js: fs-extra\n=================\n\n[![build status](https://secure.travis-ci.org/jprichardson/node-fs-extra.png)](http://travis-ci.org/jprichardson/node-fs-extra)\n\nThis module adds a few extra file system methods that aren't included in the native `fs` module. It is a drop in replacement for `fs`.\n\n\n\nWhy?\n----\n\nI got tired of including `mkdirp`, `rimraf`, and `cp -r` in most of my projects. \n\n\n\n\nInstallation\n------------\n\n    npm install --save fs-extra\n\n\n\nUsage\n-----\n\nDrop in replacement for native `fs`.\n\n\n```javascript\nvar fs = require('fs-extra');\n```\n\n\n\nMethods\n-------\n\n**NOTE:** You can still use the native Node.js methods. They are copied over to `fs-extra`.\n\n\n### copy(src, dest, callback)\n\nCopy a file or directory. The directory can have contents. Like `cp -r`. There isn't a synchronous version implemented yet.\n\nSync: (none)\n\n\nExamples:\n\n```javascript\nvar fs = require('fs-extra');\n\nfs.copy('/tmp/myfile', '/tmp/mynewfile', function(err){\n  if (err) {\n    console.error(err);\n  }\n  else {\n    console.log(\"success!\")\n  }\n}); //copies file\n\nfs.copy('/tmp/mydir', '/tmp/mynewdir', function(err){\n  if (err) {\n    console.error(err);\n  }\n  else {\n    console.log(\"success!\")\n  }\n}); //copies directory, even if it has subdirectories or files\n```\n\n\n### createFile(file, callback) \n\nCreates a file. If the file that is requested to be created is in directories that do not exist, these directories are created. If the file already exists, it is **NOT MODIFIED**.\n\nSync: `createFileSync()`\n\n\nExample:\n\n```javascript\nvar fs = require('fs-extra')\n  , file = '/tmp/this/path/does/not/exist/file.txt'\n\nfs.createFile(file, function(err) {\n  console.log(err); //null\n\n  //file has now been created, including the directory it is to be placed in\n})\n```\n\n\n\n### mkdirs(dir, callback) \n\nCreates a directory. If the parent hierarchy doesn't exist, it's created. Like `mkdir -p`.\n\nAlias: `mkdirp()`\n\nSync: `mkdirsSync()` / `mkdirpSync()`\n\n\nExamples:\n\n```javascript\nvar fs = require('fs-extra');\n\nfs.mkdirs('/tmp/some/long/path/that/prob/doesnt/exist', function(err){\n  if (err) {\n    console.error(err);\n  }\n  else {\n    console.log(\"success!\")\n  }\n});\n\nfs.mkdirsSync('/tmp/another/path');\n```\n\n\n### outputFile(file, data, callback)\n\nAlmost the same as `writeFile`, except that if the directory does not exist, it's created.\n\nSync: `outputFileSync()`\n\n\nExample:\n\n```javascript\nvar fs = require('fs-extra')\n  , file = '/tmp/this/path/does/not/exist/file.txt'\n\nfs.outputFile(file, 'hello!', function(err) {\n  console.log(err); //null\n\n  fs.readFile(file, 'utf8', function(err, data) {\n    console.log(data); //hello!\n  })\n})\n```\n\n\n\n### outputJson(file, data, callback)\n\nAlmost the same as `writeJson`, except that if the directory does not exist, it's created.\n\nAlias: `outputJSON()\n\nSync: `outputJsonSync()`, `outputJSONSync()`\n\n\nExample:\n\n```javascript\nvar fs = require('fs-extra')\n  , file = '/tmp/this/path/does/not/exist/file.txt'\n\nfs.outputJson(file, {name: 'JP'}, function(err) {\n  console.log(err); //null\n\n  fs.readJson(file, function(err, data) {\n    console.log(data.name); //'JP\n  })\n})\n```\n\n\n\n### readJson(file, callback) \n\nReads a JSON file and then parses it into an object.\n\nAlias: `readJSON()`\n\nSync: `readJsonSync()`, `readJSONSync()`\n\n\nExample:\n\n```javascript\nvar fs = require('fs-extra');\n\nfs.readJson('./package.json', function(err, packageObj) {\n  console.log(packageObj.version); //0.1.3\n});\n```\n\n\n### remove(dir, callback)\n\nRemoves a file or directory. The directory can have contents. Like `rm -rf`.\n\nAlias: `delete()`\n\nSync: `removeSync()` / `deleteSync()`\n\n\nExamples:\n\n```javascript\nvar fs = require('fs-extra');\n\nfs.remove('/tmp/myfile', function(err){\n  if (err) {\n    console.error(err);\n  }\n  else {\n    console.log(\"success!\")\n  }\n});\n\nfs.removeSync('/home/jprichardson'); //I just deleted my entire HOME directory. \n```\n\n\n\n### writeJson(file, object, callback) \n\nWrites an object to a JSON file.\n\nAlias: `writeJSON()`\n\nSync: `writeJsonSync()`, `writeJSONSync()`\n\nExample:\n\n```javascript\nvar fs = require('fs-extra');\nfs.writeJson('./package.json', {name: 'fs-extra'}, function(err){\n  console.log(err);\n});\n```\n\n\n\nRoadmap to 1.0.0\n-----------------\n\nThis contains items that I'm considering doing. I'd love community feedback.\n\n* File system walker. I really like this one: https://github.com/daaku/nodejs-walker ... this might be adding too much. Thoughts?\n* File/directory tree watcher. There are quite a few. ... this also might be adding too much. Thoughts?\n* Method to move files.\n* Copy sync.\n* Thinking about moving `rimraf`, `ncp`, and `mkdirps` code into this library. I'd like fs-extra to be a stable library that module authors\ncan depend upon. A bunch of other dependencies kinda sucks for modules/libraries. (I'm leaning against this now.)\n* Change documentation to use the `fse` prefix instead of `fs`. This may encourage people to start using `fse` as a prefix and hence make their code clearer that they're not using the native `fs`. I'm very undecided on this one since `fs-extra` is a drop in replacement for the native `fs`. (I'm leaning against this now.)\n\n\n\nNaming\n------\n\nI put a lot of thought into the naming of these function. Inspired by @coolaj86's request. So he deserves much of the credit for raising the issue. See discussion(s) here:\n\n* https://github.com/jprichardson/node-fs-extra/issues/2\n* https://github.com/flatiron/utile/issues/11\n* https://github.com/ryanmcgrath/wrench-js/issues/29\n* https://github.com/substack/node-mkdirp/issues/17\n\nFirst, I believe that in as many cases as possible, the [Node.js naming schemes](http://nodejs.org/api/fs.html) should be chosen. However, there are problems with the Node.js own naming schemes.\n\nFor example, `fs.readFile()` and `fs.readdir()`: the **F** is capitalized in *File* and the **d** is not capitalized in *dir*. Perhaps a bit pedantic, but they should still be consistent. Also, Node.js has chosen a lot of POSIX naming schemes, which I believe is great. See: `fs.mkdir()`, `fs.rmdir()`, `fs.chown()`, etc.\n\nWe have a dilemma though. How do you consistently name methods that perform the following POSIX commands: `cp`, `cp -r`, `mkdir -p`, and `rm -rf`?\n\nMy perspective: when in doubt, err on the side of simplicity. Consider that for a moment. A directory is just a hierarchical grouping of directories and files. So when you want to copy it or remove it, in most cases you'll want to copy or remove all of its contents. When you want to create a directory, if the directory that it's suppose to be contained in does not exist, then in most cases you'll want to create that too. \n\nSo, if you want to remove a file or a directory regardless of whether it has contents, just call `fs.remove(path)` or its alias `fs.delete(path)`. If you want to copy a file or a directory whether it has contents, just call `fs.copy(source, destination)`. If you want to create a directory regardless of whether its parent directories exist, just call `fs.mkdirs(path)` or `fs.mkdirp(path)`. \n\n\n\nContributors\n-------------\n- [JP Richardson](https://github.com/jprichardson)\n- [Mike McNeil](https://github.com/mikermcneil)\n- [Ian Crowther](https://github.com/iancrowther)\n- [Stephen Mathieson](https://github.com/stephenmathieson)\n- `<your name here>`\n\n\n\n\nLicense\n-------\n\n\nLicensed under MIT\n\nCopyright (c) 2011-2013 JP Richardson\n\n[1]: http://nodejs.org/docs/latest/api/fs.html \n\n\n[jsonfile]: https://github.com/jprichardson/node-jsonfile\n\n\n[aboutjp]: http://about.me/jprichardson\n[twitter]: http://twitter.com/jprichardson\n[procbits]: http://procbits.com\n[gitpilot]: http://gitpilot.com\n\n\n\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/jprichardson/node-fs-extra/issues"
                  },
                  "_id": "fs-extra@0.6.4",
                  "_from": "fs-extra@~0.6.4"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "jsonfile": "./node_modules/jsonfile",
                      "mkdirp": "./node_modules/mkdirp",
                      "ncp": "./node_modules/ncp",
                      "rimraf": "./node_modules/rimraf"
                    }
                  },
                  "mappings": {
                    ".bin": "224195cf753a407183b98beee52753ad91bdd329-.bin",
                    "jsonfile": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile",
                    "mkdirp": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp",
                    "ncp": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp",
                    "rimraf": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf"
                  }
                },
                "package.json": {
                  "name": "fs-extra",
                  "description": "fs-extra contains methods that aren't included in the vanilla Node.js fs package. Such as mkdir -p, cp -r, and rm -rf.",
                  "version": "0.6.4",
                  "locator": {
                    "pointer": "~0.6.4"
                  },
                  "homepage": "https://github.com/jprichardson/node-fs-extra",
                  "social": {
                    "bugs": {
                      "url": "https://github.com/jprichardson/node-fs-extra/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "https://github.com/jprichardson/node-fs-extra"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "ncp": "~0.4.2",
                      "mkdirp": "0.3.x",
                      "jsonfile": "~1.0.1",
                      "rimraf": "~2.2.0"
                    },
                    "development": {
                      "mocha": "*",
                      "path-extra": "0.0.x",
                      "testutil": "~0.5.0"
                    },
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "jsonfile": "./node_modules/jsonfile",
                      "mkdirp": "./node_modules/mkdirp",
                      "ncp": "./node_modules/ncp",
                      "rimraf": "./node_modules/rimraf"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "mocha test"
                    },
                    "main": "./lib/index.js"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": "http://github.com/jprichardson/node-fs-extra/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "fs",
                    "file",
                    "file system",
                    "copy",
                    "directory",
                    "extra",
                    "mkdirp",
                    "mkdir",
                    "mkdirs",
                    "recursive",
                    "json",
                    "read",
                    "write",
                    "extra",
                    "delete",
                    "remove",
                    "touch",
                    "create",
                    "text",
                    "output"
                  ],
                  "contributors": [
                    {
                      "name": "JP Richardson",
                      "email": "jprichardson@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    ".bin": "224195cf753a407183b98beee52753ad91bdd329-.bin",
                    "jsonfile": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile",
                    "mkdirp": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp",
                    "ncp": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp",
                    "rimraf": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf"
                  }
                }
              },
              "combined": {
                "name": "fs-extra",
                "description": "fs-extra contains methods that aren't included in the vanilla Node.js fs package. Such as mkdir -p, cp -r, and rm -rf.",
                "version": "0.6.4",
                "locator": {
                  "pointer": "~0.6.4"
                },
                "homepage": "https://github.com/jprichardson/node-fs-extra",
                "social": {
                  "bugs": {
                    "url": "https://github.com/jprichardson/node-fs-extra/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "https://github.com/jprichardson/node-fs-extra"
                  }
                ],
                "dependencies": {
                  "required": {
                    "ncp": "~0.4.2",
                    "mkdirp": "0.3.x",
                    "jsonfile": "~1.0.1",
                    "rimraf": "~2.2.0"
                  },
                  "development": {
                    "mocha": "*",
                    "path-extra": "0.0.x",
                    "testutil": "~0.5.0"
                  },
                  "bundled": {
                    ".bin": "./node_modules/.bin",
                    "jsonfile": "./node_modules/jsonfile",
                    "mkdirp": "./node_modules/mkdirp",
                    "ncp": "./node_modules/ncp",
                    "rimraf": "./node_modules/rimraf"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "mocha test"
                  },
                  "main": "./lib/index.js"
                },
                "licenses": [
                  {
                    "type": "MIT",
                    "url": "http://github.com/jprichardson/node-fs-extra/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "fs",
                  "file",
                  "file system",
                  "copy",
                  "directory",
                  "extra",
                  "mkdirp",
                  "mkdir",
                  "mkdirs",
                  "recursive",
                  "json",
                  "read",
                  "write",
                  "extra",
                  "delete",
                  "remove",
                  "touch",
                  "create",
                  "text",
                  "output"
                ],
                "contributors": [
                  {
                    "name": "JP Richardson",
                    "email": "jprichardson@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  ".bin": "224195cf753a407183b98beee52753ad91bdd329-.bin",
                  "jsonfile": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile",
                  "mkdirp": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp",
                  "ncp": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp",
                  "rimraf": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "b98063a15c6bafaefa93c7f701af192d69a9efd8-fs-extra/lib/index.js",
                "mappings": {
                  "jsonfile": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile",
                  "mkdirp": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp",
                  "ncp": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp",
                  "rimraf": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf"
                },
                "dirpath": "node_modules/fs-extra"
              }
            },
            "wrapper": "json"
          },
          "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/package.json": {
            "requireId": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/package.json",
            "memoizeId": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra/node_modules/jsonfile",
              "dirrealpath": "node_modules/fs-extra/node_modules/jsonfile",
              "id": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile",
              "lookupPaths": [
                "node_modules/fs-extra/node_modules/jsonfile/package.json",
                "node_modules/fs-extra/node_modules/jsonfile/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/node_modules/jsonfile/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "jsonfile",
                  "version": "1.0.1",
                  "description": "Easily read/write JSON files.",
                  "repository": {
                    "type": "git",
                    "url": "git@github.com:jprichardson/node-jsonfile.git"
                  },
                  "keywords": [],
                  "author": {
                    "name": "JP Richardson",
                    "email": "jprichardson@gmail.com"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": ""
                    }
                  ],
                  "dependencies": {},
                  "devDependencies": {
                    "testutil": "~0.5.1",
                    "mocha": "*"
                  },
                  "main": "./lib/jsonfile.js",
                  "scripts": {
                    "test": "mocha test"
                  },
                  "readme": "[![build status](https://secure.travis-ci.org/jprichardson/node-jsonfile.png)](http://travis-ci.org/jprichardson/node-jsonfile)\n\nNode.js - jsonfile\n================\n\nEasily read/write JSON files. \n\n\nWhy?\n----\n\nWriting `JSON.stringify()` and then `fs.writeFile()` and `JSON.parse()` with `fs.readFile()` enclosed in `try/catch` blocks became annoying.\n\n\n\nInstallation\n------------\n\n    npm install jsonfile --save\n\n\n\nAPI\n---\n\n### readFile()\n\n```javascript\nvar jf = require('jsonfile')\n  , util = require('util');\n\nvar file = '/tmp/data.json';\njs.readFile(file, function(err, obj) {\n  console.log(util.inspect(obj)); \n});\n```\n\n\n### readFileSync()\n\n```javascript\nvar jf = require('jsonfile')\n  , util = require('util');\n\nvar file = '/tmp/data.json';\n\nconsole.log(util.inspect(jf.readFileSync(file)));\n```\n\n\n### writeFile()\n\n```javascript\nvar jf = require('jsonfile')\n\nvar file = '/tmp/data.json';\nvar obj = {name: 'JP'};\n\njf.writeFile(file, obj, function(err) {\n  console.log(err);\n})\n```\n\n### writeFileSync()\n\n```javascript\nvar jf = require('jsonfile')\n\nvar file = '/tmp/data.json';\nvar obj = {name: 'JP'};\n\njf.writeFileSync(file, obj);\n```\n\n\n### spaces\n\nNumber of spaces to indent JSON files. \n\n**default:** 2\n\n```\nvar jf = require('jsonfile');\n\njf.spaces = 4;\n\nvar file = '/tmp/data.json';\nvar obj = {name: 'JP'};\n\njf.writeFile(file, obj, function(err) { //json file has four space indenting now\n  console.log(err);\n});\n```\n\n\nLicense\n-------\n\n(MIT License)\n\nCopyright 2012-2013, JP Richardson  <jprichardson@gmail.com>\n\n\n[aboutjp]: http://about.me/jprichardson\n[twitter]: http://twitter.com/jprichardson\n[procbits]: http://procbits.com\n\n\n\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/jprichardson/node-jsonfile/issues"
                  },
                  "_id": "jsonfile@1.0.1",
                  "_from": "jsonfile@~1.0.1"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "jsonfile",
                  "description": "Easily read/write JSON files.",
                  "version": "1.0.1",
                  "locator": {
                    "pointer": "~1.0.1"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/jprichardson/node-jsonfile/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git@github.com:jprichardson/node-jsonfile.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "testutil": "~0.5.1",
                      "mocha": "*"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "mocha test"
                    },
                    "main": "./lib/jsonfile.js"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": ""
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "JP Richardson",
                      "email": "jprichardson@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "jsonfile",
                "description": "Easily read/write JSON files.",
                "version": "1.0.1",
                "locator": {
                  "pointer": "~1.0.1"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/jprichardson/node-jsonfile/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git@github.com:jprichardson/node-jsonfile.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "testutil": "~0.5.1",
                    "mocha": "*"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "mocha test"
                  },
                  "main": "./lib/jsonfile.js"
                },
                "licenses": [
                  {
                    "type": "MIT",
                    "url": ""
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "JP Richardson",
                    "email": "jprichardson@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "d5ba5d20168aa9175f55feda3f60aab1a6ace818-jsonfile/lib/jsonfile.js",
                "dirpath": "node_modules/fs-extra/node_modules/jsonfile"
              }
            },
            "wrapper": "json"
          },
          "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/package.json": {
            "requireId": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/package.json",
            "memoizeId": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra/node_modules/mkdirp",
              "dirrealpath": "node_modules/fs-extra/node_modules/mkdirp",
              "id": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp",
              "lookupPaths": [
                "node_modules/fs-extra/node_modules/mkdirp/package.json",
                "node_modules/fs-extra/node_modules/mkdirp/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/node_modules/mkdirp/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "mkdirp",
                  "description": "Recursively mkdir, like `mkdir -p`",
                  "version": "0.3.5",
                  "author": {
                    "name": "James Halliday",
                    "email": "mail@substack.net",
                    "url": "http://substack.net"
                  },
                  "main": "./index",
                  "keywords": [
                    "mkdir",
                    "directory"
                  ],
                  "repository": {
                    "type": "git",
                    "url": "http://github.com/substack/node-mkdirp.git"
                  },
                  "scripts": {
                    "test": "tap test/*.js"
                  },
                  "devDependencies": {
                    "tap": "~0.4.0"
                  },
                  "license": "MIT",
                  "readme": "# mkdirp\n\nLike `mkdir -p`, but in node.js!\n\n[![build status](https://secure.travis-ci.org/substack/node-mkdirp.png)](http://travis-ci.org/substack/node-mkdirp)\n\n# example\n\n## pow.js\n\n```js\nvar mkdirp = require('mkdirp');\n    \nmkdirp('/tmp/foo/bar/baz', function (err) {\n    if (err) console.error(err)\n    else console.log('pow!')\n});\n```\n\nOutput\n\n```\npow!\n```\n\nAnd now /tmp/foo/bar/baz exists, huzzah!\n\n# methods\n\n```js\nvar mkdirp = require('mkdirp');\n```\n\n## mkdirp(dir, mode, cb)\n\nCreate a new directory and any necessary subdirectories at `dir` with octal\npermission string `mode`.\n\nIf `mode` isn't specified, it defaults to `0777 & (~process.umask())`.\n\n`cb(err, made)` fires with the error or the first directory `made`\nthat had to be created, if any.\n\n## mkdirp.sync(dir, mode)\n\nSynchronously create a new directory and any necessary subdirectories at `dir`\nwith octal permission string `mode`.\n\nIf `mode` isn't specified, it defaults to `0777 & (~process.umask())`.\n\nReturns the first directory that had to be created, if any.\n\n# install\n\nWith [npm](http://npmjs.org) do:\n\n```\nnpm install mkdirp\n```\n\n# license\n\nMIT\n",
                  "readmeFilename": "readme.markdown",
                  "bugs": {
                    "url": "https://github.com/substack/node-mkdirp/issues"
                  },
                  "_id": "mkdirp@0.3.5",
                  "_from": "mkdirp@0.3.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "mkdirp",
                  "description": "Recursively mkdir, like `mkdir -p`",
                  "version": "0.3.5",
                  "locator": {
                    "pointer": "0.3.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/substack/node-mkdirp/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "http://github.com/substack/node-mkdirp.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "tap": "~0.4.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "tap test/*.js"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    "MIT"
                  ],
                  "files": {
                    "readme": "./readme.markdown"
                  },
                  "keywords": [
                    "mkdir",
                    "directory"
                  ],
                  "contributors": [
                    {
                      "name": "James Halliday",
                      "email": "mail@substack.net",
                      "url": "http://substack.net"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "mkdirp",
                "description": "Recursively mkdir, like `mkdir -p`",
                "version": "0.3.5",
                "locator": {
                  "pointer": "0.3.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/substack/node-mkdirp/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "http://github.com/substack/node-mkdirp.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "tap": "~0.4.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "tap test/*.js"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  "MIT"
                ],
                "files": {
                  "readme": "./readme.markdown"
                },
                "keywords": [
                  "mkdir",
                  "directory"
                ],
                "contributors": [
                  {
                    "name": "James Halliday",
                    "email": "mail@substack.net",
                    "url": "http://substack.net"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "693ec9cb1f2f61428c63e9cd17e57775f4df0f74-mkdirp/index.js",
                "dirpath": "node_modules/fs-extra/node_modules/mkdirp"
              }
            },
            "wrapper": "json"
          },
          "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/package.json": {
            "requireId": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/package.json",
            "memoizeId": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra/node_modules/ncp",
              "dirrealpath": "node_modules/fs-extra/node_modules/ncp",
              "id": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp",
              "lookupPaths": [
                "node_modules/fs-extra/node_modules/ncp/package.json",
                "node_modules/fs-extra/node_modules/ncp/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/node_modules/ncp/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "ncp",
                  "version": "0.4.2",
                  "author": {
                    "name": "AvianFlu",
                    "email": "charlie@charlieistheman.com"
                  },
                  "description": "Asynchronous recursive file copy utility.",
                  "bin": {
                    "ncp": "./bin/ncp"
                  },
                  "devDependencies": {
                    "vows": "0.6.x",
                    "rimraf": "1.0.x",
                    "read-dir-files": "0.0.x"
                  },
                  "main": "./lib/ncp.js",
                  "repository": {
                    "type": "git",
                    "url": "https://github.com/AvianFlu/ncp.git"
                  },
                  "keywords": [
                    "cli",
                    "copy"
                  ],
                  "license": "MIT",
                  "engine": {
                    "node": ">=0.4"
                  },
                  "scripts": {
                    "test": "vows --isolate --spec"
                  },
                  "readme": "# ncp - Asynchronous recursive file & directory copying\n\n[![Build Status](https://secure.travis-ci.org/AvianFlu/ncp.png)](http://travis-ci.org/AvianFlu/ncp)\n\nThink `cp -r`, but pure node, and asynchronous.  `ncp` can be used both as a CLI tool and programmatically.\n\n## Command Line usage\n\nUsage is simple: `ncp [source] [dest] [--limit=concurrency limit]\n[--filter=filter] --stopOnErr`\n\nThe 'filter' is a Regular Expression - matched files will be copied.\n\nThe 'concurrency limit' is an integer that represents how many pending file system requests `ncp` has at a time.\n\n'stopOnErr' is a boolean flag that will tell `ncp` to stop immediately if any\nerrors arise, rather than attempting to continue while logging errors.\n\nIf there are no errors, `ncp` will output `done.` when complete.  If there are errors, the error messages will be logged to `stdout` and to `./ncp-debug.log`, and the copy operation will attempt to continue.\n\n## Programmatic usage\n\nProgrammatic usage of `ncp` is just as simple.  The only argument to the completion callback is a possible error.  \n\n```javascript\nvar ncp = require('ncp').ncp;\n\nncp.limit = 16;\n\nncp(source, destination, function (err) {\n if (err) {\n   return console.error(err);\n }\n console.log('done!');\n});\n```\n\nYou can also call ncp like `ncp(source, destination, options, callback)`. \n`options` should be a dictionary. Currently, such options are available:\n\n  * `options.filter` - a `RegExp` instance, against which each file name is\n  tested to determine whether to copy it or not, or a function taking single\n  parameter: copied file name, returning `true` or `false`, determining\n  whether to copy file or not.\n\n  * `options.transform` - a function: `function (read, write) { read.pipe(write) }`\n  used to apply streaming transforms while copying.\n\n  * `options.clobber` - boolean=true. if set to false, `ncp` will not overwrite \n  destination files that already exist.\n\nPlease open an issue if any bugs arise.  As always, I accept (working) pull requests, and refunds are available at `/dev/null`.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/AvianFlu/ncp/issues"
                  },
                  "_id": "ncp@0.4.2",
                  "_from": "ncp@~0.4.2"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "ncp",
                  "description": "Asynchronous recursive file copy utility.",
                  "version": "0.4.2",
                  "locator": {
                    "pointer": "~0.4.2"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/AvianFlu/ncp/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "https://github.com/AvianFlu/ncp.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "vows": "0.6.x",
                      "rimraf": "1.0.x",
                      "read-dir-files": "0.0.x"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.4"
                    }
                  },
                  "exports": {
                    "bin": {
                      "ncp": "./bin/ncp"
                    },
                    "scripts": {
                      "test": "vows --isolate --spec"
                    },
                    "main": "./lib/ncp.js"
                  },
                  "licenses": [
                    "MIT"
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "cli",
                    "copy"
                  ],
                  "contributors": [
                    {
                      "name": "AvianFlu",
                      "email": "charlie@charlieistheman.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "ncp",
                "description": "Asynchronous recursive file copy utility.",
                "version": "0.4.2",
                "locator": {
                  "pointer": "~0.4.2"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/AvianFlu/ncp/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "https://github.com/AvianFlu/ncp.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "vows": "0.6.x",
                    "rimraf": "1.0.x",
                    "read-dir-files": "0.0.x"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.4"
                  }
                },
                "exports": {
                  "bin": {
                    "ncp": "./bin/ncp"
                  },
                  "scripts": {
                    "test": "vows --isolate --spec"
                  },
                  "main": "./lib/ncp.js"
                },
                "licenses": [
                  "MIT"
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "cli",
                  "copy"
                ],
                "contributors": [
                  {
                    "name": "AvianFlu",
                    "email": "charlie@charlieistheman.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "c99227b03d285ab9292c0748af53c56ffc9ac859-ncp/lib/ncp.js",
                "dirpath": "node_modules/fs-extra/node_modules/ncp"
              }
            },
            "wrapper": "json"
          },
          "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/package.json": {
            "requireId": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/package.json",
            "memoizeId": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra/node_modules/rimraf",
              "dirrealpath": "node_modules/fs-extra/node_modules/rimraf",
              "id": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf",
              "lookupPaths": [
                "node_modules/fs-extra/node_modules/rimraf/package.json",
                "node_modules/fs-extra/node_modules/rimraf/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/node_modules/rimraf/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "rimraf",
                  "version": "2.2.2",
                  "main": "rimraf.js",
                  "description": "A deep deletion module for node (like `rm -rf`)",
                  "author": {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me/"
                  },
                  "license": {
                    "type": "MIT",
                    "url": "https://github.com/isaacs/rimraf/raw/master/LICENSE"
                  },
                  "optionalDependencies": {
                    "graceful-fs": "~2"
                  },
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/isaacs/rimraf.git"
                  },
                  "scripts": {
                    "test": "cd test && bash run.sh"
                  },
                  "bin": {
                    "rimraf": "./bin.js"
                  },
                  "contributors": [
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me/"
                    },
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me"
                    },
                    {
                      "name": "Wayne Larsen",
                      "email": "wayne@larsen.st",
                      "url": "http://github.com/wvl"
                    },
                    {
                      "name": "ritch",
                      "email": "skawful@gmail.com"
                    },
                    {
                      "name": "Marcel Laverdet"
                    },
                    {
                      "name": "Yosef Dinerstein",
                      "email": "yosefd@microsoft.com"
                    }
                  ],
                  "readme": "A `rm -rf` for node.\n\nInstall with `npm install rimraf`, or just drop rimraf.js somewhere.\n\n## API\n\n`rimraf(f, callback)`\n\nThe callback will be called with an error if there is one.  Certain\nerrors are handled for you:\n\n* `EBUSY` -  rimraf will back off a maximum of opts.maxBusyTries times\n  before giving up.\n* `EMFILE` - If too many file descriptors get opened, rimraf will\n  patiently wait until more become available.\n\n\n## rimraf.sync\n\nIt can remove stuff synchronously, too.  But that's not so good.  Use\nthe async API.  It's better.\n\n## CLI\n\nIf installed with `npm install rimraf -g` it can be used as a global\ncommand `rimraf <path>` which is useful for cross platform support.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/isaacs/rimraf/issues"
                  },
                  "dependencies": {
                    "graceful-fs": "~2"
                  },
                  "_id": "rimraf@2.2.2",
                  "_from": "rimraf@~2.2.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "graceful-fs": "./node_modules/graceful-fs"
                    }
                  },
                  "mappings": {
                    "graceful-fs": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs"
                  }
                },
                "package.json": {
                  "name": "rimraf",
                  "description": "A deep deletion module for node (like `rm -rf`)",
                  "version": "2.2.2",
                  "locator": {
                    "pointer": "~2.2.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/isaacs/rimraf/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/isaacs/rimraf.git"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "graceful-fs": "~2"
                    },
                    "optional": {
                      "graceful-fs": "~2"
                    },
                    "bundled": {
                      "graceful-fs": "./node_modules/graceful-fs"
                    }
                  },
                  "exports": {
                    "bin": {
                      "rimraf": "./bin.js"
                    },
                    "scripts": {
                      "test": "cd test && bash run.sh"
                    },
                    "main": "./rimraf.js"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": "https://github.com/isaacs/rimraf/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me/"
                    },
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me"
                    },
                    {
                      "name": "Wayne Larsen",
                      "email": "wayne@larsen.st",
                      "url": "http://github.com/wvl"
                    },
                    {
                      "name": "ritch",
                      "email": "skawful@gmail.com"
                    },
                    {
                      "name": "Marcel Laverdet"
                    },
                    {
                      "name": "Yosef Dinerstein",
                      "email": "yosefd@microsoft.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "graceful-fs": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs"
                  }
                }
              },
              "combined": {
                "name": "rimraf",
                "description": "A deep deletion module for node (like `rm -rf`)",
                "version": "2.2.2",
                "locator": {
                  "pointer": "~2.2.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/isaacs/rimraf/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/isaacs/rimraf.git"
                  }
                ],
                "dependencies": {
                  "required": {
                    "graceful-fs": "~2"
                  },
                  "optional": {
                    "graceful-fs": "~2"
                  },
                  "bundled": {
                    "graceful-fs": "./node_modules/graceful-fs"
                  }
                },
                "exports": {
                  "bin": {
                    "rimraf": "./bin.js"
                  },
                  "scripts": {
                    "test": "cd test && bash run.sh"
                  },
                  "main": "./rimraf.js"
                },
                "licenses": [
                  {
                    "type": "MIT",
                    "url": "https://github.com/isaacs/rimraf/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me/"
                  },
                  {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me"
                  },
                  {
                    "name": "Wayne Larsen",
                    "email": "wayne@larsen.st",
                    "url": "http://github.com/wvl"
                  },
                  {
                    "name": "ritch",
                    "email": "skawful@gmail.com"
                  },
                  {
                    "name": "Marcel Laverdet"
                  },
                  {
                    "name": "Yosef Dinerstein",
                    "email": "yosefd@microsoft.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "graceful-fs": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "16117a71d212e842209fc0336b7b2cf0572a5023-rimraf/rimraf.js",
                "mappings": {
                  "graceful-fs": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs"
                },
                "dirpath": "node_modules/fs-extra/node_modules/rimraf"
              }
            },
            "wrapper": "json"
          },
          "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/package.json": {
            "requireId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/package.json",
            "memoizeId": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/package.json",
            "descriptor": {
              "dirpath": "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs",
              "dirrealpath": "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs",
              "id": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs",
              "lookupPaths": [
                "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs/package.json",
                "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me"
                  },
                  "name": "graceful-fs",
                  "description": "A drop-in replacement for fs, making various improvements.",
                  "version": "2.0.0",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/isaacs/node-graceful-fs.git"
                  },
                  "main": "graceful-fs.js",
                  "engines": {
                    "node": ">=0.4.0"
                  },
                  "directories": {
                    "test": "test"
                  },
                  "scripts": {
                    "test": "tap test/*.js"
                  },
                  "keywords": [
                    "fs",
                    "module",
                    "reading",
                    "retry",
                    "retries",
                    "queue",
                    "error",
                    "errors",
                    "handling",
                    "EMFILE",
                    "EAGAIN",
                    "EINVAL",
                    "EPERM",
                    "EACCESS"
                  ],
                  "license": "BSD",
                  "readme": "# graceful-fs\n\ngraceful-fs functions as a drop-in replacement for the fs module,\nmaking various improvements.\n\nThe improvements are meant to normalize behavior across different\nplatforms and environments, and to make filesystem access more\nresilient to errors.\n\n## Improvements over fs module\n\ngraceful-fs:\n\n* keeps track of how many file descriptors are open, and by default\n  limits this to 1024. Any further requests to open a file are put in a\n  queue until new slots become available. If 1024 turns out to be too\n  much, it decreases the limit further.\n* fixes `lchmod` for Node versions prior to 0.6.2.\n* implements `fs.lutimes` if possible. Otherwise it becomes a noop.\n* ignores `EINVAL` and `EPERM` errors in `chown`, `fchown` or\n  `lchown` if the user isn't root.\n* makes `lchmod` and `lchown` become noops, if not available.\n* retries reading a file if `read` results in EAGAIN error.\n\nOn Windows, it retries renaming a file for up to one second if `EACCESS`\nor `EPERM` error occurs, likely because antivirus software has locked\nthe directory.\n\n## Configuration\n\nThe maximum number of open file descriptors that graceful-fs manages may\nbe adjusted by setting `fs.MAX_OPEN` to a different number. The default\nis 1024.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/isaacs/node-graceful-fs/issues"
                  },
                  "_id": "graceful-fs@2.0.0",
                  "_from": "graceful-fs@~2"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "graceful-fs",
                  "description": "A drop-in replacement for fs, making various improvements.",
                  "version": "2.0.0",
                  "locator": {
                    "pointer": "~2"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/isaacs/node-graceful-fs/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/isaacs/node-graceful-fs.git"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": ">=0.4.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "tap test/*.js"
                    },
                    "main": "./graceful-fs.js"
                  },
                  "layout": {
                    "directories": {
                      "test": "./test",
                      "dependency": "./node_modules"
                    }
                  },
                  "licenses": [
                    "BSD"
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "fs",
                    "module",
                    "reading",
                    "retry",
                    "retries",
                    "queue",
                    "error",
                    "errors",
                    "handling",
                    "EMFILE",
                    "EAGAIN",
                    "EINVAL",
                    "EPERM",
                    "EACCESS"
                  ],
                  "contributors": [
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  }
                }
              },
              "combined": {
                "name": "graceful-fs",
                "description": "A drop-in replacement for fs, making various improvements.",
                "version": "2.0.0",
                "locator": {
                  "pointer": "~2"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/isaacs/node-graceful-fs/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/isaacs/node-graceful-fs.git"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": ">=0.4.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "tap test/*.js"
                  },
                  "main": "./graceful-fs.js"
                },
                "layout": {
                  "directories": {
                    "test": "./test",
                    "dependency": "./node_modules"
                  }
                },
                "licenses": [
                  "BSD"
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "fs",
                  "module",
                  "reading",
                  "retry",
                  "retries",
                  "queue",
                  "error",
                  "errors",
                  "handling",
                  "EMFILE",
                  "EAGAIN",
                  "EINVAL",
                  "EPERM",
                  "EACCESS"
                ],
                "contributors": [
                  {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me"
                  }
                ],
                "pm": {
                  "install": "npm"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "8221f2fbd3f3ff50c6ef3876a188d48a8e78bc6e-graceful-fs/graceful-fs.js",
                "dirpath": "node_modules/fs-extra/node_modules/rimraf/node_modules/graceful-fs"
              }
            },
            "wrapper": "json"
          },
          "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/package.json": {
            "requireId": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/package.json",
            "memoizeId": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/package.json",
            "descriptor": {
              "dirpath": "node_modules/request",
              "dirrealpath": "node_modules/request",
              "id": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request",
              "lookupPaths": [
                "node_modules/request/package.json",
                "node_modules/request/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "request",
                  "description": "Simplified HTTP request client.",
                  "tags": [
                    "http",
                    "simple",
                    "util",
                    "utility"
                  ],
                  "version": "2.21.0",
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com"
                  },
                  "repository": {
                    "type": "git",
                    "url": "http://github.com/mikeal/request.git"
                  },
                  "bugs": {
                    "url": "http://github.com/mikeal/request/issues"
                  },
                  "engines": [
                    "node >= 0.8.0"
                  ],
                  "main": "index.js",
                  "dependencies": {
                    "qs": "~0.6.0",
                    "json-stringify-safe": "~4.0.0",
                    "forever-agent": "~0.5.0",
                    "tunnel-agent": "~0.3.0",
                    "http-signature": "~0.9.11",
                    "hawk": "~0.13.0",
                    "aws-sign": "~0.3.0",
                    "oauth-sign": "~0.3.0",
                    "cookie-jar": "~0.3.0",
                    "node-uuid": "~1.4.0",
                    "mime": "~1.2.9",
                    "form-data": "0.0.8"
                  },
                  "scripts": {
                    "test": "node tests/run.js"
                  },
                  "readme": "# Request -- Simplified HTTP request method\n\n## Install\n\n<pre>\n  npm install request\n</pre>\n\nOr from source:\n\n<pre>\n  git clone git://github.com/mikeal/request.git \n  cd request\n  npm link\n</pre>\n\n## Super simple to use\n\nRequest is designed to be the simplest way possible to make http calls. It supports HTTPS and follows redirects by default.\n\n```javascript\nvar request = require('request');\nrequest('http://www.google.com', function (error, response, body) {\n  if (!error && response.statusCode == 200) {\n    console.log(body) // Print the google web page.\n  }\n})\n```\n\n## Streaming\n\nYou can stream any response to a file stream.\n\n```javascript\nrequest('http://google.com/doodle.png').pipe(fs.createWriteStream('doodle.png'))\n```\n\nYou can also stream a file to a PUT or POST request. This method will also check the file extension against a mapping of file extensions to content-types, in this case `application/json`, and use the proper content-type in the PUT request if one is not already provided in the headers.\n\n```javascript\nfs.createReadStream('file.json').pipe(request.put('http://mysite.com/obj.json'))\n```\n\nRequest can also pipe to itself. When doing so the content-type and content-length will be preserved in the PUT headers.\n\n```javascript\nrequest.get('http://google.com/img.png').pipe(request.put('http://mysite.com/img.png'))\n```\n\nNow let's get fancy.\n\n```javascript\nhttp.createServer(function (req, resp) {\n  if (req.url === '/doodle.png') {\n    if (req.method === 'PUT') {\n      req.pipe(request.put('http://mysite.com/doodle.png'))\n    } else if (req.method === 'GET' || req.method === 'HEAD') {\n      request.get('http://mysite.com/doodle.png').pipe(resp)\n    } \n  }\n})\n```\n\nYou can also pipe() from a http.ServerRequest instance and to a http.ServerResponse instance. The HTTP method and headers will be sent as well as the entity-body data. Which means that, if you don't really care about security, you can do:\n\n```javascript\nhttp.createServer(function (req, resp) {\n  if (req.url === '/doodle.png') {\n    var x = request('http://mysite.com/doodle.png')\n    req.pipe(x)\n    x.pipe(resp)\n  }\n})\n```\n\nAnd since pipe() returns the destination stream in node 0.5.x you can do one line proxying :)\n\n```javascript\nreq.pipe(request('http://mysite.com/doodle.png')).pipe(resp)\n```\n\nAlso, none of this new functionality conflicts with requests previous features, it just expands them.\n\n```javascript\nvar r = request.defaults({'proxy':'http://localproxy.com'})\n\nhttp.createServer(function (req, resp) {\n  if (req.url === '/doodle.png') {\n    r.get('http://google.com/doodle.png').pipe(resp)\n  }\n})\n```\nYou can still use intermediate proxies, the requests will still follow HTTP forwards, etc.\n\n## Forms\n\n`request` supports `application/x-www-form-urlencoded` and `multipart/form-data` form uploads. For `multipart/related` refer to the `multipart` API.\n\nUrl encoded forms are simple\n\n```javascript\nrequest.post('http://service.com/upload', {form:{key:'value'}})\n// or\nrequest.post('http://service.com/upload').form({key:'value'})\n```\n\nFor `multipart/form-data` we use the [form-data](https://github.com/felixge/node-form-data) library by [@felixge](https://github.com/felixge). You don't need to worry about piping the form object or setting the headers, `request` will handle that for you.\n\n```javascript\nvar r = request.post('http://service.com/upload')\nvar form = r.form()\nform.append('my_field', 'my_value')\nform.append('my_buffer', new Buffer([1, 2, 3]))\nform.append('my_file', fs.createReadStream(path.join(__dirname, 'doodle.png'))\nform.append('remote_file', request('http://google.com/doodle.png'))\n```\n\n## HTTP Authentication\n\n```javascript\nrequest.auth('username', 'password', false).get('http://some.server.com/');\n// or\nrequest.get('http://some.server.com/', {\n  'auth': {\n    'user': 'username',\n    'pass': 'password',\n    'sendImmediately': false\n  }\n});\n```\n\nIf passed as an option, `auth` should be a hash containing values `user` || `username`, `password` || `pass`, and `sendImmediately` (optional).  The method form takes parameters `auth(username, password, sendImmediately)`.\n\n`sendImmediately` defaults to true, which will cause a basic authentication header to be sent.  If `sendImmediately` is `false`, then `request` will retry with a proper authentication header after receiving a 401 response from the server (which must contain a `WWW-Authenticate` header indicating the required authentication method).\n\nDigest authentication is supported, but it only works with `sendImmediately` set to `false` (otherwise `request` will send basic authentication on the initial request, which will probably cause the request to fail).\n\n## OAuth Signing\n\n```javascript\n// Twitter OAuth\nvar qs = require('querystring')\n  , oauth =\n    { callback: 'http://mysite.com/callback/'\n    , consumer_key: CONSUMER_KEY\n    , consumer_secret: CONSUMER_SECRET\n    }\n  , url = 'https://api.twitter.com/oauth/request_token'\n  ;\nrequest.post({url:url, oauth:oauth}, function (e, r, body) {\n  // Ideally, you would take the body in the response\n  // and construct a URL that a user clicks on (like a sign in button).\n  // The verifier is only available in the response after a user has \n  // verified with twitter that they are authorizing your app.\n  var access_token = qs.parse(body)\n    , oauth = \n      { consumer_key: CONSUMER_KEY\n      , consumer_secret: CONSUMER_SECRET\n      , token: access_token.oauth_token\n      , verifier: access_token.oauth_verifier\n      }\n    , url = 'https://api.twitter.com/oauth/access_token'\n    ;\n  request.post({url:url, oauth:oauth}, function (e, r, body) {\n    var perm_token = qs.parse(body)\n      , oauth = \n        { consumer_key: CONSUMER_KEY\n        , consumer_secret: CONSUMER_SECRET\n        , token: perm_token.oauth_token\n        , token_secret: perm_token.oauth_token_secret\n        }\n      , url = 'https://api.twitter.com/1/users/show.json?'\n      , params = \n        { screen_name: perm_token.screen_name\n        , user_id: perm_token.user_id\n        }\n      ;\n    url += qs.stringify(params)\n    request.get({url:url, oauth:oauth, json:true}, function (e, r, user) {\n      console.log(user)\n    })\n  })\n})\n```\n\n\n\n### request(options, callback)\n\nThe first argument can be either a url or an options object. The only required option is uri, all others are optional.\n\n* `uri` || `url` - fully qualified uri or a parsed url object from url.parse()\n* `qs` - object containing querystring values to be appended to the uri\n* `method` - http method, defaults to GET\n* `headers` - http headers, defaults to {}\n* `body` - entity body for PATCH, POST and PUT requests. Must be buffer or string.\n* `form` - when passed an object this will set `body` but to a querystring representation of value and adds `Content-type: application/x-www-form-urlencoded; charset=utf-8` header. When passed no option a FormData instance is returned that will be piped to request.\n* `auth` - A hash containing values `user` || `username`, `password` || `pass`, and `sendImmediately` (optional).  See documentation above.\n* `json` - sets `body` but to JSON representation of value and adds `Content-type: application/json` header.  Additionally, parses the response body as json.\n* `multipart` - (experimental) array of objects which contains their own headers and `body` attribute. Sends `multipart/related` request. See example below.\n* `followRedirect` - follow HTTP 3xx responses as redirects. defaults to true.\n* `followAllRedirects` - follow non-GET HTTP 3xx responses as redirects. defaults to false.\n* `maxRedirects` - the maximum number of redirects to follow, defaults to 10.\n* `encoding` - Encoding to be used on `setEncoding` of response data. If set to `null`, the body is returned as a Buffer.\n* `pool` - A hash object containing the agents for these requests. If omitted this request will use the global pool which is set to node's default maxSockets.\n* `pool.maxSockets` - Integer containing the maximum amount of sockets in the pool.\n* `timeout` - Integer containing the number of milliseconds to wait for a request to respond before aborting the request\t\n* `proxy` - An HTTP proxy to be used. Support proxy Auth with Basic Auth the same way it's supported with the `url` parameter by embedding the auth info in the uri.\n* `oauth` - Options for OAuth HMAC-SHA1 signing, see documentation above.\n* `hawk` - Options for [Hawk signing](https://github.com/hueniverse/hawk). The `credentials` key must contain the necessary signing info, [see hawk docs for details](https://github.com/hueniverse/hawk#usage-example).\n* `strictSSL` - Set to `true` to require that SSL certificates be valid. Note: to use your own certificate authority, you need to specify an agent that was created with that ca as an option.\n* `jar` - Set to `false` if you don't want cookies to be remembered for future use or define your custom cookie jar (see examples section)\n* `aws` - object containing aws signing information, should have the properties `key` and `secret` as well as `bucket` unless you're specifying your bucket as part of the path, or you are making a request that doesn't use a bucket (i.e. GET Services)\n* `httpSignature` - Options for the [HTTP Signature Scheme](https://github.com/joyent/node-http-signature/blob/master/http_signing.md) using [Joyent's library](https://github.com/joyent/node-http-signature). The `keyId` and `key` properties must be specified. See the docs for other options.\n* `localAddress` - Local interface to bind for network connections.\n\n\nThe callback argument gets 3 arguments. The first is an error when applicable (usually from the http.Client option not the http.ClientRequest object). The second in an http.ClientResponse object. The third is the response body String or Buffer.\n\n## Convenience methods\n\nThere are also shorthand methods for different HTTP METHODs and some other conveniences.\n\n### request.defaults(options)  \n  \nThis method returns a wrapper around the normal request API that defaults to whatever options you pass in to it.\n\n### request.put\n\nSame as request() but defaults to `method: \"PUT\"`.\n\n```javascript\nrequest.put(url)\n```\n\n### request.patch\n\nSame as request() but defaults to `method: \"PATCH\"`.\n\n```javascript\nrequest.patch(url)\n```\n\n### request.post\n\nSame as request() but defaults to `method: \"POST\"`.\n\n```javascript\nrequest.post(url)\n```\n\n### request.head\n\nSame as request() but defaults to `method: \"HEAD\"`.\n\n```javascript\nrequest.head(url)\n```\n\n### request.del\n\nSame as request() but defaults to `method: \"DELETE\"`.\n\n```javascript\nrequest.del(url)\n```\n\n### request.get\n\nAlias to normal request method for uniformity.\n\n```javascript\nrequest.get(url)\n```\n### request.cookie\n\nFunction that creates a new cookie.\n\n```javascript\nrequest.cookie('cookie_string_here')\n```\n### request.jar\n\nFunction that creates a new cookie jar.\n\n```javascript\nrequest.jar()\n```\n\n\n## Examples:\n\n```javascript\n  var request = require('request')\n    , rand = Math.floor(Math.random()*100000000).toString()\n    ;\n  request(\n    { method: 'PUT'\n    , uri: 'http://mikeal.iriscouch.com/testjs/' + rand\n    , multipart: \n      [ { 'content-type': 'application/json'\n        ,  body: JSON.stringify({foo: 'bar', _attachments: {'message.txt': {follows: true, length: 18, 'content_type': 'text/plain' }}})\n        }\n      , { body: 'I am an attachment' }\n      ] \n    }\n  , function (error, response, body) {\n      if(response.statusCode == 201){\n        console.log('document saved as: http://mikeal.iriscouch.com/testjs/'+ rand)\n      } else {\n        console.log('error: '+ response.statusCode)\n        console.log(body)\n      }\n    }\n  )\n```\nCookies are enabled by default (so they can be used in subsequent requests). To disable cookies set jar to false (either in defaults or in the options sent).\n\n```javascript\nvar request = request.defaults({jar: false})\nrequest('http://www.google.com', function () {\n  request('http://images.google.com')\n})\n```\n\nIf you to use a custom cookie jar (instead of letting request use its own global cookie jar) you do so by setting the jar default or by specifying it as an option:\n\n```javascript\nvar j = request.jar()\nvar request = request.defaults({jar:j})\nrequest('http://www.google.com', function () {\n  request('http://images.google.com')\n})\n```\nOR\n\n```javascript\nvar j = request.jar()\nvar cookie = request.cookie('your_cookie_here')\nj.add(cookie)\nrequest({url: 'http://www.google.com', jar: j}, function () {\n  request('http://images.google.com')\n})\n```\n",
                  "readmeFilename": "README.md",
                  "_id": "request@2.21.0",
                  "_from": "request@~2.21.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "aws-sign": "./node_modules/aws-sign",
                      "cookie-jar": "./node_modules/cookie-jar",
                      "forever-agent": "./node_modules/forever-agent",
                      "form-data": "./node_modules/form-data",
                      "hawk": "./node_modules/hawk",
                      "http-signature": "./node_modules/http-signature",
                      "json-stringify-safe": "./node_modules/json-stringify-safe",
                      "mime": "./node_modules/mime",
                      "node-uuid": "./node_modules/node-uuid",
                      "oauth-sign": "./node_modules/oauth-sign",
                      "qs": "./node_modules/qs",
                      "tunnel-agent": "./node_modules/tunnel-agent"
                    }
                  },
                  "mappings": {
                    "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                    "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
                    "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                    "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                    "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                    "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                    "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                    "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                    "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                    "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                    "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                    "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent"
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "request",
                  "description": "Simplified HTTP request client.",
                  "version": "2.21.0",
                  "locator": {
                    "pointer": "~2.21.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "http://github.com/mikeal/request/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "http://github.com/mikeal/request.git"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "qs": "~0.6.0",
                      "json-stringify-safe": "~4.0.0",
                      "forever-agent": "~0.5.0",
                      "tunnel-agent": "~0.3.0",
                      "http-signature": "~0.9.11",
                      "hawk": "~0.13.0",
                      "aws-sign": "~0.3.0",
                      "oauth-sign": "~0.3.0",
                      "cookie-jar": "~0.3.0",
                      "node-uuid": "~1.4.0",
                      "mime": "~1.2.9",
                      "form-data": "0.0.8"
                    },
                    "bundled": {
                      "aws-sign": "./node_modules/aws-sign",
                      "cookie-jar": "./node_modules/cookie-jar",
                      "forever-agent": "./node_modules/forever-agent",
                      "form-data": "./node_modules/form-data",
                      "hawk": "./node_modules/hawk",
                      "http-signature": "./node_modules/http-signature",
                      "json-stringify-safe": "./node_modules/json-stringify-safe",
                      "mime": "./node_modules/mime",
                      "node-uuid": "./node_modules/node-uuid",
                      "oauth-sign": "./node_modules/oauth-sign",
                      "qs": "./node_modules/qs",
                      "tunnel-agent": "./node_modules/tunnel-agent"
                    }
                  },
                  "requirements": {
                    "engines": [
                      "node >= 0.8.0"
                    ]
                  },
                  "exports": {
                    "scripts": {
                      "test": "node tests/run.js"
                    },
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                    "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
                    "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                    "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                    "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                    "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                    "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                    "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                    "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                    "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                    "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                    "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent"
                  }
                }
              },
              "combined": {
                "name": "request",
                "description": "Simplified HTTP request client.",
                "version": "2.21.0",
                "locator": {
                  "pointer": "~2.21.0"
                },
                "social": {
                  "bugs": {
                    "url": "http://github.com/mikeal/request/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "http://github.com/mikeal/request.git"
                  }
                ],
                "dependencies": {
                  "required": {
                    "qs": "~0.6.0",
                    "json-stringify-safe": "~4.0.0",
                    "forever-agent": "~0.5.0",
                    "tunnel-agent": "~0.3.0",
                    "http-signature": "~0.9.11",
                    "hawk": "~0.13.0",
                    "aws-sign": "~0.3.0",
                    "oauth-sign": "~0.3.0",
                    "cookie-jar": "~0.3.0",
                    "node-uuid": "~1.4.0",
                    "mime": "~1.2.9",
                    "form-data": "0.0.8"
                  },
                  "bundled": {
                    "aws-sign": "./node_modules/aws-sign",
                    "cookie-jar": "./node_modules/cookie-jar",
                    "forever-agent": "./node_modules/forever-agent",
                    "form-data": "./node_modules/form-data",
                    "hawk": "./node_modules/hawk",
                    "http-signature": "./node_modules/http-signature",
                    "json-stringify-safe": "./node_modules/json-stringify-safe",
                    "mime": "./node_modules/mime",
                    "node-uuid": "./node_modules/node-uuid",
                    "oauth-sign": "./node_modules/oauth-sign",
                    "qs": "./node_modules/qs",
                    "tunnel-agent": "./node_modules/tunnel-agent"
                  }
                },
                "requirements": {
                  "engines": [
                    "node >= 0.8.0"
                  ]
                },
                "exports": {
                  "scripts": {
                    "test": "node tests/run.js"
                  },
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                  "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
                  "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                  "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                  "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                  "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                  "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                  "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                  "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                  "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                  "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                  "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent"
                }
              },
              "warnings": [
                [
                  "normalize",
                  "Property 'tags' was ignored",
                  "descriptor",
                  "package.json"
                ]
              ],
              "errors": [],
              "memoized": {
                "main": "ed4bb06796db1905581e7b400da006dd7b8b1b55-request/index.js",
                "mappings": {
                  "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                  "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                  "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                  "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                  "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                  "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                  "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                  "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent",
                  "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                  "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                  "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                  "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar"
                },
                "dirpath": "node_modules/request"
              }
            },
            "wrapper": "json"
          },
          "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/package.json": {
            "requireId": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/package.json",
            "memoizeId": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/qs",
              "dirrealpath": "node_modules/request/node_modules/qs",
              "id": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
              "lookupPaths": [
                "node_modules/request/node_modules/qs/package.json",
                "node_modules/request/node_modules/qs/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/qs/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "qs",
                  "description": "querystring parser",
                  "version": "0.6.5",
                  "keywords": [
                    "query string",
                    "parser",
                    "component"
                  ],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/visionmedia/node-querystring.git"
                  },
                  "devDependencies": {
                    "mocha": "*",
                    "expect.js": "*"
                  },
                  "scripts": {
                    "test": "make test"
                  },
                  "author": {
                    "name": "TJ Holowaychuk",
                    "email": "tj@vision-media.ca",
                    "url": "http://tjholowaychuk.com"
                  },
                  "main": "index",
                  "engines": {
                    "node": "*"
                  },
                  "readme": "# node-querystring\n\n  query string parser for node and the browser supporting nesting, as it was removed from `0.3.x`, so this library provides the previous and commonly desired behaviour (and twice as fast). Used by [express](http://expressjs.com), [connect](http://senchalabs.github.com/connect) and others.\n\n## Installation\n\n    $ npm install qs\n\n## Examples\n\n```js\nvar qs = require('qs');\n\nqs.parse('user[name][first]=Tobi&user[email]=tobi@learnboost.com');\n// => { user: { name: { first: 'Tobi' }, email: 'tobi@learnboost.com' } }\n\nqs.stringify({ user: { name: 'Tobi', email: 'tobi@learnboost.com' }})\n// => user[name]=Tobi&user[email]=tobi%40learnboost.com\n```\n\n## Testing\n\nInstall dev dependencies:\n\n    $ npm install -d\n\nand execute:\n\n    $ make test\n\nbrowser:\n\n    $ open test/browser/index.html\n\n## License \n\n(The MIT License)\n\nCopyright (c) 2010 TJ Holowaychuk &lt;tj@vision-media.ca&gt;\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
                  "readmeFilename": "Readme.md",
                  "bugs": {
                    "url": "https://github.com/visionmedia/node-querystring/issues"
                  },
                  "_id": "qs@0.6.5",
                  "_from": "qs@~0.6.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "qs",
                  "description": "querystring parser",
                  "version": "0.6.5",
                  "locator": {
                    "pointer": "~0.6.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/visionmedia/node-querystring/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/visionmedia/node-querystring.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "mocha": "*",
                      "expect.js": "*"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test"
                    },
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./Readme.md"
                  },
                  "keywords": [
                    "query string",
                    "parser",
                    "component"
                  ],
                  "contributors": [
                    {
                      "name": "TJ Holowaychuk",
                      "email": "tj@vision-media.ca",
                      "url": "http://tjholowaychuk.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "qs",
                "description": "querystring parser",
                "version": "0.6.5",
                "locator": {
                  "pointer": "~0.6.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/visionmedia/node-querystring/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/visionmedia/node-querystring.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "mocha": "*",
                    "expect.js": "*"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test"
                  },
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./Readme.md"
                },
                "keywords": [
                  "query string",
                  "parser",
                  "component"
                ],
                "contributors": [
                  {
                    "name": "TJ Holowaychuk",
                    "email": "tj@vision-media.ca",
                    "url": "http://tjholowaychuk.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs/index.js",
                "dirpath": "node_modules/request/node_modules/qs"
              }
            },
            "wrapper": "json"
          },
          "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/package.json": {
            "requireId": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/package.json",
            "memoizeId": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/oauth-sign",
              "dirrealpath": "node_modules/request/node_modules/oauth-sign",
              "id": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
              "lookupPaths": [
                "node_modules/request/node_modules/oauth-sign/package.json",
                "node_modules/request/node_modules/oauth-sign/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/oauth-sign/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  },
                  "name": "oauth-sign",
                  "description": "OAuth 1 signing. Formerly a vendor lib in mikeal/request, now a standalone module.",
                  "version": "0.3.0",
                  "repository": {
                    "url": "https://github.com/mikeal/oauth-sign"
                  },
                  "main": "index.js",
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": "*"
                  },
                  "scripts": {
                    "test": "node test.js"
                  },
                  "readme": "oauth-sign\n==========\n\nOAuth 1 signing. Formerly a vendor lib in mikeal/request, now a standalone module. \n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mikeal/oauth-sign/issues"
                  },
                  "_id": "oauth-sign@0.3.0",
                  "_from": "oauth-sign@~0.3.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "oauth-sign",
                  "description": "OAuth 1 signing. Formerly a vendor lib in mikeal/request, now a standalone module.",
                  "version": "0.3.0",
                  "locator": {
                    "pointer": "~0.3.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mikeal/oauth-sign/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/mikeal/oauth-sign"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "node test.js"
                    },
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com",
                      "url": "http://www.futurealoof.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "oauth-sign",
                "description": "OAuth 1 signing. Formerly a vendor lib in mikeal/request, now a standalone module.",
                "version": "0.3.0",
                "locator": {
                  "pointer": "~0.3.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mikeal/oauth-sign/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/mikeal/oauth-sign"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "node test.js"
                  },
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign/index.js",
                "dirpath": "node_modules/request/node_modules/oauth-sign"
              }
            },
            "wrapper": "json"
          },
          "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/package.json": {
            "requireId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/package.json",
            "memoizeId": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk",
              "dirrealpath": "node_modules/request/node_modules/hawk",
              "id": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/package.json",
                "node_modules/request/node_modules/hawk/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "hawk",
                  "description": "HTTP Hawk Authentication Scheme",
                  "version": "0.13.1",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/hueniverse/hawk"
                  },
                  "main": "index",
                  "keywords": [
                    "http",
                    "authentication",
                    "scheme",
                    "hawk"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {
                    "hoek": "0.8.x",
                    "boom": "0.4.x",
                    "cryptiles": "0.2.x",
                    "sntp": "0.2.x"
                  },
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x",
                    "localStorage": "1.0.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/hawk/raw/master/LICENSE"
                    }
                  ],
                  "readme": "![hawk Logo](https://raw.github.com/hueniverse/hawk/master/images/hawk.png)\r\n\r\n<img align=\"right\" src=\"https://raw.github.com/hueniverse/hawk/master/images/logo.png\" /> **Hawk** is an HTTP authentication scheme using a message authentication code (MAC) algorithm to provide partial\r\nHTTP request cryptographic verification. For more complex use cases such as access delegation, see [Oz](https://github.com/hueniverse/oz).\r\n\r\nCurrent version: **0.13**\r\n\r\n[![Build Status](https://secure.travis-ci.org/hueniverse/hawk.png)](http://travis-ci.org/hueniverse/hawk)\r\n\r\n# Table of Content\r\n\r\n- [**Introduction**](#introduction)\r\n  - [Replay Protection](#replay-protection)\r\n  - [Usage Example](#usage-example)\r\n  - [Protocol Example](#protocol-example)\r\n    - [Payload Validation](#payload-validation)\r\n    - [Response Payload Validation](#response-payload-validation)\r\n  - [Browser Support and Considerations](#browser-support-and-considerations)\r\n<p></p>\r\n- [**Single URI Authorization**](#single-uri-authorization)\r\n  - [Usage Example](#bewit-usage-example)\r\n<p></p>\r\n- [**Security Considerations**](#security-considerations)\r\n  - [MAC Keys Transmission](#mac-keys-transmission)\r\n  - [Confidentiality of Requests](#confidentiality-of-requests)\r\n  - [Spoofing by Counterfeit Servers](#spoofing-by-counterfeit-servers)\r\n  - [Plaintext Storage of Credentials](#plaintext-storage-of-credentials)\r\n  - [Entropy of Keys](#entropy-of-keys)\r\n  - [Coverage Limitations](#coverage-limitations)\r\n  - [Future Time Manipulation](#future-time-manipulation)\r\n  - [Client Clock Poisoning](#client-clock-poisoning)\r\n  - [Bewit Limitations](#bewit-limitations)\r\n<p></p>\r\n- [**Frequently Asked Questions**](#frequently-asked-questions)\r\n<p></p>\r\n- [**Acknowledgements**](#acknowledgements)\r\n\r\n# Introduction\r\n\r\n**Hawk** is an HTTP authentication scheme providing mechanisms for making authenticated HTTP requests with\r\npartial cryptographic verification of the request and response, covering the HTTP method, request URI, host,\r\nand optionally the request payload.\r\n\r\nSimilar to the HTTP [Digest access authentication schemes](http://www.ietf.org/rfc/rfc2617.txt), **Hawk** uses a set of\r\nclient credentials which include an identifier (e.g. username) and key (e.g. password). Likewise, just as with the Digest scheme,\r\nthe key is never included in authenticated requests. Instead, it is used to calculate a request MAC value which is\r\nincluded in its place.\r\n\r\nHowever, **Hawk** has several differences from Digest. In particular, while both use a nonce to limit the possibility of\r\nreplay attacks, in **Hawk** the client generates the nonce and uses it in combination with a timestamp, leading to less\r\n\"chattiness\" (interaction with the server).\r\n\r\nAlso unlike Digest, this scheme is not intended to protect the key itself (the password in Digest) because\r\nthe client and server must both have access to the key material in the clear.\r\n\r\nThe primary design goals of this scheme are to:\r\n* simplify and improve HTTP authentication for services that are unwilling or unable to deploy TLS for all resources,\r\n* secure credentials against leakage (e.g., when the client uses some form of dynamic configuration to determine where\r\n  to send an authenticated request), and\r\n* avoid the exposure of credentials sent to a malicious server over an unauthenticated secure channel due to client\r\n  failure to validate the server's identity as part of its TLS handshake.\r\n\r\nIn addition, **Hawk** supports a method for granting third-parties temporary access to individual resources using\r\na query parameter called _bewit_ (in falconry, a leather strap used to attach a tracking device to the leg of a hawk).\r\n\r\nThe **Hawk** scheme requires the establishment of a shared symmetric key between the client and the server,\r\nwhich is beyond the scope of this module. Typically, the shared credentials are established via an initial\r\nTLS-protected phase or derived from some other shared confidential information available to both the client\r\nand the server.\r\n\r\n\r\n## Replay Protection\r\n\r\nWithout replay protection, an attacker can use a compromised (but otherwise valid and authenticated) request more \r\nthan once, gaining access to a protected resource. To mitigate this, clients include both a nonce and a timestamp when \r\nmaking requests. This gives the server enough information to prevent replay attacks.\r\n\r\nThe nonce is generated by the client, and is a string unique across all requests with the same timestamp and\r\nkey identifier combination. \r\n\r\nThe timestamp enables the server to restrict the validity period of the credentials where requests occuring afterwards\r\nare rejected. It also removes the need for the server to retain an unbounded number of nonce values for future checks.\r\nBy default, **Hawk** uses a time window of 1 minute to allow for time skew between the client and server (which in\r\npractice translates to a maximum of 2 minutes as the skew can be positive or negative).\r\n\r\nUsing a timestamp requires the client's clock to be in sync with the server's clock. **Hawk** requires both the client\r\nclock and the server clock to use NTP to ensure synchronization. However, given the limitations of some client types\r\n(e.g. browsers) to deploy NTP, the server provides the client with its current time (in seconds precision) in response\r\nto a bad timestamp.\r\n\r\nThere is no expectation that the client will adjust its system clock to match the server (in fact, this would be a\r\npotential attack vector). Instead, the client only uses the server's time to calculate an offset used only\r\nfor communications with that particular server. The protocol rewards clients with synchronized clocks by reducing\r\nthe number of round trips required to authenticate the first request.\r\n\r\n\r\n## Usage Example\r\n\r\nServer code:\r\n\r\n```javascript\r\nvar Http = require('http');\r\nvar Hawk = require('hawk');\r\n\r\n\r\n// Credentials lookup function\r\n\r\nvar credentialsFunc = function (id, callback) {\r\n\r\n    var credentials = {\r\n        key: 'werxhqb98rpaxn39848xrunpaw3489ruxnpa98w4rxn',\r\n        algorithm: 'sha256',\r\n        user: 'Steve'\r\n    };\r\n\r\n    return callback(null, credentials);\r\n};\r\n\r\n// Create HTTP server\r\n\r\nvar handler = function (req, res) {\r\n\r\n    // Authenticate incoming request\r\n\r\n    Hawk.server.authenticate(req, credentialsFunc, {}, function (err, credentials, artifacts) {\r\n\r\n        // Prepare response\r\n\r\n        var payload = (!err ? 'Hello ' + credentials.user + ' ' + artifacts.ext : 'Shoosh!');\r\n        var headers = { 'Content-Type': 'text/plain' };\r\n\r\n        // Generate Server-Authorization response header\r\n\r\n        var header = Hawk.server.header(credentials, artifacts, { payload: payload, contentType: headers['Content-Type'] });\r\n        headers['Server-Authorization'] = header;\r\n\r\n        // Send the response back\r\n\r\n        res.writeHead(!err ? 200 : 401, headers);\r\n        res.end(payload);\r\n    });\r\n};\r\n\r\n// Start server\r\n\r\nHttp.createServer(handler).listen(8000, 'example.com');\r\n```\r\n\r\nClient code:\r\n\r\n```javascript\r\nvar Request = require('request');\r\nvar Hawk = require('hawk');\r\n\r\n\r\n// Client credentials\r\n\r\nvar credentials = {\r\n    id: 'dh37fgj492je',\r\n    key: 'werxhqb98rpaxn39848xrunpaw3489ruxnpa98w4rxn',\r\n    algorithm: 'sha256'\r\n}\r\n\r\n// Request options\r\n\r\nvar requestOptions = {\r\n    uri: 'http://example.com:8000/resource/1?b=1&a=2',\r\n    method: 'GET',\r\n    headers: {}\r\n};\r\n\r\n// Generate Authorization request header\r\n\r\nvar header = Hawk.client.header('http://example.com:8000/resource/1?b=1&a=2', 'GET', { credentials: credentials, ext: 'some-app-data' });\r\nrequestOptions.headers.Authorization = header.field;\r\n\r\n// Send authenticated request\r\n\r\nRequest(requestOptions, function (error, response, body) {\r\n\r\n    // Authenticate the server's response\r\n\r\n    var isValid = Hawk.client.authenticate(response, credentials, header.artifacts, { payload: body });\r\n\r\n    // Output results\r\n\r\n    console.log(response.statusCode + ': ' + body + (isValid ? ' (valid)' : ' (invalid)'));\r\n});\r\n```\r\n\r\n**Hawk** utilized the [**SNTP**](https://github.com/hueniverse/sntp) module for time sync management. By default, the local\r\nmachine time is used. To automatically retrieve and synchronice the clock within the application, use the SNTP 'start()' method.\r\n\r\n```javascript\r\nHawk.sntp.start();\r\n```\r\n\r\n\r\n## Protocol Example\r\n\r\nThe client attempts to access a protected resource without authentication, sending the following HTTP request to\r\nthe resource server:\r\n\r\n```\r\nGET /resource/1?b=1&a=2 HTTP/1.1\r\nHost: example.com:8000\r\n```\r\n\r\nThe resource server returns an authentication challenge.\r\n\r\n```\r\nHTTP/1.1 401 Unauthorized\r\nWWW-Authenticate: Hawk\r\n```\r\n\r\nThe client has previously obtained a set of **Hawk** credentials for accessing resources on the \"http://example.com/\"\r\nserver. The **Hawk** credentials issued to the client include the following attributes:\r\n\r\n* Key identifier: dh37fgj492je\r\n* Key: werxhqb98rpaxn39848xrunpaw3489ruxnpa98w4rxn\r\n* Algorithm: sha256\r\n\r\nThe client generates the authentication header by calculating a timestamp (e.g. the number of seconds since January 1,\r\n1970 00:00:00 GMT), generating a nonce, and constructing the normalized request string (each value followed by a newline\r\ncharacter):\r\n\r\n```\r\nhawk.1.header\r\n1353832234\r\nj4h3g2\r\nGET\r\n/resource?a=1&b=2\r\nexample.com\r\n8000\r\n\r\nsome-app-ext-data\r\n\r\n```\r\n\r\nThe request MAC is calculated using HMAC with the specified hash algorithm \"sha256\" and the key over the normalized request string.\r\nThe result is base64-encoded to produce the request MAC:\r\n\r\n```\r\n6R4rV5iE+NPoym+WwjeHzjAGXUtLNIxmo1vpMofpLAE=\r\n```\r\n\r\nThe client includes the **Hawk** key identifier, timestamp, nonce, application specific data, and request MAC with the request using\r\nthe HTTP `Authorization` request header field:\r\n\r\n```\r\nGET /resource/1?b=1&a=2 HTTP/1.1\r\nHost: example.com:8000\r\nAuthorization: Hawk id=\"dh37fgj492je\", ts=\"1353832234\", nonce=\"j4h3g2\", ext=\"some-app-ext-data\", mac=\"6R4rV5iE+NPoym+WwjeHzjAGXUtLNIxmo1vpMofpLAE=\"\r\n```\r\n\r\nThe server validates the request by calculating the request MAC again based on the request received and verifies the validity\r\nand scope of the **Hawk** credentials. If valid, the server responds with the requested resource.\r\n\r\n\r\n### Payload Validation\r\n\r\n**Hawk** provides optional payload validation. When generating the authentication header, the client calculates a payload hash\r\nusing the specified hash algorithm. The hash is calculated over the concatenated value of (each followed by a newline character):\r\n* `hawk.1.payload`\r\n* the content-type in lowercase, without any parameters (e.g. `application/json`)\r\n* the request payload prior to any content encoding (the exact representation requirements should be specified by the server for payloads other than simple single-part ascii to ensure interoperability)\r\n\r\nFor example:\r\n\r\n* Payload: `Thank you for flying Hawk`\r\n* Content Type: `text/plain`\r\n* Hash (sha256): `Yi9LfIIFRtBEPt74PVmbTF/xVAwPn7ub15ePICfgnuY=`\r\n\r\nResults in the following input to the payload hash function (newline terminated values):\r\n\r\n```\r\nhawk.1.payload\r\ntext/plain\r\nThank you for flying Hawk\r\n\r\n```\r\n\r\nWhich produces the following hash value:\r\n\r\n```\r\nYi9LfIIFRtBEPt74PVmbTF/xVAwPn7ub15ePICfgnuY=\r\n```\r\n\r\nThe client constructs the normalized request string (newline terminated values):\r\n\r\n```\r\nhawk.1.header\r\n1353832234\r\nj4h3g2\r\nPOST\r\n/resource?a=1&b=2\r\nexample.com\r\n8000\r\nYi9LfIIFRtBEPt74PVmbTF/xVAwPn7ub15ePICfgnuY=\r\nsome-app-ext-data\r\n\r\n```\r\n\r\nThen calculates the request MAC and includes the **Hawk** key identifier, timestamp, nonce, payload hash, application specific data,\r\nand request MAC, with the request using the HTTP `Authorization` request header field:\r\n\r\n```\r\nPOST /resource/1 HTTP/1.1\r\nHost: example.com:8000\r\nAuthorization: Hawk id=\"dh37fgj492je\", ts=\"1353832234\", nonce=\"j4h3g2\", hash=\"Yi9LfIIFRtBEPt74PVmbTF/xVAwPn7ub15ePICfgnuY=\", ext=\"some-app-ext-data\", mac=\"aSe1DERmZuRl3pI36/9BdZmnErTw3sNzOOAUlfeKjVw=\"\r\n```\r\n\r\nIt is up to the server if and when it validates the payload for any given request, based solely on it's security policy\r\nand the nature of the data included.\r\n\r\nIf the payload is available at the time of authentication, the server uses the hash value provided by the client to construct\r\nthe normalized string and validates the MAC. If the MAC is valid, the server calculates the payload hash and compares the value\r\nwith the provided payload hash in the header. In many cases, checking the MAC first is faster than calculating the payload hash.\r\n\r\nHowever, if the payload is not available at authentication time (e.g. too large to fit in memory, streamed elsewhere, or processed\r\nat a different stage in the application), the server may choose to defer payload validation for later by retaining the hash value\r\nprovided by the client after validating the MAC.\r\n\r\nIt is important to note that MAC validation does not mean the hash value provided by the client is valid, only that the value\r\nincluded in the header was not modified. Without calculating the payload hash on the server and comparing it to the value provided\r\nby the client, the payload may be modified by an attacker.\r\n\r\n\r\n## Response Payload Validation\r\n\r\n**Hawk** provides partial response payload validation. The server includes the `Server-Authorization` response header which enables the\r\nclient to authenticate the response and ensure it is talking to the right server. **Hawk** defines the HTTP `Server-Authorization` header\r\nas a response header using the exact same syntax as the `Authorization` request header field.\r\n\r\nThe header is contructed using the same process as the client's request header. The server uses the same credentials and other\r\nartifacts provided by the client to constructs the normalized request string. The `ext` and `hash` values are replaced with\r\nnew values based on the server response. The rest as identical to those used by the client.\r\n\r\nThe result MAC digest is included with the optional `hash` and `ext` values:\r\n\r\n```\r\nServer-Authorization: Hawk mac=\"XIJRsMl/4oL+nn+vKoeVZPdCHXB4yJkNnBbTbHFZUYE=\", hash=\"f9cDF/TDm7TkYRLnGwRMfeDzT6LixQVLvrIKhh0vgmM=\", ext=\"response-specific\"\r\n```\r\n\r\n\r\n## Browser Support and Considerations\r\n\r\nA browser script is provided for including using a `<script>` tag in [lib/browser.js](/lib/browser.js).\r\n\r\n**Hawk** relies on the _Server-Authorization_ and _WWW-Authenticate_ headers in its response to communicate with the client.\r\nTherefore, in case of CORS requests, it is important to consider sending _Access-Control-Expose-Headers_ with the value\r\n_\"WWW-Authenticate, Server-Authorization\"_ on each response from your server. As explained in the\r\n[specifications](http://www.w3.org/TR/cors/#access-control-expose-headers-response-header), it will indicate that these headers\r\ncan safely be accessed by the client (using getResponseHeader() on the XmlHttpRequest object). Otherwise you will be met with a\r\n[\"simple response header\"](http://www.w3.org/TR/cors/#simple-response-header) which excludes these fields and would prevent the\r\nHawk client from authenticating the requests.You can read more about the why and how in this\r\n[article](http://www.html5rocks.com/en/tutorials/cors/#toc-adding-cors-support-to-the-server)\r\n\r\n\r\n# Single URI Authorization\r\n\r\nThere are cases in which limited and short-term access to a protected resource is granted to a third party which does not\r\nhave access to the shared credentials. For example, displaying a protected image on a web page accessed by anyone. **Hawk**\r\nprovides limited support for such URIs in the form of a _bewit_ - a URI query parameter appended to the request URI which contains\r\nthe necessary credentials to authenticate the request.\r\n\r\nBecause of the significant security risks involved in issuing such access, bewit usage is purposely limited only to GET requests\r\nand for a finite period of time. Both the client and server can issue bewit credentials, however, the server should not use the same\r\ncredentials as the client to maintain clear traceability as to who issued which credentials.\r\n\r\nIn order to simplify implementation, bewit credentials do not support single-use policy and can be replayed multiple times within\r\nthe granted access timeframe. \r\n\r\n\r\n## Bewit Usage Example\r\n\r\nServer code:\r\n\r\n```javascript\r\nvar Http = require('http');\r\nvar Hawk = require('hawk');\r\n\r\n\r\n// Credentials lookup function\r\n\r\nvar credentialsFunc = function (id, callback) {\r\n\r\n    var credentials = {\r\n        key: 'werxhqb98rpaxn39848xrunpaw3489ruxnpa98w4rxn',\r\n        algorithm: 'sha256'\r\n    };\r\n\r\n    return callback(null, credentials);\r\n};\r\n\r\n// Create HTTP server\r\n\r\nvar handler = function (req, res) {\r\n\r\n    Hawk.uri.authenticate(req, credentialsFunc, {}, function (err, credentials, attributes) {\r\n\r\n        res.writeHead(!err ? 200 : 401, { 'Content-Type': 'text/plain' });\r\n        res.end(!err ? 'Access granted' : 'Shoosh!');\r\n    });\r\n};\r\n\r\nHttp.createServer(handler).listen(8000, 'example.com');\r\n```\r\n\r\nBewit code generation:\r\n\r\n```javascript\r\nvar Request = require('request');\r\nvar Hawk = require('hawk');\r\n\r\n\r\n// Client credentials\r\n\r\nvar credentials = {\r\n    id: 'dh37fgj492je',\r\n    key: 'werxhqb98rpaxn39848xrunpaw3489ruxnpa98w4rxn',\r\n    algorithm: 'sha256'\r\n}\r\n\r\n// Generate bewit\r\n\r\nvar duration = 60 * 5;      // 5 Minutes\r\nvar bewit = Hawk.uri.getBewit('http://example.com:8080/resource/1?b=1&a=2', { credentials: credentials, ttlSec: duration, ext: 'some-app-data' });\r\nvar uri = 'http://example.com:8000/resource/1?b=1&a=2' + '&bewit=' + bewit;\r\n```\r\n\r\n\r\n# Security Considerations\r\n\r\nThe greatest sources of security risks are usually found not in **Hawk** but in the policies and procedures surrounding its use.\r\nImplementers are strongly encouraged to assess how this module addresses their security requirements. This section includes\r\nan incomplete list of security considerations that must be reviewed and understood before deploying **Hawk** on the server.\r\nMany of the protections provided in **Hawk** depends on whether and how they are used.\r\n\r\n### MAC Keys Transmission\r\n\r\n**Hawk** does not provide any mechanism for obtaining or transmitting the set of shared credentials required. Any mechanism used\r\nto obtain **Hawk** credentials must ensure that these transmissions are protected using transport-layer mechanisms such as TLS.\r\n\r\n### Confidentiality of Requests\r\n\r\nWhile **Hawk** provides a mechanism for verifying the integrity of HTTP requests, it provides no guarantee of request\r\nconfidentiality. Unless other precautions are taken, eavesdroppers will have full access to the request content. Servers should\r\ncarefully consider the types of data likely to be sent as part of such requests, and employ transport-layer security mechanisms\r\nto protect sensitive resources.\r\n\r\n### Spoofing by Counterfeit Servers\r\n\r\n**Hawk** provides limited verification of the server authenticity. When receiving a response back from the server, the server\r\nmay choose to include a response `Server-Authorization` header which the client can use to verify the response. However, it is up to\r\nthe server to determine when such measure is included, to up to the client to enforce that policy.\r\n\r\nA hostile party could take advantage of this by intercepting the client's requests and returning misleading or otherwise\r\nincorrect responses. Service providers should consider such attacks when developing services using this protocol, and should\r\nrequire transport-layer security for any requests where the authenticity of the resource server or of server responses is an issue.\r\n\r\n### Plaintext Storage of Credentials\r\n\r\nThe **Hawk** key functions the same way passwords do in traditional authentication systems. In order to compute the request MAC,\r\nthe server must have access to the key in plaintext form. This is in contrast, for example, to modern operating systems, which\r\nstore only a one-way hash of user credentials.\r\n\r\nIf an attacker were to gain access to these keys - or worse, to the server's database of all such keys - he or she would be able\r\nto perform any action on behalf of any resource owner. Accordingly, it is critical that servers protect these keys from unauthorized\r\naccess.\r\n\r\n### Entropy of Keys\r\n\r\nUnless a transport-layer security protocol is used, eavesdroppers will have full access to authenticated requests and request\r\nMAC values, and will thus be able to mount offline brute-force attacks to recover the key used. Servers should be careful to\r\nassign keys which are long enough, and random enough, to resist such attacks for at least the length of time that the **Hawk**\r\ncredentials are valid.\r\n\r\nFor example, if the credentials are valid for two weeks, servers should ensure that it is not possible to mount a brute force\r\nattack that recovers the key in less than two weeks. Of course, servers are urged to err on the side of caution, and use the\r\nlongest key reasonable.\r\n\r\nIt is equally important that the pseudo-random number generator (PRNG) used to generate these keys be of sufficiently high\r\nquality. Many PRNG implementations generate number sequences that may appear to be random, but which nevertheless exhibit\r\npatterns or other weaknesses which make cryptanalysis or brute force attacks easier. Implementers should be careful to use\r\ncryptographically secure PRNGs to avoid these problems.\r\n\r\n### Coverage Limitations\r\n\r\nThe request MAC only covers the HTTP `Host` header and optionally the `Content-Type` header. It does not cover any other headers\r\nwhich can often affect how the request body is interpreted by the server. If the server behavior is influenced by the presence\r\nor value of such headers, an attacker can manipulate the request headers without being detected. Implementers should use the\r\n`ext` feature to pass application-specific information via the `Authorization` header which is protected by the request MAC.\r\n\r\nThe response authentication, when performed, only covers the response payload, content-type, and the request information \r\nprovided by the client in it's request (method, resource, timestamp, nonce, etc.). It does not cover the HTTP status code or\r\nany other response header field (e.g. Location) which can affect the client's behaviour.\r\n\r\n### Future Time Manipulation\r\n\r\nThe protocol relies on a clock sync between the client and server. To accomplish this, the server informs the client of its\r\ncurrent time when an invalid timestamp is received.\r\n\r\nIf an attacker is able to manipulate this information and cause the client to use an incorrect time, it would be able to cause\r\nthe client to generate authenticated requests using time in the future. Such requests will fail when sent by the client, and will\r\nnot likely leave a trace on the server (given the common implementation of nonce, if at all enforced). The attacker will then\r\nbe able to replay the request at the correct time without detection.\r\n\r\nThe client must only use the time information provided by the server if:\r\n* it was delivered over a TLS connection and the server identity has been verified, or\r\n* the `tsm` MAC digest calculated using the same client credentials over the timestamp has been verified.\r\n\r\n### Client Clock Poisoning\r\n\r\nWhen receiving a request with a bad timestamp, the server provides the client with its current time. The client must never use\r\nthe time received from the server to adjust its own clock, and must only use it to calculate an offset for communicating with\r\nthat particular server.\r\n\r\n### Bewit Limitations\r\n\r\nSpecial care must be taken when issuing bewit credentials to third parties. Bewit credentials are valid until expiration and cannot\r\nbe revoked or limited without using other means. Whatever resource they grant access to will be completely exposed to anyone with\r\naccess to the bewit credentials which act as bearer credentials for that particular resource. While bewit usage is limited to GET\r\nrequests only and therefore cannot be used to perform transactions or change server state, it can still be used to expose private\r\nand sensitive information.\r\n\r\n\r\n# Frequently Asked Questions\r\n\r\n### Where is the protocol specification?\r\n\r\nIf you are looking for some prose explaining how all this works, **this is it**. **Hawk** is being developed as an open source\r\nproject instead of a standard. In other words, the [code](/hueniverse/hawk/tree/master/lib) is the specification. Not sure about\r\nsomething? Open an issue!\r\n\r\n### Is it done?\r\n\r\nAt if version 0.10.0, **Hawk** is feature-complete. However, until this module reaches version 1.0.0 it is considered experimental\r\nand is likely to change. This also means your feedback and contribution are very welcome. Feel free to open issues with questions\r\nand suggestions.\r\n\r\n### Where can I find **Hawk** implementations in other languages?\r\n\r\n**Hawk**'s only reference implementation is provided in JavaScript as a node.js module. However, others are actively porting it to other\r\nplatforms. There is already a [PHP](https://github.com/alexbilbie/PHP-Hawk),\r\n[.NET](https://github.com/pcibraro/hawknet), and [JAVA](https://github.com/wealdtech/hawk) libraries available. The full list\r\nis maintained [here](https://github.com/hueniverse/hawk/issues?labels=port). Please add an issue if you are working on another\r\nport. A cross-platform test-suite is in the works.\r\n\r\n### Why isn't the algorithm part of the challenge or dynamically negotiated?\r\n\r\nThe algorithm used is closely related to the key issued as different algorithms require different key sizes (and other\r\nrequirements). While some keys can be used for multiple algorithm, the protocol is designed to closely bind the key and algorithm\r\ntogether as part of the issued credentials.\r\n\r\n### Why is Host and Content-Type the only headers covered by the request MAC?\r\n\r\nIt is really hard to include other headers. Headers can be changed by proxies and other intermediaries and there is no\r\nwell-established way to normalize them. Many platforms change the case of header field names and values. The only\r\nstraight-forward solution is to include the headers in some blob (say, base64 encoded JSON) and include that with the request,\r\nan approach taken by JWT and other such formats. However, that design violates the HTTP header boundaries, repeats information,\r\nand introduces other security issues because firewalls will not be aware of these \"hidden\" headers. In addition, any information\r\nrepeated must be compared to the duplicated information in the header and therefore only moves the problem elsewhere.\r\n\r\n### Why not just use HTTP Digest?\r\n\r\nDigest requires pre-negotiation to establish a nonce. This means you can't just make a request - you must first send\r\na protocol handshake to the server. This pattern has become unacceptable for most web services, especially mobile\r\nwhere extra round-trip are costly.\r\n\r\n### Why bother with all this nonce and timestamp business?\r\n\r\n**Hawk** is an attempt to find a reasonable, practical compromise between security and usability. OAuth 1.0 got timestamp\r\nand nonces halfway right but failed when it came to scalability and consistent developer experience. **Hawk** addresses\r\nit by requiring the client to sync its clock, but provides it with tools to accomplish it.\r\n\r\nIn general, replay protection is a matter of application-specific threat model. It is less of an issue on a TLS-protected\r\nsystem where the clients are implemented using best practices and are under the control of the server. Instead of dropping\r\nreplay protection, **Hawk** offers a required time window and an optional nonce verification. Together, it provides developers\r\nwith the ability to decide how to enforce their security policy without impacting the client's implementation.\r\n\r\n### What are `app` and `dlg` in the authorization header and normalized mac string?\r\n\r\nThe original motivation for **Hawk** was to replace the OAuth 1.0 use cases. This included both a simple client-server mode which\r\nthis module is specifically designed for, and a delegated access mode which is being developed separately in\r\n[Oz](https://github.com/hueniverse/oz). In addition to the **Hawk** use cases, Oz requires another attribute: the application id `app`.\r\nThis provides binding between the credentials and the application in a way that prevents an attacker from tricking an application\r\nto use credentials issued to someone else. It also has an optional 'delegated-by' attribute `dlg` which is the application id of the\r\napplication the credentials were directly issued to. The goal of these two additions is to allow Oz to utilize **Hawk** directly,\r\nbut with the additional security of delegated credentials.\r\n\r\n### What is the purpose of the static strings used in each normalized MAC input?\r\n\r\nWhen calculating a hash or MAC, a static prefix (tag) is added. The prefix is used to prevent MAC values from being\r\nused or reused for a purpose other than what they were created for (i.e. prevents switching MAC values between a request,\r\nresponse, and a bewit use cases). It also protects against expliots created after a potential change in how the protocol\r\ncreates the normalized string. For example, if a future version would switch the order of nonce and timestamp, it\r\ncan create an exploit opportunity for cases where the nonce is similar in format to a timestamp.\r\n\r\n### Does **Hawk** have anything to do with OAuth?\r\n\r\nShort answer: no.\r\n\r\n**Hawk** was originally proposed as the OAuth MAC Token specification. However, the OAuth working group in its consistent\r\nincompetence failed to produce a final, usable solution to address one of the most popular use cases of OAuth 1.0 - using it\r\nto authenticate simple client-server transactions (i.e. two-legged). As you can guess, the OAuth working group is still hard\r\nat work to produce more garbage.\r\n\r\n**Hawk** provides a simple HTTP authentication scheme for making client-server requests. It does not address the OAuth use case\r\nof delegating access to a third party. If you are looking for an OAuth alternative, check out [Oz](https://github.com/hueniverse/oz).\r\n\r\n\r\n# Acknowledgements\r\n\r\n**Hawk** is a derivative work of the [HTTP MAC Authentication Scheme](http://tools.ietf.org/html/draft-hammer-oauth-v2-mac-token-05) proposal\r\nco-authored by Ben Adida, Adam Barth, and Eran Hammer, which in turn was based on the OAuth 1.0 community specification.\r\n\r\nSpecial thanks to Ben Laurie for his always insightful feedback and advice.\r\n\r\nThe **Hawk** logo was created by [Chris Carrasco](http://chriscarrasco.com).\r\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/hueniverse/hawk/issues"
                  },
                  "_id": "hawk@0.13.1",
                  "_from": "hawk@~0.13.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "boom": "./node_modules/boom",
                      "cryptiles": "./node_modules/cryptiles",
                      "hoek": "./node_modules/hoek",
                      "sntp": "./node_modules/sntp"
                    }
                  },
                  "mappings": {
                    "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                    "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                    "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                    "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "hawk",
                  "description": "HTTP Hawk Authentication Scheme",
                  "version": "0.13.1",
                  "locator": {
                    "pointer": "~0.13.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/hueniverse/hawk/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/hueniverse/hawk"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "hoek": "0.8.x",
                      "boom": "0.4.x",
                      "cryptiles": "0.2.x",
                      "sntp": "0.2.x"
                    },
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x",
                      "localStorage": "1.0.x"
                    },
                    "bundled": {
                      "boom": "./node_modules/boom",
                      "cryptiles": "./node_modules/cryptiles",
                      "hoek": "./node_modules/hoek",
                      "sntp": "./node_modules/sntp"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/hawk/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "http",
                    "authentication",
                    "scheme",
                    "hawk"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                    "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                    "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                    "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                  }
                }
              },
              "combined": {
                "name": "hawk",
                "description": "HTTP Hawk Authentication Scheme",
                "version": "0.13.1",
                "locator": {
                  "pointer": "~0.13.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/hueniverse/hawk/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/hueniverse/hawk"
                  }
                ],
                "dependencies": {
                  "required": {
                    "hoek": "0.8.x",
                    "boom": "0.4.x",
                    "cryptiles": "0.2.x",
                    "sntp": "0.2.x"
                  },
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x",
                    "localStorage": "1.0.x"
                  },
                  "bundled": {
                    "boom": "./node_modules/boom",
                    "cryptiles": "./node_modules/cryptiles",
                    "hoek": "./node_modules/hoek",
                    "sntp": "./node_modules/sntp"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/hueniverse/hawk/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "http",
                  "authentication",
                  "scheme",
                  "hawk"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                  "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                  "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                  "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk/index.js",
                "mappings": {
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                  "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp",
                  "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                  "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles"
                },
                "dirpath": "node_modules/request/node_modules/hawk"
              }
            },
            "wrapper": "json"
          },
          "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/package.json": {
            "requireId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/package.json",
            "memoizeId": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/boom",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/boom",
              "id": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/boom/package.json",
                "node_modules/request/node_modules/hawk/node_modules/boom/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/boom/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "boom",
                  "description": "HTTP-friendly error objects",
                  "version": "0.4.2",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/spumko/boom"
                  },
                  "main": "index",
                  "keywords": [
                    "error",
                    "http"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {
                    "hoek": "0.9.x"
                  },
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/boom/raw/master/LICENSE"
                    }
                  ],
                  "readme": "<a href=\"https://github.com/spumko\"><img src=\"https://raw.github.com/spumko/spumko/master/images/from.png\" align=\"right\" /></a>\n![boom Logo](https://raw.github.com/spumko/boom/master/images/boom.png)\n\nHTTP-friendly error objects\n\n[![Build Status](https://secure.travis-ci.org/spumko/boom.png)](http://travis-ci.org/spumko/boom)\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/spumko/boom/issues"
                  },
                  "_id": "boom@0.4.2",
                  "_from": "boom@0.4.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "hoek": "./node_modules/hoek"
                    }
                  },
                  "mappings": {
                    "hoek": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek"
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "boom",
                  "description": "HTTP-friendly error objects",
                  "version": "0.4.2",
                  "locator": {
                    "pointer": "0.4.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/spumko/boom/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/spumko/boom"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "hoek": "0.9.x"
                    },
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    },
                    "bundled": {
                      "hoek": "./node_modules/hoek",
                      "boom": ".",
                      "cryptiles": "../cryptiles",
                      "sntp": "../sntp"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/boom/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "error",
                    "http"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "hoek": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek",
                    "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                    "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                    "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                  }
                }
              },
              "combined": {
                "name": "boom",
                "description": "HTTP-friendly error objects",
                "version": "0.4.2",
                "locator": {
                  "pointer": "0.4.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/spumko/boom/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/spumko/boom"
                  }
                ],
                "dependencies": {
                  "required": {
                    "hoek": "0.9.x"
                  },
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "bundled": {
                    "hoek": "./node_modules/hoek",
                    "boom": ".",
                    "cryptiles": "../cryptiles",
                    "sntp": "../sntp"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/spumko/boom/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "error",
                  "http"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "hoek": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek",
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                  "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                  "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom/index.js",
                "mappings": {
                  "hoek": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek"
                },
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/boom"
              }
            },
            "wrapper": "json"
          },
          "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/package.json": {
            "requireId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/package.json",
            "memoizeId": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek",
              "id": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/package.json",
                "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.9.1",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  },
                  "main": "index",
                  "keywords": [
                    "utilities"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {},
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "readme": "<a href=\"https://github.com/spumko\"><img src=\"https://raw.github.com/spumko/spumko/master/images/from.png\" align=\"right\" /></a>\r\n![hoek Logo](https://raw.github.com/spumko/hoek/master/images/hoek.png)\r\n\r\nGeneral purpose node utilities\r\n\r\n[![Build Status](https://secure.travis-ci.org/spumko/hoek.png)](http://travis-ci.org/spumko/hoek)\r\n\r\n# Table of Contents\r\n\r\n* [Introduction](#introduction \"Introduction\")\r\n* [Object](#object \"Object\")\r\n  * [clone](#cloneobj \"clone\")\r\n  * [merge](#mergetarget-source-isnulloverride-ismergearrays \"merge\")\r\n  * [applyToDefaults](#applytodefaultsdefaults-options \"applyToDefaults\")\r\n  * [unique](#uniquearray-key \"unique\")\r\n  * [mapToObject](#maptoobjectarray-key \"mapToObject\")\r\n  * [intersect](#intersectarray1-array2 \"intersect\")\r\n  * [matchKeys](#matchkeysobj-keys \"matchKeys\")\r\n  * [flatten](#flattenarray-target \"flatten\")\r\n  * [removeKeys](#removekeysobject-keys \"removeKeys\")\r\n  * [reach](#reachobj-chain \"reach\")\r\n  * [inheritAsync](#inheritasyncself-obj-keys \"inheritAsync\")\r\n  * [rename](#renameobj-from-to \"rename\")\r\n* [Timer](#timer \"Timer\")\r\n* [Binary Encoding/Decoding](#binary \"Binary Encoding/Decoding\")\r\n  * [base64urlEncode](#binary64urlEncodevalue \"binary64urlEncode\")\r\n  * [base64urlDecode](#binary64urlDecodevalue \"binary64urlDecode\")\r\n* [Escaping Characters](#escaped \"Escaping Characters\")\r\n  * [escapeHtml](#escapeHtmlstring \"escapeHtml\")\r\n  * [escapeHeaderAttribute](#escapeHeaderAttributeattribute \"escapeHeaderAttribute\")\r\n  * [escapeRegex](#escapeRegexstring \"escapeRegex\")\r\n* [Errors](#errors \"Errors\")\r\n  * [assert](#assertmessage \"assert\")\r\n  * [abort](#abortmessage \"abort\")\r\n  * [displayStack](#displayStackslice \"displayStack\")\r\n  * [callStack](#callStackslice \"callStack\")\r\n  * [toss](#tosscondition \"toss\")\r\n* [Load files](#load-files \"Load Files\")\r\n  * [loadPackage](#loadPackagedir \"loadpackage\")\r\n  * [loadDirModules](#loadDirModulespath-excludefiles-target \"loaddirmodules\")\r\n\r\n\r\n\r\n# Introduction\r\n\r\nThe *Hoek* general purpose node utilities library is used to aid in a variety of manners. It comes with useful methods for Arrays (clone, merge, applyToDefaults), Objects (removeKeys, copy), Asserting and more. \r\n\r\nFor example, to use Hoek to set configuration with default options:\r\n```javascript\r\nvar Hoek = require('hoek');\r\n\r\nvar default = {url : \"www.github.com\", port : \"8000\", debug : true}\r\n\r\nvar config = Hoek.applyToDefaults(default, {port : \"3000\", admin : true});\r\n\r\n// In this case, config would be { url: 'www.github.com', port: '3000', debug: true, admin: true }\r\n```\r\n\r\nUnder each of the sections (such as Array), there are subsections which correspond to Hoek methods. Each subsection will explain how to use the corresponding method. In each js excerpt below, the var Hoek = require('hoek') is omitted for brevity.\r\n\r\n## Object\r\n\r\nHoek provides several helpful methods for objects and arrays.\r\n\r\n### clone(obj)\r\n\r\nThis method is used to clone an object or an array. A *deep copy* is made (duplicates everything, including values that are objects). \r\n\r\n```javascript\r\n\r\nvar nestedObj = {\r\n        w: /^something$/ig,\r\n        x: {\r\n            a: [1, 2, 3],\r\n            b: 123456,\r\n            c: new Date()\r\n        },\r\n        y: 'y',\r\n        z: new Date()\r\n    };\r\n\r\nvar copy = Hoek.clone(nestedObj);\r\n\r\ncopy.x.b = 100;\r\n\r\nconsole.log(copy.y)        // results in 'y'\r\nconsole.log(nestedObj.x.b) // results in 123456\r\nconsole.log(copy.x.b)      // results in 100\r\n```\r\n\r\n### merge(target, source, isNullOverride, isMergeArrays)\r\nisNullOverride, isMergeArrays default to true\r\n\r\nMerge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\n\r\n```javascript\r\n\r\nvar target = {a: 1, b : 2}\r\nvar source = {a: 0, c: 5}\r\nvar source2 = {a: null, c: 5}\r\n\r\nvar targetArray = [1, 2, 3];\r\nvar sourceArray = [4, 5];\r\n\r\nvar newTarget = Hoek.merge(target, source);     // results in {a: 0, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2);        // results in {a: null, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2, false); // results in {a: 1, b: 2, c: 5}\r\n\r\nnewTarget = Hoek.merge(targetArray, sourceArray)              // results in [1, 2, 3, 4, 5]\r\nnewTarget = Hoek.merge(targetArray, sourceArray, true, false) // results in [4, 5]\r\n\r\n\r\n\r\n\r\n```\r\n\r\n### applyToDefaults(defaults, options)\r\n\r\nApply options to a copy of the defaults\r\n\r\n```javascript\r\n\r\nvar defaults = {host: \"localhost\", port: 8000};\r\nvar options = {port: 8080};\r\n\r\nvar config = Hoek.applyToDefaults(defaults, options); // results in {host: \"localhost\", port: 8080};\r\n\r\n\r\n```\r\n\r\n### unique(array, key)\r\n\r\nRemove duplicate items from Array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 2, 3, 3, 4, 5, 6];\r\n\r\nvar newArray = Hoek.unique(array); // results in [1,2,3,4,5,6];\r\n\r\narray = [{id: 1}, {id: 1}, {id: 2}];\r\n\r\nnewArray = Hoek.unique(array, \"id\") // results in [{id: 1}, {id: 2}]\r\n\r\n```\r\n\r\n### mapToObject(array, key)\r\n\r\nConvert an Array into an Object\r\n\r\n```javascript\r\n\r\nvar array = [1,2,3];\r\nvar newObject = Hoek.mapToObject(array); // results in [{\"1\": true}, {\"2\": true}, {\"3\": true}]\r\n\r\narray = [{id: 1}, {id: 2}];\r\nnewObject = Hoek.mapToObject(array, \"id\") // results in [{\"id\": 1}, {\"id\": 2}]\r\n\r\n```\r\n### intersect(array1, array2)\r\n\r\nFind the common unique items in two arrays\r\n\r\n```javascript\r\n\r\nvar array1 = [1, 2, 3];\r\nvar array2 = [1, 4, 5];\r\n\r\nvar newArray = Hoek.intersect(array1, array2) // results in [1]\r\n\r\n```\r\n\r\n### matchKeys(obj, keys) \r\n\r\nFind which keys are present\r\n\r\n```javascript\r\n\r\nvar obj = {a: 1, b: 2, c: 3};\r\nvar keys = [\"a\", \"e\"];\r\n\r\nHoek.matchKeys(obj, keys) // returns [\"a\"]\r\n\r\n```\r\n\r\n### flatten(array, target)\r\n\r\nFlatten an array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 3];\r\nvar target = [4, 5]; \r\n\r\nvar flattenedArray = Hoek.flatten(array, target) // results in [4, 5, 1, 2, 3];\r\n\r\n```\r\n\r\n### removeKeys(object, keys)\r\n\r\nRemove keys\r\n\r\n```javascript\r\n\r\nvar object = {a: 1, b: 2, c: 3, d: 4};\r\n\r\nvar keys = [\"a\", \"b\"];\r\n\r\nHoek.removeKeys(object, keys) // object is now {c: 3, d: 4}\r\n\r\n```\r\n\r\n### reach(obj, chain)\r\n\r\nConverts an object key chain string to reference\r\n\r\n```javascript\r\n\r\nvar chain = 'a.b.c';\r\nvar obj = {a : {b : { c : 1}}};\r\n\r\nHoek.reach(obj, chain) // returns 1\r\n\r\n```\r\n\r\n### inheritAsync(self, obj, keys) \r\n\r\nInherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\n```javascript\r\n\r\nvar targetFunc = function () { };\r\n\r\nvar proto = {\r\n                a: function () {\r\n                    return 'a!';\r\n                },\r\n                b: function () {\r\n                    return 'b!';\r\n                },\r\n                c: function () {\r\n                    throw new Error('c!');\r\n                }\r\n            };\r\n\r\nvar keys = ['a', 'c'];\r\n\r\nHoek.inheritAsync(targetFunc, proto, ['a', 'c']);\r\n\r\nvar target = new targetFunc();\r\n\r\ntarget.a(function(err, result){console.log(result)}         // returns 'a!'       \r\n\r\ntarget.c(function(err, result){console.log(result)}         // returns undefined\r\n\r\ntarget.b(function(err, result){console.log(result)}         // gives error: Object [object Object] has no method 'b'\r\n\r\n```\r\n\r\n### rename(obj, from, to)\r\n\r\nRename a key of an object\r\n\r\n```javascript\r\n\r\nvar obj = {a : 1, b : 2};\r\n\r\nHoek.rename(obj, \"a\", \"c\");     // obj is now {c : 1, b : 2}\r\n\r\n```\r\n\r\n\r\n# Timer\r\n\r\nA Timer object. Initializing a new timer object sets the ts to the number of milliseconds elapsed since 1 January 1970 00:00:00 UTC.\r\n\r\n```javascript\r\n\r\n\r\nexample : \r\n\r\n\r\nvar timerObj = new Hoek.Timer();\r\nconsole.log(\"Time is now: \" + timerObj.ts)\r\nconsole.log(\"Elapsed time from initialization: \" + timerObj.elapsed() + 'milliseconds')\r\n\r\n```\r\n\r\n# Binary Encoding/Decoding\r\n\r\n### base64urlEncode(value)\r\n\r\nEncodes value in Base64 or URL encoding\r\n\r\n### base64urlDecode(value)\r\n\r\nDecodes data in Base64 or URL encoding.\r\n# Escaping Characters\r\n\r\nHoek provides convenient methods for escaping html characters. The escaped characters are as followed:\r\n\r\n```javascript\r\n\r\ninternals.htmlEscaped = {\r\n    '&': '&amp;',\r\n    '<': '&lt;',\r\n    '>': '&gt;',\r\n    '\"': '&quot;',\r\n    \"'\": '&#x27;',\r\n    '`': '&#x60;'\r\n};\r\n\r\n```\r\n\r\n### escapeHtml(string)\r\n\r\n```javascript\r\n\r\nvar string = '<html> hey </html>';\r\nvar escapedString = Hoek.escapeHtml(string); // returns &lt;html&gt; hey &lt;/html&gt;\r\n\r\n```\r\n\r\n### escapeHeaderAttribute(attribute)\r\n\r\nEscape attribute value for use in HTTP header\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeHeaderAttribute('I said \"go w\\\\o me\"');  //returns I said \\\"go w\\\\o me\\\"\r\n\r\n\r\n```\r\n\r\n\r\n### escapeRegex(string)\r\n\r\nEscape string for Regex construction\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeRegex('4^f$s.4*5+-_?%=#!:@|~\\\\/`\"(>)[<]d{}s,');  // returns 4\\^f\\$s\\.4\\*5\\+\\-_\\?%\\=#\\!\\:@\\|~\\\\\\/`\"\\(>\\)\\[<\\]d\\{\\}s\\,\r\n\r\n\r\n\r\n```\r\n\r\n# Errors\r\n\r\n### assert(message)\r\n\r\n```javascript\r\n\r\nvar a = 1, b =2;\r\n\r\nHoek.assert(a === b, 'a should equal b');  // ABORT: a should equal b\r\n\r\n```\r\n\r\n### abort(message)\r\n\r\nFirst checks if process.env.NODE_ENV === 'test', and if so, throws error message. Otherwise,\r\ndisplays most recent stack and then exits process.\r\n\r\n\r\n\r\n### displayStack(slice)\r\n\r\nDisplays the trace stack\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.displayStack();\r\nconsole.log(stack) // returns something like:\r\n\r\n[ 'null (/Users/user/Desktop/hoek/test.js:4:18)',\r\n  'Module._compile (module.js:449:26)',\r\n  'Module._extensions..js (module.js:467:10)',\r\n  'Module.load (module.js:356:32)',\r\n  'Module._load (module.js:312:12)',\r\n  'Module.runMain (module.js:492:10)',\r\n  'startup.processNextTick.process._tickCallback (node.js:244:9)' ]\r\n\r\n```\r\n\r\n### callStack(slice)\r\n\r\nReturns a trace stack array.\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.callStack();\r\nconsole.log(stack)  // returns something like:\r\n\r\n[ [ '/Users/user/Desktop/hoek/test.js', 4, 18, null, false ],\r\n  [ 'module.js', 449, 26, 'Module._compile', false ],\r\n  [ 'module.js', 467, 10, 'Module._extensions..js', false ],\r\n  [ 'module.js', 356, 32, 'Module.load', false ],\r\n  [ 'module.js', 312, 12, 'Module._load', false ],\r\n  [ 'module.js', 492, 10, 'Module.runMain', false ],\r\n  [ 'node.js',\r\n    244,\r\n    9,\r\n    'startup.processNextTick.process._tickCallback',\r\n    false ] ]\r\n\r\n\r\n```\r\n\r\n### toss(condition)\r\n\r\ntoss(condition /*, [message], callback */)\r\n\r\nReturn an error as first argument of a callback\r\n\r\n\r\n# Load Files\r\n\r\n### loadPackage(dir)\r\n\r\nLoad and parse package.json process root or given directory\r\n\r\n```javascript\r\n\r\nvar pack = Hoek.loadPackage();  // pack.name === 'hoek'\r\n\r\n```\r\n\r\n### loadDirModules(path, excludeFiles, target) \r\n\r\nLoads modules from a given path; option to exclude files (array).\r\n\r\n\r\n\r\n\r\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  },
                  "_id": "hoek@0.9.1",
                  "_from": "hoek@0.9.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.9.1",
                  "locator": {
                    "pointer": "0.9.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/spumko/hoek/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/spumko/hoek"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "utilities"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "hoek",
                "description": "General purpose node utilities",
                "version": "0.9.1",
                "locator": {
                  "pointer": "0.9.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  }
                ],
                "dependencies": {
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "utilities"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  {
                    "name": "Van Nguyen",
                    "email": "the.gol.effect@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "6b825b609d9fcb26d947f3cee8a737a80a9b27b3-hoek/index.js",
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/boom/node_modules/hoek"
              }
            },
            "wrapper": "json"
          },
          "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/package.json": {
            "requireId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/package.json",
            "memoizeId": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/sntp",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/sntp",
              "id": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/sntp/package.json",
                "node_modules/request/node_modules/hawk/node_modules/sntp/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/sntp/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "sntp",
                  "description": "SNTP Client",
                  "version": "0.2.4",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/hueniverse/sntp"
                  },
                  "main": "index",
                  "keywords": [
                    "sntp",
                    "ntp",
                    "time"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {
                    "hoek": "0.9.x"
                  },
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/sntp/raw/master/LICENSE"
                    }
                  ],
                  "readme": "# sntp\n\nAn SNTP v4 client (RFC4330) for node. Simpy connects to the NTP or SNTP server requested and returns the server time\nalong with the roundtrip duration and clock offset. To adjust the local time to the NTP time, add the returned `t` offset\nto the local time.\n\n[![Build Status](https://secure.travis-ci.org/hueniverse/sntp.png)](http://travis-ci.org/hueniverse/sntp)\n\n# Usage\n\n```javascript\nvar Sntp = require('sntp');\n\n// All options are optional\n\nvar options = {\n    host: 'nist1-sj.ustiming.org',  // Defaults to pool.ntp.org\n    port: 123,                      // Defaults to 123 (NTP)\n    resolveReference: true,         // Default to false (not resolving)\n    timeout: 1000                   // Defaults to zero (no timeout)\n};\n\n// Request server time\n\nSntp.time(options, function (err, time) {\n\n    if (err) {\n        console.log('Failed: ' + err.message);\n        process.exit(1);\n    }\n\n    console.log('Local clock is off by: ' + time.t + ' milliseconds');\n    process.exit(0);\n});\n```\n\nIf an application needs to maintain continuous time synchronization, the module provides a stateful method for\nquerying the current offset only when the last one is too old (defaults to daily).\n\n```javascript\n// Request offset once\n\nSntp.offset(function (err, offset) {\n\n    console.log(offset);                    // New (served fresh)\n\n    // Request offset again\n\n    Sntp.offset(function (err, offset) {\n\n        console.log(offset);                // Identical (served from cache)\n    });\n});\n```\n\nTo set a background offset refresh, start the interval and use the provided now() method. If for any reason the\nclient fails to obtain an up-to-date offset, the current system clock is used.\n\n```javascript\nvar before = Sntp.now();                    // System time without offset\n\nSntp.start(function () {\n\n    var now = Sntp.now();                   // With offset\n    Sntp.stop();\n});\n```\n\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/hueniverse/sntp/issues"
                  },
                  "_id": "sntp@0.2.4",
                  "_from": "sntp@0.2.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "hoek": "./node_modules/hoek"
                    }
                  },
                  "mappings": {
                    "hoek": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek"
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "sntp",
                  "description": "SNTP Client",
                  "version": "0.2.4",
                  "locator": {
                    "pointer": "0.2.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/hueniverse/sntp/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/hueniverse/sntp"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "hoek": "0.9.x"
                    },
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    },
                    "bundled": {
                      "hoek": "./node_modules/hoek",
                      "boom": "../boom",
                      "cryptiles": "../cryptiles",
                      "sntp": "."
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/sntp/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "sntp",
                    "ntp",
                    "time"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "hoek": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek",
                    "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                    "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                    "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                  }
                }
              },
              "combined": {
                "name": "sntp",
                "description": "SNTP Client",
                "version": "0.2.4",
                "locator": {
                  "pointer": "0.2.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/hueniverse/sntp/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/hueniverse/sntp"
                  }
                ],
                "dependencies": {
                  "required": {
                    "hoek": "0.9.x"
                  },
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "bundled": {
                    "hoek": "./node_modules/hoek",
                    "boom": "../boom",
                    "cryptiles": "../cryptiles",
                    "sntp": "."
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/hueniverse/sntp/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "sntp",
                  "ntp",
                  "time"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "hoek": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek",
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                  "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                  "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp/index.js",
                "mappings": {
                  "hoek": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek"
                },
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/sntp"
              }
            },
            "wrapper": "json"
          },
          "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/package.json": {
            "requireId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/package.json",
            "memoizeId": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek",
              "id": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/package.json",
                "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.9.1",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  },
                  "main": "index",
                  "keywords": [
                    "utilities"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {},
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "readme": "<a href=\"https://github.com/spumko\"><img src=\"https://raw.github.com/spumko/spumko/master/images/from.png\" align=\"right\" /></a>\r\n![hoek Logo](https://raw.github.com/spumko/hoek/master/images/hoek.png)\r\n\r\nGeneral purpose node utilities\r\n\r\n[![Build Status](https://secure.travis-ci.org/spumko/hoek.png)](http://travis-ci.org/spumko/hoek)\r\n\r\n# Table of Contents\r\n\r\n* [Introduction](#introduction \"Introduction\")\r\n* [Object](#object \"Object\")\r\n  * [clone](#cloneobj \"clone\")\r\n  * [merge](#mergetarget-source-isnulloverride-ismergearrays \"merge\")\r\n  * [applyToDefaults](#applytodefaultsdefaults-options \"applyToDefaults\")\r\n  * [unique](#uniquearray-key \"unique\")\r\n  * [mapToObject](#maptoobjectarray-key \"mapToObject\")\r\n  * [intersect](#intersectarray1-array2 \"intersect\")\r\n  * [matchKeys](#matchkeysobj-keys \"matchKeys\")\r\n  * [flatten](#flattenarray-target \"flatten\")\r\n  * [removeKeys](#removekeysobject-keys \"removeKeys\")\r\n  * [reach](#reachobj-chain \"reach\")\r\n  * [inheritAsync](#inheritasyncself-obj-keys \"inheritAsync\")\r\n  * [rename](#renameobj-from-to \"rename\")\r\n* [Timer](#timer \"Timer\")\r\n* [Binary Encoding/Decoding](#binary \"Binary Encoding/Decoding\")\r\n  * [base64urlEncode](#binary64urlEncodevalue \"binary64urlEncode\")\r\n  * [base64urlDecode](#binary64urlDecodevalue \"binary64urlDecode\")\r\n* [Escaping Characters](#escaped \"Escaping Characters\")\r\n  * [escapeHtml](#escapeHtmlstring \"escapeHtml\")\r\n  * [escapeHeaderAttribute](#escapeHeaderAttributeattribute \"escapeHeaderAttribute\")\r\n  * [escapeRegex](#escapeRegexstring \"escapeRegex\")\r\n* [Errors](#errors \"Errors\")\r\n  * [assert](#assertmessage \"assert\")\r\n  * [abort](#abortmessage \"abort\")\r\n  * [displayStack](#displayStackslice \"displayStack\")\r\n  * [callStack](#callStackslice \"callStack\")\r\n  * [toss](#tosscondition \"toss\")\r\n* [Load files](#load-files \"Load Files\")\r\n  * [loadPackage](#loadPackagedir \"loadpackage\")\r\n  * [loadDirModules](#loadDirModulespath-excludefiles-target \"loaddirmodules\")\r\n\r\n\r\n\r\n# Introduction\r\n\r\nThe *Hoek* general purpose node utilities library is used to aid in a variety of manners. It comes with useful methods for Arrays (clone, merge, applyToDefaults), Objects (removeKeys, copy), Asserting and more. \r\n\r\nFor example, to use Hoek to set configuration with default options:\r\n```javascript\r\nvar Hoek = require('hoek');\r\n\r\nvar default = {url : \"www.github.com\", port : \"8000\", debug : true}\r\n\r\nvar config = Hoek.applyToDefaults(default, {port : \"3000\", admin : true});\r\n\r\n// In this case, config would be { url: 'www.github.com', port: '3000', debug: true, admin: true }\r\n```\r\n\r\nUnder each of the sections (such as Array), there are subsections which correspond to Hoek methods. Each subsection will explain how to use the corresponding method. In each js excerpt below, the var Hoek = require('hoek') is omitted for brevity.\r\n\r\n## Object\r\n\r\nHoek provides several helpful methods for objects and arrays.\r\n\r\n### clone(obj)\r\n\r\nThis method is used to clone an object or an array. A *deep copy* is made (duplicates everything, including values that are objects). \r\n\r\n```javascript\r\n\r\nvar nestedObj = {\r\n        w: /^something$/ig,\r\n        x: {\r\n            a: [1, 2, 3],\r\n            b: 123456,\r\n            c: new Date()\r\n        },\r\n        y: 'y',\r\n        z: new Date()\r\n    };\r\n\r\nvar copy = Hoek.clone(nestedObj);\r\n\r\ncopy.x.b = 100;\r\n\r\nconsole.log(copy.y)        // results in 'y'\r\nconsole.log(nestedObj.x.b) // results in 123456\r\nconsole.log(copy.x.b)      // results in 100\r\n```\r\n\r\n### merge(target, source, isNullOverride, isMergeArrays)\r\nisNullOverride, isMergeArrays default to true\r\n\r\nMerge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\n\r\n```javascript\r\n\r\nvar target = {a: 1, b : 2}\r\nvar source = {a: 0, c: 5}\r\nvar source2 = {a: null, c: 5}\r\n\r\nvar targetArray = [1, 2, 3];\r\nvar sourceArray = [4, 5];\r\n\r\nvar newTarget = Hoek.merge(target, source);     // results in {a: 0, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2);        // results in {a: null, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2, false); // results in {a: 1, b: 2, c: 5}\r\n\r\nnewTarget = Hoek.merge(targetArray, sourceArray)              // results in [1, 2, 3, 4, 5]\r\nnewTarget = Hoek.merge(targetArray, sourceArray, true, false) // results in [4, 5]\r\n\r\n\r\n\r\n\r\n```\r\n\r\n### applyToDefaults(defaults, options)\r\n\r\nApply options to a copy of the defaults\r\n\r\n```javascript\r\n\r\nvar defaults = {host: \"localhost\", port: 8000};\r\nvar options = {port: 8080};\r\n\r\nvar config = Hoek.applyToDefaults(defaults, options); // results in {host: \"localhost\", port: 8080};\r\n\r\n\r\n```\r\n\r\n### unique(array, key)\r\n\r\nRemove duplicate items from Array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 2, 3, 3, 4, 5, 6];\r\n\r\nvar newArray = Hoek.unique(array); // results in [1,2,3,4,5,6];\r\n\r\narray = [{id: 1}, {id: 1}, {id: 2}];\r\n\r\nnewArray = Hoek.unique(array, \"id\") // results in [{id: 1}, {id: 2}]\r\n\r\n```\r\n\r\n### mapToObject(array, key)\r\n\r\nConvert an Array into an Object\r\n\r\n```javascript\r\n\r\nvar array = [1,2,3];\r\nvar newObject = Hoek.mapToObject(array); // results in [{\"1\": true}, {\"2\": true}, {\"3\": true}]\r\n\r\narray = [{id: 1}, {id: 2}];\r\nnewObject = Hoek.mapToObject(array, \"id\") // results in [{\"id\": 1}, {\"id\": 2}]\r\n\r\n```\r\n### intersect(array1, array2)\r\n\r\nFind the common unique items in two arrays\r\n\r\n```javascript\r\n\r\nvar array1 = [1, 2, 3];\r\nvar array2 = [1, 4, 5];\r\n\r\nvar newArray = Hoek.intersect(array1, array2) // results in [1]\r\n\r\n```\r\n\r\n### matchKeys(obj, keys) \r\n\r\nFind which keys are present\r\n\r\n```javascript\r\n\r\nvar obj = {a: 1, b: 2, c: 3};\r\nvar keys = [\"a\", \"e\"];\r\n\r\nHoek.matchKeys(obj, keys) // returns [\"a\"]\r\n\r\n```\r\n\r\n### flatten(array, target)\r\n\r\nFlatten an array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 3];\r\nvar target = [4, 5]; \r\n\r\nvar flattenedArray = Hoek.flatten(array, target) // results in [4, 5, 1, 2, 3];\r\n\r\n```\r\n\r\n### removeKeys(object, keys)\r\n\r\nRemove keys\r\n\r\n```javascript\r\n\r\nvar object = {a: 1, b: 2, c: 3, d: 4};\r\n\r\nvar keys = [\"a\", \"b\"];\r\n\r\nHoek.removeKeys(object, keys) // object is now {c: 3, d: 4}\r\n\r\n```\r\n\r\n### reach(obj, chain)\r\n\r\nConverts an object key chain string to reference\r\n\r\n```javascript\r\n\r\nvar chain = 'a.b.c';\r\nvar obj = {a : {b : { c : 1}}};\r\n\r\nHoek.reach(obj, chain) // returns 1\r\n\r\n```\r\n\r\n### inheritAsync(self, obj, keys) \r\n\r\nInherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\n```javascript\r\n\r\nvar targetFunc = function () { };\r\n\r\nvar proto = {\r\n                a: function () {\r\n                    return 'a!';\r\n                },\r\n                b: function () {\r\n                    return 'b!';\r\n                },\r\n                c: function () {\r\n                    throw new Error('c!');\r\n                }\r\n            };\r\n\r\nvar keys = ['a', 'c'];\r\n\r\nHoek.inheritAsync(targetFunc, proto, ['a', 'c']);\r\n\r\nvar target = new targetFunc();\r\n\r\ntarget.a(function(err, result){console.log(result)}         // returns 'a!'       \r\n\r\ntarget.c(function(err, result){console.log(result)}         // returns undefined\r\n\r\ntarget.b(function(err, result){console.log(result)}         // gives error: Object [object Object] has no method 'b'\r\n\r\n```\r\n\r\n### rename(obj, from, to)\r\n\r\nRename a key of an object\r\n\r\n```javascript\r\n\r\nvar obj = {a : 1, b : 2};\r\n\r\nHoek.rename(obj, \"a\", \"c\");     // obj is now {c : 1, b : 2}\r\n\r\n```\r\n\r\n\r\n# Timer\r\n\r\nA Timer object. Initializing a new timer object sets the ts to the number of milliseconds elapsed since 1 January 1970 00:00:00 UTC.\r\n\r\n```javascript\r\n\r\n\r\nexample : \r\n\r\n\r\nvar timerObj = new Hoek.Timer();\r\nconsole.log(\"Time is now: \" + timerObj.ts)\r\nconsole.log(\"Elapsed time from initialization: \" + timerObj.elapsed() + 'milliseconds')\r\n\r\n```\r\n\r\n# Binary Encoding/Decoding\r\n\r\n### base64urlEncode(value)\r\n\r\nEncodes value in Base64 or URL encoding\r\n\r\n### base64urlDecode(value)\r\n\r\nDecodes data in Base64 or URL encoding.\r\n# Escaping Characters\r\n\r\nHoek provides convenient methods for escaping html characters. The escaped characters are as followed:\r\n\r\n```javascript\r\n\r\ninternals.htmlEscaped = {\r\n    '&': '&amp;',\r\n    '<': '&lt;',\r\n    '>': '&gt;',\r\n    '\"': '&quot;',\r\n    \"'\": '&#x27;',\r\n    '`': '&#x60;'\r\n};\r\n\r\n```\r\n\r\n### escapeHtml(string)\r\n\r\n```javascript\r\n\r\nvar string = '<html> hey </html>';\r\nvar escapedString = Hoek.escapeHtml(string); // returns &lt;html&gt; hey &lt;/html&gt;\r\n\r\n```\r\n\r\n### escapeHeaderAttribute(attribute)\r\n\r\nEscape attribute value for use in HTTP header\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeHeaderAttribute('I said \"go w\\\\o me\"');  //returns I said \\\"go w\\\\o me\\\"\r\n\r\n\r\n```\r\n\r\n\r\n### escapeRegex(string)\r\n\r\nEscape string for Regex construction\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeRegex('4^f$s.4*5+-_?%=#!:@|~\\\\/`\"(>)[<]d{}s,');  // returns 4\\^f\\$s\\.4\\*5\\+\\-_\\?%\\=#\\!\\:@\\|~\\\\\\/`\"\\(>\\)\\[<\\]d\\{\\}s\\,\r\n\r\n\r\n\r\n```\r\n\r\n# Errors\r\n\r\n### assert(message)\r\n\r\n```javascript\r\n\r\nvar a = 1, b =2;\r\n\r\nHoek.assert(a === b, 'a should equal b');  // ABORT: a should equal b\r\n\r\n```\r\n\r\n### abort(message)\r\n\r\nFirst checks if process.env.NODE_ENV === 'test', and if so, throws error message. Otherwise,\r\ndisplays most recent stack and then exits process.\r\n\r\n\r\n\r\n### displayStack(slice)\r\n\r\nDisplays the trace stack\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.displayStack();\r\nconsole.log(stack) // returns something like:\r\n\r\n[ 'null (/Users/user/Desktop/hoek/test.js:4:18)',\r\n  'Module._compile (module.js:449:26)',\r\n  'Module._extensions..js (module.js:467:10)',\r\n  'Module.load (module.js:356:32)',\r\n  'Module._load (module.js:312:12)',\r\n  'Module.runMain (module.js:492:10)',\r\n  'startup.processNextTick.process._tickCallback (node.js:244:9)' ]\r\n\r\n```\r\n\r\n### callStack(slice)\r\n\r\nReturns a trace stack array.\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.callStack();\r\nconsole.log(stack)  // returns something like:\r\n\r\n[ [ '/Users/user/Desktop/hoek/test.js', 4, 18, null, false ],\r\n  [ 'module.js', 449, 26, 'Module._compile', false ],\r\n  [ 'module.js', 467, 10, 'Module._extensions..js', false ],\r\n  [ 'module.js', 356, 32, 'Module.load', false ],\r\n  [ 'module.js', 312, 12, 'Module._load', false ],\r\n  [ 'module.js', 492, 10, 'Module.runMain', false ],\r\n  [ 'node.js',\r\n    244,\r\n    9,\r\n    'startup.processNextTick.process._tickCallback',\r\n    false ] ]\r\n\r\n\r\n```\r\n\r\n### toss(condition)\r\n\r\ntoss(condition /*, [message], callback */)\r\n\r\nReturn an error as first argument of a callback\r\n\r\n\r\n# Load Files\r\n\r\n### loadPackage(dir)\r\n\r\nLoad and parse package.json process root or given directory\r\n\r\n```javascript\r\n\r\nvar pack = Hoek.loadPackage();  // pack.name === 'hoek'\r\n\r\n```\r\n\r\n### loadDirModules(path, excludeFiles, target) \r\n\r\nLoads modules from a given path; option to exclude files (array).\r\n\r\n\r\n\r\n\r\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  },
                  "_id": "hoek@0.9.1",
                  "_from": "hoek@0.9.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.9.1",
                  "locator": {
                    "pointer": "0.9.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/spumko/hoek/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/spumko/hoek"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "utilities"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "hoek",
                "description": "General purpose node utilities",
                "version": "0.9.1",
                "locator": {
                  "pointer": "0.9.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  }
                ],
                "dependencies": {
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "utilities"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  {
                    "name": "Van Nguyen",
                    "email": "the.gol.effect@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "d5ffe40658ed1d8bb0108338b7999512eedb8a6f-hoek/index.js",
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/sntp/node_modules/hoek"
              }
            },
            "wrapper": "json"
          },
          "f7d6999ac201573ce8335e058ee0439994171772-hoek/package.json": {
            "requireId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/package.json",
            "memoizeId": "f7d6999ac201573ce8335e058ee0439994171772-hoek/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/hoek",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/hoek",
              "id": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/hoek/package.json",
                "node_modules/request/node_modules/hawk/node_modules/hoek/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/hoek/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.8.5",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  },
                  "main": "index",
                  "keywords": [
                    "utilities"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {},
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "readme": "<a href=\"https://github.com/spumko\"><img src=\"https://raw.github.com/spumko/spumko/master/images/from.png\" align=\"right\" /></a>\r\n![hoek Logo](https://raw.github.com/spumko/hoek/master/images/hoek.png)\r\n\r\nGeneral purpose node utilities\r\n\r\n[![Build Status](https://secure.travis-ci.org/spumko/hoek.png)](http://travis-ci.org/spumko/hoek)\r\n\r\n# Table of Contents\r\n\r\n* [Introduction](#introduction \"Introduction\")\r\n* [Object](#object \"Object\")\r\n  * [clone](#cloneobj \"clone\")\r\n  * [merge](#mergetarget-source-isnulloverride-ismergearrays \"merge\")\r\n  * [applyToDefaults](#applytodefaultsdefaults-options \"applyToDefaults\")\r\n  * [unique](#uniquearray-key \"unique\")\r\n  * [mapToObject](#maptoobjectarray-key \"mapToObject\")\r\n  * [intersect](#intersectarray1-array2 \"intersect\")\r\n  * [matchKeys](#matchkeysobj-keys \"matchKeys\")\r\n  * [flatten](#flattenarray-target \"flatten\")\r\n  * [removeKeys](#removekeysobject-keys \"removeKeys\")\r\n  * [reach](#reachobj-chain \"reach\")\r\n  * [inheritAsync](#inheritasyncself-obj-keys \"inheritAsync\")\r\n  * [rename](#renameobj-from-to \"rename\")\r\n* [Timer](#timer \"Timer\")\r\n* [Binary Encoding/Decoding](#binary \"Binary Encoding/Decoding\")\r\n  * [base64urlEncode](#binary64urlEncodevalue \"binary64urlEncode\")\r\n  * [base64urlDecode](#binary64urlDecodevalue \"binary64urlDecode\")\r\n* [Escaping Characters](#escaped \"Escaping Characters\")\r\n  * [escapeHtml](#escapeHtmlstring \"escapeHtml\")\r\n  * [escapeHeaderAttribute](#escapeHeaderAttributeattribute \"escapeHeaderAttribute\")\r\n  * [escapeRegex](#escapeRegexstring \"escapeRegex\")\r\n* [Errors](#errors \"Errors\")\r\n  * [assert](#assertmessage \"assert\")\r\n  * [abort](#abortmessage \"abort\")\r\n  * [displayStack](#displayStackslice \"displayStack\")\r\n  * [callStack](#callStackslice \"callStack\")\r\n  * [toss](#tosscondition \"toss\")\r\n* [Load files](#load-files \"Load Files\")\r\n  * [loadPackage](#loadPackagedir \"loadpackage\")\r\n  * [loadDirModules](#loadDirModulespath-excludefiles-target \"loaddirmodules\")\r\n\r\n\r\n\r\n# Introduction\r\n\r\nThe *Hoek* general purpose node utilities library is used to aid in a variety of manners. It comes with useful methods for Arrays (clone, merge, applyToDefaults), Objects (removeKeys, copy), Asserting and more. \r\n\r\nFor example, to use Hoek to set configuration with default options:\r\n```javascript\r\nvar Hoek = require('hoek');\r\n\r\nvar default = {url : \"www.github.com\", port : \"8000\", debug : true}\r\n\r\nvar config = Hoek.applyToDefaults(default, {port : \"3000\", admin : true});\r\n\r\n// In this case, config would be { url: 'www.github.com', port: '3000', debug: true, admin: true }\r\n```\r\n\r\nUnder each of the sections (such as Array), there are subsections which correspond to Hoek methods. Each subsection will explain how to use the corresponding method. In each js excerpt below, the var Hoek = require('hoek') is omitted for brevity.\r\n\r\n## Object\r\n\r\nHoek provides several helpful methods for objects and arrays.\r\n\r\n### clone(obj)\r\n\r\nThis method is used to clone an object or an array. A *deep copy* is made (duplicates everything, including values that are objects). \r\n\r\n```javascript\r\n\r\nvar nestedObj = {\r\n        w: /^something$/ig,\r\n        x: {\r\n            a: [1, 2, 3],\r\n            b: 123456,\r\n            c: new Date()\r\n        },\r\n        y: 'y',\r\n        z: new Date()\r\n    };\r\n\r\nvar copy = Hoek.clone(nestedObj);\r\n\r\ncopy.x.b = 100;\r\n\r\nconsole.log(copy.y)        // results in 'y'\r\nconsole.log(nestedObj.x.b) // results in 123456\r\nconsole.log(copy.x.b)      // results in 100\r\n```\r\n\r\n### merge(target, source, isNullOverride, isMergeArrays)\r\nisNullOverride, isMergeArrays default to true\r\n\r\nMerge all the properties of source into target, source wins in conflic, and by default null and undefined from source are applied\r\n\r\n\r\n```javascript\r\n\r\nvar target = {a: 1, b : 2}\r\nvar source = {a: 0, c: 5}\r\nvar source2 = {a: null, c: 5}\r\n\r\nvar targetArray = [1, 2, 3];\r\nvar sourceArray = [4, 5];\r\n\r\nvar newTarget = Hoek.merge(target, source);     // results in {a: 0, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2);        // results in {a: null, b: 2, c: 5}\r\nnewTarget = Hoek.merge(target, source2, false); // results in {a: 1, b: 2, c: 5}\r\n\r\nnewTarget = Hoek.merge(targetArray, sourceArray)              // results in [1, 2, 3, 4, 5]\r\nnewTarget = Hoek.merge(targetArray, sourceArray, true, false) // results in [4, 5]\r\n\r\n\r\n\r\n\r\n```\r\n\r\n### applyToDefaults(defaults, options)\r\n\r\nApply options to a copy of the defaults\r\n\r\n```javascript\r\n\r\nvar defaults = {host: \"localhost\", port: 8000};\r\nvar options = {port: 8080};\r\n\r\nvar config = Hoek.applyToDefaults(defaults, options); // results in {host: \"localhost\", port: 8080};\r\n\r\n\r\n```\r\n\r\n### unique(array, key)\r\n\r\nRemove duplicate items from Array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 2, 3, 3, 4, 5, 6];\r\n\r\nvar newArray = Hoek.unique(array); // results in [1,2,3,4,5,6];\r\n\r\narray = [{id: 1}, {id: 1}, {id: 2}];\r\n\r\nnewArray = Hoek.unique(array, \"id\") // results in [{id: 1}, {id: 2}]\r\n\r\n```\r\n\r\n### mapToObject(array, key)\r\n\r\nConvert an Array into an Object\r\n\r\n```javascript\r\n\r\nvar array = [1,2,3];\r\nvar newObject = Hoek.mapToObject(array); // results in [{\"1\": true}, {\"2\": true}, {\"3\": true}]\r\n\r\narray = [{id: 1}, {id: 2}];\r\nnewObject = Hoek.mapToObject(array, \"id\") // results in [{\"id\": 1}, {\"id\": 2}]\r\n\r\n```\r\n### intersect(array1, array2)\r\n\r\nFind the common unique items in two arrays\r\n\r\n```javascript\r\n\r\nvar array1 = [1, 2, 3];\r\nvar array2 = [1, 4, 5];\r\n\r\nvar newArray = Hoek.intersect(array1, array2) // results in [1]\r\n\r\n```\r\n\r\n### matchKeys(obj, keys) \r\n\r\nFind which keys are present\r\n\r\n```javascript\r\n\r\nvar obj = {a: 1, b: 2, c: 3};\r\nvar keys = [\"a\", \"e\"];\r\n\r\nHoek.matchKeys(obj, keys) // returns [\"a\"]\r\n\r\n```\r\n\r\n### flatten(array, target)\r\n\r\nFlatten an array\r\n\r\n```javascript\r\n\r\nvar array = [1, 2, 3];\r\nvar target = [4, 5]; \r\n\r\nvar flattenedArray = Hoek.flatten(array, target) // results in [4, 5, 1, 2, 3];\r\n\r\n```\r\n\r\n### removeKeys(object, keys)\r\n\r\nRemove keys\r\n\r\n```javascript\r\n\r\nvar object = {a: 1, b: 2, c: 3, d: 4};\r\n\r\nvar keys = [\"a\", \"b\"];\r\n\r\nHoek.removeKeys(object, keys) // object is now {c: 3, d: 4}\r\n\r\n```\r\n\r\n### reach(obj, chain)\r\n\r\nConverts an object key chain string to reference\r\n\r\n```javascript\r\n\r\nvar chain = 'a.b.c';\r\nvar obj = {a : {b : { c : 1}}};\r\n\r\nHoek.reach(obj, chain) // returns 1\r\n\r\n```\r\n\r\n### inheritAsync(self, obj, keys) \r\n\r\nInherits a selected set of methods from an object, wrapping functions in asynchronous syntax and catching errors\r\n\r\n```javascript\r\n\r\nvar targetFunc = function () { };\r\n\r\nvar proto = {\r\n                a: function () {\r\n                    return 'a!';\r\n                },\r\n                b: function () {\r\n                    return 'b!';\r\n                },\r\n                c: function () {\r\n                    throw new Error('c!');\r\n                }\r\n            };\r\n\r\nvar keys = ['a', 'c'];\r\n\r\nHoek.inheritAsync(targetFunc, proto, ['a', 'c']);\r\n\r\nvar target = new targetFunc();\r\n\r\ntarget.a(function(err, result){console.log(result)}         // returns 'a!'       \r\n\r\ntarget.c(function(err, result){console.log(result)}         // returns undefined\r\n\r\ntarget.b(function(err, result){console.log(result)}         // gives error: Object [object Object] has no method 'b'\r\n\r\n```\r\n\r\n### rename(obj, from, to)\r\n\r\nRename a key of an object\r\n\r\n```javascript\r\n\r\nvar obj = {a : 1, b : 2};\r\n\r\nHoek.rename(obj, \"a\", \"c\");     // obj is now {c : 1, b : 2}\r\n\r\n```\r\n\r\n\r\n# Timer\r\n\r\nA Timer object. Initializing a new timer object sets the ts to the number of milliseconds elapsed since 1 January 1970 00:00:00 UTC.\r\n\r\n```javascript\r\n\r\n\r\nexample : \r\n\r\n\r\nvar timerObj = new Hoek.Timer();\r\nconsole.log(\"Time is now: \" + timerObj.ts)\r\nconsole.log(\"Elapsed time from initialization: \" + timerObj.elapsed() + 'milliseconds')\r\n\r\n```\r\n\r\n# Binary Encoding/Decoding\r\n\r\n### base64urlEncode(value)\r\n\r\nEncodes value in Base64 or URL encoding\r\n\r\n### base64urlDecode(value)\r\n\r\nDecodes data in Base64 or URL encoding.\r\n# Escaping Characters\r\n\r\nHoek provides convenient methods for escaping html characters. The escaped characters are as followed:\r\n\r\n```javascript\r\n\r\ninternals.htmlEscaped = {\r\n    '&': '&amp;',\r\n    '<': '&lt;',\r\n    '>': '&gt;',\r\n    '\"': '&quot;',\r\n    \"'\": '&#x27;',\r\n    '`': '&#x60;'\r\n};\r\n\r\n```\r\n\r\n### escapeHtml(string)\r\n\r\n```javascript\r\n\r\nvar string = '<html> hey </html>';\r\nvar escapedString = Hoek.escapeHtml(string); // returns &lt;html&gt; hey &lt;/html&gt;\r\n\r\n```\r\n\r\n### escapeHeaderAttribute(attribute)\r\n\r\nEscape attribute value for use in HTTP header\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeHeaderAttribute('I said \"go w\\\\o me\"');  //returns I said \\\"go w\\\\o me\\\"\r\n\r\n\r\n```\r\n\r\n\r\n### escapeRegex(string)\r\n\r\nEscape string for Regex construction\r\n\r\n```javascript\r\n\r\nvar a = Hoek.escapeRegex('4^f$s.4*5+-_?%=#!:@|~\\\\/`\"(>)[<]d{}s,');  // returns 4\\^f\\$s\\.4\\*5\\+\\-_\\?%\\=#\\!\\:@\\|~\\\\\\/`\"\\(>\\)\\[<\\]d\\{\\}s\\,\r\n\r\n\r\n\r\n```\r\n\r\n# Errors\r\n\r\n### assert(message)\r\n\r\n```javascript\r\n\r\nvar a = 1, b =2;\r\n\r\nHoek.assert(a === b, 'a should equal b');  // ABORT: a should equal b\r\n\r\n```\r\n\r\n### abort(message)\r\n\r\nFirst checks if process.env.NODE_ENV === 'test', and if so, throws error message. Otherwise,\r\ndisplays most recent stack and then exits process.\r\n\r\n\r\n\r\n### displayStack(slice)\r\n\r\nDisplays the trace stack\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.displayStack();\r\nconsole.log(stack) // returns something like:\r\n\r\n[ 'null (/Users/user/Desktop/hoek/test.js:4:18)',\r\n  'Module._compile (module.js:449:26)',\r\n  'Module._extensions..js (module.js:467:10)',\r\n  'Module.load (module.js:356:32)',\r\n  'Module._load (module.js:312:12)',\r\n  'Module.runMain (module.js:492:10)',\r\n  'startup.processNextTick.process._tickCallback (node.js:244:9)' ]\r\n\r\n```\r\n\r\n### callStack(slice)\r\n\r\nReturns a trace stack array.\r\n\r\n```javascript\r\n\r\nvar stack = Hoek.callStack();\r\nconsole.log(stack)  // returns something like:\r\n\r\n[ [ '/Users/user/Desktop/hoek/test.js', 4, 18, null, false ],\r\n  [ 'module.js', 449, 26, 'Module._compile', false ],\r\n  [ 'module.js', 467, 10, 'Module._extensions..js', false ],\r\n  [ 'module.js', 356, 32, 'Module.load', false ],\r\n  [ 'module.js', 312, 12, 'Module._load', false ],\r\n  [ 'module.js', 492, 10, 'Module.runMain', false ],\r\n  [ 'node.js',\r\n    244,\r\n    9,\r\n    'startup.processNextTick.process._tickCallback',\r\n    false ] ]\r\n\r\n\r\n```\r\n\r\n### toss(condition)\r\n\r\ntoss(condition /*, [message], callback */)\r\n\r\nReturn an error as first argument of a callback\r\n\r\n\r\n# Load Files\r\n\r\n### loadPackage(dir)\r\n\r\nLoad and parse package.json process root or given directory\r\n\r\n```javascript\r\n\r\nvar pack = Hoek.loadPackage();  // pack.name === 'hoek'\r\n\r\n```\r\n\r\n### loadDirModules(path, excludeFiles, target) \r\n\r\nLoads modules from a given path; option to exclude files (array).\r\n\r\n\r\n\r\n\r\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  },
                  "_id": "hoek@0.8.5",
                  "_from": "hoek@0.8.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "hoek",
                  "description": "General purpose node utilities",
                  "version": "0.8.5",
                  "locator": {
                    "pointer": "0.8.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/spumko/hoek/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/spumko/hoek"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "utilities"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    },
                    {
                      "name": "Van Nguyen",
                      "email": "the.gol.effect@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "hoek",
                "description": "General purpose node utilities",
                "version": "0.8.5",
                "locator": {
                  "pointer": "0.8.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/spumko/hoek/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/spumko/hoek"
                  }
                ],
                "dependencies": {
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/spumko/hoek/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "utilities"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  {
                    "name": "Van Nguyen",
                    "email": "the.gol.effect@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "f7d6999ac201573ce8335e058ee0439994171772-hoek/index.js",
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/hoek"
              }
            },
            "wrapper": "json"
          },
          "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/package.json": {
            "requireId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/package.json",
            "memoizeId": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/hawk/node_modules/cryptiles",
              "dirrealpath": "node_modules/request/node_modules/hawk/node_modules/cryptiles",
              "id": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
              "lookupPaths": [
                "node_modules/request/node_modules/hawk/node_modules/cryptiles/package.json",
                "node_modules/request/node_modules/hawk/node_modules/cryptiles/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/hawk/node_modules/cryptiles/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "cryptiles",
                  "description": "General purpose crypto utilities",
                  "version": "0.2.2",
                  "author": {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  },
                  "contributors": [],
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/hueniverse/cryptiles"
                  },
                  "main": "index",
                  "keywords": [
                    "cryptography",
                    "security",
                    "utilites"
                  ],
                  "engines": {
                    "node": ">=0.8.0"
                  },
                  "dependencies": {
                    "boom": "0.4.x"
                  },
                  "devDependencies": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/cryptiles/raw/master/LICENSE"
                    }
                  ],
                  "readme": "cryptiles\n=========\n\nGeneral purpose crypto utilities\n\n[![Build Status](https://secure.travis-ci.org/hueniverse/cryptiles.png)](http://travis-ci.org/hueniverse/cryptiles)\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/hueniverse/cryptiles/issues"
                  },
                  "_id": "cryptiles@0.2.2",
                  "_from": "cryptiles@0.2.x"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "cryptiles",
                  "description": "General purpose crypto utilities",
                  "version": "0.2.2",
                  "locator": {
                    "pointer": "0.2.x"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/hueniverse/cryptiles/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/hueniverse/cryptiles"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "boom": "0.4.x"
                    },
                    "development": {
                      "lab": "0.1.x",
                      "complexity-report": "0.x.x"
                    },
                    "bundled": {
                      "boom": "../boom",
                      "cryptiles": ".",
                      "hoek": "../hoek",
                      "sntp": "../sntp"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test-cov"
                    },
                    "main": "./index.js"
                  },
                  "licenses": [
                    {
                      "type": "BSD",
                      "url": "http://github.com/hueniverse/cryptiles/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "cryptography",
                    "security",
                    "utilites"
                  ],
                  "contributors": [
                    {
                      "name": "Eran Hammer",
                      "email": "eran@hueniverse.com",
                      "url": "http://hueniverse.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                    "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                    "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                    "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                  }
                }
              },
              "combined": {
                "name": "cryptiles",
                "description": "General purpose crypto utilities",
                "version": "0.2.2",
                "locator": {
                  "pointer": "0.2.x"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/hueniverse/cryptiles/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/hueniverse/cryptiles"
                  }
                ],
                "dependencies": {
                  "required": {
                    "boom": "0.4.x"
                  },
                  "development": {
                    "lab": "0.1.x",
                    "complexity-report": "0.x.x"
                  },
                  "bundled": {
                    "boom": "../boom",
                    "cryptiles": ".",
                    "hoek": "../hoek",
                    "sntp": "../sntp"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test-cov"
                  },
                  "main": "./index.js"
                },
                "licenses": [
                  {
                    "type": "BSD",
                    "url": "http://github.com/hueniverse/cryptiles/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "cryptography",
                  "security",
                  "utilites"
                ],
                "contributors": [
                  {
                    "name": "Eran Hammer",
                    "email": "eran@hueniverse.com",
                    "url": "http://hueniverse.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom",
                  "cryptiles": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles",
                  "hoek": "f7d6999ac201573ce8335e058ee0439994171772-hoek",
                  "sntp": "99cc0c112bc5e48183c985f6e4c69af129c98ba7-sntp"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "0d16239d3ef60fdd17d17b1d50d2c59ee8e63166-cryptiles/index.js",
                "mappings": {
                  "boom": "799caeb4798b9c4de483910de2aa52868f1f47d9-boom"
                },
                "dirpath": "node_modules/request/node_modules/hawk/node_modules/cryptiles"
              }
            },
            "wrapper": "json"
          },
          "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/package.json": {
            "requireId": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/package.json",
            "memoizeId": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/aws-sign",
              "dirrealpath": "node_modules/request/node_modules/aws-sign",
              "id": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
              "lookupPaths": [
                "node_modules/request/node_modules/aws-sign/package.json",
                "node_modules/request/node_modules/aws-sign/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/aws-sign/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  },
                  "name": "aws-sign",
                  "description": "AWS signing. Originally pulled from LearnBoost/knox, maintained as vendor in request, now a standalone module.",
                  "version": "0.3.0",
                  "repository": {
                    "url": "https://github.com/mikeal/aws-sign"
                  },
                  "main": "index.js",
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": "*"
                  },
                  "readme": "aws-sign\n========\n\nAWS signing. Originally pulled from LearnBoost/knox, maintained as vendor in request, now a standalone module.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mikeal/aws-sign/issues"
                  },
                  "_id": "aws-sign@0.3.0",
                  "_from": "aws-sign@~0.3.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "aws-sign",
                  "description": "AWS signing. Originally pulled from LearnBoost/knox, maintained as vendor in request, now a standalone module.",
                  "version": "0.3.0",
                  "locator": {
                    "pointer": "~0.3.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mikeal/aws-sign/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/mikeal/aws-sign"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com",
                      "url": "http://www.futurealoof.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "aws-sign",
                "description": "AWS signing. Originally pulled from LearnBoost/knox, maintained as vendor in request, now a standalone module.",
                "version": "0.3.0",
                "locator": {
                  "pointer": "~0.3.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mikeal/aws-sign/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/mikeal/aws-sign"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign/index.js",
                "dirpath": "node_modules/request/node_modules/aws-sign"
              }
            },
            "wrapper": "json"
          },
          "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/package.json": {
            "requireId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/package.json",
            "memoizeId": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/http-signature",
              "dirrealpath": "node_modules/request/node_modules/http-signature",
              "id": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
              "lookupPaths": [
                "node_modules/request/node_modules/http-signature/package.json",
                "node_modules/request/node_modules/http-signature/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/http-signature/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Joyent, Inc"
                  },
                  "name": "http-signature",
                  "description": "Reference implementation of Joyent's HTTP Signature Scheme",
                  "version": "0.9.11",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/joyent/node-http-signature.git"
                  },
                  "engines": {
                    "node": ">=0.8"
                  },
                  "main": "lib/index.js",
                  "scripts": {
                    "test": "./node_modules/.bin/tap tst/*.js"
                  },
                  "dependencies": {
                    "assert-plus": "0.1.2",
                    "asn1": "0.1.11",
                    "ctype": "0.5.2"
                  },
                  "devDependencies": {
                    "node-uuid": "1.4.0",
                    "tap": "0.3.1"
                  },
                  "readme": "node-http-signature is a node.js library that has client and server components\nfor Joyent's `HTTP Signature Scheme`.\n\n## Usage\n\nNote the example below signs a request with the same key/cert used to start an\nHTTP server. This is almost certainly not what you actaully want, but is just\nused to illustrate the API calls; you will need to provide your own key\nmanagement in addition to this library.\n\n### Client\n\n    var fs = require('fs');\n    var https = require('https');\n    var httpSignature = require('http-signature');\n\n    var key = fs.readFileSync('./key.pem', 'ascii');\n\n    var options = {\n      host: 'localhost',\n      port: 8443,\n      path: '/',\n      method: 'GET',\n      headers: {}\n    };\n\n    // Adds a 'Date' header in, signs it, and adds the\n    // 'Authorization' header in.\n    var req = https.request(options, function(res) {\n      console.log(res.statusCode);\n    });\n\n\n    httpSignature.sign(req, {\n      key: key,\n      keyId: './cert.pem'\n    });\n\n    req.end();\n\n### Server\n\n    var fs = require('fs');\n    var https = require('https');\n    var httpSignature = require('http-signature');\n\n    var options = {\n      key: fs.readFileSync('./key.pem'),\n      cert: fs.readFileSync('./cert.pem')\n    };\n\n    https.createServer(options, function (req, res) {\n      var rc = 200;\n      var parsed = httpSignature.parseRequest(req);\n      var pub = fs.readFileSync(parsed.keyId, 'ascii');\n      if (!httpSignature.verifySignature(parsed, pub))\n        rc = 401;\n\n      res.writeHead(rc);\n      res.end();\n    }).listen(8443);\n\n## Installation\n\n    npm install http-signature\n\n## License\n\nMIT.\n\n## Bugs\n\nSee <https://github.com/joyent/node-http-signature/issues>.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/joyent/node-http-signature/issues"
                  },
                  "_id": "http-signature@0.9.11",
                  "_from": "http-signature@~0.9.11"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "asn1": "./node_modules/asn1",
                      "assert-plus": "./node_modules/assert-plus",
                      "ctype": "./node_modules/ctype"
                    }
                  },
                  "mappings": {
                    "asn1": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1",
                    "assert-plus": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus",
                    "ctype": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype"
                  }
                },
                "package.json": {
                  "name": "http-signature",
                  "description": "Reference implementation of Joyent's HTTP Signature Scheme",
                  "version": "0.9.11",
                  "locator": {
                    "pointer": "~0.9.11"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/joyent/node-http-signature/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/joyent/node-http-signature.git"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "assert-plus": "0.1.2",
                      "asn1": "0.1.11",
                      "ctype": "0.5.2"
                    },
                    "development": {
                      "node-uuid": "1.4.0",
                      "tap": "0.3.1"
                    },
                    "bundled": {
                      "asn1": "./node_modules/asn1",
                      "assert-plus": "./node_modules/assert-plus",
                      "ctype": "./node_modules/ctype"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.8"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "./node_modules/.bin/tap tst/*.js"
                    },
                    "main": "./lib/index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Joyent, Inc"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "asn1": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1",
                    "assert-plus": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus",
                    "ctype": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype"
                  }
                }
              },
              "combined": {
                "name": "http-signature",
                "description": "Reference implementation of Joyent's HTTP Signature Scheme",
                "version": "0.9.11",
                "locator": {
                  "pointer": "~0.9.11"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/joyent/node-http-signature/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/joyent/node-http-signature.git"
                  }
                ],
                "dependencies": {
                  "required": {
                    "assert-plus": "0.1.2",
                    "asn1": "0.1.11",
                    "ctype": "0.5.2"
                  },
                  "development": {
                    "node-uuid": "1.4.0",
                    "tap": "0.3.1"
                  },
                  "bundled": {
                    "asn1": "./node_modules/asn1",
                    "assert-plus": "./node_modules/assert-plus",
                    "ctype": "./node_modules/ctype"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.8"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "./node_modules/.bin/tap tst/*.js"
                  },
                  "main": "./lib/index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Joyent, Inc"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "asn1": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1",
                  "assert-plus": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus",
                  "ctype": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature/lib/index.js",
                "mappings": {
                  "assert-plus": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus",
                  "asn1": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1",
                  "ctype": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype"
                },
                "dirpath": "node_modules/request/node_modules/http-signature"
              }
            },
            "wrapper": "json"
          },
          "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/package.json": {
            "requireId": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/package.json",
            "memoizeId": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/http-signature/node_modules/assert-plus",
              "dirrealpath": "node_modules/request/node_modules/http-signature/node_modules/assert-plus",
              "id": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus",
              "lookupPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/assert-plus/package.json",
                "node_modules/request/node_modules/http-signature/node_modules/assert-plus/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/assert-plus/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mark Cavage",
                    "email": "mcavage@gmail.com"
                  },
                  "name": "assert-plus",
                  "description": "Extra assertions on top of node's assert module",
                  "version": "0.1.2",
                  "main": "./assert.js",
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": ">=0.6"
                  },
                  "readme": "# node-assert-plus\n\nThis library is a super small wrapper over node's assert module that has two\nthings: (1) the ability to disable assertions with the environment variable\nNODE_NDEBUG, and (2) some API wrappers for argument testing.  Like\n`assert.string(myArg, 'myArg')`.  As a simple example, most of my code looks\nlike this:\n\n    var assert = require('assert-plus');\n\n    function fooAccount(options, callback) {\n\t    assert.object(options, 'options');\n\t\tassert.number(options.id, 'options.id);\n\t\tassert.bool(options.isManager, 'options.isManager');\n\t\tassert.string(options.name, 'options.name');\n\t\tassert.arrayOfString(options.email, 'options.email');\n\t\tassert.func(callback, 'callback');\n\n        // Do stuff\n\t\tcallback(null, {});\n    }\n\n# API\n\nAll methods that *aren't* part of node's core assert API are simply assumed to\ntake an argument, and then a string 'name' that's not a message; `AssertionError`\nwill be thrown if the assertion fails with a message like:\n\n    AssertionError: foo (string) is required\n\tat test (/home/mark/work/foo/foo.js:3:9)\n\tat Object.<anonymous> (/home/mark/work/foo/foo.js:15:1)\n\tat Module._compile (module.js:446:26)\n\tat Object..js (module.js:464:10)\n\tat Module.load (module.js:353:31)\n\tat Function._load (module.js:311:12)\n\tat Array.0 (module.js:484:10)\n\tat EventEmitter._tickCallback (node.js:190:38)\n\nfrom:\n\n    function test(foo) {\n\t    assert.string(foo, 'foo');\n    }\n\nThere you go.  You can check that arrays are of a homogenous type with `Arrayof$Type`:\n\n    function test(foo) {\n\t    assert.arrayOfString(foo, 'foo');\n    }\n\nYou can assert IFF an argument is not `undefined` (i.e., an optional arg):\n\n    assert.optionalString(foo, 'foo');\n\nLastly, you can opt-out of assertion checking altogether by setting the\nenvironment variable `NODE_NDEBUG=1`.  This is pseudo-useful if you have\nlots of assertions, and don't want to pay `typeof ()` taxes to v8 in\nproduction.\n\nThe complete list of APIs is:\n\n* assert.bool\n* assert.buffer\n* assert.func\n* assert.number\n* assert.object\n* assert.string\n* assert.arrayOfBool\n* assert.arrayOfFunc\n* assert.arrayOfNumber\n* assert.arrayOfObject\n* assert.arrayOfString\n* assert.optionalBool\n* assert.optionalBuffer\n* assert.optionalFunc\n* assert.optionalNumber\n* assert.optionalObject\n* assert.optionalString\n* assert.optionalArrayOfBool\n* assert.optionalArrayOfFunc\n* assert.optionalArrayOfNumber\n* assert.optionalArrayOfObject\n* assert.optionalArrayOfString\n* assert.AssertionError\n* assert.fail\n* assert.ok\n* assert.equal\n* assert.notEqual\n* assert.deepEqual\n* assert.notDeepEqual\n* assert.strictEqual\n* assert.notStrictEqual\n* assert.throws\n* assert.doesNotThrow\n* assert.ifError\n\n# Installation\n\n    npm install assert-plus\n\n## License\n\nThe MIT License (MIT)\nCopyright (c) 2012 Mark Cavage\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n## Bugs\n\nSee <https://github.com/mcavage/node-assert-plus/issues>.\n",
                  "readmeFilename": "README.md",
                  "_id": "assert-plus@0.1.2",
                  "_from": "assert-plus@0.1.2"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "assert-plus",
                  "description": "Extra assertions on top of node's assert module",
                  "version": "0.1.2",
                  "locator": {
                    "pointer": "0.1.2"
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.6"
                    }
                  },
                  "exports": {
                    "main": "./assert.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mark Cavage",
                      "email": "mcavage@gmail.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "assert-plus",
                "description": "Extra assertions on top of node's assert module",
                "version": "0.1.2",
                "locator": {
                  "pointer": "0.1.2"
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.6"
                  }
                },
                "exports": {
                  "main": "./assert.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mark Cavage",
                    "email": "mcavage@gmail.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "fbda01465fe6db497c8c3e6b1a4a2bfae5a62cfc-assert-plus/assert.js",
                "dirpath": "node_modules/request/node_modules/http-signature/node_modules/assert-plus"
              }
            },
            "wrapper": "json"
          },
          "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/package.json": {
            "requireId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/package.json",
            "memoizeId": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/http-signature/node_modules/asn1",
              "dirrealpath": "node_modules/request/node_modules/http-signature/node_modules/asn1",
              "id": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1",
              "lookupPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/asn1/package.json",
                "node_modules/request/node_modules/http-signature/node_modules/asn1/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/asn1/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mark Cavage",
                    "email": "mcavage@gmail.com"
                  },
                  "contributors": [
                    {
                      "name": "Mark Cavage",
                      "email": "mcavage@gmail.com"
                    },
                    {
                      "name": "David Gwynne",
                      "email": "loki@animata.net"
                    },
                    {
                      "name": "Yunong Xiao",
                      "email": "yunong@joyent.com"
                    }
                  ],
                  "name": "asn1",
                  "description": "Contains parsers and serializers for ASN.1 (currently BER only)",
                  "version": "0.1.11",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/mcavage/node-asn1.git"
                  },
                  "main": "lib/index.js",
                  "engines": {
                    "node": ">=0.4.9"
                  },
                  "dependencies": {},
                  "devDependencies": {
                    "tap": "0.1.4"
                  },
                  "scripts": {
                    "pretest": "which gjslint; if [[ \"$?\" = 0 ]] ; then  gjslint --nojsdoc -r lib -r tst; else echo \"Missing gjslint. Skipping lint\"; fi",
                    "test": "./node_modules/.bin/tap ./tst"
                  },
                  "readme": "node-asn1 is a library for encoding and decoding ASN.1 datatypes in pure JS.\nCurrently BER encoding is supported; at some point I'll likely have to do DER.\n\n## Usage\n\nMostly, if you're *actually* needing to read and write ASN.1, you probably don't\nneed this readme to explain what and why.  If you have no idea what ASN.1 is,\nsee this: ftp://ftp.rsa.com/pub/pkcs/ascii/layman.asc\n\nThe source is pretty much self-explanatory, and has read/write methods for the\ncommon types out there.\n\n### Decoding\n\nThe following reads an ASN.1 sequence with a boolean.\n\n    var Ber = require('asn1').Ber;\n\n    var reader = new Ber.Reader(new Buffer([0x30, 0x03, 0x01, 0x01, 0xff]));\n\n    reader.readSequence();\n    console.log('Sequence len: ' + reader.length);\n    if (reader.peek() === Ber.Boolean)\n      console.log(reader.readBoolean());\n\n### Encoding\n\nThe following generates the same payload as above.\n\n    var Ber = require('asn1').Ber;\n\n    var writer = new Ber.Writer();\n\n    writer.startSequence();\n    writer.writeBoolean(true);\n    writer.endSequence();\n\n    console.log(writer.buffer);\n\n## Installation\n\n    npm install asn1\n\n## License\n\nMIT.\n\n## Bugs\n\nSee <https://github.com/mcavage/node-asn1/issues>.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mcavage/node-asn1/issues"
                  },
                  "_id": "asn1@0.1.11",
                  "_from": "asn1@0.1.11"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "asn1",
                  "description": "Contains parsers and serializers for ASN.1 (currently BER only)",
                  "version": "0.1.11",
                  "locator": {
                    "pointer": "0.1.11"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mcavage/node-asn1/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/mcavage/node-asn1.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "tap": "0.1.4"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.4.9"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "pretest": "which gjslint; if [[ \"$?\" = 0 ]] ; then  gjslint --nojsdoc -r lib -r tst; else echo \"Missing gjslint. Skipping lint\"; fi",
                      "test": "./node_modules/.bin/tap ./tst"
                    },
                    "main": "./lib/index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mark Cavage",
                      "email": "mcavage@gmail.com"
                    },
                    {
                      "name": "David Gwynne",
                      "email": "loki@animata.net"
                    },
                    {
                      "name": "Yunong Xiao",
                      "email": "yunong@joyent.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "asn1",
                "description": "Contains parsers and serializers for ASN.1 (currently BER only)",
                "version": "0.1.11",
                "locator": {
                  "pointer": "0.1.11"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mcavage/node-asn1/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/mcavage/node-asn1.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "tap": "0.1.4"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.4.9"
                  }
                },
                "exports": {
                  "scripts": {
                    "pretest": "which gjslint; if [[ \"$?\" = 0 ]] ; then  gjslint --nojsdoc -r lib -r tst; else echo \"Missing gjslint. Skipping lint\"; fi",
                    "test": "./node_modules/.bin/tap ./tst"
                  },
                  "main": "./lib/index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mark Cavage",
                    "email": "mcavage@gmail.com"
                  },
                  {
                    "name": "David Gwynne",
                    "email": "loki@animata.net"
                  },
                  {
                    "name": "Yunong Xiao",
                    "email": "yunong@joyent.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "e612e189cff4640079c1b54bfddcf962015c2f30-asn1/lib/index.js",
                "dirpath": "node_modules/request/node_modules/http-signature/node_modules/asn1"
              }
            },
            "wrapper": "json"
          },
          "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/package.json": {
            "requireId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/package.json",
            "memoizeId": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/http-signature/node_modules/ctype",
              "dirrealpath": "node_modules/request/node_modules/http-signature/node_modules/ctype",
              "id": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype",
              "lookupPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/ctype/package.json",
                "node_modules/request/node_modules/http-signature/node_modules/ctype/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/http-signature/node_modules/ctype/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "ctype",
                  "version": "0.5.2",
                  "description": "read and write binary structures and data types",
                  "homepage": "https://github.com/rmustacc/node-ctype",
                  "author": {
                    "name": "Robert Mustacchi",
                    "email": "rm@fingolfin.org"
                  },
                  "engines": {
                    "node": ">= 0.4"
                  },
                  "main": "ctype.js",
                  "readme": "Node-CType is a way to read and write binary data in structured and easy to use\nformat. Its name comes from the C header file.\n\nTo get started, simply clone the repository or use npm to install it. Once it is\nthere, simply require it.\n\ngit clone git://github.com/rmustacc/node-ctype\nnpm install ctype\nvar mod_ctype = require('ctype')\n\n\nThere are two APIs that you can use, depending on what abstraction you'd like.\nThe low level API let's you read and write individual integers and floats from\nbuffers. The higher level API let's you read and write structures of these. To\nillustrate this, let's looks look at how we would read and write a binary\nencoded x,y point.\n\nIn C we would define this structure as follows:\n\ntypedef struct point {\n\tuint16_t\tp_x;\n\tuint16_t\tp_y;\n} point_t;\n\nTo read a binary encoded point from a Buffer, we first need to create a CType\nparser (where we specify the endian and other options) and add the typedef.\n\nvar parser = new mod_ctype.Parser({ endian: 'big' });\nparser.typedef('point_t', [\n\t{ x: { type: 'uint16_t' } },\n\t{ y: { type: 'uint16_t' } }\n]);\n\nFrom here, given a buffer buf and an offset into it, we can read a point.\n\nvar out = parser.readData([ { point: { type: 'point_t' } } ], buffer, 0);\nconsole.log(out);\n{ point: { x: 23, y: 42 } }\n\nAnother way to get the same information would be to use the low level methods.\nNote that these require you to manually deal with the offset. Here's how we'd\nget the same values of x and y from the buffer.\n\nvar x = mod_ctype.ruint16(buf, 'big', 0);\nvar y = mod_ctype.ruint16(buf, 'big', 2);\nconsole.log(x + ', ' + y);\n23, 42\n\nThe true power of this API comes from the ability to define and nest typedefs,\njust as you would in C. By default, the following types are defined by default.\nNote that they return a Number, unless indicated otherwise.\n\n    * int8_t\n    * int16_t\n    * int32_t\n    * int64_t (returns an array where val[0] << 32 + val[1] would be the value)\n    * uint8_t\n    * uint16_t\n    * uint32_t\n    * uint64_t (returns an array where val[0] << 32 + val[1] would be the value)\n    * float\n    * double\n    * char (either returns a buffer with that character or a uint8_t)\n    * char[] (returns an object with the buffer and the number of characters read which is either the total amount requested or until the first 0)\n\n\nctf2json integration:\n\nNode-CType supports consuming the output of ctf2json. Once you read in a JSON file,\nall you have to do to add all the definitions it contains is:\n\nvar data, parser;\ndata = JSON.parse(parsedJSONData);\nparser = mod_ctype.parseCTF(data, { endian: 'big' });\n\nFor more documentation, see the file README.old. Full documentation is in the\nprocess of being rewritten as a series of manual pages which will be available\nin the repository and online for viewing.\n\nTo read the ctio manual page simple run, from the root of the workspace:\n\nman -Mman -s 3ctype ctio\n",
                  "readmeFilename": "README",
                  "_id": "ctype@0.5.2",
                  "_from": "ctype@0.5.2"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "ctype",
                  "description": "read and write binary structures and data types",
                  "version": "0.5.2",
                  "locator": {
                    "pointer": "0.5.2"
                  },
                  "homepage": "https://github.com/rmustacc/node-ctype",
                  "requirements": {
                    "engines": {
                      "node": ">= 0.4"
                    }
                  },
                  "exports": {
                    "main": "./ctype.js"
                  },
                  "files": {
                    "readme": "./README"
                  },
                  "contributors": [
                    {
                      "name": "Robert Mustacchi",
                      "email": "rm@fingolfin.org"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "ctype",
                "description": "read and write binary structures and data types",
                "version": "0.5.2",
                "locator": {
                  "pointer": "0.5.2"
                },
                "homepage": "https://github.com/rmustacc/node-ctype",
                "requirements": {
                  "engines": {
                    "node": ">= 0.4"
                  }
                },
                "exports": {
                  "main": "./ctype.js"
                },
                "files": {
                  "readme": "./README"
                },
                "contributors": [
                  {
                    "name": "Robert Mustacchi",
                    "email": "rm@fingolfin.org"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "772d995e44ccaf42f98f64a0097b4a58863c38af-ctype/ctype.js",
                "dirpath": "node_modules/request/node_modules/http-signature/node_modules/ctype"
              }
            },
            "wrapper": "json"
          },
          "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/package.json": {
            "requireId": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/package.json",
            "memoizeId": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/node-uuid",
              "dirrealpath": "node_modules/request/node_modules/node-uuid",
              "id": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
              "lookupPaths": [
                "node_modules/request/node_modules/node-uuid/package.json",
                "node_modules/request/node_modules/node-uuid/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/node-uuid/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "node-uuid",
                  "description": "Rigorous implementation of RFC4122 (v1 and v4) UUIDs.",
                  "url": "http://github.com/broofa/node-uuid",
                  "keywords": [
                    "uuid",
                    "guid",
                    "rfc4122"
                  ],
                  "author": {
                    "name": "Robert Kieffer",
                    "email": "robert@broofa.com"
                  },
                  "contributors": [
                    {
                      "name": "Robert Kieffer",
                      "email": "robert@broofa.com"
                    },
                    {
                      "name": "Christoph Tavan",
                      "email": "dev@tavan.de"
                    }
                  ],
                  "lib": ".",
                  "main": "./uuid.js",
                  "repository": {
                    "type": "git",
                    "url": "https://github.com/broofa/node-uuid.git"
                  },
                  "version": "1.4.0",
                  "readme": "# node-uuid\n\nSimple, fast generation of [RFC4122](http://www.ietf.org/rfc/rfc4122.txt) UUIDS.\n\nFeatures:\n\n* Generate RFC4122 version 1 or version 4 UUIDs\n* Runs in node.js and all browsers.\n* Cryptographically strong random # generation on supporting platforms\n* 1.1K minified and gzip'ed  (Want something smaller?  Check this [crazy shit](https://gist.github.com/982883) out! )\n* [Annotated source code](http://broofa.github.com/node-uuid/docs/uuid.html)\n\n## Getting Started\n\nInstall it in your browser:\n\n```html\n<script src=\"uuid.js\"></script>\n```\n\nOr in node.js:\n\n```\nnpm install node-uuid\n```\n\n```javascript\nvar uuid = require('node-uuid');\n```\n\nThen create some ids ...\n\n```javascript\n// Generate a v1 (time-based) id\nuuid.v1(); // -> '6c84fb90-12c4-11e1-840d-7b25c5ee775a'\n\n// Generate a v4 (random) id\nuuid.v4(); // -> '110ec58a-a0f2-4ac4-8393-c866d813b8d1'\n```\n\n## API\n\n### uuid.v1([`options` [, `buffer` [, `offset`]]])\n\nGenerate and return a RFC4122 v1 (timestamp-based) UUID.\n\n* `options` - (Object) Optional uuid state to apply. Properties may include:\n\n  * `node` - (Array) Node id as Array of 6 bytes (per 4.1.6). Default: Randomly generated ID.  See note 1.\n  * `clockseq` - (Number between 0 - 0x3fff) RFC clock sequence.  Default: An internally maintained clockseq is used.\n  * `msecs` - (Number | Date) Time in milliseconds since unix Epoch.  Default: The current time is used.\n  * `nsecs` - (Number between 0-9999) additional time, in 100-nanosecond units. Ignored if `msecs` is unspecified. Default: internal uuid counter is used, as per 4.2.1.2.\n\n* `buffer` - (Array | Buffer) Array or buffer where UUID bytes are to be written.\n* `offset` - (Number) Starting index in `buffer` at which to begin writing.\n\nReturns `buffer`, if specified, otherwise the string form of the UUID\n\nNotes:\n\n1. The randomly generated node id is only guaranteed to stay constant for the lifetime of the current JS runtime. (Future versions of this module may use persistent storage mechanisms to extend this guarantee.)\n\nExample: Generate string UUID with fully-specified options\n\n```javascript\nuuid.v1({\n  node: [0x01, 0x23, 0x45, 0x67, 0x89, 0xab],\n  clockseq: 0x1234,\n  msecs: new Date('2011-11-01').getTime(),\n  nsecs: 5678\n});   // -> \"710b962e-041c-11e1-9234-0123456789ab\"\n```\n\nExample: In-place generation of two binary IDs\n\n```javascript\n// Generate two ids in an array\nvar arr = new Array(32); // -> []\nuuid.v1(null, arr, 0);   // -> [02 a2 ce 90 14 32 11 e1 85 58 0b 48 8e 4f c1 15]\nuuid.v1(null, arr, 16);  // -> [02 a2 ce 90 14 32 11 e1 85 58 0b 48 8e 4f c1 15 02 a3 1c b0 14 32 11 e1 85 58 0b 48 8e 4f c1 15]\n\n// Optionally use uuid.unparse() to get stringify the ids\nuuid.unparse(buffer);    // -> '02a2ce90-1432-11e1-8558-0b488e4fc115'\nuuid.unparse(buffer, 16) // -> '02a31cb0-1432-11e1-8558-0b488e4fc115'\n```\n\n### uuid.v4([`options` [, `buffer` [, `offset`]]])\n\nGenerate and return a RFC4122 v4 UUID.\n\n* `options` - (Object) Optional uuid state to apply. Properties may include:\n\n  * `random` - (Number[16]) Array of 16 numbers (0-255) to use in place of randomly generated values\n  * `rng` - (Function) Random # generator to use.  Set to one of the built-in generators - `uuid.mathRNG` (all platforms), `uuid.nodeRNG` (node.js only), `uuid.whatwgRNG` (WebKit only) - or a custom function that returns an array[16] of byte values.\n\n* `buffer` - (Array | Buffer) Array or buffer where UUID bytes are to be written.\n* `offset` - (Number) Starting index in `buffer` at which to begin writing.\n\nReturns `buffer`, if specified, otherwise the string form of the UUID\n\nExample: Generate string UUID with fully-specified options\n\n```javascript\nuuid.v4({\n  random: [\n    0x10, 0x91, 0x56, 0xbe, 0xc4, 0xfb, 0xc1, 0xea,\n    0x71, 0xb4, 0xef, 0xe1, 0x67, 0x1c, 0x58, 0x36\n  ]\n});\n// -> \"109156be-c4fb-41ea-b1b4-efe1671c5836\"\n```\n\nExample: Generate two IDs in a single buffer\n\n```javascript\nvar buffer = new Array(32); // (or 'new Buffer' in node.js)\nuuid.v4(null, buffer, 0);\nuuid.v4(null, buffer, 16);\n```\n\n### uuid.parse(id[, buffer[, offset]])\n### uuid.unparse(buffer[, offset])\n\nParse and unparse UUIDs\n\n  * `id` - (String) UUID(-like) string\n  * `buffer` - (Array | Buffer) Array or buffer where UUID bytes are to be written. Default: A new Array or Buffer is used\n  * `offset` - (Number) Starting index in `buffer` at which to begin writing. Default: 0\n\nExample parsing and unparsing a UUID string\n\n```javascript\nvar bytes = uuid.parse('797ff043-11eb-11e1-80d6-510998755d10'); // -> <Buffer 79 7f f0 43 11 eb 11 e1 80 d6 51 09 98 75 5d 10>\nvar string = uuid.unparse(bytes); // -> '797ff043-11eb-11e1-80d6-510998755d10'\n```\n\n### uuid.noConflict()\n\n(Browsers only) Set `uuid` property back to it's previous value.\n\nReturns the node-uuid object.\n\nExample:\n\n```javascript\nvar myUuid = uuid.noConflict();\nmyUuid.v1(); // -> '6c84fb90-12c4-11e1-840d-7b25c5ee775a'\n```\n\n## Deprecated APIs\n\nSupport for the following v1.2 APIs is available in v1.3, but is deprecated and will be removed in the next major version.\n\n### uuid([format [, buffer [, offset]]])\n\nuuid() has become uuid.v4(), and the `format` argument is now implicit in the `buffer` argument. (i.e. if you specify a buffer, the format is assumed to be binary).\n\n### uuid.BufferClass\n\nThe class of container created when generating binary uuid data if no buffer argument is specified.  This is expected to go away, with no replacement API.\n\n## Testing\n\nIn node.js\n\n```\n> cd test\n> node test.js\n```\n\nIn Browser\n\n```\nopen test/test.html\n```\n\n### Benchmarking\n\nRequires node.js\n\n```\nnpm install uuid uuid-js\nnode benchmark/benchmark.js\n```\n\nFor a more complete discussion of node-uuid performance, please see the `benchmark/README.md` file, and the [benchmark wiki](https://github.com/broofa/node-uuid/wiki/Benchmark)\n\nFor browser performance [checkout the JSPerf tests](http://jsperf.com/node-uuid-performance).\n\n## Release notes\n\nv1.4\n* Improved module context detection\n* Removed public RNG functions\n\nv1.3.2:\n* Improve tests and handling of v1() options (Issue #24)\n* Expose RNG option to allow for perf testing with different generators\n\nv1.3:\n* Support for version 1 ids, thanks to [@ctavan](https://github.com/ctavan)!\n* Support for node.js crypto API\n* De-emphasizing performance in favor of a) cryptographic quality PRNGs where available and b) more manageable code\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/broofa/node-uuid/issues"
                  },
                  "_id": "node-uuid@1.4.0",
                  "_from": "node-uuid@~1.4.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "node-uuid",
                  "description": "Rigorous implementation of RFC4122 (v1 and v4) UUIDs.",
                  "version": "1.4.0",
                  "locator": {
                    "pointer": "~1.4.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/broofa/node-uuid/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "https://github.com/broofa/node-uuid.git"
                    }
                  ],
                  "exports": {
                    "main": "./uuid.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "uuid",
                    "guid",
                    "rfc4122"
                  ],
                  "contributors": [
                    {
                      "name": "Robert Kieffer",
                      "email": "robert@broofa.com"
                    },
                    {
                      "name": "Christoph Tavan",
                      "email": "dev@tavan.de"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "node-uuid",
                "description": "Rigorous implementation of RFC4122 (v1 and v4) UUIDs.",
                "version": "1.4.0",
                "locator": {
                  "pointer": "~1.4.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/broofa/node-uuid/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "https://github.com/broofa/node-uuid.git"
                  }
                ],
                "exports": {
                  "main": "./uuid.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "uuid",
                  "guid",
                  "rfc4122"
                ],
                "contributors": [
                  {
                    "name": "Robert Kieffer",
                    "email": "robert@broofa.com"
                  },
                  {
                    "name": "Christoph Tavan",
                    "email": "dev@tavan.de"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [
                [
                  "normalize",
                  "Property 'url' was ignored",
                  "descriptor",
                  "package.json"
                ],
                [
                  "normalize",
                  "Property 'lib' was ignored",
                  "descriptor",
                  "package.json"
                ]
              ],
              "errors": [],
              "memoized": {
                "main": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid/uuid.js",
                "dirpath": "node_modules/request/node_modules/node-uuid"
              }
            },
            "wrapper": "json"
          },
          "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/package.json": {
            "requireId": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/package.json",
            "memoizeId": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/mime",
              "dirrealpath": "node_modules/request/node_modules/mime",
              "id": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
              "lookupPaths": [
                "node_modules/request/node_modules/mime/package.json",
                "node_modules/request/node_modules/mime/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/mime/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Robert Kieffer",
                    "email": "robert@broofa.com",
                    "url": "http://github.com/broofa"
                  },
                  "contributors": [
                    {
                      "name": "Robert Kieffer",
                      "email": "robert@broofa.com",
                      "url": "http://github.com/broofa"
                    },
                    {
                      "name": "Benjamin Thomas",
                      "email": "benjamin@benjaminthomas.org",
                      "url": "http://github.com/bentomas"
                    }
                  ],
                  "dependencies": {},
                  "description": "A comprehensive library for mime-type mapping",
                  "devDependencies": {},
                  "keywords": [
                    "util",
                    "mime"
                  ],
                  "main": "mime.js",
                  "name": "mime",
                  "repository": {
                    "url": "https://github.com/broofa/node-mime",
                    "type": "git"
                  },
                  "version": "1.2.10",
                  "readme": "# mime\n\nComprehensive MIME type mapping API. Includes all 600+ types and 800+ extensions defined by the Apache project, plus additional types submitted by the node.js community.\n\n## Install\n\nInstall with [npm](http://github.com/isaacs/npm):\n\n    npm install mime\n\n## API - Queries\n\n### mime.lookup(path)\nGet the mime type associated with a file, if no mime type is found `application/octet-stream` is returned. Performs a case-insensitive lookup using the extension in `path` (the substring after the last '/' or '.').  E.g.\n\n    var mime = require('mime');\n\n    mime.lookup('/path/to/file.txt');         // => 'text/plain'\n    mime.lookup('file.txt');                  // => 'text/plain'\n    mime.lookup('.TXT');                      // => 'text/plain'\n    mime.lookup('htm');                       // => 'text/html'\n\n### mime.default_type\nSets the mime type returned when `mime.lookup` fails to find the extension searched for. (Default is `application/octet-stream`.)\n\n### mime.extension(type)\nGet the default extension for `type`\n\n    mime.extension('text/html');                 // => 'html'\n    mime.extension('application/octet-stream');  // => 'bin'\n\n### mime.charsets.lookup()\n\nMap mime-type to charset\n\n    mime.charsets.lookup('text/plain');        // => 'UTF-8'\n\n(The logic for charset lookups is pretty rudimentary.  Feel free to suggest improvements.)\n\n## API - Defining Custom Types\n\nThe following APIs allow you to add your own type mappings within your project.  If you feel a type should be included as part of node-mime, see [requesting new types](https://github.com/broofa/node-mime/wiki/Requesting-New-Types).\n\n### mime.define()\n\nAdd custom mime/extension mappings\n\n    mime.define({\n        'text/x-some-format': ['x-sf', 'x-sft', 'x-sfml'],\n        'application/x-my-type': ['x-mt', 'x-mtt'],\n        // etc ...\n    });\n\n    mime.lookup('x-sft');                 // => 'text/x-some-format'\n\nThe first entry in the extensions array is returned by `mime.extension()`. E.g.\n\n    mime.extension('text/x-some-format'); // => 'x-sf'\n\n### mime.load(filepath)\n\nLoad mappings from an Apache \".types\" format file\n\n    mime.load('./my_project.types');\n\nThe .types file format is simple -  See the `types` dir for examples.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/broofa/node-mime/issues"
                  },
                  "_id": "mime@1.2.10",
                  "_from": "mime@~1.2.9"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "mime",
                  "description": "A comprehensive library for mime-type mapping",
                  "version": "1.2.10",
                  "locator": {
                    "pointer": "~1.2.9"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/broofa/node-mime/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/broofa/node-mime",
                      "type": "git"
                    }
                  ],
                  "exports": {
                    "main": "./mime.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "util",
                    "mime"
                  ],
                  "contributors": [
                    {
                      "name": "Robert Kieffer",
                      "email": "robert@broofa.com",
                      "url": "http://github.com/broofa"
                    },
                    {
                      "name": "Benjamin Thomas",
                      "email": "benjamin@benjaminthomas.org",
                      "url": "http://github.com/bentomas"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "mime",
                "description": "A comprehensive library for mime-type mapping",
                "version": "1.2.10",
                "locator": {
                  "pointer": "~1.2.9"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/broofa/node-mime/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/broofa/node-mime",
                    "type": "git"
                  }
                ],
                "exports": {
                  "main": "./mime.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "util",
                  "mime"
                ],
                "contributors": [
                  {
                    "name": "Robert Kieffer",
                    "email": "robert@broofa.com",
                    "url": "http://github.com/broofa"
                  },
                  {
                    "name": "Benjamin Thomas",
                    "email": "benjamin@benjaminthomas.org",
                    "url": "http://github.com/bentomas"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime/mime.js",
                "dirpath": "node_modules/request/node_modules/mime"
              }
            },
            "wrapper": "json"
          },
          "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/package.json": {
            "requireId": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/package.json",
            "memoizeId": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/tunnel-agent",
              "dirrealpath": "node_modules/request/node_modules/tunnel-agent",
              "id": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent",
              "lookupPaths": [
                "node_modules/request/node_modules/tunnel-agent/package.json",
                "node_modules/request/node_modules/tunnel-agent/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/tunnel-agent/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  },
                  "name": "tunnel-agent",
                  "description": "HTTP proxy tunneling agent. Formerly part of mikeal/request, now a standalone module.",
                  "version": "0.3.0",
                  "repository": {
                    "url": "https://github.com/mikeal/tunnel-agent"
                  },
                  "main": "index.js",
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": "*"
                  },
                  "readme": "tunnel-agent\n============\n\nHTTP proxy tunneling agent. Formerly part of mikeal/request, now a standalone module.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mikeal/tunnel-agent/issues"
                  },
                  "_id": "tunnel-agent@0.3.0",
                  "_from": "tunnel-agent@~0.3.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "tunnel-agent",
                  "description": "HTTP proxy tunneling agent. Formerly part of mikeal/request, now a standalone module.",
                  "version": "0.3.0",
                  "locator": {
                    "pointer": "~0.3.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mikeal/tunnel-agent/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/mikeal/tunnel-agent"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com",
                      "url": "http://www.futurealoof.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "tunnel-agent",
                "description": "HTTP proxy tunneling agent. Formerly part of mikeal/request, now a standalone module.",
                "version": "0.3.0",
                "locator": {
                  "pointer": "~0.3.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mikeal/tunnel-agent/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/mikeal/tunnel-agent"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent/index.js",
                "dirpath": "node_modules/request/node_modules/tunnel-agent"
              }
            },
            "wrapper": "json"
          },
          "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/package.json": {
            "requireId": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/package.json",
            "memoizeId": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/json-stringify-safe",
              "dirrealpath": "node_modules/request/node_modules/json-stringify-safe",
              "id": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
              "lookupPaths": [
                "node_modules/request/node_modules/json-stringify-safe/package.json",
                "node_modules/request/node_modules/json-stringify-safe/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/json-stringify-safe/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "json-stringify-safe",
                  "version": "4.0.0",
                  "description": "Like JSON.stringify, but doesn't blow up on circular refs",
                  "main": "stringify.js",
                  "scripts": {
                    "test": "node test.js"
                  },
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/isaacs/json-stringify-safe"
                  },
                  "keywords": [
                    "json",
                    "stringify",
                    "circular",
                    "safe"
                  ],
                  "author": {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me"
                  },
                  "license": "BSD",
                  "readmeFilename": "README.md",
                  "readme": "# json-stringify-safe\n\nLike JSON.stringify, but doesn't throw on circular references.\n\n## Usage\n\nTakes the same arguments as `JSON.stringify`.\n\n```javascript\nvar stringify = require('json-stringify-safe');\nvar circularObj = {};\ncircularObj.circularRef = circularObj;\ncircularObj.list = [ circularObj, circularObj ];\nconsole.log(stringify(circularObj, null, 2));\n```\n\nOutput:\n\n```json\n{\n  \"circularRef\": \"[Circular]\",\n  \"list\": [\n    \"[Circular]\",\n    \"[Circular]\"\n  ]\n}\n```\n",
                  "bugs": {
                    "url": "https://github.com/isaacs/json-stringify-safe/issues"
                  },
                  "_id": "json-stringify-safe@4.0.0",
                  "_from": "json-stringify-safe@~4.0.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "json-stringify-safe",
                  "description": "Like JSON.stringify, but doesn't blow up on circular refs",
                  "version": "4.0.0",
                  "locator": {
                    "pointer": "~4.0.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/isaacs/json-stringify-safe/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/isaacs/json-stringify-safe"
                    }
                  ],
                  "exports": {
                    "scripts": {
                      "test": "node test.js"
                    },
                    "main": "./stringify.js"
                  },
                  "licenses": [
                    "BSD"
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "keywords": [
                    "json",
                    "stringify",
                    "circular",
                    "safe"
                  ],
                  "contributors": [
                    {
                      "name": "Isaac Z. Schlueter",
                      "email": "i@izs.me",
                      "url": "http://blog.izs.me"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "json-stringify-safe",
                "description": "Like JSON.stringify, but doesn't blow up on circular refs",
                "version": "4.0.0",
                "locator": {
                  "pointer": "~4.0.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/isaacs/json-stringify-safe/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/isaacs/json-stringify-safe"
                  }
                ],
                "exports": {
                  "scripts": {
                    "test": "node test.js"
                  },
                  "main": "./stringify.js"
                },
                "licenses": [
                  "BSD"
                ],
                "files": {
                  "readme": "./README.md"
                },
                "keywords": [
                  "json",
                  "stringify",
                  "circular",
                  "safe"
                ],
                "contributors": [
                  {
                    "name": "Isaac Z. Schlueter",
                    "email": "i@izs.me",
                    "url": "http://blog.izs.me"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe/stringify.js",
                "dirpath": "node_modules/request/node_modules/json-stringify-safe"
              }
            },
            "wrapper": "json"
          },
          "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/package.json": {
            "requireId": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/package.json",
            "memoizeId": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/forever-agent",
              "dirrealpath": "node_modules/request/node_modules/forever-agent",
              "id": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
              "lookupPaths": [
                "node_modules/request/node_modules/forever-agent/package.json",
                "node_modules/request/node_modules/forever-agent/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/forever-agent/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  },
                  "name": "forever-agent",
                  "description": "HTTP Agent that keeps socket connections alive between keep-alive requests. Formerly part of mikeal/request, now a standalone module.",
                  "version": "0.5.0",
                  "repository": {
                    "url": "https://github.com/mikeal/forever-agent"
                  },
                  "main": "index.js",
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": "*"
                  },
                  "readme": "forever-agent\n=============\n\nHTTP Agent that keeps socket connections alive between keep-alive requests. Formerly part of mikeal/request, now a standalone module.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mikeal/forever-agent/issues"
                  },
                  "_id": "forever-agent@0.5.0",
                  "_from": "forever-agent@~0.5.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "forever-agent",
                  "description": "HTTP Agent that keeps socket connections alive between keep-alive requests. Formerly part of mikeal/request, now a standalone module.",
                  "version": "0.5.0",
                  "locator": {
                    "pointer": "~0.5.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mikeal/forever-agent/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/mikeal/forever-agent"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com",
                      "url": "http://www.futurealoof.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "forever-agent",
                "description": "HTTP Agent that keeps socket connections alive between keep-alive requests. Formerly part of mikeal/request, now a standalone module.",
                "version": "0.5.0",
                "locator": {
                  "pointer": "~0.5.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mikeal/forever-agent/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/mikeal/forever-agent"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent/index.js",
                "dirpath": "node_modules/request/node_modules/forever-agent"
              }
            },
            "wrapper": "json"
          },
          "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/package.json": {
            "requireId": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/package.json",
            "memoizeId": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/form-data",
              "dirrealpath": "node_modules/request/node_modules/form-data",
              "id": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
              "lookupPaths": [
                "node_modules/request/node_modules/form-data/package.json",
                "node_modules/request/node_modules/form-data/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/form-data/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  },
                  "name": "form-data",
                  "description": "A module to create readable `\"multipart/form-data\"` streams.  Can be used to submit forms and file uploads to other web applications.",
                  "version": "0.0.8",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/felixge/node-form-data.git"
                  },
                  "main": "./lib/form_data",
                  "scripts": {
                    "test": "node test/run.js"
                  },
                  "engines": {
                    "node": ">= 0.6"
                  },
                  "dependencies": {
                    "combined-stream": "~0.0.4",
                    "mime": "~1.2.2",
                    "async": "~0.2.7"
                  },
                  "devDependencies": {
                    "fake": "~0.2.1",
                    "far": "~0.0.7",
                    "formidable": "~1.0.13",
                    "request": "~2.16.6"
                  },
                  "readme": "# Form-Data [![Build Status](https://travis-ci.org/alexindigo/node-form-data.png?branch=master)](https://travis-ci.org/alexindigo/node-form-data)\n\nA module to create readable `\"multipart/form-data\"` streams.  Can be used to\nsubmit forms and file uploads to other web applications.\n\nThe API of this module is inspired by the\n[XMLHttpRequest-2 FormData Interface][xhr2-fd].\n\n[xhr2-fd]: http://dev.w3.org/2006/webapi/XMLHttpRequest-2/Overview.html#the-formdata-interface\n\n## Install\n\n```\nnpm install form-data\n```\n\n## Usage\n\nIn this example we are constructing a form with 3 fields that contain a string,\na buffer and a file stream.\n\n``` javascript\nvar FormData = require('form-data');\nvar fs = require('fs');\n\nvar form = new FormData();\nform.append('my_field', 'my value');\nform.append('my_buffer', new Buffer(10));\nform.append('my_file', fs.createReadStream('/foo/bar.jpg'));\n```\n\nAlso you can use http-response stream:\n\n``` javascript\nvar FormData = require('form-data');\nvar http = require('http');\n\nvar form = new FormData();\n\nhttp.request('http://nodejs.org/images/logo.png', function(response) {\n  form.append('my_field', 'my value');\n  form.append('my_buffer', new Buffer(10));\n  form.append('my_logo', response);\n});\n```\n\nOr @mikeal's request stream:\n\n``` javascript\nvar FormData = require('form-data');\nvar request = require('request');\n\nvar form = new FormData();\n\nform.append('my_field', 'my value');\nform.append('my_buffer', new Buffer(10));\nform.append('my_logo', request('http://nodejs.org/images/logo.png'));\n```\n\nIn order to submit this form to a web application, you can use node's http\nclient interface:\n\n``` javascript\nvar http = require('http');\n\nvar request = http.request({\n  method: 'post',\n  host: 'example.org',\n  path: '/upload',\n  headers: form.getHeaders()\n});\n\nform.pipe(request);\n\nrequest.on('response', function(res) {\n  console.log(res.statusCode);\n});\n```\n\nOr if you would prefer the `'Content-Length'` header to be set for you:\n\n``` javascript\nform.submit('example.org/upload', function(err, res) {\n  console.log(res.statusCode);\n});\n```\n\nTo use custom headers and pre-known length in parts:\n\n``` javascript\nvar CRLF = '\\r\\n';\nvar form = new FormData();\n\nvar options = {\n  header: CRLF + '--' + form.getBoundary() + CRLF + 'X-Custom-Header: 123' + CRLF + CRLF,\n  knownLength: 1\n};\n\nform.append('my_buffer', buffer, options);\n\nform.submit('http://example.com/', function(err, res) {\n  if (err) throw err;\n  console.log('Done');\n});\n```\n\nForm-Data can recognize and fetch all the required information from common types of streams (fs.readStream, http.response and mikeal's request), for some other types of streams you'd need to provide \"file\"-related information manually:\n\n``` javascript\nsomeModule.stream(function(err, stdout, stderr) {\n  if (err) throw err;\n\n  var form = new FormData();\n\n  form.append('file', stdout, {\n    filename: 'unicycle.jpg',\n    contentType: 'image/jpg',\n    knownLength: 19806\n  });\n\n  form.submit('http://example.com/', function(err, res) {\n    if (err) throw err;\n    console.log('Done');\n  });\n});\n```\n\nFor edge cases, like POST request to URL with query string or to pass HTTP auth credentials, object can be passed to `form.submit()` as first parameter:\n\n``` javascript\nform.submit({\n  host: 'example.com',\n  path: '/probably.php?extra=params',\n  auth: 'username:password'\n}, function(err, res) {\n  console.log(res.statusCode);\n});\n```\n\n## TODO\n\n- Add new streams (0.10) support and try really hard not to break it for 0.8.x.\n\n## License\n\nForm-Data is licensed under the MIT license.\n",
                  "readmeFilename": "Readme.md",
                  "bugs": {
                    "url": "https://github.com/felixge/node-form-data/issues"
                  },
                  "_id": "form-data@0.0.8",
                  "_from": "form-data@0.0.8"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "async": "./node_modules/async",
                      "combined-stream": "./node_modules/combined-stream"
                    }
                  },
                  "mappings": {
                    "async": "257a70b6290719603e5079400727f3d2d2d1b03a-async",
                    "combined-stream": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream"
                  }
                },
                "package.json": {
                  "name": "form-data",
                  "description": "A module to create readable `\"multipart/form-data\"` streams.  Can be used to submit forms and file uploads to other web applications.",
                  "version": "0.0.8",
                  "locator": {
                    "pointer": "0.0.8"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/felixge/node-form-data/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/felixge/node-form-data.git"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "combined-stream": "~0.0.4",
                      "mime": "~1.2.2",
                      "async": "~0.2.7"
                    },
                    "development": {
                      "fake": "~0.2.1",
                      "far": "~0.0.7",
                      "formidable": "~1.0.13",
                      "request": "~2.16.6"
                    },
                    "bundled": {
                      "async": "./node_modules/async",
                      "combined-stream": "./node_modules/combined-stream",
                      "aws-sign": "../aws-sign",
                      "cookie-jar": "../cookie-jar",
                      "forever-agent": "../forever-agent",
                      "form-data": ".",
                      "hawk": "../hawk",
                      "http-signature": "../http-signature",
                      "json-stringify-safe": "../json-stringify-safe",
                      "mime": "../mime",
                      "node-uuid": "../node-uuid",
                      "oauth-sign": "../oauth-sign",
                      "qs": "../qs",
                      "tunnel-agent": "../tunnel-agent"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">= 0.6"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "node test/run.js"
                    },
                    "main": "./lib/form_data.js"
                  },
                  "files": {
                    "readme": "./Readme.md"
                  },
                  "contributors": [
                    {
                      "name": "Felix Geisendrfer",
                      "email": "felix@debuggable.com",
                      "url": "http://debuggable.com/"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "async": "257a70b6290719603e5079400727f3d2d2d1b03a-async",
                    "combined-stream": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream",
                    "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                    "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
                    "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                    "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                    "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                    "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                    "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                    "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                    "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                    "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                    "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                    "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent"
                  }
                }
              },
              "combined": {
                "name": "form-data",
                "description": "A module to create readable `\"multipart/form-data\"` streams.  Can be used to submit forms and file uploads to other web applications.",
                "version": "0.0.8",
                "locator": {
                  "pointer": "0.0.8"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/felixge/node-form-data/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/felixge/node-form-data.git"
                  }
                ],
                "dependencies": {
                  "required": {
                    "combined-stream": "~0.0.4",
                    "mime": "~1.2.2",
                    "async": "~0.2.7"
                  },
                  "development": {
                    "fake": "~0.2.1",
                    "far": "~0.0.7",
                    "formidable": "~1.0.13",
                    "request": "~2.16.6"
                  },
                  "bundled": {
                    "async": "./node_modules/async",
                    "combined-stream": "./node_modules/combined-stream",
                    "aws-sign": "../aws-sign",
                    "cookie-jar": "../cookie-jar",
                    "forever-agent": "../forever-agent",
                    "form-data": ".",
                    "hawk": "../hawk",
                    "http-signature": "../http-signature",
                    "json-stringify-safe": "../json-stringify-safe",
                    "mime": "../mime",
                    "node-uuid": "../node-uuid",
                    "oauth-sign": "../oauth-sign",
                    "qs": "../qs",
                    "tunnel-agent": "../tunnel-agent"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">= 0.6"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "node test/run.js"
                  },
                  "main": "./lib/form_data.js"
                },
                "files": {
                  "readme": "./Readme.md"
                },
                "contributors": [
                  {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "async": "257a70b6290719603e5079400727f3d2d2d1b03a-async",
                  "combined-stream": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream",
                  "aws-sign": "effa10bda53b956d3e4fe3fada19d444ee3ea1ac-aws-sign",
                  "cookie-jar": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
                  "forever-agent": "0aece9af14f253ebe7db431e7f82a4db65578bac-forever-agent",
                  "form-data": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data",
                  "hawk": "29eb5a18eb620cc598527d89a0c5c611db63e91b-hawk",
                  "http-signature": "6f0d5981580f5664565c0af7ca279d689a790fb5-http-signature",
                  "json-stringify-safe": "cd513417702c216d7e831b5e07732580c4cd46ff-json-stringify-safe",
                  "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                  "node-uuid": "e999f0bd6e194076d315ffd2a431c4c6e32def1e-node-uuid",
                  "oauth-sign": "4c8c493e0464365389fe0601e4bb6254d3b41a3c-oauth-sign",
                  "qs": "bad905498fb7a8a034fa664d6ed1a9c67f1b189c-qs",
                  "tunnel-agent": "11cb05bc0940ffae1a1e1f73ca7c89e4731519fe-tunnel-agent"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "30e023fb56d12219edd0fa0dc5fec5bc671e23d7-form-data/lib/form_data.js",
                "mappings": {
                  "combined-stream": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream",
                  "mime": "acbfdcf6c33b2a153969671d593b45e4d0cd5768-mime",
                  "async": "257a70b6290719603e5079400727f3d2d2d1b03a-async"
                },
                "dirpath": "node_modules/request/node_modules/form-data"
              }
            },
            "wrapper": "json"
          },
          "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/package.json": {
            "requireId": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/package.json",
            "memoizeId": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream",
              "dirrealpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream",
              "id": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream",
              "lookupPaths": [
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/package.json",
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  },
                  "name": "combined-stream",
                  "description": "A stream that emits multiple other streams one after another.",
                  "version": "0.0.4",
                  "homepage": "https://github.com/felixge/node-combined-stream",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/felixge/node-combined-stream.git"
                  },
                  "main": "./lib/combined_stream",
                  "engines": {
                    "node": "*"
                  },
                  "dependencies": {
                    "delayed-stream": "0.0.5"
                  },
                  "devDependencies": {
                    "far": "0.0.1"
                  },
                  "readme": "# combined-stream\n\nA stream that emits multiple other streams one after another.\n\n## Installation\n\n``` bash\nnpm install combined-stream\n```\n\n## Usage\n\nHere is a simple example that shows how you can use combined-stream to combine\ntwo files into one:\n\n``` javascript\nvar CombinedStream = require('combined-stream');\nvar fs = require('fs');\n\nvar combinedStream = CombinedStream.create();\ncombinedStream.append(fs.createReadStream('file1.txt'));\ncombinedStream.append(fs.createReadStream('file2.txt'));\n\ncombinedStream.pipe(fs.createWriteStream('combined.txt'));\n```\n\nWhile the example above works great, it will pause all source streams until\nthey are needed. If you don't want that to happen, you can set `pauseStreams`\nto `false`:\n\n``` javascript\nvar CombinedStream = require('combined-stream');\nvar fs = require('fs');\n\nvar combinedStream = CombinedStream.create({pauseStreams: false});\ncombinedStream.append(fs.createReadStream('file1.txt'));\ncombinedStream.append(fs.createReadStream('file2.txt'));\n\ncombinedStream.pipe(fs.createWriteStream('combined.txt'));\n```\n\nHowever, what if you don't have all the source streams yet, or you don't want\nto allocate the resources (file descriptors, memory, etc.) for them right away?\nWell, in that case you can simply provide a callback that supplies the stream\nby calling a `next()` function:\n\n``` javascript\nvar CombinedStream = require('combined-stream');\nvar fs = require('fs');\n\nvar combinedStream = CombinedStream.create();\ncombinedStream.append(function(next) {\n  next(fs.createReadStream('file1.txt'));\n});\ncombinedStream.append(function(next) {\n  next(fs.createReadStream('file2.txt'));\n});\n\ncombinedStream.pipe(fs.createWriteStream('combined.txt'));\n```\n\n## API\n\n### CombinedStream.create([options])\n\nReturns a new combined stream object. Available options are:\n\n* `maxDataSize`\n* `pauseStreams`\n\nThe effect of those options is described below.\n\n### combinedStream.pauseStreams = true\n\nWhether to apply back pressure to the underlaying streams. If set to `false`,\nthe underlaying streams will never be paused. If set to `true`, the\nunderlaying streams will be paused right after being appended, as well as when\n`delayedStream.pipe()` wants to throttle.\n\n### combinedStream.maxDataSize = 2 * 1024 * 1024\n\nThe maximum amount of bytes (or characters) to buffer for all source streams.\nIf this value is exceeded, `combinedStream` emits an `'error'` event.\n\n### combinedStream.dataSize = 0\n\nThe amount of bytes (or characters) currently buffered by `combinedStream`.\n\n### combinedStream.append(stream)\n\nAppends the given `stream` to the combinedStream object. If `pauseStreams` is\nset to `true, this stream will also be paused right away.\n\n`streams` can also be a function that takes one parameter called `next`. `next`\nis a function that must be invoked in order to provide the `next` stream, see\nexample above.\n\nRegardless of how the `stream` is appended, combined-stream always attaches an\n`'error'` listener to it, so you don't have to do that manually.\n\nSpecial case: `stream` can also be a String or Buffer.\n\n### combinedStream.write(data)\n\nYou should not call this, `combinedStream` takes care of piping the appended\nstreams into itself for you.\n\n### combinedStream.resume()\n\nCauses `combinedStream` to start drain the streams it manages. The function is\nidempotent, and also emits a `'resume'` event each time which usually goes to\nthe stream that is currently being drained.\n\n### combinedStream.pause();\n\nIf `combinedStream.pauseStreams` is set to `false`, this does nothing.\nOtherwise a `'pause'` event is emitted, this goes to the stream that is\ncurrently being drained, so you can use it to apply back pressure.\n\n### combinedStream.end();\n\nSets `combinedStream.writable` to false, emits an `'end'` event, and removes\nall streams from the queue.\n\n### combinedStream.destroy();\n\nSame as `combinedStream.end()`, except it emits a `'close'` event instead of\n`'end'`.\n\n## License\n\ncombined-stream is licensed under the MIT license.\n",
                  "readmeFilename": "Readme.md",
                  "bugs": {
                    "url": "https://github.com/felixge/node-combined-stream/issues"
                  },
                  "_id": "combined-stream@0.0.4",
                  "_from": "combined-stream@~0.0.4"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      "delayed-stream": "./node_modules/delayed-stream"
                    }
                  },
                  "mappings": {
                    "delayed-stream": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream"
                  }
                },
                "package.json": {
                  "name": "combined-stream",
                  "description": "A stream that emits multiple other streams one after another.",
                  "version": "0.0.4",
                  "locator": {
                    "pointer": "~0.0.4"
                  },
                  "homepage": "https://github.com/felixge/node-combined-stream",
                  "social": {
                    "bugs": {
                      "url": "https://github.com/felixge/node-combined-stream/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/felixge/node-combined-stream.git"
                    }
                  ],
                  "dependencies": {
                    "required": {
                      "delayed-stream": "0.0.5"
                    },
                    "development": {
                      "far": "0.0.1"
                    },
                    "bundled": {
                      "delayed-stream": "./node_modules/delayed-stream"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "main": "./lib/combined_stream.js"
                  },
                  "files": {
                    "readme": "./Readme.md"
                  },
                  "contributors": [
                    {
                      "name": "Felix Geisendrfer",
                      "email": "felix@debuggable.com",
                      "url": "http://debuggable.com/"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    "delayed-stream": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream"
                  }
                }
              },
              "combined": {
                "name": "combined-stream",
                "description": "A stream that emits multiple other streams one after another.",
                "version": "0.0.4",
                "locator": {
                  "pointer": "~0.0.4"
                },
                "homepage": "https://github.com/felixge/node-combined-stream",
                "social": {
                  "bugs": {
                    "url": "https://github.com/felixge/node-combined-stream/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/felixge/node-combined-stream.git"
                  }
                ],
                "dependencies": {
                  "required": {
                    "delayed-stream": "0.0.5"
                  },
                  "development": {
                    "far": "0.0.1"
                  },
                  "bundled": {
                    "delayed-stream": "./node_modules/delayed-stream"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "main": "./lib/combined_stream.js"
                },
                "files": {
                  "readme": "./Readme.md"
                },
                "contributors": [
                  {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  "delayed-stream": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "06cbcc54faef9f40e30e431889706609e5cfcee5-combined-stream/lib/combined_stream.js",
                "mappings": {
                  "delayed-stream": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream"
                },
                "dirpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream"
              }
            },
            "wrapper": "json"
          },
          "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/package.json": {
            "requireId": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/package.json",
            "memoizeId": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream",
              "dirrealpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream",
              "id": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream",
              "lookupPaths": [
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/package.json",
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  },
                  "name": "delayed-stream",
                  "description": "Buffers events from a stream until you are ready to handle them.",
                  "version": "0.0.5",
                  "homepage": "https://github.com/felixge/node-delayed-stream",
                  "repository": {
                    "type": "git",
                    "url": "git://github.com/felixge/node-delayed-stream.git"
                  },
                  "main": "./lib/delayed_stream",
                  "engines": {
                    "node": ">=0.4.0"
                  },
                  "dependencies": {},
                  "devDependencies": {
                    "fake": "0.2.0",
                    "far": "0.0.1"
                  },
                  "readme": "# delayed-stream\n\nBuffers events from a stream until you are ready to handle them.\n\n## Installation\n\n``` bash\nnpm install delayed-stream\n```\n\n## Usage\n\nThe following example shows how to write a http echo server that delays its\nresponse by 1000 ms.\n\n``` javascript\nvar DelayedStream = require('delayed-stream');\nvar http = require('http');\n\nhttp.createServer(function(req, res) {\n  var delayed = DelayedStream.create(req);\n\n  setTimeout(function() {\n    res.writeHead(200);\n    delayed.pipe(res);\n  }, 1000);\n});\n```\n\nIf you are not using `Stream#pipe`, you can also manually release the buffered\nevents by calling `delayedStream.resume()`:\n\n``` javascript\nvar delayed = DelayedStream.create(req);\n\nsetTimeout(function() {\n  // Emit all buffered events and resume underlaying source\n  delayed.resume();\n}, 1000);\n```\n\n## Implementation\n\nIn order to use this meta stream properly, here are a few things you should\nknow about the implementation.\n\n### Event Buffering / Proxying\n\nAll events of the `source` stream are hijacked by overwriting the `source.emit`\nmethod. Until node implements a catch-all event listener, this is the only way.\n\nHowever, delayed-stream still continues to emit all events it captures on the\n`source`, regardless of whether you have released the delayed stream yet or\nnot.\n\nUpon creation, delayed-stream captures all `source` events and stores them in\nan internal event buffer. Once `delayedStream.release()` is called, all\nbuffered events are emitted on the `delayedStream`, and the event buffer is\ncleared. After that, delayed-stream merely acts as a proxy for the underlaying\nsource.\n\n### Error handling\n\nError events on `source` are buffered / proxied just like any other events.\nHowever, `delayedStream.create` attaches a no-op `'error'` listener to the\n`source`. This way you only have to handle errors on the `delayedStream`\nobject, rather than in two places.\n\n### Buffer limits\n\ndelayed-stream provides a `maxDataSize` property that can be used to limit\nthe amount of data being buffered. In order to protect you from bad `source`\nstreams that don't react to `source.pause()`, this feature is enabled by\ndefault.\n\n## API\n\n### DelayedStream.create(source, [options])\n\nReturns a new `delayedStream`. Available options are:\n\n* `pauseStream`\n* `maxDataSize`\n\nThe description for those properties can be found below.\n\n### delayedStream.source\n\nThe `source` stream managed by this object. This is useful if you are\npassing your `delayedStream` around, and you still want to access properties\non the `source` object.\n\n### delayedStream.pauseStream = true\n\nWhether to pause the underlaying `source` when calling\n`DelayedStream.create()`. Modifying this property afterwards has no effect.\n\n### delayedStream.maxDataSize = 1024 * 1024\n\nThe amount of data to buffer before emitting an `error`.\n\nIf the underlaying source is emitting `Buffer` objects, the `maxDataSize`\nrefers to bytes.\n\nIf the underlaying source is emitting JavaScript strings, the size refers to\ncharacters.\n\nIf you know what you are doing, you can set this property to `Infinity` to\ndisable this feature. You can also modify this property during runtime.\n\n### delayedStream.maxDataSize = 1024 * 1024\n\nThe amount of data to buffer before emitting an `error`.\n\nIf the underlaying source is emitting `Buffer` objects, the `maxDataSize`\nrefers to bytes.\n\nIf the underlaying source is emitting JavaScript strings, the size refers to\ncharacters.\n\nIf you know what you are doing, you can set this property to `Infinity` to\ndisable this feature.\n\n### delayedStream.dataSize = 0\n\nThe amount of data buffered so far.\n\n### delayedStream.readable\n\nAn ECMA5 getter that returns the value of `source.readable`.\n\n### delayedStream.resume()\n\nIf the `delayedStream` has not been released so far, `delayedStream.release()`\nis called.\n\nIn either case, `source.resume()` is called.\n\n### delayedStream.pause()\n\nCalls `source.pause()`.\n\n### delayedStream.pipe(dest)\n\nCalls `delayedStream.resume()` and then proxies the arguments to `source.pipe`.\n\n### delayedStream.release()\n\nEmits and clears all events that have been buffered up so far. This does not\nresume the underlaying source, use `delayedStream.resume()` instead.\n\n## License\n\ndelayed-stream is licensed under the MIT license.\n",
                  "readmeFilename": "Readme.md",
                  "bugs": {
                    "url": "https://github.com/felixge/node-delayed-stream/issues"
                  },
                  "_id": "delayed-stream@0.0.5",
                  "_from": "delayed-stream@0.0.5"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "delayed-stream",
                  "description": "Buffers events from a stream until you are ready to handle them.",
                  "version": "0.0.5",
                  "locator": {
                    "pointer": "0.0.5"
                  },
                  "homepage": "https://github.com/felixge/node-delayed-stream",
                  "social": {
                    "bugs": {
                      "url": "https://github.com/felixge/node-delayed-stream/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "git://github.com/felixge/node-delayed-stream.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "fake": "0.2.0",
                      "far": "0.0.1"
                    }
                  },
                  "requirements": {
                    "engines": {
                      "node": ">=0.4.0"
                    }
                  },
                  "exports": {
                    "main": "./lib/delayed_stream.js"
                  },
                  "files": {
                    "readme": "./Readme.md"
                  },
                  "contributors": [
                    {
                      "name": "Felix Geisendrfer",
                      "email": "felix@debuggable.com",
                      "url": "http://debuggable.com/"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "delayed-stream",
                "description": "Buffers events from a stream until you are ready to handle them.",
                "version": "0.0.5",
                "locator": {
                  "pointer": "0.0.5"
                },
                "homepage": "https://github.com/felixge/node-delayed-stream",
                "social": {
                  "bugs": {
                    "url": "https://github.com/felixge/node-delayed-stream/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "git://github.com/felixge/node-delayed-stream.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "fake": "0.2.0",
                    "far": "0.0.1"
                  }
                },
                "requirements": {
                  "engines": {
                    "node": ">=0.4.0"
                  }
                },
                "exports": {
                  "main": "./lib/delayed_stream.js"
                },
                "files": {
                  "readme": "./Readme.md"
                },
                "contributors": [
                  {
                    "name": "Felix Geisendrfer",
                    "email": "felix@debuggable.com",
                    "url": "http://debuggable.com/"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "199a58ca20a8d32f3b68d292b20fd112db88b5ec-delayed-stream/lib/delayed_stream.js",
                "dirpath": "node_modules/request/node_modules/form-data/node_modules/combined-stream/node_modules/delayed-stream"
              }
            },
            "wrapper": "json"
          },
          "257a70b6290719603e5079400727f3d2d2d1b03a-async/package.json": {
            "requireId": "257a70b6290719603e5079400727f3d2d2d1b03a-async/package.json",
            "memoizeId": "257a70b6290719603e5079400727f3d2d2d1b03a-async/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/form-data/node_modules/async",
              "dirrealpath": "node_modules/request/node_modules/form-data/node_modules/async",
              "id": "257a70b6290719603e5079400727f3d2d2d1b03a-async",
              "lookupPaths": [
                "node_modules/request/node_modules/form-data/node_modules/async/package.json",
                "node_modules/request/node_modules/form-data/node_modules/async/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/form-data/node_modules/async/package.json"
              ],
              "raw": {
                "package.json": {
                  "name": "async",
                  "description": "Higher-order functions and common patterns for asynchronous code",
                  "main": "./lib/async",
                  "author": {
                    "name": "Caolan McMahon"
                  },
                  "version": "0.2.9",
                  "repository": {
                    "type": "git",
                    "url": "https://github.com/caolan/async.git"
                  },
                  "bugs": {
                    "url": "https://github.com/caolan/async/issues"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": "https://github.com/caolan/async/raw/master/LICENSE"
                    }
                  ],
                  "devDependencies": {
                    "nodeunit": ">0.0.0",
                    "uglify-js": "1.2.x",
                    "nodelint": ">0.0.0"
                  },
                  "jam": {
                    "main": "lib/async.js",
                    "include": [
                      "lib/async.js",
                      "README.md",
                      "LICENSE"
                    ]
                  },
                  "scripts": {
                    "test": "nodeunit test/test-async.js"
                  },
                  "readme": "# Async.js\n\nAsync is a utility module which provides straight-forward, powerful functions\nfor working with asynchronous JavaScript. Although originally designed for\nuse with [node.js](http://nodejs.org), it can also be used directly in the\nbrowser. Also supports [component](https://github.com/component/component).\n\nAsync provides around 20 functions that include the usual 'functional'\nsuspects (map, reduce, filter, each) as well as some common patterns\nfor asynchronous control flow (parallel, series, waterfall). All these\nfunctions assume you follow the node.js convention of providing a single\ncallback as the last argument of your async function.\n\n\n## Quick Examples\n\n```javascript\nasync.map(['file1','file2','file3'], fs.stat, function(err, results){\n    // results is now an array of stats for each file\n});\n\nasync.filter(['file1','file2','file3'], fs.exists, function(results){\n    // results now equals an array of the existing files\n});\n\nasync.parallel([\n    function(){ ... },\n    function(){ ... }\n], callback);\n\nasync.series([\n    function(){ ... },\n    function(){ ... }\n]);\n```\n\nThere are many more functions available so take a look at the docs below for a\nfull list. This module aims to be comprehensive, so if you feel anything is\nmissing please create a GitHub issue for it.\n\n## Common Pitfalls\n\n### Binding a context to an iterator\n\nThis section is really about bind, not about async. If you are wondering how to\nmake async execute your iterators in a given context, or are confused as to why\na method of another library isn't working as an iterator, study this example:\n\n```js\n// Here is a simple object with an (unnecessarily roundabout) squaring method\nvar AsyncSquaringLibrary = {\n  squareExponent: 2,\n  square: function(number, callback){ \n    var result = Math.pow(number, this.squareExponent);\n    setTimeout(function(){\n      callback(null, result);\n    }, 200);\n  }\n};\n\nasync.map([1, 2, 3], AsyncSquaringLibrary.square, function(err, result){\n  // result is [NaN, NaN, NaN]\n  // This fails because the `this.squareExponent` expression in the square\n  // function is not evaluated in the context of AsyncSquaringLibrary, and is\n  // therefore undefined.\n});\n\nasync.map([1, 2, 3], AsyncSquaringLibrary.square.bind(AsyncSquaringLibrary), function(err, result){\n  // result is [1, 4, 9]\n  // With the help of bind we can attach a context to the iterator before\n  // passing it to async. Now the square function will be executed in its \n  // 'home' AsyncSquaringLibrary context and the value of `this.squareExponent`\n  // will be as expected.\n});\n```\n\n## Download\n\nThe source is available for download from\n[GitHub](http://github.com/caolan/async).\nAlternatively, you can install using Node Package Manager (npm):\n\n    npm install async\n\n__Development:__ [async.js](https://github.com/caolan/async/raw/master/lib/async.js) - 29.6kb Uncompressed\n\n## In the Browser\n\nSo far it's been tested in IE6, IE7, IE8, FF3.6 and Chrome 5. Usage:\n\n```html\n<script type=\"text/javascript\" src=\"async.js\"></script>\n<script type=\"text/javascript\">\n\n    async.map(data, asyncProcess, function(err, results){\n        alert(results);\n    });\n\n</script>\n```\n\n## Documentation\n\n### Collections\n\n* [each](#each)\n* [map](#map)\n* [filter](#filter)\n* [reject](#reject)\n* [reduce](#reduce)\n* [detect](#detect)\n* [sortBy](#sortBy)\n* [some](#some)\n* [every](#every)\n* [concat](#concat)\n\n### Control Flow\n\n* [series](#series)\n* [parallel](#parallel)\n* [whilst](#whilst)\n* [doWhilst](#doWhilst)\n* [until](#until)\n* [doUntil](#doUntil)\n* [forever](#forever)\n* [waterfall](#waterfall)\n* [compose](#compose)\n* [applyEach](#applyEach)\n* [queue](#queue)\n* [cargo](#cargo)\n* [auto](#auto)\n* [iterator](#iterator)\n* [apply](#apply)\n* [nextTick](#nextTick)\n* [times](#times)\n* [timesSeries](#timesSeries)\n\n### Utils\n\n* [memoize](#memoize)\n* [unmemoize](#unmemoize)\n* [log](#log)\n* [dir](#dir)\n* [noConflict](#noConflict)\n\n\n## Collections\n\n<a name=\"forEach\" />\n<a name=\"each\" />\n### each(arr, iterator, callback)\n\nApplies an iterator function to each item in an array, in parallel.\nThe iterator is called with an item from the list and a callback for when it\nhas finished. If the iterator passes an error to this callback, the main\ncallback for the each function is immediately called with the error.\n\nNote, that since this function applies the iterator to each item in parallel\nthere is no guarantee that the iterator functions will complete in order.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err) which must be called once it has \n  completed. If no error has occured, the callback should be run without \n  arguments or with an explicit null argument.\n* callback(err) - A callback which is called after all the iterator functions\n  have finished, or an error has occurred.\n\n__Example__\n\n```js\n// assuming openFiles is an array of file names and saveFile is a function\n// to save the modified contents of that file:\n\nasync.each(openFiles, saveFile, function(err){\n    // if any of the saves produced an error, err would equal that error\n});\n```\n\n---------------------------------------\n\n<a name=\"forEachSeries\" />\n<a name=\"eachSeries\" />\n### eachSeries(arr, iterator, callback)\n\nThe same as each only the iterator is applied to each item in the array in\nseries. The next iterator is only called once the current one has completed\nprocessing. This means the iterator functions will complete in order.\n\n\n---------------------------------------\n\n<a name=\"forEachLimit\" />\n<a name=\"eachLimit\" />\n### eachLimit(arr, limit, iterator, callback)\n\nThe same as each only no more than \"limit\" iterators will be simultaneously \nrunning at any time.\n\nNote that the items are not processed in batches, so there is no guarantee that\n the first \"limit\" iterator functions will complete before any others are \nstarted.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* limit - The maximum number of iterators to run at any time.\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err) which must be called once it has \n  completed. If no error has occured, the callback should be run without \n  arguments or with an explicit null argument.\n* callback(err) - A callback which is called after all the iterator functions\n  have finished, or an error has occurred.\n\n__Example__\n\n```js\n// Assume documents is an array of JSON objects and requestApi is a\n// function that interacts with a rate-limited REST api.\n\nasync.eachLimit(documents, 20, requestApi, function(err){\n    // if any of the saves produced an error, err would equal that error\n});\n```\n\n---------------------------------------\n\n<a name=\"map\" />\n### map(arr, iterator, callback)\n\nProduces a new array of values by mapping each value in the given array through\nthe iterator function. The iterator is called with an item from the array and a\ncallback for when it has finished processing. The callback takes 2 arguments, \nan error and the transformed item from the array. If the iterator passes an\nerror to this callback, the main callback for the map function is immediately\ncalled with the error.\n\nNote, that since this function applies the iterator to each item in parallel\nthere is no guarantee that the iterator functions will complete in order, however\nthe results array will be in the same order as the original array.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err, transformed) which must be called once \n  it has completed with an error (which can be null) and a transformed item.\n* callback(err, results) - A callback which is called after all the iterator\n  functions have finished, or an error has occurred. Results is an array of the\n  transformed items from the original array.\n\n__Example__\n\n```js\nasync.map(['file1','file2','file3'], fs.stat, function(err, results){\n    // results is now an array of stats for each file\n});\n```\n\n---------------------------------------\n\n<a name=\"mapSeries\" />\n### mapSeries(arr, iterator, callback)\n\nThe same as map only the iterator is applied to each item in the array in\nseries. The next iterator is only called once the current one has completed\nprocessing. The results array will be in the same order as the original.\n\n\n---------------------------------------\n\n<a name=\"mapLimit\" />\n### mapLimit(arr, limit, iterator, callback)\n\nThe same as map only no more than \"limit\" iterators will be simultaneously \nrunning at any time.\n\nNote that the items are not processed in batches, so there is no guarantee that\n the first \"limit\" iterator functions will complete before any others are \nstarted.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* limit - The maximum number of iterators to run at any time.\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err, transformed) which must be called once \n  it has completed with an error (which can be null) and a transformed item.\n* callback(err, results) - A callback which is called after all the iterator\n  functions have finished, or an error has occurred. Results is an array of the\n  transformed items from the original array.\n\n__Example__\n\n```js\nasync.map(['file1','file2','file3'], 1, fs.stat, function(err, results){\n    // results is now an array of stats for each file\n});\n```\n\n---------------------------------------\n\n<a name=\"filter\" />\n### filter(arr, iterator, callback)\n\n__Alias:__ select\n\nReturns a new array of all the values which pass an async truth test.\n_The callback for each iterator call only accepts a single argument of true or\nfalse, it does not accept an error argument first!_ This is in-line with the\nway node libraries work with truth tests like fs.exists. This operation is\nperformed in parallel, but the results array will be in the same order as the\noriginal.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A truth test to apply to each item in the array.\n  The iterator is passed a callback(truthValue) which must be called with a \n  boolean argument once it has completed.\n* callback(results) - A callback which is called after all the iterator\n  functions have finished.\n\n__Example__\n\n```js\nasync.filter(['file1','file2','file3'], fs.exists, function(results){\n    // results now equals an array of the existing files\n});\n```\n\n---------------------------------------\n\n<a name=\"filterSeries\" />\n### filterSeries(arr, iterator, callback)\n\n__alias:__ selectSeries\n\nThe same as filter only the iterator is applied to each item in the array in\nseries. The next iterator is only called once the current one has completed\nprocessing. The results array will be in the same order as the original.\n\n---------------------------------------\n\n<a name=\"reject\" />\n### reject(arr, iterator, callback)\n\nThe opposite of filter. Removes values that pass an async truth test.\n\n---------------------------------------\n\n<a name=\"rejectSeries\" />\n### rejectSeries(arr, iterator, callback)\n\nThe same as reject, only the iterator is applied to each item in the array\nin series.\n\n\n---------------------------------------\n\n<a name=\"reduce\" />\n### reduce(arr, memo, iterator, callback)\n\n__aliases:__ inject, foldl\n\nReduces a list of values into a single value using an async iterator to return\neach successive step. Memo is the initial state of the reduction. This\nfunction only operates in series. For performance reasons, it may make sense to\nsplit a call to this function into a parallel map, then use the normal\nArray.prototype.reduce on the results. This function is for situations where\neach step in the reduction needs to be async, if you can get the data before\nreducing it then it's probably a good idea to do so.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* memo - The initial state of the reduction.\n* iterator(memo, item, callback) - A function applied to each item in the\n  array to produce the next step in the reduction. The iterator is passed a\n  callback(err, reduction) which accepts an optional error as its first \n  argument, and the state of the reduction as the second. If an error is \n  passed to the callback, the reduction is stopped and the main callback is \n  immediately called with the error.\n* callback(err, result) - A callback which is called after all the iterator\n  functions have finished. Result is the reduced value.\n\n__Example__\n\n```js\nasync.reduce([1,2,3], 0, function(memo, item, callback){\n    // pointless async:\n    process.nextTick(function(){\n        callback(null, memo + item)\n    });\n}, function(err, result){\n    // result is now equal to the last value of memo, which is 6\n});\n```\n\n---------------------------------------\n\n<a name=\"reduceRight\" />\n### reduceRight(arr, memo, iterator, callback)\n\n__Alias:__ foldr\n\nSame as reduce, only operates on the items in the array in reverse order.\n\n\n---------------------------------------\n\n<a name=\"detect\" />\n### detect(arr, iterator, callback)\n\nReturns the first value in a list that passes an async truth test. The\niterator is applied in parallel, meaning the first iterator to return true will\nfire the detect callback with that result. That means the result might not be\nthe first item in the original array (in terms of order) that passes the test.\n\nIf order within the original array is important then look at detectSeries.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A truth test to apply to each item in the array.\n  The iterator is passed a callback(truthValue) which must be called with a \n  boolean argument once it has completed.\n* callback(result) - A callback which is called as soon as any iterator returns\n  true, or after all the iterator functions have finished. Result will be\n  the first item in the array that passes the truth test (iterator) or the\n  value undefined if none passed.\n\n__Example__\n\n```js\nasync.detect(['file1','file2','file3'], fs.exists, function(result){\n    // result now equals the first file in the list that exists\n});\n```\n\n---------------------------------------\n\n<a name=\"detectSeries\" />\n### detectSeries(arr, iterator, callback)\n\nThe same as detect, only the iterator is applied to each item in the array\nin series. This means the result is always the first in the original array (in\nterms of array order) that passes the truth test.\n\n\n---------------------------------------\n\n<a name=\"sortBy\" />\n### sortBy(arr, iterator, callback)\n\nSorts a list by the results of running each value through an async iterator.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err, sortValue) which must be called once it\n  has completed with an error (which can be null) and a value to use as the sort\n  criteria.\n* callback(err, results) - A callback which is called after all the iterator\n  functions have finished, or an error has occurred. Results is the items from\n  the original array sorted by the values returned by the iterator calls.\n\n__Example__\n\n```js\nasync.sortBy(['file1','file2','file3'], function(file, callback){\n    fs.stat(file, function(err, stats){\n        callback(err, stats.mtime);\n    });\n}, function(err, results){\n    // results is now the original array of files sorted by\n    // modified date\n});\n```\n\n---------------------------------------\n\n<a name=\"some\" />\n### some(arr, iterator, callback)\n\n__Alias:__ any\n\nReturns true if at least one element in the array satisfies an async test.\n_The callback for each iterator call only accepts a single argument of true or\nfalse, it does not accept an error argument first!_ This is in-line with the\nway node libraries work with truth tests like fs.exists. Once any iterator\ncall returns true, the main callback is immediately called.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A truth test to apply to each item in the array.\n  The iterator is passed a callback(truthValue) which must be called with a \n  boolean argument once it has completed.\n* callback(result) - A callback which is called as soon as any iterator returns\n  true, or after all the iterator functions have finished. Result will be\n  either true or false depending on the values of the async tests.\n\n__Example__\n\n```js\nasync.some(['file1','file2','file3'], fs.exists, function(result){\n    // if result is true then at least one of the files exists\n});\n```\n\n---------------------------------------\n\n<a name=\"every\" />\n### every(arr, iterator, callback)\n\n__Alias:__ all\n\nReturns true if every element in the array satisfies an async test.\n_The callback for each iterator call only accepts a single argument of true or\nfalse, it does not accept an error argument first!_ This is in-line with the\nway node libraries work with truth tests like fs.exists.\n\n__Arguments__\n\n* arr - An array to iterate over.\n* iterator(item, callback) - A truth test to apply to each item in the array.\n  The iterator is passed a callback(truthValue) which must be called with a \n  boolean argument once it has completed.\n* callback(result) - A callback which is called after all the iterator\n  functions have finished. Result will be either true or false depending on\n  the values of the async tests.\n\n__Example__\n\n```js\nasync.every(['file1','file2','file3'], fs.exists, function(result){\n    // if result is true then every file exists\n});\n```\n\n---------------------------------------\n\n<a name=\"concat\" />\n### concat(arr, iterator, callback)\n\nApplies an iterator to each item in a list, concatenating the results. Returns the\nconcatenated list. The iterators are called in parallel, and the results are\nconcatenated as they return. There is no guarantee that the results array will\nbe returned in the original order of the arguments passed to the iterator function.\n\n__Arguments__\n\n* arr - An array to iterate over\n* iterator(item, callback) - A function to apply to each item in the array.\n  The iterator is passed a callback(err, results) which must be called once it \n  has completed with an error (which can be null) and an array of results.\n* callback(err, results) - A callback which is called after all the iterator\n  functions have finished, or an error has occurred. Results is an array containing\n  the concatenated results of the iterator function.\n\n__Example__\n\n```js\nasync.concat(['dir1','dir2','dir3'], fs.readdir, function(err, files){\n    // files is now a list of filenames that exist in the 3 directories\n});\n```\n\n---------------------------------------\n\n<a name=\"concatSeries\" />\n### concatSeries(arr, iterator, callback)\n\nSame as async.concat, but executes in series instead of parallel.\n\n\n## Control Flow\n\n<a name=\"series\" />\n### series(tasks, [callback])\n\nRun an array of functions in series, each one running once the previous\nfunction has completed. If any functions in the series pass an error to its\ncallback, no more functions are run and the callback for the series is\nimmediately called with the value of the error. Once the tasks have completed,\nthe results are passed to the final callback as an array.\n\nIt is also possible to use an object instead of an array. Each property will be\nrun as a function and the results will be passed to the final callback as an object\ninstead of an array. This can be a more readable way of handling results from\nasync.series.\n\n\n__Arguments__\n\n* tasks - An array or object containing functions to run, each function is passed\n  a callback(err, result) it must call on completion with an error (which can\n  be null) and an optional result value.\n* callback(err, results) - An optional callback to run once all the functions\n  have completed. This function gets a results array (or object) containing all \n  the result arguments passed to the task callbacks.\n\n__Example__\n\n```js\nasync.series([\n    function(callback){\n        // do some stuff ...\n        callback(null, 'one');\n    },\n    function(callback){\n        // do some more stuff ...\n        callback(null, 'two');\n    }\n],\n// optional callback\nfunction(err, results){\n    // results is now equal to ['one', 'two']\n});\n\n\n// an example using an object instead of an array\nasync.series({\n    one: function(callback){\n        setTimeout(function(){\n            callback(null, 1);\n        }, 200);\n    },\n    two: function(callback){\n        setTimeout(function(){\n            callback(null, 2);\n        }, 100);\n    }\n},\nfunction(err, results) {\n    // results is now equal to: {one: 1, two: 2}\n});\n```\n\n---------------------------------------\n\n<a name=\"parallel\" />\n### parallel(tasks, [callback])\n\nRun an array of functions in parallel, without waiting until the previous\nfunction has completed. If any of the functions pass an error to its\ncallback, the main callback is immediately called with the value of the error.\nOnce the tasks have completed, the results are passed to the final callback as an\narray.\n\nIt is also possible to use an object instead of an array. Each property will be\nrun as a function and the results will be passed to the final callback as an object\ninstead of an array. This can be a more readable way of handling results from\nasync.parallel.\n\n\n__Arguments__\n\n* tasks - An array or object containing functions to run, each function is passed \n  a callback(err, result) it must call on completion with an error (which can\n  be null) and an optional result value.\n* callback(err, results) - An optional callback to run once all the functions\n  have completed. This function gets a results array (or object) containing all \n  the result arguments passed to the task callbacks.\n\n__Example__\n\n```js\nasync.parallel([\n    function(callback){\n        setTimeout(function(){\n            callback(null, 'one');\n        }, 200);\n    },\n    function(callback){\n        setTimeout(function(){\n            callback(null, 'two');\n        }, 100);\n    }\n],\n// optional callback\nfunction(err, results){\n    // the results array will equal ['one','two'] even though\n    // the second function had a shorter timeout.\n});\n\n\n// an example using an object instead of an array\nasync.parallel({\n    one: function(callback){\n        setTimeout(function(){\n            callback(null, 1);\n        }, 200);\n    },\n    two: function(callback){\n        setTimeout(function(){\n            callback(null, 2);\n        }, 100);\n    }\n},\nfunction(err, results) {\n    // results is now equals to: {one: 1, two: 2}\n});\n```\n\n---------------------------------------\n\n<a name=\"parallel\" />\n### parallelLimit(tasks, limit, [callback])\n\nThe same as parallel only the tasks are executed in parallel with a maximum of \"limit\" \ntasks executing at any time.\n\nNote that the tasks are not executed in batches, so there is no guarantee that \nthe first \"limit\" tasks will complete before any others are started.\n\n__Arguments__\n\n* tasks - An array or object containing functions to run, each function is passed \n  a callback(err, result) it must call on completion with an error (which can\n  be null) and an optional result value.\n* limit - The maximum number of tasks to run at any time.\n* callback(err, results) - An optional callback to run once all the functions\n  have completed. This function gets a results array (or object) containing all \n  the result arguments passed to the task callbacks.\n\n---------------------------------------\n\n<a name=\"whilst\" />\n### whilst(test, fn, callback)\n\nRepeatedly call fn, while test returns true. Calls the callback when stopped,\nor an error occurs.\n\n__Arguments__\n\n* test() - synchronous truth test to perform before each execution of fn.\n* fn(callback) - A function to call each time the test passes. The function is\n  passed a callback(err) which must be called once it has completed with an \n  optional error argument.\n* callback(err) - A callback which is called after the test fails and repeated\n  execution of fn has stopped.\n\n__Example__\n\n```js\nvar count = 0;\n\nasync.whilst(\n    function () { return count < 5; },\n    function (callback) {\n        count++;\n        setTimeout(callback, 1000);\n    },\n    function (err) {\n        // 5 seconds have passed\n    }\n);\n```\n\n---------------------------------------\n\n<a name=\"doWhilst\" />\n### doWhilst(fn, test, callback)\n\nThe post check version of whilst. To reflect the difference in the order of operations `test` and `fn` arguments are switched. `doWhilst` is to `whilst` as `do while` is to `while` in plain JavaScript.\n\n---------------------------------------\n\n<a name=\"until\" />\n### until(test, fn, callback)\n\nRepeatedly call fn, until test returns true. Calls the callback when stopped,\nor an error occurs.\n\nThe inverse of async.whilst.\n\n---------------------------------------\n\n<a name=\"doUntil\" />\n### doUntil(fn, test, callback)\n\nLike doWhilst except the test is inverted. Note the argument ordering differs from `until`.\n\n---------------------------------------\n\n<a name=\"forever\" />\n### forever(fn, callback)\n\nCalls the asynchronous function 'fn' repeatedly, in series, indefinitely.\nIf an error is passed to fn's callback then 'callback' is called with the\nerror, otherwise it will never be called.\n\n---------------------------------------\n\n<a name=\"waterfall\" />\n### waterfall(tasks, [callback])\n\nRuns an array of functions in series, each passing their results to the next in\nthe array. However, if any of the functions pass an error to the callback, the\nnext function is not executed and the main callback is immediately called with\nthe error.\n\n__Arguments__\n\n* tasks - An array of functions to run, each function is passed a \n  callback(err, result1, result2, ...) it must call on completion. The first\n  argument is an error (which can be null) and any further arguments will be \n  passed as arguments in order to the next task.\n* callback(err, [results]) - An optional callback to run once all the functions\n  have completed. This will be passed the results of the last task's callback.\n\n\n\n__Example__\n\n```js\nasync.waterfall([\n    function(callback){\n        callback(null, 'one', 'two');\n    },\n    function(arg1, arg2, callback){\n        callback(null, 'three');\n    },\n    function(arg1, callback){\n        // arg1 now equals 'three'\n        callback(null, 'done');\n    }\n], function (err, result) {\n   // result now equals 'done'    \n});\n```\n\n---------------------------------------\n<a name=\"compose\" />\n### compose(fn1, fn2...)\n\nCreates a function which is a composition of the passed asynchronous\nfunctions. Each function consumes the return value of the function that\nfollows. Composing functions f(), g() and h() would produce the result of\nf(g(h())), only this version uses callbacks to obtain the return values.\n\nEach function is executed with the `this` binding of the composed function.\n\n__Arguments__\n\n* functions... - the asynchronous functions to compose\n\n\n__Example__\n\n```js\nfunction add1(n, callback) {\n    setTimeout(function () {\n        callback(null, n + 1);\n    }, 10);\n}\n\nfunction mul3(n, callback) {\n    setTimeout(function () {\n        callback(null, n * 3);\n    }, 10);\n}\n\nvar add1mul3 = async.compose(mul3, add1);\n\nadd1mul3(4, function (err, result) {\n   // result now equals 15\n});\n```\n\n---------------------------------------\n<a name=\"applyEach\" />\n### applyEach(fns, args..., callback)\n\nApplies the provided arguments to each function in the array, calling the\ncallback after all functions have completed. If you only provide the first\nargument then it will return a function which lets you pass in the\narguments as if it were a single function call.\n\n__Arguments__\n\n* fns - the asynchronous functions to all call with the same arguments\n* args... - any number of separate arguments to pass to the function\n* callback - the final argument should be the callback, called when all\n  functions have completed processing\n\n\n__Example__\n\n```js\nasync.applyEach([enableSearch, updateSchema], 'bucket', callback);\n\n// partial application example:\nasync.each(\n    buckets,\n    async.applyEach([enableSearch, updateSchema]),\n    callback\n);\n```\n\n---------------------------------------\n\n<a name=\"applyEachSeries\" />\n### applyEachSeries(arr, iterator, callback)\n\nThe same as applyEach only the functions are applied in series.\n\n---------------------------------------\n\n<a name=\"queue\" />\n### queue(worker, concurrency)\n\nCreates a queue object with the specified concurrency. Tasks added to the\nqueue will be processed in parallel (up to the concurrency limit). If all\nworkers are in progress, the task is queued until one is available. Once\na worker has completed a task, the task's callback is called.\n\n__Arguments__\n\n* worker(task, callback) - An asynchronous function for processing a queued\n  task, which must call its callback(err) argument when finished, with an \n  optional error as an argument.\n* concurrency - An integer for determining how many worker functions should be\n  run in parallel.\n\n__Queue objects__\n\nThe queue object returned by this function has the following properties and\nmethods:\n\n* length() - a function returning the number of items waiting to be processed.\n* concurrency - an integer for determining how many worker functions should be\n  run in parallel. This property can be changed after a queue is created to\n  alter the concurrency on-the-fly.\n* push(task, [callback]) - add a new task to the queue, the callback is called\n  once the worker has finished processing the task.\n  instead of a single task, an array of tasks can be submitted. the respective callback is used for every task in the list.\n* unshift(task, [callback]) - add a new task to the front of the queue.\n* saturated - a callback that is called when the queue length hits the concurrency and further tasks will be queued\n* empty - a callback that is called when the last item from the queue is given to a worker\n* drain - a callback that is called when the last item from the queue has returned from the worker\n\n__Example__\n\n```js\n// create a queue object with concurrency 2\n\nvar q = async.queue(function (task, callback) {\n    console.log('hello ' + task.name);\n    callback();\n}, 2);\n\n\n// assign a callback\nq.drain = function() {\n    console.log('all items have been processed');\n}\n\n// add some items to the queue\n\nq.push({name: 'foo'}, function (err) {\n    console.log('finished processing foo');\n});\nq.push({name: 'bar'}, function (err) {\n    console.log('finished processing bar');\n});\n\n// add some items to the queue (batch-wise)\n\nq.push([{name: 'baz'},{name: 'bay'},{name: 'bax'}], function (err) {\n    console.log('finished processing bar');\n});\n\n// add some items to the front of the queue\n\nq.unshift({name: 'bar'}, function (err) {\n    console.log('finished processing bar');\n});\n```\n\n---------------------------------------\n\n<a name=\"cargo\" />\n### cargo(worker, [payload])\n\nCreates a cargo object with the specified payload. Tasks added to the\ncargo will be processed altogether (up to the payload limit). If the\nworker is in progress, the task is queued until it is available. Once\nthe worker has completed some tasks, each callback of those tasks is called.\n\n__Arguments__\n\n* worker(tasks, callback) - An asynchronous function for processing an array of\n  queued tasks, which must call its callback(err) argument when finished, with \n  an optional error as an argument.\n* payload - An optional integer for determining how many tasks should be\n  processed per round; if omitted, the default is unlimited.\n\n__Cargo objects__\n\nThe cargo object returned by this function has the following properties and\nmethods:\n\n* length() - a function returning the number of items waiting to be processed.\n* payload - an integer for determining how many tasks should be\n  process per round. This property can be changed after a cargo is created to\n  alter the payload on-the-fly.\n* push(task, [callback]) - add a new task to the queue, the callback is called\n  once the worker has finished processing the task.\n  instead of a single task, an array of tasks can be submitted. the respective callback is used for every task in the list.\n* saturated - a callback that is called when the queue length hits the concurrency and further tasks will be queued\n* empty - a callback that is called when the last item from the queue is given to a worker\n* drain - a callback that is called when the last item from the queue has returned from the worker\n\n__Example__\n\n```js\n// create a cargo object with payload 2\n\nvar cargo = async.cargo(function (tasks, callback) {\n    for(var i=0; i<tasks.length; i++){\n      console.log('hello ' + tasks[i].name);\n    }\n    callback();\n}, 2);\n\n\n// add some items\n\ncargo.push({name: 'foo'}, function (err) {\n    console.log('finished processing foo');\n});\ncargo.push({name: 'bar'}, function (err) {\n    console.log('finished processing bar');\n});\ncargo.push({name: 'baz'}, function (err) {\n    console.log('finished processing baz');\n});\n```\n\n---------------------------------------\n\n<a name=\"auto\" />\n### auto(tasks, [callback])\n\nDetermines the best order for running functions based on their requirements.\nEach function can optionally depend on other functions being completed first,\nand each function is run as soon as its requirements are satisfied. If any of\nthe functions pass an error to their callback, that function will not complete\n(so any other functions depending on it will not run) and the main callback\nwill be called immediately with the error. Functions also receive an object\ncontaining the results of functions which have completed so far.\n\nNote, all functions are called with a results object as a second argument, \nso it is unsafe to pass functions in the tasks object which cannot handle the\nextra argument. For example, this snippet of code:\n\n```js\nasync.auto({\n  readData: async.apply(fs.readFile, 'data.txt', 'utf-8');\n}, callback);\n```\n\nwill have the effect of calling readFile with the results object as the last\nargument, which will fail:\n\n```js\nfs.readFile('data.txt', 'utf-8', cb, {});\n```\n\nInstead, wrap the call to readFile in a function which does not forward the \nresults object:\n\n```js\nasync.auto({\n  readData: function(cb, results){\n    fs.readFile('data.txt', 'utf-8', cb);\n  }\n}, callback);\n```\n\n__Arguments__\n\n* tasks - An object literal containing named functions or an array of\n  requirements, with the function itself the last item in the array. The key\n  used for each function or array is used when specifying requirements. The \n  function receives two arguments: (1) a callback(err, result) which must be \n  called when finished, passing an error (which can be null) and the result of \n  the function's execution, and (2) a results object, containing the results of\n  the previously executed functions.\n* callback(err, results) - An optional callback which is called when all the\n  tasks have been completed. The callback will receive an error as an argument\n  if any tasks pass an error to their callback. Results will always be passed\n\tbut if an error occurred, no other tasks will be performed, and the results\n\tobject will only contain partial results.\n  \n\n__Example__\n\n```js\nasync.auto({\n    get_data: function(callback){\n        // async code to get some data\n    },\n    make_folder: function(callback){\n        // async code to create a directory to store a file in\n        // this is run at the same time as getting the data\n    },\n    write_file: ['get_data', 'make_folder', function(callback){\n        // once there is some data and the directory exists,\n        // write the data to a file in the directory\n        callback(null, filename);\n    }],\n    email_link: ['write_file', function(callback, results){\n        // once the file is written let's email a link to it...\n        // results.write_file contains the filename returned by write_file.\n    }]\n});\n```\n\nThis is a fairly trivial example, but to do this using the basic parallel and\nseries functions would look like this:\n\n```js\nasync.parallel([\n    function(callback){\n        // async code to get some data\n    },\n    function(callback){\n        // async code to create a directory to store a file in\n        // this is run at the same time as getting the data\n    }\n],\nfunction(err, results){\n    async.series([\n        function(callback){\n            // once there is some data and the directory exists,\n            // write the data to a file in the directory\n        },\n        function(callback){\n            // once the file is written let's email a link to it...\n        }\n    ]);\n});\n```\n\nFor a complicated series of async tasks using the auto function makes adding\nnew tasks much easier and makes the code more readable.\n\n\n---------------------------------------\n\n<a name=\"iterator\" />\n### iterator(tasks)\n\nCreates an iterator function which calls the next function in the array,\nreturning a continuation to call the next one after that. It's also possible to\n'peek' the next iterator by doing iterator.next().\n\nThis function is used internally by the async module but can be useful when\nyou want to manually control the flow of functions in series.\n\n__Arguments__\n\n* tasks - An array of functions to run.\n\n__Example__\n\n```js\nvar iterator = async.iterator([\n    function(){ sys.p('one'); },\n    function(){ sys.p('two'); },\n    function(){ sys.p('three'); }\n]);\n\nnode> var iterator2 = iterator();\n'one'\nnode> var iterator3 = iterator2();\n'two'\nnode> iterator3();\n'three'\nnode> var nextfn = iterator2.next();\nnode> nextfn();\n'three'\n```\n\n---------------------------------------\n\n<a name=\"apply\" />\n### apply(function, arguments..)\n\nCreates a continuation function with some arguments already applied, a useful\nshorthand when combined with other control flow functions. Any arguments\npassed to the returned function are added to the arguments originally passed\nto apply.\n\n__Arguments__\n\n* function - The function you want to eventually apply all arguments to.\n* arguments... - Any number of arguments to automatically apply when the\n  continuation is called.\n\n__Example__\n\n```js\n// using apply\n\nasync.parallel([\n    async.apply(fs.writeFile, 'testfile1', 'test1'),\n    async.apply(fs.writeFile, 'testfile2', 'test2'),\n]);\n\n\n// the same process without using apply\n\nasync.parallel([\n    function(callback){\n        fs.writeFile('testfile1', 'test1', callback);\n    },\n    function(callback){\n        fs.writeFile('testfile2', 'test2', callback);\n    }\n]);\n```\n\nIt's possible to pass any number of additional arguments when calling the\ncontinuation:\n\n```js\nnode> var fn = async.apply(sys.puts, 'one');\nnode> fn('two', 'three');\none\ntwo\nthree\n```\n\n---------------------------------------\n\n<a name=\"nextTick\" />\n### nextTick(callback)\n\nCalls the callback on a later loop around the event loop. In node.js this just\ncalls process.nextTick, in the browser it falls back to setImmediate(callback)\nif available, otherwise setTimeout(callback, 0), which means other higher priority\nevents may precede the execution of the callback.\n\nThis is used internally for browser-compatibility purposes.\n\n__Arguments__\n\n* callback - The function to call on a later loop around the event loop.\n\n__Example__\n\n```js\nvar call_order = [];\nasync.nextTick(function(){\n    call_order.push('two');\n    // call_order now equals ['one','two']\n});\ncall_order.push('one')\n```\n\n<a name=\"times\" />\n### times(n, callback)\n\nCalls the callback n times and accumulates results in the same manner\nyou would use with async.map.\n\n__Arguments__\n\n* n - The number of times to run the function.\n* callback - The function to call n times.\n\n__Example__\n\n```js\n// Pretend this is some complicated async factory\nvar createUser = function(id, callback) {\n  callback(null, {\n    id: 'user' + id\n  })\n}\n// generate 5 users\nasync.times(5, function(n, next){\n    createUser(n, function(err, user) {\n      next(err, user)\n    })\n}, function(err, users) {\n  // we should now have 5 users\n});\n```\n\n<a name=\"timesSeries\" />\n### timesSeries(n, callback)\n\nThe same as times only the iterator is applied to each item in the array in\nseries. The next iterator is only called once the current one has completed\nprocessing. The results array will be in the same order as the original.\n\n\n## Utils\n\n<a name=\"memoize\" />\n### memoize(fn, [hasher])\n\nCaches the results of an async function. When creating a hash to store function\nresults against, the callback is omitted from the hash and an optional hash\nfunction can be used.\n\nThe cache of results is exposed as the `memo` property of the function returned\nby `memoize`.\n\n__Arguments__\n\n* fn - the function you to proxy and cache results from.\n* hasher - an optional function for generating a custom hash for storing\n  results, it has all the arguments applied to it apart from the callback, and\n  must be synchronous.\n\n__Example__\n\n```js\nvar slow_fn = function (name, callback) {\n    // do something\n    callback(null, result);\n};\nvar fn = async.memoize(slow_fn);\n\n// fn can now be used as if it were slow_fn\nfn('some name', function () {\n    // callback\n});\n```\n\n<a name=\"unmemoize\" />\n### unmemoize(fn)\n\nUndoes a memoized function, reverting it to the original, unmemoized\nform. Comes handy in tests.\n\n__Arguments__\n\n* fn - the memoized function\n\n<a name=\"log\" />\n### log(function, arguments)\n\nLogs the result of an async function to the console. Only works in node.js or\nin browsers that support console.log and console.error (such as FF and Chrome).\nIf multiple arguments are returned from the async function, console.log is\ncalled on each argument in order.\n\n__Arguments__\n\n* function - The function you want to eventually apply all arguments to.\n* arguments... - Any number of arguments to apply to the function.\n\n__Example__\n\n```js\nvar hello = function(name, callback){\n    setTimeout(function(){\n        callback(null, 'hello ' + name);\n    }, 1000);\n};\n```\n```js\nnode> async.log(hello, 'world');\n'hello world'\n```\n\n---------------------------------------\n\n<a name=\"dir\" />\n### dir(function, arguments)\n\nLogs the result of an async function to the console using console.dir to\ndisplay the properties of the resulting object. Only works in node.js or\nin browsers that support console.dir and console.error (such as FF and Chrome).\nIf multiple arguments are returned from the async function, console.dir is\ncalled on each argument in order.\n\n__Arguments__\n\n* function - The function you want to eventually apply all arguments to.\n* arguments... - Any number of arguments to apply to the function.\n\n__Example__\n\n```js\nvar hello = function(name, callback){\n    setTimeout(function(){\n        callback(null, {hello: name});\n    }, 1000);\n};\n```\n```js\nnode> async.dir(hello, 'world');\n{hello: 'world'}\n```\n\n---------------------------------------\n\n<a name=\"noConflict\" />\n### noConflict()\n\nChanges the value of async back to its original value, returning a reference to the\nasync object.\n",
                  "readmeFilename": "README.md",
                  "_id": "async@0.2.9",
                  "_from": "async@~0.2.7"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                },
                "package.json": {
                  "name": "async",
                  "description": "Higher-order functions and common patterns for asynchronous code",
                  "version": "0.2.9",
                  "locator": {
                    "pointer": "~0.2.7"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/caolan/async/issues"
                    }
                  },
                  "repositories": [
                    {
                      "type": "git",
                      "url": "https://github.com/caolan/async.git"
                    }
                  ],
                  "dependencies": {
                    "development": {
                      "nodeunit": ">0.0.0",
                      "uglify-js": "1.2.x",
                      "nodelint": ">0.0.0"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "nodeunit test/test-async.js"
                    },
                    "main": "./lib/async.js"
                  },
                  "licenses": [
                    {
                      "type": "MIT",
                      "url": "https://github.com/caolan/async/raw/master/LICENSE"
                    }
                  ],
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Caolan McMahon"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "async",
                "description": "Higher-order functions and common patterns for asynchronous code",
                "version": "0.2.9",
                "locator": {
                  "pointer": "~0.2.7"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/caolan/async/issues"
                  }
                },
                "repositories": [
                  {
                    "type": "git",
                    "url": "https://github.com/caolan/async.git"
                  }
                ],
                "dependencies": {
                  "development": {
                    "nodeunit": ">0.0.0",
                    "uglify-js": "1.2.x",
                    "nodelint": ">0.0.0"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "nodeunit test/test-async.js"
                  },
                  "main": "./lib/async.js"
                },
                "licenses": [
                  {
                    "type": "MIT",
                    "url": "https://github.com/caolan/async/raw/master/LICENSE"
                  }
                ],
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Caolan McMahon"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [
                [
                  "normalize",
                  "Property 'jam' was ignored",
                  "descriptor",
                  "package.json"
                ]
              ],
              "errors": [],
              "memoized": {
                "main": "257a70b6290719603e5079400727f3d2d2d1b03a-async/lib/async.js",
                "dirpath": "node_modules/request/node_modules/form-data/node_modules/async"
              }
            },
            "wrapper": "json"
          },
          "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/package.json": {
            "requireId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/package.json",
            "memoizeId": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/package.json",
            "descriptor": {
              "dirpath": "node_modules/request/node_modules/cookie-jar",
              "dirrealpath": "node_modules/request/node_modules/cookie-jar",
              "id": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar",
              "lookupPaths": [
                "node_modules/request/node_modules/cookie-jar/package.json",
                "node_modules/request/node_modules/cookie-jar/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/request/node_modules/cookie-jar/package.json"
              ],
              "raw": {
                "package.json": {
                  "author": {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  },
                  "name": "cookie-jar",
                  "description": "Cookie Jar. Originally pulled form tobi, maintained as vendor in request, now a standalone module.",
                  "version": "0.3.0",
                  "repository": {
                    "url": "https://github.com/mikeal/cookie-jar"
                  },
                  "main": "index.js",
                  "scripts": {
                    "test": "node tests/run.js"
                  },
                  "dependencies": {},
                  "devDependencies": {},
                  "optionalDependencies": {},
                  "engines": {
                    "node": "*"
                  },
                  "readme": "cookie-jar\n==========\n\nCookie Jar. Originally pulled from LearnBoost/tobi, maintained as vendor in request, now a standalone module.\n",
                  "readmeFilename": "README.md",
                  "bugs": {
                    "url": "https://github.com/mikeal/cookie-jar/issues"
                  },
                  "_id": "cookie-jar@0.3.0",
                  "_from": "cookie-jar@~0.3.0"
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "exports": {
                    "main": "./index.js"
                  }
                },
                "package.json": {
                  "name": "cookie-jar",
                  "description": "Cookie Jar. Originally pulled form tobi, maintained as vendor in request, now a standalone module.",
                  "version": "0.3.0",
                  "locator": {
                    "pointer": "~0.3.0"
                  },
                  "social": {
                    "bugs": {
                      "url": "https://github.com/mikeal/cookie-jar/issues"
                    }
                  },
                  "repositories": [
                    {
                      "url": "https://github.com/mikeal/cookie-jar"
                    }
                  ],
                  "requirements": {
                    "engines": {
                      "node": "*"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "node tests/run.js"
                    },
                    "main": "./index.js"
                  },
                  "files": {
                    "readme": "./README.md"
                  },
                  "contributors": [
                    {
                      "name": "Mikeal Rogers",
                      "email": "mikeal.rogers@gmail.com",
                      "url": "http://www.futurealoof.com"
                    }
                  ],
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  }
                }
              },
              "combined": {
                "name": "cookie-jar",
                "description": "Cookie Jar. Originally pulled form tobi, maintained as vendor in request, now a standalone module.",
                "version": "0.3.0",
                "locator": {
                  "pointer": "~0.3.0"
                },
                "social": {
                  "bugs": {
                    "url": "https://github.com/mikeal/cookie-jar/issues"
                  }
                },
                "repositories": [
                  {
                    "url": "https://github.com/mikeal/cookie-jar"
                  }
                ],
                "requirements": {
                  "engines": {
                    "node": "*"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "node tests/run.js"
                  },
                  "main": "./index.js"
                },
                "files": {
                  "readme": "./README.md"
                },
                "contributors": [
                  {
                    "name": "Mikeal Rogers",
                    "email": "mikeal.rogers@gmail.com",
                    "url": "http://www.futurealoof.com"
                  }
                ],
                "pm": {
                  "install": "npm"
                },
                "layout": {
                  "directories": {
                    "dependency": "./node_modules"
                  }
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "96d6c97b8f07f8f227fbeb5b214187b162ad8c7c-cookie-jar/index.js",
                "dirpath": "node_modules/request/node_modules/cookie-jar"
              }
            },
            "wrapper": "json"
          },
          "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/package.json": {
            "requireId": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/package.json",
            "memoizeId": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/package.json",
            "descriptor": {
              "dirpath": "node_modules/pinf-loader-js",
              "dirrealpath": "../github.com~pinf~pinf-loader-js",
              "id": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js",
              "lookupPaths": [
                "node_modules/pinf-loader-js/package.json",
                "node_modules/pinf-loader-js/.package.json"
              ],
              "descriptorPaths": [
                "node_modules/pinf-loader-js/package.json"
              ],
              "raw": {
                "package.json": {
                  "uid": "https://github.com/pinf/pinf-loader-js/",
                  "name": "pinf-loader-js",
                  "version": "0.4.5",
                  "pm": "npm",
                  "publish": true,
                  "main": "./loader.js",
                  "directories": {
                    "lib": "./"
                  },
                  "devDependencies": {
                    "fs-extra": "~0.6.0",
                    "request": "~2.16.6",
                    "mocha": "~1.9.0",
                    "grunt": "~0.4.1",
                    "grunt-mocha": "~0.3.1",
                    "grunt-saucelabs": "~4.1.2",
                    "istanbul": "~0.1.44",
                    "coveralls": "~2.3.0"
                  },
                  "scripts": {
                    "test": "make test"
                  },
                  "overrides": {
                    "./node_modules/request/node_modules/hawk/node_modules/boom": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/form-data": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    }
                  }
                }
              },
              "normalized": {
                ".package.json": {
                  "pm": {
                    "install": "npm"
                  },
                  "layout": {
                    "directories": {
                      "dependency": "./node_modules"
                    }
                  },
                  "dependencies": {
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "coveralls": "./node_modules/coveralls",
                      "fs-extra": "./node_modules/fs-extra",
                      "grunt": "./node_modules/grunt",
                      "grunt-mocha": "./node_modules/grunt-mocha",
                      "grunt-saucelabs": "./node_modules/grunt-saucelabs",
                      "istanbul": "./node_modules/istanbul",
                      "mocha": "./node_modules/mocha",
                      "request": "./node_modules/request"
                    }
                  },
                  "mappings": {
                    ".bin": "dccbee6c64674100a7f8864eb8a4e5a04f47089f-.bin",
                    "coveralls": "4505fc61df8557102611709b19679fb3e28201b8-coveralls",
                    "fs-extra": "b4d8d407b59ce4079481a01da21bfefc9a119dee-fs-extra",
                    "grunt": "35c48ebb18769c6d005634ebd25c0087afe0a63b-grunt",
                    "grunt-mocha": "20b4b293b8d3c5a0697c900325122703f7389262-grunt-mocha",
                    "grunt-saucelabs": "5675c42b45e03381f74df2497be009dcce061e35-grunt-saucelabs",
                    "istanbul": "fdbe87a2bfacae8e9cd09ab7c0e892640f238275-istanbul",
                    "mocha": "241cf3bd47a5a2bff3a94431f504090d1025184d-mocha",
                    "request": "f984e602d5c47a9b77686fb51b6bad41eeb94807-request"
                  }
                },
                "package.json": {
                  "uid": "https://github.com/pinf/pinf-loader-js/",
                  "name": "pinf-loader-js",
                  "version": "0.4.5",
                  "pm": {
                    "install": "npm"
                  },
                  "dependencies": {
                    "development": {
                      "fs-extra": "~0.6.0",
                      "request": "~2.16.6",
                      "mocha": "~1.9.0",
                      "grunt": "~0.4.1",
                      "grunt-mocha": "~0.3.1",
                      "grunt-saucelabs": "~4.1.2",
                      "istanbul": "~0.1.44",
                      "coveralls": "~2.3.0"
                    },
                    "bundled": {
                      ".bin": "./node_modules/.bin",
                      "coveralls": "./node_modules/coveralls",
                      "fs-extra": "./node_modules/fs-extra",
                      "grunt": "./node_modules/grunt",
                      "grunt-mocha": "./node_modules/grunt-mocha",
                      "grunt-saucelabs": "./node_modules/grunt-saucelabs",
                      "istanbul": "./node_modules/istanbul",
                      "mocha": "./node_modules/mocha",
                      "request": "./node_modules/request"
                    }
                  },
                  "exports": {
                    "scripts": {
                      "test": "make test"
                    },
                    "main": "./loader.js"
                  },
                  "overrides": {
                    "./node_modules/request/node_modules/hawk/node_modules/boom": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    },
                    "./node_modules/request/node_modules/form-data": {
                      "descriptor": {
                        "config": {
                          "pinf/0/bundler/options/0": {
                            "mapParentSiblingPackages": 2
                          }
                        }
                      }
                    }
                  },
                  "events": {
                    "publish": true
                  },
                  "layout": {
                    "directories": {
                      "lib": ".",
                      "dependency": "./node_modules"
                    }
                  },
                  "mappings": {
                    ".bin": "dccbee6c64674100a7f8864eb8a4e5a04f47089f-.bin",
                    "coveralls": "4505fc61df8557102611709b19679fb3e28201b8-coveralls",
                    "fs-extra": "b4d8d407b59ce4079481a01da21bfefc9a119dee-fs-extra",
                    "grunt": "35c48ebb18769c6d005634ebd25c0087afe0a63b-grunt",
                    "grunt-mocha": "20b4b293b8d3c5a0697c900325122703f7389262-grunt-mocha",
                    "grunt-saucelabs": "5675c42b45e03381f74df2497be009dcce061e35-grunt-saucelabs",
                    "istanbul": "fdbe87a2bfacae8e9cd09ab7c0e892640f238275-istanbul",
                    "mocha": "241cf3bd47a5a2bff3a94431f504090d1025184d-mocha",
                    "request": "f984e602d5c47a9b77686fb51b6bad41eeb94807-request"
                  }
                }
              },
              "combined": {
                "uid": "https://github.com/pinf/pinf-loader-js/",
                "name": "pinf-loader-js",
                "version": "0.4.5",
                "pm": {
                  "install": "npm"
                },
                "dependencies": {
                  "development": {
                    "fs-extra": "~0.6.0",
                    "request": "~2.16.6",
                    "mocha": "~1.9.0",
                    "grunt": "~0.4.1",
                    "grunt-mocha": "~0.3.1",
                    "grunt-saucelabs": "~4.1.2",
                    "istanbul": "~0.1.44",
                    "coveralls": "~2.3.0"
                  },
                  "bundled": {
                    ".bin": "./node_modules/.bin",
                    "coveralls": "./node_modules/coveralls",
                    "fs-extra": "./node_modules/fs-extra",
                    "grunt": "./node_modules/grunt",
                    "grunt-mocha": "./node_modules/grunt-mocha",
                    "grunt-saucelabs": "./node_modules/grunt-saucelabs",
                    "istanbul": "./node_modules/istanbul",
                    "mocha": "./node_modules/mocha",
                    "request": "./node_modules/request"
                  }
                },
                "exports": {
                  "scripts": {
                    "test": "make test"
                  },
                  "main": "./loader.js"
                },
                "overrides": {
                  "./node_modules/request/node_modules/hawk/node_modules/boom": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/hawk/node_modules/sntp": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/hawk/node_modules/cryptiles": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  },
                  "./node_modules/request/node_modules/form-data": {
                    "descriptor": {
                      "config": {
                        "pinf/0/bundler/options/0": {
                          "mapParentSiblingPackages": 2
                        }
                      }
                    }
                  }
                },
                "events": {
                  "publish": true
                },
                "layout": {
                  "directories": {
                    "lib": ".",
                    "dependency": "./node_modules"
                  }
                },
                "mappings": {
                  ".bin": "dccbee6c64674100a7f8864eb8a4e5a04f47089f-.bin",
                  "coveralls": "4505fc61df8557102611709b19679fb3e28201b8-coveralls",
                  "fs-extra": "b4d8d407b59ce4079481a01da21bfefc9a119dee-fs-extra",
                  "grunt": "35c48ebb18769c6d005634ebd25c0087afe0a63b-grunt",
                  "grunt-mocha": "20b4b293b8d3c5a0697c900325122703f7389262-grunt-mocha",
                  "grunt-saucelabs": "5675c42b45e03381f74df2497be009dcce061e35-grunt-saucelabs",
                  "istanbul": "fdbe87a2bfacae8e9cd09ab7c0e892640f238275-istanbul",
                  "mocha": "241cf3bd47a5a2bff3a94431f504090d1025184d-mocha",
                  "request": "f984e602d5c47a9b77686fb51b6bad41eeb94807-request"
                }
              },
              "warnings": [],
              "errors": [],
              "memoized": {
                "main": "46436413248440678ad5c9378e5dd00081b623bd-pinf-loader-js/loader.js",
                "directories": {
                  "lib": "."
                },
                "dirpath": "node_modules/pinf-loader-js"
              }
            },
            "wrapper": "json"
          }
        },
        "expectExistingModules": {},
        "bundle": {
          "path": "/Volumes/Ginseng-Independence-Desktop/ginseng-source/projects/github.com+pinf+pinf-for-nodejs/bundles/lib/loader.js"
        },
        "warnings": [],
        "errors": [],
        "id": "/lib/loader.js"
      }
    },
    "warnings": [],
    "errors": [],
    "exports": {
      "main": "/lib/loader.js"
    }
  },
  "#pinf": {
    "status": 200,
    "data": {
      "rootBundlePath": "/Volumes/Ginseng-Independence-Desktop/ginseng-source/projects/github.com+pinf+pinf-for-nodejs/bundles/lib/loader.js"
    }
  }
}